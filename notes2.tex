\documentclass[numbers=enddot,12pt,final,onecolumn,notitlepage]{scrartcl}%
\usepackage[headsepline,footsepline,manualmark]{scrlayer-scrpage}
\usepackage[all,cmtip]{xy}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{framed}
\usepackage{comment}
\usepackage{color}
\usepackage{hyperref}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{tikz}
\usepackage{needspace}
\usepackage{tabls}
\usepackage{wasysym}
%TCIDATA{OutputFilter=latex2.dll}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{LastRevised=Friday, April 19, 2019 12:05:32}
%TCIDATA{SuppressPackageManagement}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%TCIDATA{Language=American English}
%BeginMSIPreambleData
\providecommand{\U}[1]{\protect\rule{.1in}{.1in}}
%EndMSIPreambleData
\usetikzlibrary{arrows}
\newcounter{exer}
\newcounter{exera}
\numberwithin{exer}{subsection}
\theoremstyle{definition}
\newtheorem{theo}{Theorem}[subsection]
\newenvironment{theorem}[1][]
{\begin{theo}[#1]\begin{leftbar}}
{\end{leftbar}\end{theo}}
\newtheorem{lem}[theo]{Lemma}
\newenvironment{lemma}[1][]
{\begin{lem}[#1]\begin{leftbar}}
{\end{leftbar}\end{lem}}
\newtheorem{prop}[theo]{Proposition}
\newenvironment{proposition}[1][]
{\begin{prop}[#1]\begin{leftbar}}
{\end{leftbar}\end{prop}}
\newtheorem{defi}[theo]{Definition}
\newenvironment{definition}[1][]
{\begin{defi}[#1]\begin{leftbar}}
{\end{leftbar}\end{defi}}
\newtheorem{remk}[theo]{Remark}
\newenvironment{remark}[1][]
{\begin{remk}[#1]\begin{leftbar}}
{\end{leftbar}\end{remk}}
\newtheorem{coro}[theo]{Corollary}
\newenvironment{corollary}[1][]
{\begin{coro}[#1]\begin{leftbar}}
{\end{leftbar}\end{coro}}
\newtheorem{conv}[theo]{Convention}
\newenvironment{convention}[1][]
{\begin{conv}[#1]\begin{leftbar}}
{\end{leftbar}\end{conv}}
\newtheorem{quest}[theo]{Question}
\newenvironment{question}[1][]
{\begin{quest}[#1]\begin{leftbar}}
{\end{leftbar}\end{quest}}
\newtheorem{warn}[theo]{Warning}
\newenvironment{conclusion}[1][]
{\begin{warn}[#1]\begin{leftbar}}
{\end{leftbar}\end{warn}}
\newtheorem{conj}[theo]{Conjecture}
\newenvironment{conjecture}[1][]
{\begin{conj}[#1]\begin{leftbar}}
{\end{leftbar}\end{conj}}
\newtheorem{exam}[theo]{Example}
\newenvironment{example}[1][]
{\begin{exam}[#1]\begin{leftbar}}
{\end{leftbar}\end{exam}}
\newtheorem{exmp}[exer]{Exercise}
\newenvironment{exercise}[1][]
{\begin{exmp}[#1]\begin{leftbar}}
{\end{leftbar}\end{exmp}}
\newenvironment{statement}{\begin{quote}}{\end{quote}}
\newenvironment{fineprint}{\begin{small}}{\end{small}}
\iffalse
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\newenvironment{question}[1][Question]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\newenvironment{teachingnote}[1][Teaching note]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\fi
\let\sumnonlimits\sum
\let\prodnonlimits\prod
\let\cupnonlimits\bigcup
\let\capnonlimits\bigcap
\renewcommand{\sum}{\sumnonlimits\limits}
\renewcommand{\prod}{\prodnonlimits\limits}
\renewcommand{\bigcup}{\cupnonlimits\limits}
\renewcommand{\bigcap}{\capnonlimits\limits}
\setlength\tablinesep{3pt}
\setlength\arraylinesep{3pt}
\setlength\extrarulesep{3pt}
\voffset=0cm
\hoffset=-0.7cm
\setlength\textheight{22.5cm}
\setlength\textwidth{15.5cm}
\newcommand\arxiv[1]{\href{http://www.arxiv.org/abs/#1}{\texttt{arXiv:#1}}}
\newenvironment{verlong}{}{}
\newenvironment{vershort}{}{}
\newenvironment{noncompile}{}{}
\newenvironment{teachingnote}{}{}
\excludecomment{verlong}
\includecomment{vershort}
\excludecomment{noncompile}
\excludecomment{teachingnote}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\KK}{\mathbb{K}}
\newcommand{\id}{\operatorname{id}}
\newcommand{\lcm}{\operatorname{lcm}}
\newcommand{\rev}{\operatorname{rev}}
\newcommand{\powset}[2][]{\ifthenelse{\equal{#2}{}}{\mathcal{P}\left(#1\right)}{\mathcal{P}_{#1}\left(#2\right)}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\tup}[1]{\left( #1 \right)}
\newcommand{\ive}[1]{\left[ #1 \right]}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\lf}[2]{#1^{\underline{#2}}}
\newcommand{\underbrack}[2]{\underbrace{#1}_{\substack{#2}}}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}
\newcommand{\nnn}{\nonumber\\}
\newcommand{\sslash}{\mathbin{/\mkern-6mu/}}
\ihead{Math 4281 notes}
\ohead{page \thepage}
\cfoot{}
\begin{document}

\title{UMN Spring 2019 Math 4281 notes}
\author{Darij Grinberg}
\date{
%TCIMACRO{\TeXButton{today}{\today} }%
%BeginExpansion
\today
%EndExpansion
}
\maketitle
\tableofcontents

\section{Introduction}

This file will contain the notes from the Math 4281 class (``Introduction to
Modern Algebra'') I am teaching at UMN in Spring 2019. I will type the first
draft directly in the classroom, and subsequently expand it into proper
writing. Occasionally, I will also add extra sections not covered in class.

The website of the class is
\url{http://www-users.math.umn.edu/~dgrinber/19s/index.html} ; you will find
homework sets there.

\subsection{Organisation}

See \href{http://www-users.math.umn.edu/~dgrinber/19s/syll.pdf}{the syllabus}
for the organization of this class and for the homework.

\subsection{Literature}

Many books have been written about abstract algebra. I have only a passing
familiarity with most of them. Some of the ``bibles'' of the subject (bulky
texts covering lots of material) are Dummit/Foote \cite{Dummit-Foote}, Knapp
\cite{Knapp1} and \cite{Knapp2} (both freely available), van der Waerden
\cite{Waerden1} and \cite{Waerden2} (one of the oldest texts on modern
algebra, thus rather dated, but still as readable as ever).
%Two other textbooks are Bosch \cite{Bosch} and Artin \cite{Artin}.


Of course, any book longer than 200 pages likely goes further than our course
will (unless it is full of details or solved exercises or printed in really
large letters). Thus, let me recommend some more introductory sources.
Siksek's lecture notes \cite{Siksek} are a readable introduction that is a lot
more amusing than I had ever expected an algebra text to be. Goodman's free
book \cite{Goodman} combines introductory material with geometric motivation
and applications, such as the classification of regular polyhedra and
2-dimensional crystals. In a sense, it is a great complement to our
ungeometric course. Pinter's \cite{Pinter} often gets used in classes like
ours. Armstrong's notes \cite{Armstrong} cover a significant part of what we
do (and he will likely have notes for a second course written up by the end of
this semester). Childs's \cite{Childs00} comes the closest to what we are
setting out to do here, that is, give an example-grounded introduction to
basic abstract algebra.

Keith Conrad's blurbs \cite{Conrad*} are not a book, as they only cover
selected topics. But at pretty much every topic they cover, they are one of
the best sources (clear, full of examples, and often going fairly deep). We
shall follow one of them particularly closely: the one on Gaussian integers
\cite{Conrad-Gauss}.

We will use some basic linear algebra, all of which can be found in Hefferon's
book \cite{Hefferon} (but we won't need all of this book). As far as
determinants are concerned, we will briefly build up their theory; we refer to
\cite[Section 12 \& Appendix B]{Strickland} for proofs (and to \cite[Chapter
6]{detnotes} for a really detailed and formal treatment).

This course will begin (after some motivating questions) with a survey of
elementary number theory. This is in itself a deep subject (despite the name)
with a long history (\href{https://en.wikipedia.org/wiki/Plimpton_322}{perhaps
as old as mathematics}), and of course we will just scratch the surface. Books
like \cite{NiZuMo91}, \cite{Burton} and \cite{Uspensky-Heaslet} cover a lot
more than we can do. The Gallier/Quaintance survey \cite{Gallier-RSA} covers a
good amount of basics and more.

We assume that the reader is familiar with the commonplaces of mathematical
argumentation, such as induction (including strong induction),
\textquotedblleft WLOG\textquotedblright\ arguments, proof by contradiction,
summation signs ($\sum$) and polynomials (a vague notion of polynomials will
suffice; we will give a precise definition when it becomes necessary). If not,
several texts can be helpful in achieving such familiarity: e.g.,
\cite[particularly Chapters 1--5]{LeLeMe}, \cite{Hammack}, \cite{Day}.

I thank the students of the Math 4281 class for discovering and reporting
errors in previous versions of these notes. Some of the discussion of variants
of Gaussian integers (and the occasional correction) is due to Keith Conrad;
the discussion of Gaussian integers itself owes much to his
\cite{Conrad-Gauss}.

These notes include some excerpts from \cite{floor} and slightly rewritten
sections of \cite{detnotes}.

\begin{center}
\textbf{2019-01-23 lecture}
\end{center}

\subsection{The plan}

The material I am going to cover is mostly standard. However, the order in
which I will go through it is somewhat unusual: I will spend a lot of time
studying the basic examples before defining abstract notions such as
``group'', ``monoid'', ``ring'' and ``field''. This way, once I come to these
notions, you'll already have many examples to work with. (Don't be fooled by
the word ``example'': We will prove a lot about them, much of which is neither
straightforward nor easy.)

First, I will show some motivating questions that are easy to state yet
require abstract algebra to answer. We will hopefully see their answers by the
end of this class. (Some of them can also be answered elementarily, without
using abstract algebra, but such answers usually take more work and are harder
to find.)

\subsection{\label{sect.intro.sum-of-2sq}Motivation: $n=x^{2}+y^{2}$}

A \textit{perfect square} means the square of an integer. Thus, the perfect
squares are
\[
0^{2} = 0, \qquad1^{2} = 1, \qquad2^{2} = 4, \qquad3^{2} = 9, \qquad4^{2} =
16, \qquad\ldots.
\]


Here is an old problem (first solved by Pierre de Fermat in 1640, but
apparently already studied by Diophantus in the 3rd Century):

\begin{question}
\label{quest.intro.sum-of-2sq.1} What integers can be written as sums of two
perfect squares?
\end{question}

For example, $5$ can be written in this way, since $5=2^{2}+1^{2}$.

So can $4$, since $4=2^{2}+0^{2}$. (Keep in mind that $0$ is a perfect square.)

However, $7$ cannot be written in this way. In fact, if we had $7 = a^{2} +
b^{2}$ for two integers $a$ and $b$, then $a^{2}$ and $b^{2}$ would have to be
$\leq7$ (since $a^{2}$ and $b^{2}$ are always $\geq0$, no matter what sign $a$
and $b$ have); but the only perfect squares that are $\leq7$ are $0,1,4$, and
there is no way to write $7$ as a sum of two of these perfect squares (just
check all the possibilities).

For a similar but simpler reason, no negative number can be written as a sum
of two perfect squares.

We can of course approach Question~\ref{quest.intro.sum-of-2sq.1} using a
computer: It is easy to check, for a given integer $n$, whether $n$ is a sum
of two perfect squares. (Just check all possibilities for $a$ and $b$ for the
validity of the equation $n=a^{2}+b^{2}$. You only need to try $a$ and $b$
belonging to $\left\{  0,1,\ldots,\left\lfloor \sqrt{n}\right\rfloor \right\}
$, where $\left\lfloor y\right\rfloor $ (for a real number $y$) denotes the
largest integer that is less or equal than $y$ (also known as
\textquotedblleft$y$ rounded down\textquotedblright).) If you do this, you
will see that among the first $101$ nonnegative integers, the ones that can be
written as sums of two perfect squares are precisely
\begin{align*}
&  0,1,2,4,5,8,9,10,13,16,17,18,20,25,26,29,\\
&  32,34,36,37,40,41,45,49,50,52,53,58,61,64,\\
&  65,68,72,73,74,80,81,82,85,89,90,97,98,100.
\end{align*}
Having this data, you can look up the sequence in \href{https://oeis.org/}{the
Online Encyclopedia of Integer Sequences (short OEIS)}, and see that the
sequence of these integers is known as \href{https://oeis.org/A001481}{OEIS
Sequence A001481}. In the \textquotedblleft Comments\textquotedblright\ field,
you can read a lot of what is known about it (albeit in telegraphic style).

For example, one of the comments says ``Closed under multiplication''. This is
short for ``if you multiply two entries of the sequence, then the product will
again be an entry of the sequence''. In other words, if you multiply two
integers that are sums of two perfect squares, then you get another sum of two
perfect squares. Why is this so?

It turns out that there is a \textquotedblleft simple\textquotedblright%
\ reason for this: the identity
\begin{equation}
\left(  a^{2}+b^{2}\right)  \left(  c^{2}+d^{2}\right)  =\left(  ad+bc\right)
^{2}+\left(  ac-bd\right)  ^{2}, \label{eq.intro.sum-of-2sq.sum*sum}%
\end{equation}
which holds for arbitrary reals $a,b,c,d$ (and thus, in particular, for
integers). This is known as
\href{https://en.wikipedia.org/wiki/Brahmagupta-Fibonacci_identity}{the
Brahmagupta-Fibonacci identity}, and of course can easily be proven by
expanding both sides. But how would you come up with such an identity?

If you stare at the above sequence long enough, you may also discover another
pattern: An integer of the form $4k+3$ with integer $k$ (that is, an integer
that is larger by $3$ than a multiple of $4$) can never be written as a sum of
two perfect squares. (Thus, $3,7,11,15,19,23,\ldots$ cannot be written in this
way.) This does not account for all integers that cannot be written in this
way, but it does provide some clues to the answer that we will later see. In
order to prove this observation, we shall need basic modular arithmetic (or at
least division with remainder); we will see this proof very soon (see Exercise
\ref{exe.ent.even-odd-sumsq} \textbf{(c)}).

We will resolve Question \ref{quest.intro.sum-of-2sq.1} using the theory of
Gaussian integers in Chapter \ref{chp.CC}. For a survey of different
approaches to Question \ref{quest.intro.sum-of-2sq.1} (including a full answer
using finite fields), see \cite[Chapter 4]{AigZie}.

Further questions can be asked. One of them is: Given an integer $n$, how many
ways are there to represent $n$ as a sum of two perfect squares? This is
actually several questions masquerading as one, since it is not so clear what
a ``way'' is. Do $5 = 1^{2} + 2^{2}$ and $5 = 2^{2} + 1^{2}$ count as two
different ways? What about $5 = 1^{2} + 2^{2}$ versus $5 = \left(  -1 \right)
^{2} + 2^{2}$ (here, the perfect squares are the same, but do we really want
to count the squares or rather the numbers we are squaring?).

Let me formalize the question as follows:

\begin{question}
\label{quest.intro.sum-of-2sq.2} Let $n$ be an integer.

\textbf{(a)} How many pairs $\left(  a, b \right)  \in\mathbb{N}^{2}$ are
there that satisfy $n = a^{2} + b^{2}$ ? Here, and in the following,
$\mathbb{N}$ denotes the set $\left\{  0, 1, 2, \ldots\right\}  $ of all
nonnegative integers.

\textbf{(b)} How many pairs $\left(  a, b \right)  \in\mathbb{Z}^{2}$ are
there that satisfy $n = a^{2} + b^{2}$ ? Here, and in the following,
$\mathbb{Z}$ denotes the set $\left\{  \ldots, -2, -1, 0, 1, 2, \ldots
\right\}  $ of all integers.

\textbf{(c)} How do these counts change if we count \textbf{unordered} pairs
instead (i.e., count $\left(  a, b \right)  $ and $\left(  b, a \right)  $ as
one only)?
\end{question}

Note that when I say ``pair'', I always mean ``ordered pair'' by default,
unless I explicitly say ``unordered pair''.

Again, a little bit of programming easily yields answers to all three parts of
this question for small values of $n$, and the resulting data can be plugged
into the OEIS and yields lots of information.

\begin{proof}
[First steps toward answering Question~\ref{quest.intro.sum-of-2sq.2}%
.]\textbf{(a)} I claim that the number of such pairs is even unless $n$ is
twice a perfect square (i.e., unless $n = 2m^{2}$ for some integer $m$); in
the latter case, this number is odd instead.

Why? Let me define a \textit{solution} to be a pair $\left(  a,b\right)  $
such that $n=a^{2}+b^{2}$. So I want to know whether the number of solutions
is even or odd. But we have $a^{2}+b^{2}=b^{2}+a^{2}$ for all $a$ and $b$.
Thus, if $\left(  a,b\right)  $ is a solution, then so is $\left(  b,a\right)
$. Hence, the solutions themselves \textquotedblleft come in
pairs\textquotedblright, with each solution $\left(  a,b\right)  $ being
matched to the solution $\left(  b,a\right)  $, unless there is a solution
$\left(  a,b\right)  $ with $a=b$ (because such a solution would be matched to
itself, and thus not form an actual pair). But solutions $\left(  a,b\right)
$ with $a=b$ are easy to classify: If $n$ is twice a perfect square, then
there is exactly one such solution (namely, $\left(  \sqrt{n/2},\sqrt
{n/2}\right)  $); otherwise there is none (because $n=a^{2}+b^{2}$ with $a=b$
leads to $n=b^{2}+b^{2}=2b^{2}$, which can only happen when $n$ is twice a
perfect square). Since we know that all the other solutions \textquotedblleft
come in pairs\textquotedblright, we thus conclude that the number of solutions
is odd if $n$ is twice a perfect square and even otherwise. This proves our claim.

Of course, we have not made much headway into
Question~\ref{quest.intro.sum-of-2sq.2}; knowing whether a number is even or
odd is far from knowing the number itself. But I think the argument above was
worth showing; similar reasoning is used a lot in algebra.

\textbf{(b)} By reasoning analogous to the one we used in part \textbf{(a)},
we can see that the number of such pairs will be divisible by $8$ whenever $n$
is neither a perfect square nor twice a perfect square. Indeed, this relies on
the fact that
\begin{align*}
a^{2} + b^{2}  &  = b^{2} + a^{2} = \left(  -a \right)  ^{2} + b^{2} = b^{2} +
\left(  -a \right)  ^{2} = a^{2} + \left(  -b \right)  ^{2} = \left(  -b
\right)  ^{2} + a^{2}\\
&  = \left(  -a \right)  ^{2} + \left(  -b \right)  ^{2} = \left(  -b \right)
^{2} + \left(  -a \right)  ^{2}%
\end{align*}
for all $a$ and $b$. Thus the pairs $\left(  a, b \right)  \in\mathbb{Z}^{2}$
that satisfy $n = a^{2} + b^{2}$ don't just come in pairs; they come in sets
of $8$ (namely, each $\left(  a, b \right)  $ comes in a set with $\left(  b,
a \right)  $, $\left(  -a, b \right)  $, $\left(  b, -a \right)  $, $\left(
a, -b \right)  $, $\left(  -b, a \right)  $, $\left(  -a, -b \right)  $ and
$\left(  -b, -a \right)  $). These sets of $8$ can ``degenerate'' to smaller
sets when some of their elements coincide, but this can only happen when $n$
is a perfect square (in which case we can have $\left(  a, b \right)  =
\left(  -a, b \right)  $ for example) or twice a perfect square (in which case
we can have $\left(  a, b \right)  = \left(  b, a \right)  $ or $\left(  a, b
\right)  = \left(  -b, -a \right)  $ or other such coincidences). (Check this!)

\textbf{(c)} We can reduce this to parts \textbf{(a)} and \textbf{(b)}.
Indeed:\footnote{In the rest of this argument, \textquotedblleft
pair\textquotedblright\ will always mean \textquotedblleft pair $\left(
a,b\right)  $ satisfying $n=a^{2}+b^{2}$\textquotedblright.}

\begin{itemize}
\item When $n$ is not twice a perfect square, the number of unordered pairs
will be half the number of ordered pairs, since each unordered pair $\left(
u,v\right)  _{\text{unordered}}$ corresponds to precisely two ordered pairs
$\left(  u,v\right)  $ and $\left(  v,u\right)  $.

\item When $n$ is twice a perfect square, we have%
\begin{align*}
&  \left(  \text{the number of unordered pairs}\right) \\
&  =\dfrac{\left(  \text{the number of ordered pairs}\right)  +\left(
\text{the number of pairs with }a=b\right)  }{2}.
\end{align*}
Indeed, each unordered pair $\left(  u,v\right)  _{\text{unordered}}$
corresponds to precisely two ordered pairs $\left(  u,v\right)  $ and $\left(
v,u\right)  $ unless $u=v$, in which case it corresponds to only one ordered
pair. Thus, if we multiply the number of unordered pairs by $2$, then we
\textbf{overcount} the number of ordered pairs, because we are counting the
pairs $\left(  u,v\right)  $ with $u=v$ (that is, the pairs with $a=b$) twice.
So we get $\left(  \text{the number of ordered pairs}\right)  +\left(
\text{the number of pairs with }a=b\right)  $. This proves our above formula.

What is the number of pairs with $a=b$ ? If $n=0$, then it is $1$ (and the
only such pair is $\left(  0,0\right)  $). Otherwise, it is $1$ if we are
counting pairs in $\mathbb{N}^{2}$ (and the only such pair is $\left(
\sqrt{n/2},\sqrt{n/2}\right)  $), and is $2$ if we are counting pairs in
$\mathbb{Z}^{2}$ (and the only two such pairs are $\left(  \sqrt{n/2}%
,\sqrt{n/2}\right)  $ and $\left(  -\sqrt{n/2},-\sqrt{n/2}\right)  $).
\qedhere

\end{itemize}
\end{proof}

Note that sums of squares have a geometric meaning (going back to Pythagoras):
Two real numbers $a$ and $b$ satisfy $a^{2}+b^{2}=n$ (for a given integer
$n\geq0$) if and only if the point with Cartesian coordinates $\left(
a,b\right)  $ lies on the circle with center $0$ and radius $\sqrt{n}$. This
will actually prove a valuable insight that will lead us to the answers to the
above questions.

Just as a teaser: There are formulas for all three parts of
Question~\ref{quest.intro.sum-of-2sq.2}, in terms of divisors of $n$ of the
forms $4k+1$ and $4k+3$. We will see these formulas after we have properly
understood the concept of Gaussian integers.

\subsection{\label{sect.intro.algnum}Motivation: Algebraic numbers}

\begin{noncompile}
Recall how the number system was constructed. In a way, each extension was
done in order to allow a certain operation to proceed: The natural numbers
were extended to the integers in order to allow subtraction (in all cases, not
just when we are subtracting a smaller number from a larger). Then, the
integers were extended to the rational numbers in order to allow division (in
all reasonable cases\footnote{``Reasonable'' in this case means that division
by $0$ is still forbidden. If we allowed division by $0$ as well, then our
``rational numbers'' would all be equal to each other and therefore a huge
step back from the integers.}, not just when the division works out
remainder-less). Then, the rational numbers were extended to the real numbers
in order to allow limits (in all reasonable cases). Finally, the real numbers
were (or will be -- we will see this in more detail) extended to the complex
numbers in order to allow square roots.

From an algebraic point of view, the step from the rational numbers to the
real numbers is somewhat of an overkill. Algebraists often want to work with
roots, particularly roots of polynomials; ideally, every polynomial of degree
$n$ should have ``all'' $n$ roots (counted with multiplicity), so it can be
factored into linear factors. This does indeed happen once you get to complex
numbers (the so-called ``Fundamental Theorem of Algebra''), but the road there
is bumpy and non-algebraic (at the very least, you need continuity to prove
the ``Fundamental Theorem of Algebra''). So algebraists have wondered whether
there is a cheaper way to buy roots for their polynomials -- without having to
pay the price of analysis. (The question became even more relevant when they
started working over arbitrary fields and even commutative rings -- in a
sense, ``alternative number systems'' in which analysis won't help you.)

The answer is ``yes'', and we will eventually see how. But for now, let me
focus on a simple problem that is already interesting if one works inside the
real numbers.
\end{noncompile}

A real number $z$ is said to be \textit{algebraic} if there exists a nonzero
polynomial $P$ with rational coefficients such that $P\left(  z \right)  = 0$.
In other words, a real number $z$ is algebraic if and only if it is a root of
a nonzero polynomial with rational coefficients.

(If you know the complex numbers, you can replace \textquotedblleft
real\textquotedblright\ by \textquotedblleft complex\textquotedblright\ in
this definition; but we shall only see real numbers in this little
motivational section.)

Examples:

\begin{itemize}
\item Each rational number $a$ is algebraic (being a root of the nonzero
polynomial $x-a$ with rational coefficients).

\item The number $\sqrt{2}$ is algebraic (being a root of the nonzero
polynomial $x^{2}-2$).

\item The number $\sqrt[3]{5}$ is algebraic (being a root of $x^{3}-5$).

\item All the roots of the polynomial $f\left(  x \right)  := \dfrac{3}%
{2}x^{4}+17x^{3}-12x+\dfrac{9}{4}$ (whatever they are) are algebraic. \newline
Speaking of these roots, what are they? Using a computer, one can show that
this polynomial $f\left(  x \right)  $ has $4$ real roots ($-11.269\ldots,
-0.960\ldots, 0.198\ldots, 0.697\ldots$), which can be written as complicated
expressions with radicals (i.e., $\sqrt[k]{}$ signs), though complex numbers
appear in these expressions (despite the roots being real!). All this does not
matter to the fact that they are algebraic :)

\item All the roots of the polynomial $g\left(  x \right)  := x^{7} - x^{5} +
1$ are algebraic. \newline This polynomial has only one real root. This root
cannot be written as an expression with radicals (as can be proven using
\href{https://en.wikipedia.org/wiki/Galois_theory}{Galois theory} -- indeed,
the discovery of this theory greatly motivated the development of abstract
algebra).
%(Nor can the remaining $6$ complex roots be.)
Nevertheless, it is algebraic, by definition. (The same holds for the
remaining $6$ complex roots of $g$ -- we are working with real numbers here
only for the sake of familiarity.)

\item The most famous number that is not algebraic is $\pi$. This is a famous
result of Lindemann, but it belongs to analysis, not to algebra, because $\pi$
is not defined algebraically in the first place (it is defined as the length
of a curve or as an area of a curved region -- but either of these definitions
boils down to a limit of a sequence).

\item The second most famous number that is not algebraic is
\href{https://en.wikipedia.org/wiki/E_(mathematical_constant)}{Euler's number
$e$} (the basis of the natural logarithm). Again, analysis is needed to define
$e$, and thus also to prove its non-algebraicity.
\end{itemize}

Numbers that are not algebraic are called
\href{https://en.wikipedia.org/wiki/Transcendental_number}{\textit{transcendental}%
}. We shall not study them much, since most of them do not come from algebra.
Instead, we shall try our hands at the following question:

\begin{question}
\label{quest.intro.algnum.1} \textbf{(a)} Is the sum of two (or, more
generally, finitely many) algebraic numbers always algebraic?

\textbf{(b)} What if we replace ``sum'' by ``difference'' or ``product''?
\end{question}

Let me motivate why this is a natural question to ask. The sum of two integers
is still an integer; the sum of two rational numbers is still a rational
number. These facts are fundamental; without them we could hardly work with
integers and rational numbers. If a similar fact would not hold for algebraic
numbers, it would mean that the algebraic numbers are not a good ``number
system'' to work in; on a practical level, it would mean that (e.g.) if we
defined a function on the set of all algebraic numbers, then we could not plug
a sum of algebraic numbers into it.

\begin{proof}
[Attempts at answering Question~\ref{quest.intro.algnum.1} \textbf{(a)}.]Let
us try a particularly simple example of a sum of two algebraic numbers: Let
$w$ be $\sqrt{2} + \sqrt{3}$. Is $w$ algebraic?

To answer this question affirmatively, we need to find a nonzero polynomial
$f\left(  x \right)  $ with rational coefficients that has $w$ as a root.

Just looking at the equality $w = \sqrt{2} + \sqrt{3}$, we cannot directly
eyeball such an $f$. The problem, in a sense, is that there are too many
(namely, two) square roots in this equality.

However, if we square this equality, then we obtain
\[
w^{2}=\left(  \sqrt{2}+\sqrt{3}\right)  ^{2}=2+2\sqrt{2}\cdot\sqrt{3}+3
=5+2\sqrt{6},
\]
which is an equality with only one square root (a sign of progress).
Subtracting $5$ from this equality (in order to ``isolate'' this remaining
square root), we obtain $w^{2}-5=2\sqrt{6}$. If we now square this equality,
then we obtain $\left(  w^{2}-5\right)  ^{2}=\left(  2\sqrt{6}\right)
^{2}=24$. At this point all square roots are gone, and we are left with an
equality that contains rational numbers and $w$ only! We can further rewrite
it as $\left(  w^{2} - 5 \right)  ^{2} - 24 = 0$. Thus, $w$ is a root of the
polynomial $f\left(  x \right)  := \left(  x^{2}-5\right)  ^{2}-24 =
x^{4}-10x^{2}+1$. This means that $w$ is algebraic (since $f$ is nonzero).

Let us try a more complicated example: Let $z$ be the number $\sqrt
{2}+\sqrt[3]{2}$. Is $z$ algebraic? The squaring trick no longer works, since
squaring $\sqrt{2}+\sqrt[3]{2}$ does not reduce the number of radicals (= root
signs). Let's instead try rewriting $z=\sqrt{2}+\sqrt[3]{2}$ as $z-\sqrt
{2}=\sqrt[3]{2}$. Cubing this equality, we obtain $\left(  z-\sqrt{2}\right)
^{3}=2$. In view of
\[
\left(  z-\sqrt{2}\right)  ^{3}=z^{3}-3z^{2}\sqrt{2}+3z\left(  \sqrt
{2}\right)  ^{2}-\left(  \sqrt{2}\right)  ^{3}%
\]
(this is a particular case of the identity $\left(  a-b\right)  ^{3}%
=a^{3}-3a^{2}b+3ab^{2}-b^{3}$, which is one form of the Binomial Theorem for
exponent $3$), this rewrites a
\[
z^{3}-3z^{2}\sqrt{2}+3z\left(  \sqrt{2}\right)  ^{2}-\left(  \sqrt{2}\right)
^{3}=2.
\]
This simplifies to%
\[
z^{3}-3\sqrt{2}z^{2}+6z-2\sqrt{2}=2.
\]
Let us transform this inequality in such a way that all terms with a $\sqrt
{2}$ in them end up on the right hand side while all the remaining terms end
up on the left. We thus obtain
\[
z^{3}+6z-2=\sqrt{2}\left(  3z^{2}+2\right)  .
\]
Now, squaring this equality yields
\[
\left(  z^{3}+6z-2\right)  ^{2}=2\left(  3z^{2}+2\right)  ^{2}.
\]
Hence, $z$ is a root of the polynomial
\[
g\left(  x\right)  :=\left(  x^{3}+6x-2\right)  ^{2}-2\left(  3x^{2}+2\right)
^{2}=x^{6}-6x^{4}-4x^{3}+12x^{2}-24x-4.
\]
This is a nonzero polynomial with rational coefficients; hence, $z$ is algebraic.

We thus have verified that the sum of two algebraic numbers is algebraic in
two cases. What about more complicated cases, such as
\[
\sqrt{2}+\sqrt{3}+\sqrt[7]{11}\text{ ?}%
\]
This is a sum of two algebraic numbers (since we already know that $\sqrt
{2}+\sqrt{3}=w$ is algebraic). Is it algebraic? Neither of our above two
methods properly works here; do we have to come up with new ad-hoc tricks?
\end{proof}

\begin{center}
\textbf{2019-01-25 lecture}
\end{center}

\subsection{\label{sect.intro.shamir}Motivation: Shamir's Secret Sharing
Scheme}

\subsubsection{The problem}

Adi Shamir is one of the founders of modern mathematical cryptography (famous
in particular for \href{https://en.wikipedia.org/wiki/RSA_(cryptosystem)}{the
RSA cryptosystem}, which we will discuss in Subsection
\ref{subsect.equiv.apps.RSA}).

Shamir's Secret Sharing Scheme is a way in which a secret $\mathbf{a}$ (a
piece of data -- e.g., nuclear launch codes) can be distributed among $n$
people in such a way that

\begin{itemize}
\item any $k$ of them can (if they come together) reconstruct it uniquely, but

\item any $k-1$ of them (if they come together) cannot gain \textbf{any}
insight about it (i.e., not only cannot they reconstruct it, but they cannot
even tell that some values are more likely than others to be $\mathbf{a}$).
\end{itemize}

Here $n$ and $k$ are fixed positive integers.

Understanding this scheme completely will require some abstract algebra, but
we can already start thinking about the problem and get reasonably far.

So we have $n$ people $1,2,\ldots,n$, a positive integer $k\in\left\{
1,2,\ldots,n\right\}  $ and a secret piece of data $\mathbf{a}$. We assume
that this data $\mathbf{a}$ is encoded as a \textit{bitstring} -- i.e., a
finite sequence of bits. A \textit{bit} is an element of the set $\left\{
0,1\right\}  $. Thus, examples of bitstrings are $\left(  0,1,1,0\right)  $
and $\left(  1,0\right)  $ and $\left(  1,1,0,1,0,0,0\right)  $ as well as the
empty sequence $\left(  {}\right)  $. When writing bitstring, we shall usually
omit both the commas and the parentheses; thus, e.g., the bitstring $\left(
1,1,0,1,0,0,0\right)  $ will become $1101000$. Make sure you don't mistake it
for a number. Our goal is to give each of the $n$ people $1,2,\ldots,n$ some
bitstring in such a way that:

\begin{itemize}
\item \textit{Requirement 1:} Any $k$ of the $n$ people can (if they come
together) reconstruct $\mathbf{a}$ uniquely.

\item \textit{Requirement 2:} Any $k-1$ of the $n$ people are unable to gain
any insight about $\mathbf{a}$ (even if they collaborate).
\end{itemize}

We denote the bitstrings given to the people $1,2,\ldots,n$ by $\mathbf{a}%
_{1},\mathbf{a}_{2},\ldots,\mathbf{a}_{n}$, respectively.

We assume that the length of our secret bitstring $\mathbf{a}$ is known in
advance to all parties; i.e., it is not a secret. Thus, when we say
\textquotedblleft$k-1$ persons cannot gain any insight about $\mathbf{a}%
$\textquotedblright, we do not mean that they don't know the length; and when
we say \textquotedblleft some values are more likely than others to be
$\mathbf{a}$\textquotedblright, we only mean values that fit this length.

\subsubsection{The $k=1$ case}

One simple special case of our problem is when $k=1$. In this case, it
suffices to give each of the $n$ people the full secret $\mathbf{a}$ (that is,
we set $\mathbf{a}_{i}=\mathbf{a}$ for all $i$). Then, Requirement 1 is
satisfied (since any $1$ of the $n$ people already knows $\mathbf{a}$), while
Requirement 2 is satisfied as well ($0$ people know nothing).

\subsubsection{The $k=n$ case: what doesn't work}

Let us now consider the case when $k=n$. This case will not help us solve the
general problem, but it will show some ideas that we will encounter again and
again in abstract algebra.

We want to ensure that all $n$ people needed to reconstruct the secret
$\mathbf{a}$, while any $n-1$ of them will be completely clueless.

It sounds reasonable to split $\mathbf{a}$ into $n$ parts, and give each
person one of these parts\footnote{assuming that $\mathbf{a}$ is long enough
for that} (i.e., we let $\mathbf{a}_{i}$ be the $i$-th part of $\mathbf{a}$
for each $i\in\left\{  1,2,\ldots,n\right\}  $). This method satisfies
Requirement 1 (indeed, all $n$ people together can reconstruct $\mathbf{a}$
simply by fusing the $n$ parts back together), but fails Requirement 2
(indeed, any $n-1$ people know $n-1$ parts of the secret $\mathbf{a}$, which
is a far from being clueless about $\mathbf{a}$). So this method doesn't work.
It is not that easy.

\subsubsection{\label{subsect.intro.XOR}The $\operatorname*{XOR}$ operations}

One way to solve the $k=n$ case is using the $\operatorname*{XOR}$ operation.

Let us first define some basic language. A \textit{binary operation} on a set
$S$ is (informally speaking) a function that takes two elements of $S$ and
assigns a new element of $S$ to them. More formally:

\begin{definition}
\label{def.intro.binop}A \textit{binary operation} on a set $S$ is a map $f$
from $S\times S$ to $S$. When $f$ is a binary operation on $S$ and $a$ and $b$
are two elements of $S$, we shall write $afb$ for the value $f\left(
a,b\right)  $.
\end{definition}

\begin{example}
Addition, subtraction and multiplication of integers are three binary
operations on the set $\mathbb{Q}$ (the set of all rational numbers). For
example, addition is the map from $\mathbb{Q}\times\mathbb{Q}$ to $\mathbb{Q}$
that sends each pair $\left(  a,b\right)  \in\mathbb{Q}\times\mathbb{Q}$ to
$a+b$.

Division is not a binary operation on the set $\mathbb{Q}$. Indeed, if it was,
then it would send the pair $\left(  1,0\right)  $ to some integer called
$1/0$; but there is no such integer.

There are myriad more complicated binary operations around waiting for someone
to name them. For example, you could define a binary operation $\smiley{}$ on
the set $\mathbb{Q}$ by $a\smiley{}b=\dfrac{a-b}{1+a^{2}+b^{2}}$. Indeed, you
can do this because $1+a^{2}+b^{2}$ is always nonzero when $a,b\in\mathbb{Q}$
(after all, squares are nonnegative, so that $1+\underbrace{a^{2}}_{\geq
0}+\underbrace{b^{2}}_{\geq0}\geq1>0$). I am not saying that you should...
\end{example}

Now, we define some specific binary operations on the set $\left\{
0,1\right\}  $ of all bits, and on the set $\left\{  0,1\right\}  ^{n}$ of all
length-$n$ bitstrings (for a given $n$).

\begin{definition}
\label{def.intro.XOR.XOR01}We define a binary operation $\operatorname*{XOR}$
on the set $\left\{  0,1\right\}  $ by setting%
\begin{align*}
0\operatorname*{XOR}0  &  =0,\\
0\operatorname*{XOR}1  &  =1,\\
1\operatorname*{XOR}0  &  =1,\\
1\operatorname*{XOR}1  &  =0.
\end{align*}
This is a valid definition, because there are only four pairs $\left(
a,b\right)  \in\left\{  0,1\right\}  \times\left\{  0,1\right\}  $, and we
have just defined $a\operatorname*{XOR}b$ for each of these four options. We
can also rewrite this definition as follows:%
\[
a\operatorname*{XOR}b=%
\begin{cases}
1, & \text{if }a\neq b;\\
0, & \text{if }a=b
\end{cases}
=%
\begin{cases}
1, & \text{if \textbf{exactly} one of }a\text{ and }b\text{ is }1;\\
0, & \text{otherwise.}%
\end{cases}
\]
For lack of a better name, we refer to $a\operatorname*{XOR}b$ as the
\textquotedblleft XOR of $a$ and $b$\textquotedblright.
\end{definition}

The name \textquotedblleft$\operatorname*{XOR}$\textquotedblright\ is short
for \textquotedblleft exclusive or\textquotedblright. In fact, if you identify
bits with boolean truth values (so the bit $0$ stands for \textquotedblleft
False\textquotedblright\ and the bit $1$ stands for \textquotedblleft
True\textquotedblright), then $a\operatorname*{XOR}b$ is precisely the truth
value for \textquotedblleft exactly one of $a$ and $b$ is
True\textquotedblright, which is also known as \textquotedblleft$a$
exclusive-or $b$\textquotedblright.

\begin{definition}
\label{def.intro.XOR.XOR01m}Let $m$ be a nonnegative integer. We define a
binary operation $\operatorname*{XOR}$ on the set $\left\{  0,1\right\}  ^{m}$
(this is the set of all length-$m$ bitstrings) by%
\[
\left(  a_{1},a_{2},\ldots,a_{m}\right)  \operatorname*{XOR}\left(
b_{1},b_{2},\ldots,b_{m}\right)  =\left(  a_{1}\operatorname*{XOR}b_{1}%
,a_{2}\operatorname*{XOR}b_{2},\ldots,a_{m}\operatorname*{XOR}b_{m}\right)  .
\]
In other words, if $\mathbf{a}$ and $\mathbf{b}$ are two length-$m$
bitstrings, then $\mathbf{a}\operatorname*{XOR}\mathbf{b}$ is obtained by
taking the XOR of each entry of $\mathbf{a}$ with the corresponding entry of
$\mathbf{b}$, and packing these $m$ XORs into a new length-$m$ bitstring.
\end{definition}

For example,%
\begin{align*}
\left(  1001\right)  \operatorname*{XOR}\left(  1100\right)   &  =0101;\\
\left(  11011\right)  \operatorname*{XOR}\left(  10101\right)   &  =01110;\\
\left(  11010\right)  \operatorname*{XOR}\left(  01011\right)   &  =10001;\\
\left(  1\right)  \operatorname*{XOR}\left(  0\right)   &  =1;\\
\left(  {}\right)  \operatorname*{XOR}\left(  {}\right)   &  =\left(
{}\right)  .
\end{align*}


Note that if $\mathbf{a}$ and $\mathbf{b}$ are two length-$m$ bitstrings, then
the $0$'s in the bitstring $\mathbf{a}\operatorname*{XOR}\mathbf{b}$ are at
the positions where $\mathbf{a}$ and $\mathbf{b}$ have equal entries, and the
$1$'s in $\mathbf{a}\operatorname*{XOR}\mathbf{b}$ are at the positions where
$\mathbf{a}$ and $\mathbf{b}$ have different entries. Thus, $\mathbf{a}%
\operatorname*{XOR}\mathbf{b}$ essentially pinpoints the differences between
$\mathbf{a}$ and $\mathbf{b}$.

We observe the following simple properties of these operations
$\operatorname*{XOR}$ on bits and on bitstrings\footnote{As a mnemonic, we
shall try to use boldfaced letters like $\mathbf{a}$ and $\mathbf{b}$ for
bitstrings and regular italic letters like $a$ and $b$ for single bits.}:

\begin{itemize}
\item We have $a\operatorname*{XOR}0=a$ for any bit $a$. (This can be
trivially checked by considering both possibilities for $a$.)

\item Thus, $\mathbf{a}\operatorname*{XOR}\mathbf{0}=\mathbf{a}$ for any
bitstring $\mathbf{a}$, where $\mathbf{0}$ denotes the bitstring
$00\cdots0=\left(  0,0,\ldots,0\right)  $ (of appropriate length -- i.e., of
the same length as $\mathbf{a}$).

\item We have $a\operatorname*{XOR}a=0$ for any bit $a$. (This can be
trivially checked by considering both possibilities for $a$.)

\item Thus, $\mathbf{a}\operatorname*{XOR}\mathbf{a}=\mathbf{0}$ for any
bitstring $\mathbf{a}$. We shall refer to this as the
\textit{self-cancellation law}.

\item We have $a\operatorname*{XOR}b=b\operatorname*{XOR}a$ for any bits
$a,b$. (Again, this is easy to check by going through all four options for $a$
and $b$.)

\item Thus, $\mathbf{a}\operatorname*{XOR}\mathbf{b}=\mathbf{b}%
\operatorname*{XOR}\mathbf{a}$ for any bitstrings $\mathbf{a},\mathbf{b}$.

\item We have $a\operatorname*{XOR}\left(  b\operatorname*{XOR}c\right)
=\left(  a\operatorname*{XOR}b\right)  \operatorname*{XOR}c$ for any bits
$a,b,c$. (Again, this is easy to check by going through all eight options for
$a,b,c$.)

\item Thus, $\mathbf{a}\operatorname*{XOR}\left(  \mathbf{b}%
\operatorname*{XOR}\mathbf{c}\right)  =\left(  \mathbf{a}\operatorname*{XOR}%
\mathbf{b}\right)  \operatorname*{XOR}\mathbf{c}$ for any bitstrings
$\mathbf{a},\mathbf{b},\mathbf{c}$.

\item Thus, for any bitstrings $\mathbf{a}$ and $\mathbf{b}$, we have%
\[
\left(  \mathbf{a}\operatorname*{XOR}\mathbf{b}\right)  \operatorname*{XOR}%
\mathbf{b}=\mathbf{a}\operatorname*{XOR}\underbrace{\left(  \mathbf{b}%
\operatorname*{XOR}\mathbf{b}\right)  }_{\substack{=\mathbf{0}\\\text{(by the
self-cancellation law)}}}=\mathbf{a}\operatorname*{XOR}\mathbf{0}=\mathbf{a}.
\]


This observation gives rise to a primitive cryptosystem (known as a
\textit{\href{https://en.wikipedia.org/wiki/One-time_pad}{\textit{one-time
pad}}}): If you have a secret bitstring $\mathbf{a}$ that you want to encrypt,
and another secret bitstring $\mathbf{b}$ that can be used as a key, then you
can encrypt\ $\mathbf{a}$ by XORing it with $\mathbf{b}$ (that is, you
transform it into $\mathbf{a}\operatorname*{XOR}\mathbf{b}$). Then, you can
decrypt it again by XORing it with $\mathbf{b}$ again; indeed, if you do this,
you will obtain $\left(  \mathbf{a}\operatorname*{XOR}\mathbf{b}\right)
\operatorname*{XOR}\mathbf{b}=\mathbf{a}$. This is a highly safe cryptosystem
as long as you can safely communicate the key $\mathbf{b}$ to whomever needs
to be able to decrypt (or encrypt) your secrets, and as long as you are able
to generate uniformly random keys $\mathbf{b}$ of sufficient length. Its only
weakness is its impracticality (in many situations): If the secret you want to
encrypt is long (say, a whole book), your key will need to be equally long.
Even storing such keys can become difficult.
\end{itemize}

We shall refer to the properties $a\operatorname*{XOR}b=b\operatorname*{XOR}a$
and $\mathbf{a}\operatorname*{XOR}\mathbf{b}=\mathbf{b}\operatorname*{XOR}%
\mathbf{a}$ as \textit{laws of commutativity}, and we shall refer to the
properties $a\operatorname*{XOR}\left(  b\operatorname*{XOR}c\right)  =\left(
a\operatorname*{XOR}b\right)  \operatorname*{XOR}c$ and $\mathbf{a}%
\operatorname*{XOR}\left(  \mathbf{b}\operatorname*{XOR}\mathbf{c}\right)
=\left(  \mathbf{a}\operatorname*{XOR}\mathbf{b}\right)  \operatorname*{XOR}%
\mathbf{c}$ as \textit{laws of associativity}. These are, of course, similar
to well-known facts like $\alpha+\beta=\beta+\alpha$ and $\alpha+\left(
\beta+\gamma\right)  =\left(  \alpha+\beta\right)  +\gamma$ for numbers
$\alpha,\beta,\gamma$ (which is why we are giving them the same names). This
similarity is not coincidental. Just as for addition or multiplication of
numbers, these laws lead to a notion of \textquotedblleft
XOR-products\textquotedblright:

\begin{proposition}
\label{prop.intro.xor.prodm}Let $m$ be a positive integer. Let $\mathbf{a}%
_{1},\mathbf{a}_{2},\ldots,\mathbf{a}_{m}$ be $m$ bitstrings. Then, the
\textquotedblleft$\operatorname*{XOR}$-product\textquotedblright\ expression%
\[
\mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\operatorname*{XOR}%
\mathbf{a}_{3}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{a}_{m}%
\]
is well-defined, in the sense that it does not depend on the parenthesization.
\end{proposition}

What do we mean by \textquotedblleft parenthesization\textquotedblright? To
clarify things, let us set $m=4$. In this case, we want to make sense of the
expression $\mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\operatorname*{XOR}%
\mathbf{a}_{3}\operatorname*{XOR}\mathbf{a}_{4}$. This expression does not
make sense a priori, since it is a $\operatorname*{XOR}$ of \textbf{four}
bitstrings, whereas we have defined only the $\operatorname*{XOR}$ of
\textbf{two} bitstrings. But there are five ways to put parentheses around
some of its sub-expressions such that the expression becomes meaningful:
\begin{align*}
&  \left(  \mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\right)
\operatorname*{XOR}\left(  \mathbf{a}_{3}\operatorname*{XOR}\mathbf{a}%
_{4}\right)  ,\\
&  \left(  \left(  \mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\right)
\operatorname*{XOR}\mathbf{a}_{3}\right)  \operatorname*{XOR}\mathbf{a}_{4},\\
&  \mathbf{a}_{1}\operatorname*{XOR}\left(  \left(  \mathbf{a}_{2}%
\operatorname*{XOR}\mathbf{a}_{3}\right)  \operatorname*{XOR}\mathbf{a}%
_{4}\right)  ,\\
&  \mathbf{a}_{1}\operatorname*{XOR}\left(  \mathbf{a}_{2}\operatorname*{XOR}%
\left(  \mathbf{a}_{3}\operatorname*{XOR}\mathbf{a}_{4}\right)  \right)  ,\\
&  \left(  \mathbf{a}_{1}\operatorname*{XOR}\left(  \mathbf{a}_{2}%
\operatorname*{XOR}\mathbf{a}_{3}\right)  \right)  \operatorname*{XOR}%
\mathbf{a}_{4}.
\end{align*}
Each of these five parenthesizations (= placements of parentheses) turns our
expression $\mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\operatorname*{XOR}%
\mathbf{a}_{3}\operatorname*{XOR}\mathbf{a}_{4}$ into a combination of
$\operatorname*{XOR}$'s of \textbf{two} bitstrings each, and thus gives it
meaning. The question is: Do these five parenthesizations give it the
\textbf{same} meaning?

Well, let us calculate:%
\begin{align*}
&  \left(  \mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\right)
\operatorname*{XOR}\left(  \mathbf{a}_{3}\operatorname*{XOR}\mathbf{a}%
_{4}\right) \\
&  =\mathbf{a}_{1}\operatorname*{XOR}\underbrace{\left(  \mathbf{a}%
_{2}\operatorname*{XOR}\left(  \mathbf{a}_{3}\operatorname*{XOR}\mathbf{a}%
_{4}\right)  \right)  }_{=\left(  \mathbf{a}_{2}\operatorname*{XOR}%
\mathbf{a}_{3}\right)  \operatorname*{XOR}\mathbf{a}_{4}}\\
&  =\mathbf{a}_{1}\operatorname*{XOR}\left(  \left(  \mathbf{a}_{2}%
\operatorname*{XOR}\mathbf{a}_{3}\right)  \operatorname*{XOR}\mathbf{a}%
_{4}\right) \\
&  =\underbrace{\left(  \mathbf{a}_{1}\operatorname*{XOR}\left(
\mathbf{a}_{2}\operatorname*{XOR}\mathbf{a}_{3}\right)  \right)  }_{=\left(
\mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\right)  \operatorname*{XOR}%
\mathbf{a}_{3}}\operatorname*{XOR}\mathbf{a}_{4}\\
&  =\left(  \left(  \mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\right)
\operatorname*{XOR}\mathbf{a}_{3}\right)  \operatorname*{XOR}\mathbf{a}_{4},
\end{align*}
where we used the law of associativity in each step. This shows that our five
parenthesizations yield the same result. Thus, they all give our
\textquotedblleft$\operatorname*{XOR}$-product\textquotedblright\ expression
$\mathbf{a}_{1}\operatorname*{XOR}\mathbf{a}_{2}\operatorname*{XOR}%
\mathbf{a}_{3}\operatorname*{XOR}\mathbf{a}_{4}$ the same meaning; so we can
say that this expression is well-defined. This confirms Proposition
\ref{prop.intro.xor.prodm} for $m=4$.

Of course, proving Proposition \ref{prop.intro.xor.prodm} is less simple. Such
a proof will appear in Exercise 4 on homework set \#0.

\subsubsection{The $k=n$ case: an answer}

Let us now return to our problem. We have $n$ persons $1,2,\ldots,n$ and a
secret $\mathbf{a}$ (encoded as a bitstring). We want to give each person $i$
some bitstring $\mathbf{a}_{i}$ such that only all $n$ of them can recover
$\mathbf{a}$ but any $n-1$ of them cannot gain any insight about $\mathbf{a}$.

We let $\mathbf{a}_{1},\mathbf{a}_{2},\ldots,\mathbf{a}_{n-1}$ be $n-1$
\textbf{uniformly} random bitstrings of the same length as $\mathbf{a}$.
(Think of them as random gibberish.) Set%
\[
\mathbf{a}_{n}=\mathbf{a}\operatorname*{XOR}\mathbf{a}_{1}\operatorname*{XOR}%
\mathbf{a}_{2}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{a}_{n-1}.
\]
(This expression makes sense because of Proposition \ref{prop.intro.xor.prodm}.)

Then,%
\begin{align*}
&  \mathbf{a}_{n}\operatorname*{XOR}\mathbf{a}_{n-1}\operatorname*{XOR}%
\mathbf{a}_{n-2}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{a}_{1}\\
&  =\left(  \mathbf{a}\operatorname*{XOR}\mathbf{a}_{1}\operatorname*{XOR}%
\mathbf{a}_{2}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{a}%
_{n-1}\right)  \operatorname*{XOR}\mathbf{a}_{n-1}\operatorname*{XOR}%
\mathbf{a}_{n-2}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{a}_{1}\\
&  =\mathbf{a}\operatorname*{XOR}\mathbf{a}_{1}\operatorname*{XOR}%
\mathbf{a}_{2}\operatorname*{XOR}\cdots\operatorname*{XOR}%
\underbrace{\mathbf{a}_{n-1}\operatorname*{XOR}\mathbf{a}_{n-1}}_{=\mathbf{0}%
}\operatorname*{XOR}\mathbf{a}_{n-2}\operatorname*{XOR}\cdots
\operatorname*{XOR}\mathbf{a}_{1}\\
&  =\mathbf{a}\operatorname*{XOR}\mathbf{a}_{1}\operatorname*{XOR}%
\mathbf{a}_{2}\operatorname*{XOR}\cdots\operatorname*{XOR}%
\underbrace{\mathbf{a}_{n-2}\operatorname*{XOR}\mathbf{0}}_{=\mathbf{a}_{n-2}%
}\operatorname*{XOR}\mathbf{a}_{n-2}\operatorname*{XOR}\cdots
\operatorname*{XOR}\mathbf{a}_{1}\\
&  =\mathbf{a}\operatorname*{XOR}\mathbf{a}_{1}\operatorname*{XOR}%
\mathbf{a}_{2}\operatorname*{XOR}\cdots\operatorname*{XOR}%
\underbrace{\mathbf{a}_{n-2}\operatorname*{XOR}\mathbf{a}_{n-2}}_{=\mathbf{0}%
}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{a}_{1}\\
&  =\cdots\\
&  =\mathbf{a}%
\end{align*}
(here, we have been unravelling the big $\operatorname*{XOR}$-product from the
middle on, by cancelling equal bitstrings using the self-cancellation law and
then removing the resulting $\mathbf{0}$ using the $\mathbf{a}%
\operatorname*{XOR}\mathbf{0}=\mathbf{a}$ law). Hence, the $n$ people together
can decrypt the secret $\mathbf{a}$.

Can $n-1$ people gain any insight about it? The $n-1$ people $1,2,\ldots,n-1$
certainly cannot, since all they know are the random bitstrings $\mathbf{a}%
_{1},\mathbf{a}_{2},\ldots,\mathbf{a}_{n-1}$. But the $n-1$ people
$2,3,\ldots,n$ cannot gain any insight about $\mathbf{a}$ either: In fact, all
they know are the random bitstrings $\mathbf{a}_{2},\mathbf{a}_{3}%
,\ldots,\mathbf{a}_{n-1}$ and the bitstring%
\[
\mathbf{a}_{n}=\mathbf{a}\operatorname*{XOR}\mathbf{a}_{1}\operatorname*{XOR}%
\mathbf{a}_{2}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{a}_{n-1};
\]
therefore, all the information they have about $\mathbf{a}$ and $\mathbf{a}%
_{1}$ comes to them through $\mathbf{a}\operatorname*{XOR}\mathbf{a}_{1}$,
which says nothing about $\mathbf{a}$ as long as they know nothing about
$\mathbf{a}_{1}$. (We used a bit of handwaving in this argument, but then
again we never formally defined what it means to \textquotedblleft gain no
insight\textquotedblright; this is done in courses on cryptography and
information theory.) Similar arguments show that any other choice of $n-1$
persons remains equally clueless about $\mathbf{a}$. So we have solved the
problem in the case $k=n$.

\subsubsection{The $k=2$ case}

The next simple case is when $k=2$. So we want to ensure that any $2$ of our
$n$ people can together recover the secret, but no $1$ person can learn
anything about it alone.

A really nice approach was suggested by Nathan in class: We pick $n$ random
bitstrings $\mathbf{x}_{1},\mathbf{x}_{2},\ldots,\mathbf{x}_{n-1}$ of the same
length as $\mathbf{a}$. Set
\[
\mathbf{x}_{n}=\mathbf{a}\operatorname*{XOR}\mathbf{x}_{1}\operatorname*{XOR}%
\mathbf{x}_{2}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{x}_{n-1};
\]
thus, as in the $k=n$ case, we have%
\begin{equation}
\mathbf{x}_{n}\operatorname*{XOR}\mathbf{x}_{n-1}\operatorname*{XOR}%
\mathbf{x}_{n-2}\operatorname*{XOR}\cdots\operatorname*{XOR}\mathbf{x}%
_{1}=\mathbf{a}. \label{eq.intro.shamir.k=2.2}%
\end{equation}


Each person $i$ now receives the bitstring%
\[
\mathbf{a}_{i}=\mathbf{x}_{1}\mathbf{x}_{2}\cdots\mathbf{x}_{i-1}%
\mathbf{x}_{i+1}\mathbf{x}_{i+2}\cdots\mathbf{x}_{n},
\]
where the product stands for \textit{concatenation} (i.e., the bitstring
$\mathbf{a}_{i}$ is formed by writing down all of the bitstrings
$\mathbf{x}_{1},\mathbf{x}_{2},\ldots,\mathbf{x}_{n}$ one after the other but
skipping $\mathbf{x}_{i}$). Thus, each person $i$ can recover all the $n-1$
bitstrings $\mathbf{x}_{1},\mathbf{x}_{2},\ldots,\mathbf{x}_{i-1}%
,\mathbf{x}_{i+1},\mathbf{x}_{i+2},\ldots,\mathbf{x}_{n}$ (because their
lengths are the length of $\mathbf{a}$, which is known), but knows nothing
about $\mathbf{x}_{i}$ (his \textquotedblleft blind spot\textquotedblright).
Hence, $2$ people together can recover all the $n$ bitstrings $\mathbf{x}%
_{1},\mathbf{x}_{2},\ldots,\mathbf{x}_{n}$ and therefore recover the secret
$\mathbf{a}$ (by (\ref{eq.intro.shamir.k=2.2})). On the other hand, each
single person has no insight about $\mathbf{a}$ (this is proven similarly to
the $k=n$ case). So again, the problem is solved in this case.

\subsubsection{\label{subsect.intro.shamir.k=3}The $k=3$ case}

Now, let us come to the case when $k=3$. Now I think the usefulness of the
$\operatorname*{XOR}$ approach has come to its end: at least I don't know how
to make it work here. Instead, out of the blue, I will invoke something
completely different: polynomials (let's say with rational coefficients).

Recall a fact you might have heard in high school: A polynomial $p\left(
x\right)  =cx^{2}+bx+a$ of degree $\leq2$ is uniquely determined by any three
of its values. More precisely: If $u,v,w$ are three fixed distinct numbers,
then a polynomial $p\left(  x\right)  =cx^{2}+bx+a$ of degree $\leq2$ is
uniquely determined by the values $p\left(  u\right)  ,p\left(  v\right)
,p\left(  w\right)  $. We will put this to use now, and sort-of solve the problem.

Also recall that any bitstring of given length $N$ can be encoded as an
integer in $\left\{  0,1,\ldots,2^{N}-1\right\}  $; just read it as a number
in binary. More precisely, any bitstring $a_{N-1}a_{N-2}\cdots a_{0}$ of
length $N$ becomes the integer $a_{N-1}\cdot2^{N-1}+a_{N-2}\cdot2^{N-2}%
+\cdots+a_{0}\cdot2^{0}\in\left\{  0,1,\ldots,2^{N}-1\right\}  $. For example,
the bitstring $010110$ of length $6$ becomes the integer%
\[
0\cdot2^{5}+1\cdot2^{4}+0\cdot2^{3}+1\cdot2^{2}+1\cdot2^{1}+0\cdot2^{0}%
=22\in\left\{  0,1,\ldots,2^{6}-1\right\}  .
\]


Choose two \textbf{uniformly random} bitstrings $\mathbf{c}$ and $\mathbf{b}$
(of the same length as $\mathbf{a}$) and encode them as numbers $c$ and $b$
(as just explained). Encode the secret $\mathbf{a}$ as a number $a$ as well
(in the same way). Define the polynomial $p\left(  x\right)  =cx^{2}+bx+a$.
Reveal to each person $i\in\left\{  1,2,\ldots,n\right\}  $ the value
$p\left(  i\right)  $ -- or, rather, a bitstring that encodes it in binary --
as $\mathbf{a}_{i}$.

As we know, any three of the values $p\left(  i\right)  $ uniquely determine
the polynomial $p$. Thus, any three people can use their bitstrings
$\mathbf{a}_{i}$ to recover three values $p\left(  i\right)  $ and therefore
$p$ and therefore $a$ (as the constant term of $p$) and therefore $\mathbf{a}$
(by decoding $a$). So our method satisfies Requirement 1.

Now, let us see whether it satisfies Requirement 2. Any $2$ people can recover
two values $p\left(  i\right)  $, which generally do not determine $p$
uniquely. It is not hard to show that they do not even determine $a$ uniquely;
thus, they do not determine $\mathbf{a}$ uniquely. What's better: If you know
just two values of $p$, there are infinitely many possible choices for $p$,
and all of them have distinct constant terms (unless one of the two values you
know is $p\left(  0\right)  $, which of course pins down the constant term).
So we get infinitely many possible values for $a$, and thus infinitely many
possible values for $\mathbf{a}$. This means that our $2$ people don't gain
any insight about $\mathbf{a}$, right?

Not so fast! We cannot really have \textquotedblleft infinitely many possible
values for $\mathbf{a}$\textquotedblright, since $\mathbf{a}$ is bound to be a
bitstring of a given length -- there are only finitely many of those! You can
only get infinitely many possible values for $p$ if you forget how $p$ was
constructed (from $c$, $b$ and $a$) and pretend that $p$ is just a
\textquotedblleft uniformly random\textquotedblright\ polynomial (whatever
this means). But no one can force the $2$ people to do this; it is certainly
not in their interest! Here are some things they might do with this knowledge:

\begin{itemize}
\item Let $N$ be the length of $\mathbf{a}$ (which, as we said, is known).
Thus, $\mathbf{c}$ and $\mathbf{b}$ are bitstrings of length $N$, so that $c$
and $b$ are integers in $\left\{  0,1,\ldots,2^{N}-1\right\}  $. Assume that
one of the $2$ people is person $2$. Now, person $2$ knows $p\left(  2\right)
=c2^{2}+b2+a=4c+2b+a$, and thus knows whether $a$ is even or odd (because $a$
is even resp. odd if and only if $4c+2b+a$ is even resp. odd). This means she
knows the last bit of the secret $\mathbf{a}$. This is not \textquotedblleft
clueless\textquotedblright.

\item You might try to fix this by picking $c$ and $b$ to be uniformly random
rational numbers instead (rather than using uniformly random bitstrings
$\mathbf{c}$ and $\mathbf{b}$).

Unfortunately, there is no such thing as a \textquotedblleft uniformly random
rational number\textquotedblright\ (in the sense that, e.g., larger numbers
aren't less likely to be picked than smaller numbers). Any probability
distribution will make some numbers more likely than others, and this will
usually cause information about $\mathbf{a}$ to \textquotedblleft
leak\textquotedblright. For example, if $c$ and $b$ are chosen from the
interval $\left[  0,2^{N}-1\right]  $, then person $1$'s knowledge of
$p\left(  1\right)  =c1^{2}+b1+a=c+b+a$ will sometimes reveal to person $1$
that $a\geq0.5\cdot\left(  2^{N}-1\right)  $ (namely, this will happen when
$p\left(  1\right)  \geq2.5\cdot\left(  2^{N}-1\right)  $, which occasionally
happens). This, again, is nontrivial information about the secret $\mathbf{a}%
$, which a single person (or even two people) should not be having.
\end{itemize}

So we cannot make Requirement 2 hold, and the culprit is that there are too
many numbers (namely, infinitely many). What would help is a finite
\textquotedblleft number system\textquotedblright\ in which we can add,
subtract, multiply and divide (so that we can define polynomials over it, and
a polynomial of degree $\leq2$ is still uniquely determined by any $3$
values). Assuming that this \textquotedblleft number system\textquotedblright%
\ is large enough that we can encode bitstrings using \textquotedblleft
numbers\textquotedblright\ of this system (instead of integers), we can then
play the above game using this \textquotedblleft number
system\textquotedblright\ and obtain actually uniformly random numbers.

It turns out that such \textquotedblleft number systems\textquotedblright%
\ exist. They are called \textit{finite fields}, and we will construct them
later in this course.

Assuming that they can be constructed, we thus obtain a method of solving the
problem for $k=3$. A similar method works for arbitrary $k$, using polynomials
of degree $\leq k-1$. This is called \textit{Shamir's secret sharing scheme}.

\begin{center}
\textbf{2019-01-30 lecture (virtual)}
\end{center}

\section{Elementary number theory}

Let us now begin a systematic introduction to algebra. We start with studying
integers and their divisibility properties -- the beginnings of number theory.
Part of these will be used directly in what will follow; part of these will
inspire more general results and proofs.

\subsection{Notations}

\begin{definition}
Let $\mathbb{N}=\left\{  0,1,2,\ldots\right\}  $ be the set of
\textbf{nonnegative} integers.

Let $\mathbb{P}=\left\{  1,2,3,\ldots\right\}  $ be the set of
\textbf{positive} integers.

Let $\mathbb{Z}=\left\{  \ldots,-1,0,1,\ldots\right\}  $ be the set of integers.

Let $\mathbb{Q}$ be the set of rational numbers.

Let $\mathbb{R}$ be the set of real numbers.
\end{definition}

Be careful with the notation $\mathbb{N}$: While I use it for $\left\{
0,1,2,\ldots\right\}  $, various other authors use it for $\left\{
1,2,3,\ldots\right\}  $ instead. There is no consensus in sight on what
$\mathbb{N}$ should mean.

Same holds for the word \textquotedblleft natural number\textquotedblright%
\ (which I will avoid): It means \textquotedblleft element of $\mathbb{N}%
$\textquotedblright, so again its ultimate meaning depends on the author.

\subsection{Divisibility}

We now go through the basics of divisibility of integers.

\begin{definition}
\label{def.ent.div.div}Let $a$ and $b$ be two integers. We say that $a\mid b$
(or \textquotedblleft$a$ \textit{divides} $b$\textquotedblright\ or
\textquotedblleft$b$ is \textit{divisible by }$a$\textquotedblright\ or
\textquotedblleft$b$ is a \textit{multiple} of $a$\textquotedblright) if there
exists an integer $c$ such that $b=ac$.

We furthermore say that $a\nmid b$ if $a$ does not divide $b$.
\end{definition}

Some authors define the \textquotedblleft divisibility\textquotedblright%
\ relation a bit differently, in that they forbid $a=0$. From the viewpoint of
abstract algebra, this feels like an unnecessary exception, so we don't follow them.

\begin{example}
\label{exa.ent.div.triv}\textbf{(a)} We have $4\mid12$, since $12=4\cdot3$.

\textbf{(b)} We have $a\mid0$ for any $a\in\mathbb{Z}$, since $0=a\cdot0$.

\textbf{(c)} An integer $b$ satisfies $0\mid b$ only when $b=0$, since $0\mid
b$ implies $b=0c=0$ (for some $c\in\mathbb{Z}$).

\textbf{(d)} We have $a\mid a$ for any $a\in\mathbb{Z}$, since $a=a\cdot1$.

\textbf{(e)} We have $1\mid b$ for each $b\in\mathbb{Z}$, since $b=1\cdot b$.
\end{example}

I apologize in advance for the next proposition, in which vertical bars stand
both for the \textquotedblleft divides\textquotedblright\ relation and for the
absolute value of a number. Unfortunately, both of these uses are standard
notation. Confusion is possible, but hopefully will not happen
often\footnote{Unfortunately, the use of vertical bars for absolute values
alone suffices to generate confusion! Just think of the meaning of
\textquotedblleft$\left\vert a\right\vert b\left\vert c\right\vert
$\textquotedblright\ when $a$, $b$ and $c$ are three numbers. Does it stand
for \textquotedblleft$\left(  \left\vert a\right\vert \right)  \cdot
b\cdot\left(  \left\vert c\right\vert \right)  $\textquotedblright\ (where I
am using parentheses to make the ambiguity disappear) or for \textquotedblleft%
$\left\vert \left(  a\cdot\left\vert b\right\vert \cdot c\right)  \right\vert
$\textquotedblright? If you see any expressions in my notes that allow for
more than one meaningful interpretation, please let me know!}.

\begin{proposition}
\label{prop.ent.div.1}Let $a$ and $b$ be two integers.

\textbf{(a)} We have $a\mid b$ if and only if $\left\vert a\right\vert
\mid\left\vert b\right\vert $. (Here, \textquotedblleft$\left\vert
a\right\vert \mid\left\vert b\right\vert $\textquotedblright\ means
\textquotedblleft$\left\vert a\right\vert $ divides $\left\vert b\right\vert
$\textquotedblright.)

\textbf{(b)} If $a\mid b$ and $b\neq0$, then $\left\vert a\right\vert
\leq\left\vert b\right\vert $.

\textbf{(c)} Assume that $a\neq0$. Then, $a\mid b$ if and only if $\dfrac
{b}{a}\in\mathbb{Z}$.
\end{proposition}

Before we prove this proposition, let us recall a well-known fact: We have
\begin{equation}
\left\vert xy\right\vert =\left\vert x\right\vert \cdot\left\vert y\right\vert
\label{eq.ent.div.abs(xy)}%
\end{equation}
for any two integers\footnote{or real numbers} $x$ and $y$. (This can be
easily proven by case distinction: $x$ is either nonnegative or negative, and
so is $y$.)

\begin{proof}
[Proof of Proposition \ref{prop.ent.div.1}.]\textbf{(a)} $\Longrightarrow
:$\footnote{If you are unfamiliar with the shorthand notation
\textquotedblleft$\Longrightarrow:$\textquotedblright, let me explain it. Our
goal is to prove that $a\mid b$ if and only if $\left\vert a\right\vert
\mid\left\vert b\right\vert $. In other words, we need to prove the
equivalence $\left(  a\mid b\right)  \Longleftrightarrow\left(  \left\vert
a\right\vert \mid\left\vert b\right\vert \right)  $. In order to prove this
equivalence, it suffices to prove the two implications $\left(  a\mid
b\right)  \Longrightarrow\left(  \left\vert a\right\vert \mid\left\vert
b\right\vert \right)  $ (called the \textquotedblleft forward
implication\textquotedblright\ or the \textquotedblleft$\Longrightarrow$
direction\textquotedblright\ of the equivalence) and $\left(  a\mid b\right)
\Longleftarrow\left(  \left\vert a\right\vert \mid\left\vert b\right\vert
\right)  $ (called the \textquotedblleft backward
implication\textquotedblright\ or the \textquotedblleft$\Longleftarrow$
direction\textquotedblright). The shorthand \textquotedblleft$\Longrightarrow
:$\textquotedblright\ simply marks the beginning of the proof of the forward
implication; similarly, the symbol \textquotedblleft$\Longleftarrow
:$\textquotedblright\ heralds in the proof of the backward implication.}
Assume that $a\mid b$. Thus, there exists an integer $d$ such that $b=ad$ (by
Definition \ref{def.ent.div.div}). Consider\footnote{Me saying
\textquotedblleft Consider this $d$\textquotedblright\ means that I am picking
some integer $d$ such that $b=ad$ (this can be done, since we have just proven
that such a $d$ exists), and will be referring to it as $d$ from now on.} this
$d$. We have $b=ad$ and thus $\left\vert b\right\vert =\left\vert
ad\right\vert =\left\vert a\right\vert \cdot\left\vert d\right\vert $ (by
(\ref{eq.ent.div.abs(xy)})). Thus, there exists an integer $c$ such that
$\left\vert b\right\vert =\left\vert a\right\vert \cdot c$ (namely,
$c=\left\vert d\right\vert $). In other words, $\left\vert a\right\vert
\mid\left\vert b\right\vert $. This proves the \textquotedblleft%
$\Longrightarrow$\textquotedblright\ direction of Proposition
\ref{prop.ent.div.1} \textbf{(a)}.

$\Longleftarrow:$ Assume that $\left\vert a\right\vert \mid\left\vert
b\right\vert $. Thus, there exists an integer $f$ such that $\left\vert
b\right\vert =\left\vert a\right\vert \cdot f$ (by Definition
\ref{def.ent.div.div}). Consider this $f$.

The definition of $\left\vert b\right\vert $ shows that $\left\vert
b\right\vert $ equals either $b$ or $-b$. In other words, $\left\vert
b\right\vert $ equals either $1b$ or $\left(  -1\right)  b$ (since $b=1b$ and
$-b=\left(  -1\right)  b$). In other words, $\left\vert b\right\vert =qb$ for
some $q\in\left\{  1,-1\right\}  $. Similarly, $\left\vert a\right\vert =ra$
for some $r\in\left\{  1,-1\right\}  $. Consider these $q$ and $r$.

From $q\in\left\{  1,-1\right\}  $, we obtain $q^{2}\in\left\{
\underbrace{1^{2}}_{=1},\underbrace{\left(  -1\right)  ^{2}}_{=1}\right\}
=\left\{  1,1\right\}  =\left\{  1\right\}  $. In other words, $q^{2}=1$.

Now, $q\underbrace{\left\vert b\right\vert }_{=qb}=\underbrace{qq}_{=q^{2}%
=1}b=b$, so that $b=q\underbrace{\left\vert b\right\vert }_{=\left\vert
a\right\vert \cdot f}=q\underbrace{\left\vert a\right\vert }_{=ra}\cdot
f=qra\cdot f=a\cdot qfr$. Hence, there exists an integer $c$ such that $b=ac$
(namely, $c=qfr$). In other words, $a\mid b$. This proves the
\textquotedblleft$\Longleftarrow$\textquotedblright\ direction of Proposition
\ref{prop.ent.div.1} \textbf{(a)}.

Thus, the proof of Proposition \ref{prop.ent.div.1} \textbf{(a)} is complete.

\textbf{(b)} Assume that $a\mid b$ and $b\neq0$.

From $a\mid b$, we conclude that there exists an integer $c$ such that $b=ac$.
Consider this $c$. We have $ac=b\neq0$, thus $c\neq0$. Hence, $\left\vert
c\right\vert >0$, and thus $\left\vert c\right\vert \geq1$ (since $\left\vert
c\right\vert $ is an integer). We can multiply this inequality by $\left\vert
a\right\vert $ (since $\left\vert a\right\vert \geq0$), and obtain $\left\vert
a\right\vert \cdot\left\vert c\right\vert \geq\left\vert a\right\vert
\cdot1=\left\vert a\right\vert $.

From $b=ac$, we obtain $\left\vert b\right\vert =\left\vert ac\right\vert
=\left\vert a\right\vert \cdot\left\vert c\right\vert $ (by
(\ref{eq.ent.div.abs(xy)})). Hence, $\left\vert b\right\vert =\left\vert
a\right\vert \cdot\left\vert c\right\vert \geq\left\vert a\right\vert $. This
proves Proposition \ref{prop.ent.div.1} \textbf{(b)}.

\textbf{(c)} $\Longrightarrow:$ Assume that $a\mid b$. We must prove that
$\dfrac{b}{a}\in\mathbb{Z}$.

We have $a\mid b$. In other words, there exists an integer $d$ such that
$b=ad$. Consider this $d$. We can divide the equality $b=ad$ by $a$ (since
$a\neq0$), and thus obtain $\dfrac{b}{a}=d\in\mathbb{Z}$. This proves the
\textquotedblleft$\Longrightarrow$\textquotedblright\ direction of Proposition
\ref{prop.ent.div.1} \textbf{(c)}.

$\Longleftarrow:$ Assume that $\dfrac{b}{a}\in\mathbb{Z}$. We must prove that
$a\mid b$.

We have $\dfrac{b}{a}\in\mathbb{Z}$ and $b=a\cdot\dfrac{b}{a}$. Thus, there
exists an integer $c$ such that $b=ac$ (namely, $c=\dfrac{b}{a}$). In other
words, $a\mid b$. This proves the \textquotedblleft$\Longleftarrow
$\textquotedblright\ direction of Proposition \ref{prop.ent.div.1}
\textbf{(c)}. Hence, the proof of Proposition \ref{prop.ent.div.1}
\textbf{(c)} is complete.
\end{proof}

Proposition \ref{prop.ent.div.1} \textbf{(a)} shows that both $a$ and $b$ in
the statement \textquotedblleft$a\mid b$\textquotedblright\ can be replaced by
their absolute values. Thus, when we talk about divisibility of integers, the
sign of the integers does not really matter -- it usually suffices to work
with nonnegative integers. We will often use this (tacitly, after a couple
times) in proofs.

The next proposition shows some basic properties of the divisibility relation:

\begin{proposition}
\label{prop.ent.div.2}\textbf{(a)} We have $a\mid a$ for every $a\in
\mathbb{Z}$. (This is called the \textit{reflexivity of divisibility}.)

\textbf{(b)} If $a,b,c\in\mathbb{Z}$ satisfy $a\mid b$ and $b\mid c$, then
$a\mid c$. (This is called the \textit{transitivity of divisibility}.)

\textbf{(c)} If $a_{1},a_{2},b_{1},b_{2}\in\mathbb{Z}$ satisfy $a_{1}\mid
b_{1}$ and $a_{2}\mid b_{2}$, then $a_{1}a_{2}\mid b_{1}b_{2}$.
\end{proposition}

\begin{proof}
\textbf{(a)} Let $a\in\mathbb{Z}$. Then, there exists an integer $c$ such that
$a=ac$ (namely, $c=1$). In other words, $a\mid a$. This proves Proposition
\ref{prop.ent.div.2} \textbf{(a)}.

\textbf{(b)} Let $a,b,c\in\mathbb{Z}$ satisfy $a\mid b$ and $b\mid c$.

From $a\mid b$, we conclude that there exists an integer $d$ such that $b=ad$.
Consider this $d$.

From $b\mid c$, we conclude that there exists an integer $e$ such that $c=be$.
Consider this $e$.

We have $c=\underbrace{b}_{=ad}e=ade$. Hence, there exists an integer $f$ such
that $c=af$ (namely, $f=de$). In other words, $a\mid c$ (by Definition
\ref{def.ent.div.div}). This proves Proposition \ref{prop.ent.div.2}
\textbf{(b)}.

\textbf{(c)} Let $a_{1},a_{2},b_{1},b_{2}\in\mathbb{Z}$ satisfy $a_{1}\mid
b_{1}$ and $a_{2}\mid b_{2}$.

From $a_{1}\mid b_{1}$, we conclude that there exists an integer $d$ such that
$b_{1}=a_{1}d$. Consider this $d$.

From $a_{2}\mid b_{2}$, we conclude that there exists an integer $e$ such that
$b_{2}=a_{2}e$. Consider this $e$.

We have $\underbrace{b_{1}}_{=a_{1}d}\underbrace{b_{2}}_{=a_{2}e}=a_{1}%
da_{2}e=a_{1}a_{2}de$. Hence, there exists an integer $f$ such that
$b_{1}b_{2}=a_{1}a_{2}f$ (namely, $f=de$). In other words, $a_{1}a_{2}\mid
b_{1}b_{2}$ (by Definition \ref{def.ent.div.div}). This proves Proposition
\ref{prop.ent.div.2} \textbf{(c)}.
\end{proof}

\begin{exercise}
\label{exe.ent.div.aabs}Let $a\in\mathbb{Z}$.

\textbf{(a)} Prove that $a\mid\left\vert a\right\vert $. (This means
\textquotedblleft$a$ divides $\left\vert a\right\vert $\textquotedblright.)

\textbf{(b)} Prove that $\left\vert a\right\vert \mid a$. (This means
\textquotedblleft$\left\vert a\right\vert $ divides $a$\textquotedblright.)
\end{exercise}

\begin{exercise}
\label{exe.ent.div.abba}Let $a$ and $b$ be two integers such that $a\mid b$
and $b\mid a$. Prove that $\left\vert a\right\vert =\left\vert b\right\vert $.
\end{exercise}

\begin{exercise}
\label{exe.ent.div.acbc}Let $a,b,c$ be three integers such that $c\neq0$.
Prove that $a\mid b$ holds if and only if $ac\mid bc$.
\end{exercise}

\begin{exercise}
\label{exe.ent.div.powers}Let $n\in\mathbb{Z}$. Let $a,b\in\mathbb{N}$ be such
that $a\leq b$. Prove that $n^{a}\mid n^{b}$.
\end{exercise}

\begin{exercise}
\label{exe.ent.div.g|1}Let $g$ be a nonnegative integer such that $g\mid1$.
Prove that $g=1$.
\end{exercise}

\begin{exercise}
\label{exe.ent.div.powers-ab}Let $a,b\in\mathbb{Z}$ be such that $a\mid b$.
Let $k\in\mathbb{N}$. Prove that $a^{k}\mid b^{k}$.
\end{exercise}

\subsection{Congruence modulo $n$}

The next definition is simple but crucial:

\begin{definition}
\label{def.ent.cong}Let $n,a,b\in\mathbb{Z}$. We say that $a$ \textit{is
congruent to }$b$ \textit{modulo }$n$ if and only if $n\mid a-b$. We shall use
the notation \textquotedblleft$a\equiv b\operatorname{mod}n$\textquotedblright%
\ for \textquotedblleft$a$ is congruent to $b$ modulo $n$\textquotedblright.

We furthermore shall use the notation \textquotedblleft$a\not \equiv
b\operatorname{mod}n$\textquotedblright\ for \textquotedblleft$a$ is not
congruent to $b$ modulo $n$\textquotedblright.
\end{definition}

\begin{example}
\label{exa.ent.cong.triv}\textbf{(a)} Is $3\equiv7\operatorname{mod}2$ ? Yes,
since $2\mid3-7=-4$.

\textbf{(b)} Is $3\equiv6\operatorname{mod}2$ ? No, since $2\nmid3-6=-3$. So
we have $3\not \equiv 6\operatorname{mod}2$.

Now, let $a$ and $b$ be two integers.

\textbf{(c)} We have $a\equiv b\operatorname{mod}0$ if and only if $a=b$.
(Indeed, $a\equiv b\operatorname{mod}0$ is defined to mean $0\mid a-b$, but
the latter divisibility happens only when $a-b=0$, which is tantamount to
saying $a=b$.)

\textbf{(d)} We have $a\equiv b\operatorname{mod}1$ always, since $1\mid a-b$
always holds (remember: $1$ divides everything).
\end{example}

Note that being congruent modulo $2$ means having the same parity: i.e., two
even numbers will be congruent modulo $2$, and two odd numbers will be, but an
even number will never be congruent to an odd number modulo $2$. (To be
rigorous: This is not quite obvious at this point yet; but it will be easy
once we have properly introduced division with remainder. See Exercise
\ref{exe.ent.even-odd.1} \textbf{(i)} below for the proof.)

\href{https://en.wikipedia.org/wiki/Modulo_(jargon)}{The word
\textquotedblleft modulo\textquotedblright}\ in the phrase \textquotedblleft%
$a$ is congruent to $b$ modulo $n$\textquotedblright\ is due to Gauss and
means something like \textquotedblleft with respect to\textquotedblright. You
should think of \textquotedblleft$a$ is congruent to $b$ modulo $n$%
\textquotedblright\ as a relation between all three of the numbers $a$, $b$
and $n$, but $a$ and $b$ are the \textquotedblleft main
characters\textquotedblright\ and $n$ sets the scene.

\begin{exercise}
\label{exe.ent.mod.a+b=a-b}Let $a,b\in\mathbb{Z}$. Prove that $a+b\equiv
a-b\operatorname{mod}2$.
\end{exercise}

We begin with a proposition so fundamental that we will always use it without saying:

\begin{proposition}
\label{prop.ent.mod.0}Let $n\in\mathbb{Z}$ and $a\in\mathbb{Z}$. Then,
$a\equiv0\operatorname{mod}n$ if and only if $n\mid a$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.mod.0}.]We have the following chain of
equivalences:%
\begin{align*}
\left(  a\equiv0\operatorname{mod}n\right)  \  &  \Longleftrightarrow\ \left(
n\mid a-0\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Definition
\ref{def.ent.cong}}\right) \\
&  \Longleftrightarrow\ \left(  n\mid a\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }a-0=a\right)  .
\end{align*}
This proves Proposition \ref{prop.ent.mod.0}.
\end{proof}

Next come some staple properties of congruences:

\begin{proposition}
\label{prop.ent.mod.basics}Let $n\in\mathbb{Z}$.

\textbf{(a)} We have $a\equiv a\operatorname{mod}n$ for every $a\in\mathbb{Z}$.

\textbf{(b)} If $a,b,c\in\mathbb{Z}$ satisfy $a\equiv b\operatorname{mod}n$
and $b\equiv c\operatorname{mod}n$, then $a\equiv c\operatorname{mod}n$.

\textbf{(c)} If $a,b\in\mathbb{Z}$ satisfy $a\equiv b\operatorname{mod}n$,
then $b\equiv a\operatorname{mod}n$.

\textbf{(d)} If $a_{1},a_{2},b_{1},b_{2}\in\mathbb{Z}$ satisfy $a_{1}\equiv
b_{1}\operatorname{mod}n$ and $a_{2}\equiv b_{2}\operatorname{mod}n$, then%
\begin{align}
a_{1}+a_{2}  &  \equiv b_{1}+b_{2}\operatorname{mod}%
n;\label{eq.prop.ent.mod.basics.d.1}\\
a_{1}-a_{2}  &  \equiv b_{1}-b_{2}\operatorname{mod}%
n;\label{eq.prop.ent.mod.basics.d.2}\\
a_{1}a_{2}  &  \equiv b_{1}b_{2}\operatorname{mod}n.
\label{eq.prop.ent.mod.basics.d.3}%
\end{align}


\textbf{(e)} Let $m\in\mathbb{Z}$ be such that $m\mid n$. If $a,b\in
\mathbb{Z}$ satisfy $a\equiv b\operatorname{mod}n$, then $a\equiv
b\operatorname{mod}m$.
\end{proposition}

\begin{proof}
\textbf{(a)} Let $a\in\mathbb{Z}$. Recall that $a\equiv a\operatorname{mod}n$
is defined to mean $n\mid a-a$. Since $n\mid a-a$ holds (because
$a-a=0=n\cdot0$), we thus see that $a\equiv a\operatorname{mod}n$ holds. This
proves Proposition \ref{prop.ent.mod.basics} \textbf{(a)}.

\textbf{(b)} Let $a,b,c\in\mathbb{Z}$ satisfy $a\equiv b\operatorname{mod}n$
and $b\equiv c\operatorname{mod}n$.

We have $a\equiv b\operatorname{mod}n$. In other words, $n\mid a-b$ (by
Definition \ref{def.ent.cong}). In other words, there exists an integer $p$
such that $a-b=np$ (by Definition \ref{def.ent.div.div}). Consider this $p$.

We have $b\equiv c\operatorname{mod}n$. In other words, $n\mid b-c$ (by
Definition \ref{def.ent.cong}). In other words, there exists an integer $q$
such that $b-c=nq$ (by Definition \ref{def.ent.div.div}). Consider this $q$.

Now,
\[
a-c=\underbrace{\left(  a-b\right)  }_{=np}+\underbrace{\left(  b-c\right)
}_{=nq}=np+nq=n\left(  p+q\right)  .
\]
Hence, there exists an integer $r$ such that $a-c=nr$ (namely, $r=p+q$). In
other words, $n\mid a-c$ (by Definition \ref{def.ent.div.div}). In other
words, $a\equiv c\operatorname{mod}n$ (by Definition \ref{def.ent.cong}). This
proves Proposition \ref{prop.ent.mod.basics} \textbf{(b)}.

\textbf{(c)} Let $a,b\in\mathbb{Z}$ satisfy $a\equiv b\operatorname{mod}n$.

We have $a\equiv b\operatorname{mod}n$. In other words, $n\mid a-b$ (by
Definition \ref{def.ent.cong}). In other words, there exists an integer $p$
such that $a-b=np$ (by Definition \ref{def.ent.div.div}). Consider this $p$.
Now,%
\[
b-a=-\underbrace{\left(  a-b\right)  }_{=np}=-np=n\left(  -p\right)  .
\]
Hence, there exists an integer $c$ such that $b-a=nc$ (namely, $c=-p$). In
other words, $n\mid b-a$ (by Definition \ref{def.ent.div.div}). In other
words, $b\equiv a\operatorname{mod}n$ (by Definition \ref{def.ent.cong}). This
proves Proposition \ref{prop.ent.mod.basics} \textbf{(c)}.

\textbf{(d)} Let $a_{1},a_{2},b_{1},b_{2}\in\mathbb{Z}$ satisfy $a_{1}\equiv
b_{1}\operatorname{mod}n$ and $a_{2}\equiv b_{2}\operatorname{mod}n$.

We have $a_{1}\equiv b_{1}\operatorname{mod}n$. In other words, $n\mid
a_{1}-b_{1}$ (by Definition \ref{def.ent.cong}). In other words, there exists
an integer $p$ such that $a_{1}-b_{1}=np$ (by Definition \ref{def.ent.div.div}%
). Consider this $p$.

We have $a_{2}\equiv b_{2}\operatorname{mod}n$. In other words, $n\mid
a_{2}-b_{2}$ (by Definition \ref{def.ent.cong}). In other words, there exists
an integer $q$ such that $a_{2}-b_{2}=nq$ (by Definition \ref{def.ent.div.div}%
). Consider this $q$.

We have%
\[
\left(  a_{1}+a_{2}\right)  -\left(  b_{1}+b_{2}\right)  =\underbrace{\left(
a_{1}-b_{1}\right)  }_{=np}+\underbrace{\left(  a_{2}-b_{2}\right)  }%
_{=nq}=np+nq=n\left(  p+q\right)  .
\]
Hence, there exists an integer $c$ such that $\left(  a_{1}+a_{2}\right)
-\left(  b_{1}+b_{2}\right)  =nc$ (namely, $c=p+q$). In other words,
$n\mid\left(  a_{1}+a_{2}\right)  -\left(  b_{1}+b_{2}\right)  $ (by
Definition \ref{def.ent.div.div}). In other words, $a_{1}+a_{2}\equiv
b_{1}+b_{2}\operatorname{mod}n$ (by Definition \ref{def.ent.cong}). A similar
argument (using $p-q$ instead of $p+q$) shows that $a_{1}-a_{2}\equiv
b_{1}-b_{2}\operatorname{mod}n$. It thus remains to show that $a_{1}%
a_{2}\equiv b_{1}b_{2}\operatorname{mod}n$.

Let us first show that $a_{1}a_{2}\equiv a_{1}b_{2}\operatorname{mod}n$.
Indeed, $a_{1}a_{2}-a_{1}b_{2}=a_{1}\underbrace{\left(  a_{2}-b_{2}\right)
}_{=nq}=a_{1}nq=n\left(  a_{1}q\right)  $. Hence, there exists an integer $c$
such that $a_{1}a_{2}-a_{1}b_{2}=nc$ (namely, $c=a_{1}q$). In other words,
$n\mid a_{1}a_{2}-a_{1}b_{2}$ (by Definition \ref{def.ent.div.div}). In other
words, $a_{1}a_{2}\equiv a_{1}b_{2}\operatorname{mod}n$ (by Definition
\ref{def.ent.cong}).

Next, let us show that $a_{1}b_{2}\equiv b_{1}b_{2}\operatorname{mod}n$.
Indeed, $a_{1}b_{2}-b_{1}b_{2}=b_{2}\underbrace{\left(  a_{1}-b_{1}\right)
}_{=np}=b_{2}np=n\left(  b_{2}p\right)  $. Hence, there exists an integer $c$
such that $a_{1}b_{2}-b_{1}b_{2}=nc$ (namely, $c=b_{2}p$). In other words,
$n\mid a_{1}b_{2}-b_{1}b_{2}$ (by Definition \ref{def.ent.div.div}). In other
words, $a_{1}b_{2}\equiv b_{1}b_{2}\operatorname{mod}n$ (by Definition
\ref{def.ent.cong}).

From $a_{1}a_{2}\equiv a_{1}b_{2}\operatorname{mod}n$ and $a_{1}b_{2}\equiv
b_{1}b_{2}\operatorname{mod}n$, we now conclude that $a_{1}a_{2}\equiv
b_{1}b_{2}\operatorname{mod}n$ (by Proposition \ref{prop.ent.mod.basics}
\textbf{(c)}, applied to $a=a_{1}a_{2}$, $b=a_{1}b_{2}$ and $c=b_{1}b_{2}$).
This completes the proof of Proposition \ref{prop.ent.mod.basics} \textbf{(d)}.

\textbf{(e)} Let $a,b\in\mathbb{Z}$ satisfy $a\equiv b\operatorname{mod}n$.

We have $a\equiv b\operatorname{mod}n$. In other words, $n\mid a-b$ (by
Definition \ref{def.ent.cong}). From $m\mid n$ and $n\mid a-b$, we obtain
$m\mid a-b$ (by Proposition \ref{prop.ent.div.2} \textbf{(b)}, applied to $m$,
$n$ and $a-b$ instead of $a$, $b$ and $c$). In other words, $a\equiv
b\operatorname{mod}m$ (by Definition \ref{def.ent.cong}). This proves
Proposition \ref{prop.ent.mod.basics} \textbf{(e)}.
\end{proof}

In the above proof, we took care to explicitly cite Definition
\ref{def.ent.div.div} and Definition \ref{def.ent.cong} whenever we used them;
in the following, we will omit references like this.

Proposition \ref{prop.ent.mod.basics} \textbf{(d)} is saying that congruences
modulo $n$ (for a fixed integer $n$) can be added, subtracted and multiplied
together. This does not mean that you can do everything with them that you can
do with equalities. The next exercise shows that dividing congruences and
taking a congruence to the power of another does not generally work:

\begin{exercise}
\label{exe.ent.mod.basics-nope}Let $n,a_{1},a_{2},b_{1},b_{2}\in\mathbb{Z}$
satisfy $a_{1}\equiv b_{1}\operatorname{mod}n$ and $a_{2}\equiv b_{2}%
\operatorname{mod}n$. Then, \textbf{in general}, neither $a_{1}/a_{2}\equiv
b_{1}/b_{2}\operatorname{mod}n$ nor $a_{1}^{a_{2}}\equiv b_{1}^{b_{2}%
}\operatorname{mod}n$ is necessarily true. Of course, this is partly due to
the fact that $a_{1}/a_{2}$, $b_{1}/b_{2}$ and $a_{1}^{a_{2}}$ and
$b_{1}^{b_{2}}$ are not always integers in the first place (and being
congruent modulo $n$ only makes sense for integers, at least for now). But
even when $a_{1}/a_{2}$, $b_{1}/b_{2}$ and $a_{1}^{a_{2}}$ and $b_{1}^{b_{2}}$
are integers, the congruences $a_{1}/a_{2}\equiv b_{1}/b_{2}\operatorname{mod}%
n$ and $a_{1}^{a_{2}}\equiv b_{1}^{b_{2}}\operatorname{mod}n$ are often false.
Find examples of $n,a_{1},a_{2},b_{1},b_{2}$ such that $a_{1}/a_{2}$,
$b_{1}/b_{2}$ and $a_{1}^{a_{2}}$ and $b_{1}^{b_{2}}$ are integers but the
congruences $a_{1}/a_{2}\equiv b_{1}/b_{2}\operatorname{mod}n$ and
$a_{1}^{a_{2}}\equiv b_{1}^{b_{2}}\operatorname{mod}n$ are false.
\end{exercise}

However, we can divide a congruence $a\equiv b\operatorname{mod}n$ by a
nonzero integer $d$ when all of $a,b,n$ are divisible by $d$:

\begin{exercise}
\label{exe.ent.mod.basics.2}Let $n,d,a,b\in\mathbb{Z}$, and assume that
$d\neq0$. Assume that $d$ divides each of $a,b,n$, and assume that $a\equiv
b\operatorname{mod}n$. Prove that $a/d\equiv b/d\operatorname{mod}n/d$.
\end{exercise}

We can also take a congruence to the $k$-th power when $k\in\mathbb{N}$:

\begin{exercise}
\label{exe.ent.mod.basics.k-power}Let $n,a,b\in\mathbb{Z}$ be such that
$a\equiv b\operatorname{mod}n$. Prove that $a^{k}\equiv b^{k}%
\operatorname{mod}n$ for each $k\in\mathbb{N}$.
\end{exercise}

(Note that the \textquotedblleft$n$\textquotedblright\ is not being taken to
the $k$-th power here.)

We can add not just two, but any number of congruences (where
\textquotedblleft number\textquotedblright\ means \textquotedblleft finite
number\textquotedblright):

\begin{exercise}
\label{exe.ent.mod.k-sum}Let $n$ be an integer. Let $S$ be a finite set. For
each $s\in S$, let $a_{s}$ and $b_{s}$ be two integers. Assume that%
\begin{equation}
a_{s}\equiv b_{s}\operatorname{mod}n\ \ \ \ \ \ \ \ \ \ \text{for each }s\in
S. \label{eq.exe.ent.mod.k-sum.ass}%
\end{equation}


\textbf{(a)} Prove that%
\begin{equation}
\sum_{s\in S}a_{s}\equiv\sum_{s\in S}b_{s}\operatorname{mod}n.
\label{eq.exe.ent.mod.k-sum.a}%
\end{equation}


\textbf{(b)} Prove that
\begin{equation}
\prod_{s\in S}a_{s}\equiv\prod_{s\in S}b_{s}\operatorname{mod}n.
\label{eq.exe.ent.mod.k-sum.b}%
\end{equation}


(Keep in mind that if the set $S$ is empty, then $\sum_{s\in S}a_{s}%
=\sum_{s\in S}b_{s}=0$ and $\prod_{s\in S}a_{s}=\prod_{s\in S}b_{s}=1$; this
holds by the definition of empty sums and of empty products.)
\end{exercise}

\begin{exercise}
\label{exe.ent.mod.prod-wrong}Is it true that if $a_{1},a_{2},b_{1}%
,b_{2},n_{1},n_{2}\in\mathbb{Z}$ satisfy $a_{1}\equiv b_{1}\operatorname{mod}%
n_{1}$ and $a_{2}\equiv b_{2}\operatorname{mod}n_{2}$, then $a_{1}a_{2}\equiv
b_{1}b_{2}\operatorname{mod}n_{1}n_{2}$ ?
\end{exercise}

\begin{exercise}
\label{exe.ent.mod.a+nd}Let $a,b,n\in\mathbb{Z}$. Prove that $a\equiv
b\operatorname{mod}n$ if and only if there exists some $d\in\mathbb{Z}$ such
that $b=a+nd$.
\end{exercise}

\begin{exercise}
\label{exe.ent.mod.diff}Let $a,b,c,n\in\mathbb{Z}$. Prove that we have
$a-b\equiv c\operatorname{mod}n$ if and only if $a\equiv b+c\operatorname{mod}%
n$.
\end{exercise}

\begin{exercise}
\label{exe.ent.mod.-}Let $a,b,n\in\mathbb{Z}$. Prove that $a\equiv
b\operatorname{mod}n$ if and only if $a\equiv b\operatorname{mod}-n$.
\end{exercise}

\subsection{\label{sect.ent.subst-chain}Chains of congruences}

For this whole Section \ref{sect.ent.subst-chain}, we fix an integer $n$.

Chains of equalities are a fundamental piece of notation used throughout
mathematics. For example, here is a chain of equalities:%
\begin{align*}
&  \left(  ad+bc\right)  ^{2}+\left(  ac-bd\right)  ^{2}\\
&  =\left(  ad\right)  ^{2}+2ad\cdot bc+\left(  bc\right)  ^{2}+\left(
ac\right)  ^{2}-2ac\cdot bd+\left(  bd\right)  ^{2}\\
&  =a^{2}d^{2}+2abcd+b^{2}c^{2}+a^{2}c^{2}-2abcd+b^{2}d^{2}\\
&  =a^{2}c^{2}+a^{2}d^{2}+b^{2}c^{2}+b^{2}d^{2}\\
&  =\left(  a^{2}+b^{2}\right)  \left(  c^{2}+d^{2}\right)
\end{align*}
(where $a,b,c,d$ are arbitrary numbers). This chain proves the equality
(\ref{eq.intro.sum-of-2sq.sum*sum}). But why does it really? If we look
closely at this chain of equalities, we see that it has the form
\textquotedblleft$A=B=C=D=E$\textquotedblright, where $A,B,C,D,E$ are five
numbers (namely, $A=\left(  ad+bc\right)  ^{2}+\left(  ac-bd\right)  ^{2}$ and
$B=\left(  ad\right)  ^{2}+2ad\cdot bc+\left(  bc\right)  ^{2}+\left(
ac\right)  ^{2}-2ac\cdot bd+\left(  bd\right)  ^{2}$ and so on). This kind of
statement is called a \textquotedblleft chain of equalities\textquotedblright,
and, a priori, it simply means that any two \textbf{adjacent} numbers in this
chain are equal: $A=B$ and $B=C$ and $C=D$ and $D=E$. Without as much as
noticing it, we have concluded that \textbf{any} two numbers in this chain are
equal; thus, in particular, $A=E$, which is precisely the equality
(\ref{eq.intro.sum-of-2sq.sum*sum}) we wanted to prove.

That this kind of \textquotedblleft chaining\textquotedblright\ is possible is
one of the most basic facts in mathematics. Let us define a chain of
equalities formally:

\begin{definition}
If $a_{1},a_{2},\ldots,a_{k}$ are $k$ objects\footnotemark, then the statement
\textquotedblleft$a_{1}=a_{2}=\cdots=a_{k}$\textquotedblright\ shall mean
that
\[
a_{i}=a_{i+1}\text{ holds for each }i\in\left\{  1,2,\ldots,k-1\right\}  .
\]
(In other words, it shall mean that $a_{1}=a_{2}$ and $a_{2}=a_{3}$ and
$a_{3}=a_{4}$ and $\cdots$ and $a_{k-1}=a_{k}$. This is vacuously true when
$k\leq1$. If $k=2$, then it simply means that $a_{1}=a_{2}$.)

Such a statement will be called a \textit{chain of equalities}.
\end{definition}

\footnotetext{\textquotedblleft Objects\textquotedblright\ can be numbers,
sets, tuples or any other well-defined things in mathematics.}

\begin{proposition}
\label{prop.mod.chain-eq}Let $a_{1},a_{2},\ldots,a_{k}$ be $k$ objects such
that $a_{1}=a_{2}=\cdots=a_{k}$. Let $u$ and $v$ be two elements of $\left\{
1,2,\ldots,k\right\}  $. Then, $a_{u}=a_{v}$.
\end{proposition}

So we have defined a chain of equalities to be true if and only if any two
adjacent terms in this chain are equal (i.e., if \textquotedblleft each
equality sign in the chain is satisfied\textquotedblright). Proposition
\ref{prop.mod.chain-eq} shows that in such a chain, \textbf{any two} terms are
equal. This is intuitively rather clear, but can also be formally proven by
induction using the basic properties of equality
(transitivity\footnote{\textit{Transitivity of equality} says that if $a,b,c$
are three objects satisfying $a=b$ and $b=c$, then $a=c$.},
reflexivity\footnote{\textit{Reflexivity of equality} says that every object
$a$ satisfies $a=a$.} and symmetry\footnote{\textit{Symmetry of equality} says
that if $a,b$ are two objects satisfying $a=b$, then $b=a$.}).

But our goal is to understand basic number theory, not to scrutinize the
foundations of mathematics. So let us recall that we have fixed an integer
$n$, and consider congruences modulo $n$. We claim that these can be chained
just as equalities:

\begin{definition}
\label{def.mod.chain}If $a_{1},a_{2},\ldots,a_{k}$ are $k$ integers, then the
statement \textquotedblleft$a_{1}\equiv a_{2}\equiv\cdots\equiv a_{k}%
\operatorname{mod}n$\textquotedblright\ shall mean that
\[
a_{i}\equiv a_{i+1}\operatorname{mod}n\text{ holds for each }i\in\left\{
1,2,\ldots,k-1\right\}  .
\]
(In other words, it shall mean that $a_{1}\equiv a_{2}\operatorname{mod}n$ and
$a_{2}\equiv a_{3}\operatorname{mod}n$ and $a_{3}\equiv a_{4}%
\operatorname{mod}n$ and $\cdots$ and $a_{k-1}\equiv a_{k}\operatorname{mod}%
n$. This is vacuously true when $k\leq1$. If $k=2$, then it simply means that
$a_{1}\equiv a_{2}\operatorname{mod}n$.)

Such a statement will be called a \textit{chain of congruences modulo }$n$.
\end{definition}

\begin{proposition}
\label{prop.mod.chain}Let $a_{1},a_{2},\ldots,a_{k}$ be $k$ integers such that
$a_{1}\equiv a_{2}\equiv\cdots\equiv a_{k}\operatorname{mod}n$. Let $u$ and
$v$ be two elements of $\left\{  1,2,\ldots,k\right\}  $. Then, $a_{u}\equiv
a_{v}\operatorname{mod}n$.
\end{proposition}

Proposition \ref{prop.mod.chain} shows that any two terms in a chain of
congruences modulo $n$ must be congruent to each other modulo $n$. Again, this
can be formally proven by induction; see \cite[proof of Proposition
2.16]{detnotes}. The ingredients of the proof are basic properties of
congruence modulo $n$: transitivity, reflexivity and symmetry. These are fancy
names for parts \textbf{(b)}, \textbf{(a)} and \textbf{(c)} of Proposition
\ref{prop.ent.mod.basics}.

We will use Proposition \ref{prop.mod.chain} tacitly (just as you would use
Proposition \ref{prop.mod.chain-eq}): i.e., every time we prove a chain of
congruences like $a_{1}\equiv a_{2}\equiv\cdots\equiv a_{k}\operatorname{mod}%
n$, we assume that the reader will automatically conclude that any two of its
terms are congruent to each other modulo $n$ (and will remember this
conclusion). For instance, if we show that $1\equiv4\equiv34\equiv
334\equiv304\operatorname{mod}3$, then we automatically get the congruences
$1\equiv304\operatorname{mod}3$ and $334\equiv1\operatorname{mod}3$ and
$4\equiv334\operatorname{mod}3$ and several others out of this chain.

Chains of congruences can also include equality signs. For example, if
$a,b,c,d$ are integers, then \textquotedblleft$a\equiv b=c\equiv
d\operatorname{mod}n$\textquotedblright\ means that $a\equiv
b\operatorname{mod}n$ and $b=c$ and $c\equiv d\operatorname{mod}n$. Such a
chain is still a chain of congruences, because $b=c$ implies $b\equiv
c\operatorname{mod}n$ (by Proposition \ref{prop.ent.mod.basics} \textbf{(a)}).

Just as there are chains of equalities and chains of congruences, there are
chains of divisibilities:

\begin{definition}
If $a_{1},a_{2},\ldots,a_{k}$ are $k$ integers, then the statement
\textquotedblleft$a_{1}\mid a_{2}\mid\cdots\mid a_{k}$\textquotedblright%
\ shall mean that
\[
a_{i}\mid a_{i+1}\text{ holds for each }i\in\left\{  1,2,\ldots,k-1\right\}
.
\]
(In other words, it shall mean that $a_{1}\mid a_{2}$ and $a_{2}\mid a_{3}$
and $a_{3}\mid a_{4}$ and $\cdots$ and $a_{k-1}\mid a_{k}$. This is vacuously
true when $k\leq1$. If $k=2$, then it simply means that $a_{1}\mid a_{2}$.)

Such a statement will be called a \textit{chain of divisibilities}.
\end{definition}

\begin{proposition}
\label{prop.ent.div.chain}Let $a_{1},a_{2},\ldots,a_{k}$ be $k$ integers such
that $a_{1}\mid a_{2}\mid\cdots\mid a_{k}$. Let $u$ and $v$ be two elements of
$\left\{  1,2,\ldots,k\right\}  $ such that $u\leq v$. Then, $a_{u}\mid a_{v}$.
\end{proposition}

Note that we had to require $u\leq v$ in this proposition, unlike the
analogous propositions for chains of equalities and chains of congruences,
because there is no \textquotedblleft symmetry of
divisibility\textquotedblright\ (i.e., if $a\mid b$, then we don't generally
have $b\mid a$). The proof of Proposition \ref{prop.ent.div.chain} relies on
the reflexivity of divisibility (Proposition \ref{prop.ent.div.2}
\textbf{(a)}) and on the transitivity of divisibility (Proposition
\ref{prop.ent.div.2} \textbf{(b)}).

Again, chains of divisibilities can include equality signs. For example,
$4\mid3\cdot4=12=2\cdot6\mid4\cdot6=24$.

\subsection{\label{sect.ent.subst-mod}Substitutivity for congruences}

In\ Section \ref{sect.ent.subst-chain}, we have learnt that congruences modulo
an integer $n$ can be chained together like equalities. A further important
feature of congruences is the principle of \textit{substitutivity for
congruences}. This is yet another way in which congruences behave like
equalities. We are not going to state it fully formally (as it is a
meta-mathematical principle), but merely explain its meaning. Later on, once
we understand what the rings $\mathbb{Z}/n$ (for integer $n$) are, we will no
longer need this principle, since it will just boil down to \textquotedblleft
equal things can be substituted for one another\textquotedblright\ (the whole
point of $\mathbb{Z}/n$ is to \textquotedblleft make congruent numbers
equal\textquotedblright); but for now, we cannot treat \textquotedblleft
congruent modulo $n$\textquotedblright\ as \textquotedblleft
equal\textquotedblright, so we have to state it.

You are probably used to making computations like these:%
\begin{align*}
\underbrace{\left(  a+b\right)  ^{2}}_{=a^{2}+2ab+b^{2}}+\underbrace{\left(
a-b\right)  ^{2}}_{=a^{2}-2ab+b^{2}}  &  =\left(  a^{2}+2ab+b^{2}\right)
+\left(  a^{2}-2ab+b^{2}\right) \\
&  =\underbrace{a^{2}+a^{2}}_{=2a^{2}}+\underbrace{b^{2}+b^{2}}_{=2b^{2}%
}=2a^{2}+2b^{2}%
\end{align*}
(for any two numbers $a$ and $b$). What is going on in these underbraces (like
\textquotedblleft$\underbrace{\left(  a+b\right)  ^{2}}_{=a^{2}+2ab+b^{2}}%
$\textquotedblright)? Something pretty simple is going on: You are replacing a
number (in this case, $\left(  a+b\right)  ^{2}$) by an equal number (in this
case, $a^{2}+2ab+b^{2}$). This relies on a fundamental principle of
mathematics (called the \textit{principle of substitutivity for equalities}),
which says that an object in an expression can indeed be replaced by any
object equal to it (without changing the value of the expression). (This is
also known as \textit{Leibniz's equality law}.) To be precise, we are using
this principle twice in some of our equality signs above, since we are making
several replacements at the same time; but this is fine (we can just do the
replacement one by one instead).

We would like to have a similar principle for congruences modulo $n$: We would
like to be able to replace any integer by an integer congruent to it modulo
$n$. For example, we would like to be able to say that if seven integers
$a,a^{\prime},b,b^{\prime},c,c^{\prime},n$ satisfy $a\equiv a^{\prime
}\operatorname{mod}n$ and $b\equiv b^{\prime}\operatorname{mod}n$ and $c\equiv
c^{\prime}\operatorname{mod}n$, then%
\[
\underbrace{b}_{\equiv b^{\prime}\operatorname{mod}n}\ \ \underbrace{c}%
_{\equiv c^{\prime}\operatorname{mod}n}+\underbrace{c}_{\equiv c^{\prime
}\operatorname{mod}n}\ \ \underbrace{a}_{\equiv a^{\prime}\operatorname{mod}%
n}+\underbrace{a}_{\equiv a^{\prime}\operatorname{mod}n}\ \ \underbrace{b}%
_{\equiv b^{\prime}\operatorname{mod}n}\equiv b^{\prime}c^{\prime}+c^{\prime
}a^{\prime}+a^{\prime}b^{\prime}\operatorname{mod}n.
\]


We have to be careful with this: For example, we run into troubles if division
is involved in our expressions. For example, we have $6\equiv
9\operatorname{mod}3$, but we do not have $\underbrace{6}_{\equiv
9\operatorname{mod}3}/3\equiv9/3\operatorname{mod}3$. Similarly,
exponentiation can be problematic. So we need to state the principle we are
using here in clearer terms, so that we know what we can do.

For this whole Section \ref{sect.ent.subst-mod}, we fix an integer $n$.

The \textit{principle of substitutivity for equalities} says the following:

\begin{statement}
\textit{Principle of substitutivity for equalities (PSE):} If two objects $x$
and $x^{\prime}$ are equal, and if we have any expression $A$ that involves
the object $x$, then we can replace this $x$ (or, more precisely, any
arbitrary appearance of $x$ in $A$) in $A$ by $x^{\prime}$; the value of the
resulting expression $A^{\prime}$ will equal the value of $A$.
\end{statement}

Here are two examples of how this principle can be used:

\begin{itemize}
\item If $a,b,c,d,e,c^{\prime}$ are numbers such that $c=c^{\prime}$, then the
PSE says that we can replace $c$ by $c^{\prime}$ in the expression $a\left(
b-\left(  c+d\right)  e\right)  $, and the value of the resulting expression
$a\left(  b-\left(  c^{\prime}+d\right)  e\right)  $ will equal the value of
$a\left(  b-\left(  c+d\right)  e\right)  $; that is, we have%
\begin{equation}
a\left(  b-\left(  c+d\right)  e\right)  =a\left(  b-\left(  c^{\prime
}+d\right)  e\right)  . \label{eq.mod.substitutivity-nums.1}%
\end{equation}


\item If $a,b,c,a^{\prime}$ are numbers such that $a=a^{\prime}$, then
\begin{equation}
\left(  a-b\right)  \left(  a+b\right)  =\left(  a^{\prime}-b\right)  \left(
a+b\right)  , \label{eq.mod.substitutivity-nums.2}%
\end{equation}
because the PSE allows us to replace the first $a$ appearing in the expression
$\left(  a-b\right)  \left(  a+b\right)  $ by an $a^{\prime}$. (We can also
replace the second $a$ by $a^{\prime}$, of course.)
\end{itemize}

More generally, we can make several such replacements at the same time.

The PSE is one of the headstones of mathematical logic; it is the essence of
what it means for two objects to be equal.

The \textit{principle of substitutivity for congruences} is similar, but far
less fundamental; it says the following:

\begin{statement}
\textit{Principle of substitutivity for congruences (PSC):} If two numbers $x$
and $x^{\prime}$ are congruent to each other modulo $n$ (that is, $x\equiv
x^{\prime}\operatorname{mod}n$), and if we have any expression $A$ that
involves only integers, addition, subtraction and multiplication, and involves
the object $x$, then we can replace this $x$ (or, more precisely, any
arbitrary appearance of $x$ in $A$) in $A$ by $x^{\prime}$; the value of the
resulting expression $A^{\prime}$ will be congruent to the value of $A$ modulo
$n$.
\end{statement}

This principle is less general than the PSE, since it only applies to
expressions that are built from integers and certain operations (note that
division is not one of these operations). But it still lets us prove analogues
of our above examples (\ref{eq.mod.substitutivity-nums.1}) and
(\ref{eq.mod.substitutivity-nums.2}):

\begin{itemize}
\item If $a,b,c,d,e,c^{\prime}$ are integers such that $c\equiv c^{\prime
}\operatorname{mod}n$, then the PSC says that we can replace $c$ by
$c^{\prime}$ in the expression $a\left(  b-\left(  c+d\right)  e\right)  $,
and the value of the resulting expression $a\left(  b-\left(  c^{\prime
}+d\right)  e\right)  $ will be congruent to the value of $a\left(  b-\left(
c+d\right)  e\right)  $ modulo $n$; that is, we have%
\begin{equation}
a\left(  b-\left(  c+d\right)  e\right)  \equiv a\left(  b-\left(  c^{\prime
}+d\right)  e\right)  \operatorname{mod}n.
\label{eq.mod.substitutivity-congs.1}%
\end{equation}


\item If $a,b,c,a^{\prime}$ are integers such that $a\equiv a^{\prime
}\operatorname{mod}n$, then
\begin{equation}
\left(  a-b\right)  \left(  a+b\right)  \equiv\left(  a^{\prime}-b\right)
\left(  a+b\right)  \operatorname{mod}n, \label{eq.mod.substitutivity-congs.2}%
\end{equation}
because the PSC allows us to replace the first $a$ appearing in the expression
$\left(  a-b\right)  \left(  a+b\right)  $ by an $a^{\prime}$. (We can also
replace the second $a$ by $a^{\prime}$, of course.)
\end{itemize}

We shall not prove the PSC, since we have not formalized it (after all, we
have not defined what an \textquotedblleft expression\textquotedblright\ is).
But we shall prove the specific congruences
(\ref{eq.mod.substitutivity-congs.1}) and (\ref{eq.mod.substitutivity-congs.2}%
) using Proposition \ref{prop.ent.mod.basics}; the way in which we prove these
congruences is symptomatic: Every congruence obtained from the PSC can be
proven in a manner like these. Thus, the proofs of
(\ref{eq.mod.substitutivity-congs.1}) and (\ref{eq.mod.substitutivity-congs.2}%
) given below can serve as templates which can easily be adapted to any other
situation in which an application of the PSC needs to be justified.

\begin{proof}
[Proof of (\ref{eq.mod.substitutivity-congs.1}).]Let $n$ be any integer, and
let $a,b,c,d,e,c^{\prime}$ be integers such that $c\equiv c^{\prime
}\operatorname{mod}n$.

Adding the congruence\footnote{Proposition \ref{prop.ent.mod.basics}
\textbf{(d)} shows that we can add, subtract and multiply congruences modulo
$n$ at will. We are using this freedom here and will use it many times below.}
$c\equiv c^{\prime}\operatorname{mod}n$ with the congruence $d\equiv
d\operatorname{mod}n$ (which follows from Proposition
\ref{prop.ent.mod.basics} \textbf{(a)}), we obtain $c+d\equiv c^{\prime
}+d\operatorname{mod}n$. Multiplying this congruence with the congruence
$e\equiv e\operatorname{mod}n$ (which follows from Proposition
\ref{prop.ent.mod.basics} \textbf{(a)}), we obtain $\left(  c+d\right)
e\equiv\left(  c^{\prime}+d\right)  e\operatorname{mod}n$. Subtracting this
congruence from the congruence $b\equiv b\operatorname{mod}n$ (which, again,
follows from Proposition \ref{prop.ent.mod.basics} \textbf{(a)}), we obtain
$b-\left(  c+d\right)  e\equiv b-\left(  c^{\prime}+d\right)
e\operatorname{mod}n$. Multiplying the congruence $a\equiv a\operatorname{mod}%
n$ (which follows from Proposition \ref{prop.ent.mod.basics} \textbf{(a)})
with this congruence, we obtain $a\left(  b-\left(  c+d\right)  e\right)
\equiv a\left(  b-\left(  c^{\prime}+d\right)  e\right)  \operatorname{mod}n$.
This proves (\ref{eq.mod.substitutivity-congs.1}).
\end{proof}

\begin{proof}
[Proof of (\ref{eq.mod.substitutivity-congs.2}).]Let $n$ be any integer, and
let $a,b,c,a^{\prime}$ be integers such that $a\equiv a^{\prime}%
\operatorname{mod}n$.

Subtracting the congruence $b\equiv b\operatorname{mod}n$ (which follows from
Proposition \ref{prop.ent.mod.basics} \textbf{(a)}) from the congruence
$a\equiv a^{\prime}\operatorname{mod}n$, we obtain $a-b\equiv a^{\prime
}-b\operatorname{mod}n$. Multiplying this congruence with the congruence
$a+b\equiv a+b\operatorname{mod}n$ (which follows from Proposition
\ref{prop.ent.mod.basics} \textbf{(a)}), we obtain $\left(  a-b\right)
\left(  a+b\right)  \equiv\left(  a^{\prime}-b\right)  \left(  a+b\right)
\operatorname{mod}n$. This proves (\ref{eq.mod.substitutivity-congs.2}).
\end{proof}

As we said, these two proofs are exemplary: Any congruence obtained from the
PSC can be proven in such a way (starting with the congruence $x\equiv
x^{\prime}\operatorname{mod}n$, and then \textquotedblleft
wrapping\textquotedblright\ it up in the expression $A$ by repeatedly adding,
multiplying and subtracting congruences that follow from Proposition
\ref{prop.ent.mod.basics} \textbf{(a)}).

When we apply the PSC, we shall use underbraces to point out which integers we
are replacing. For example, when deriving (\ref{eq.mod.substitutivity-congs.1}%
) from this principle, we shall write%
\[
a\left(  b-\left(  \underbrace{c}_{\equiv c^{\prime}\operatorname{mod}%
n}+d\right)  e\right)  \equiv a\left(  b-\left(  c^{\prime}+d\right)
e\right)  \operatorname{mod}n,
\]
in order to stress that we are replacing $c$ by $c^{\prime}$. Likewise, when
deriving (\ref{eq.mod.substitutivity-congs.2}) from the PSC, we shall write%
\[
\left(  \underbrace{a}_{\equiv a^{\prime}\operatorname{mod}n}-b\right)
\left(  a+b\right)  \equiv\left(  a^{\prime}-b\right)  \left(  a+b\right)
\operatorname{mod}n,
\]
in order to stress that we are replacing the first $a$ (but not the second
$a$) by $a^{\prime}$.

The PSC allows us to replace a \textbf{single} integer $x$ appearing in an
expression by another integer $x^{\prime}$ that is congruent to $x$ modulo
$n$. Applying this principle many times, we thus conclude that we can also
replace \textbf{several} integers at the same time (because we can get to the
same result by performing these replacements one at a time, and Proposition
\ref{prop.mod.chain} shows that the value of the final result will be
congruent to the value of the original result). For example, if seven integers
$a,a^{\prime},b,b^{\prime},c,c^{\prime},n$ satisfy $a\equiv a^{\prime
}\operatorname{mod}n$ and $b\equiv b^{\prime}\operatorname{mod}n$ and $c\equiv
c^{\prime}\operatorname{mod}n$, then%
\begin{equation}
bc+ca+ab\equiv b^{\prime}c^{\prime}+c^{\prime}a^{\prime}+a^{\prime}b^{\prime
}\operatorname{mod}n, \label{eq.mod.substitutivity-congs.3}%
\end{equation}
because we can replace all the six integers $b,c,c,a,a,b$ in the expression
$bc+ca+ab$ (listed in the order of their appearance in this expression) by
$b^{\prime},c^{\prime},c^{\prime},a^{\prime},a^{\prime},b^{\prime}$,
respectively. If we want to derive this from the PSC, then we must perform the
replacements one at a time, e.g., as follows:%
\begin{align*}
\underbrace{b}_{\equiv b^{\prime}\operatorname{mod}n}c+ca+ab  &  \equiv
b^{\prime}\underbrace{c}_{\equiv c^{\prime}\operatorname{mod}n}+ca+ab\equiv
b^{\prime}c^{\prime}+\underbrace{c}_{\equiv c^{\prime}\operatorname{mod}%
n}a+ab\\
&  \equiv b^{\prime}c^{\prime}+c^{\prime}\underbrace{a}_{\equiv a^{\prime
}\operatorname{mod}n}+ab\equiv b^{\prime}c^{\prime}+c^{\prime}a^{\prime
}+\underbrace{a}_{\equiv a^{\prime}\operatorname{mod}n}b\\
&  \equiv b^{\prime}c^{\prime}+c^{\prime}a^{\prime}+a^{\prime}\underbrace{b}%
_{\equiv b^{\prime}\operatorname{mod}n}\equiv b^{\prime}c^{\prime}+c^{\prime
}a^{\prime}+a^{\prime}b^{\prime}\operatorname{mod}n.
\end{align*}
Of course, we shall always just show the replacements as a single step:%
\[
\underbrace{b}_{\equiv b^{\prime}\operatorname{mod}n}\ \ \underbrace{c}%
_{\equiv c^{\prime}\operatorname{mod}n}+\underbrace{c}_{\equiv c^{\prime
}\operatorname{mod}n}\ \ \underbrace{a}_{\equiv a^{\prime}\operatorname{mod}%
n}+\underbrace{a}_{\equiv a^{\prime}\operatorname{mod}n}\ \ \underbrace{b}%
_{\equiv b^{\prime}\operatorname{mod}n}\equiv b^{\prime}c^{\prime}+c^{\prime
}a^{\prime}+a^{\prime}b^{\prime}\operatorname{mod}n.
\]


The PSC can be extended: The expression $A$ can be allowed to involve not only
integers, addition, subtraction, multiplication and $x$, but also $k$-th
powers for $k\in\mathbb{N}$ (as long as $k$ remains unchanged in our
replacement) as well as finite sums and products (as long as the bounds of the
sums and products are unchanged). This follows from Exercise
\ref{exe.ent.mod.basics.k-power} and Exercise \ref{exe.ent.mod.k-sum}.

\begin{exercise}
\label{exe.ent.mod.substitutivity.7div}Let $n\in\mathbb{N}$. Show that
$7\mid3^{2n+1}+2^{n+2}$.
\end{exercise}

\begin{center}
\textbf{2019-02-01 lecture}
\end{center}

\subsection{\label{sect.ent.quorem}Division with remainder}

The following fact you likely remember from high school:

\begin{theorem}
\label{thm.ent.quorem.full}Let $n$ be a positive integer. Let $u\in\mathbb{Z}%
$. Then, there exists a unique pair $\left(  q,r\right)  \in\mathbb{Z}%
\times\left\{  0,1,\ldots,n-1\right\}  $ such that $u=qn+r$.
\end{theorem}

We shall refer to this as the \textquotedblleft\textit{division-with-remainder
theorem for integers}\textquotedblright. Before we prove this theorem, let us
introduce the notations that it justifies:

\begin{definition}
\label{def.ent.quorem}Let $n$ be a positive integer. Let $u\in\mathbb{Z}$.
Theorem \ref{thm.ent.quorem.full} shows that there exists a unique pair
$\left(  q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $
such that $u=qn+r$. Consider this pair.

\textbf{(a)} We denote the integer $q$ by $u//n$, and refer to it as the
\textit{quotient of the division of }$u$ \textit{by }$n$.

\textbf{(b)} We denote the integer $r$ by $u\%n$, and refer to it as the
\textit{remainder of the division of }$u$ \textit{by }$n$.
\end{definition}

The words \textquotedblleft quotient\textquotedblright\ and \textquotedblleft
remainder\textquotedblright\ are standard, but the notations \textquotedblleft%
$u//n$\textquotedblright\ and \textquotedblleft$u\%n$\textquotedblright\ are
not (I have taken them from the Python programming language); be prepared to
see other notations in the literature (e.g., the notations \textquotedblleft%
$\operatorname*{quo}\left(  u,n\right)  $\textquotedblright\ and
\textquotedblleft$\operatorname*{rem}\left(  u,n\right)  $\textquotedblright%
\ for $u//n$ and $u\%n$, respectively).

\begin{example}
\textbf{(a)} We have $14//3=4$ and $14\%3=2$, because $\left(  4,2\right)  $
is the unique pair $\left(  q,r\right)  \in\mathbb{Z}\times\left\{
0,1,2\right\}  $ satisfying $14=q\cdot3+r$.

\textbf{(b)} We have $18//3=6$ and $18\%3=0$, because $\left(  6,0\right)  $
is the unique pair $\left(  q,r\right)  \in\mathbb{Z}\times\left\{
0,1,2\right\}  $ satisfying $18=q\cdot3+r$.

\textbf{(c)} We have $\left(  -2\right)  //3=-1$ and $\left(  -2\right)
\%3=1$, because $\left(  -1,1\right)  $ is the unique pair $\left(
q,r\right)  \in\mathbb{Z}\times\left\{  0,1,2\right\}  $ satisfying
$-2=q\cdot3+r$.

\textbf{(d)} For each $u\in\mathbb{Z}$, we have $u//1=u$ and $u\%1=0$, because
$\left(  u,0\right)  $ is the unique pair $\left(  q,r\right)  \in
\mathbb{Z}\times\left\{  0\right\}  $ satisfying $u=q\cdot1+r$.
\end{example}

But we have gotten ahead of ourselves: We need to prove Theorem
\ref{thm.ent.quorem.full} before we can use the notations \textquotedblleft%
$u//n$\textquotedblright\ and \textquotedblleft$u\%n$\textquotedblright.

Let us split Theorem \ref{thm.ent.quorem.full} into two parts: existence and uniqueness:

\begin{lemma}
\label{lem.ent.quorem.exist}Let $n$ be a positive integer. Let $u\in
\mathbb{Z}$. Then, there exists \textbf{at least one} pair $\left(
q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that
$u=qn+r$.
\end{lemma}

\begin{lemma}
\label{lem.ent.quorem.unique}Let $n$ be a positive integer. Let $u\in
\mathbb{Z}$. Then, there exists \textbf{at most one} pair $\left(  q,r\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that $u=qn+r$.
\end{lemma}

We begin by proving Lemma \ref{lem.ent.quorem.unique} (which is the easier one):

\begin{proof}
[Proof of Lemma \ref{lem.ent.quorem.unique}.]Let $\left(  q_{1},r_{1}\right)
$ and $\left(  q_{2},r_{2}\right)  $ be two pairs $\left(  q,r\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that $u=qn+r$. We
shall show that $\left(  q_{1},r_{1}\right)  =\left(  q_{2},r_{2}\right)  $.

We know that $\left(  q_{1},r_{1}\right)  $ is a pair $\left(  q,r\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that $u=qn+r$. In
other words, $\left(  q_{1},r_{1}\right)  \in\mathbb{Z}\times\left\{
0,1,\ldots,n-1\right\}  $ and $u=q_{1}n+r_{1}$. Similarly, $\left(
q_{2},r_{2}\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ and
$u=q_{2}n+r_{2}$.

From $\left(  q_{1},r_{1}\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots
,n-1\right\}  $, we obtain $q_{1}\in\mathbb{Z}$ and $r_{1}\in\left\{
0,1,\ldots,n-1\right\}  $. Similarly, $q_{2}\in\mathbb{Z}$ and $r_{2}%
\in\left\{  0,1,\ldots,n-1\right\}  $. Thus, in particular, $q_{1},q_{2}%
,r_{1},r_{2}$ are integers.

From $r_{1}\in\left\{  0,1,\ldots,n-1\right\}  $ and $r_{2}\in\left\{
0,1,\ldots,n-1\right\}  $, we can easily derive%
\begin{equation}
\left\vert r_{2}-r_{1}\right\vert \leq n-1.
\label{pf.lem.ent.quorem.unique.ineq}%
\end{equation}


\begin{fineprint}
[\textit{Proof of (\ref{pf.lem.ent.quorem.unique.ineq}):} Intuitively, this
should be clear: Both $r_{1}$ and $r_{2}$ belong to the integer interval
$\left\{  0,1,\ldots,n-1\right\}  $, and thus the unsigned distance between
$r_{1}$ and $r_{2}$ is at most $n-1$ (with the worst case being when $r_{1}$
and $r_{2}$ are at opposite ends of this interval).

Here is a formal restatement of this argument: We have $r_{1}\in\left\{
0,1,\ldots,n-1\right\}  $, thus $r_{1}\geq0$. Also, $r_{2}\in\left\{
0,1,\ldots,n-1\right\}  $, hence $r_{2}\leq n-1$. Hence, $\underbrace{r_{2}%
}_{\leq n-1}-\underbrace{r_{1}}_{\geq0}\leq\left(  n-1\right)  -0=n-1$.
Similarly, $r_{1}-r_{2}\leq n-1$. But recall that $\left\vert x\right\vert
\in\left\{  x,-x\right\}  $ for each $x\in\mathbb{Z}$. Applying this to
$x=r_{2}-r_{1}$, we obtain
\[
\left\vert r_{2}-r_{1}\right\vert \in\left\{  r_{2}-r_{1},\underbrace{-\left(
r_{2}-r_{1}\right)  }_{=r_{1}-r_{2}}\right\}  =\left\{  r_{2}-r_{1}%
,r_{1}-r_{2}\right\}  .
\]
In other words, $\left\vert r_{2}-r_{1}\right\vert $ is one of the two numbers
$r_{2}-r_{1}$ and $r_{1}-r_{2}$. Since both of these numbers $r_{2}-r_{1}$ and
$r_{1}-r_{2}$ are $\leq n-1$ (as we have just shown), we thus conclude that
$\left\vert r_{2}-r_{1}\right\vert \leq n-1$. This proves
(\ref{pf.lem.ent.quorem.unique.ineq}).]
\end{fineprint}

We have $q_{1}n+r_{1}=u=q_{2}n+r_{2}$, thus $q_{1}n-q_{2}n=r_{2}-r_{1}$.
Hence,%
\begin{equation}
r_{2}-r_{1}=q_{1}n-q_{2}n=\left(  q_{1}-q_{2}\right)  n.
\label{pf.lem.ent.quorem.unique.1}%
\end{equation}


Assume (for the sake of contradiction) that $q_{1}\neq q_{2}$. Thus,
$q_{1}-q_{2}\neq0$, so that $\left\vert q_{1}-q_{2}\right\vert >0$ and
therefore $\left\vert q_{1}-q_{2}\right\vert \geq1$ (since $\left\vert
q_{1}-q_{2}\right\vert $ is an integer). We can multiply this inequality by
$n$ (since $n$ is positive) and thus obtain $\left\vert q_{1}-q_{2}\right\vert
n\geq1n=n$. But from (\ref{pf.lem.ent.quorem.unique.1}), we obtain%
\begin{align*}
\left\vert r_{2}-r_{1}\right\vert  &  =\left\vert \left(  q_{1}-q_{2}\right)
n\right\vert =\left\vert q_{1}-q_{2}\right\vert \cdot\underbrace{\left\vert
n\right\vert }_{\substack{=n\\\text{(since }n\text{ is positive)}%
}}\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{eq.ent.div.abs(xy)})}\right) \\
&  =\left\vert q_{1}-q_{2}\right\vert n\geq n>n-1.
\end{align*}
This contradicts (\ref{pf.lem.ent.quorem.unique.ineq}). This contradiction
shows that our assumption (that $q_{1}\neq q_{2}$) was false. Hence, we have
$q_{1}=q_{2}$. Thus, $q_{1}-q_{2}=0$, so that
(\ref{pf.lem.ent.quorem.unique.1}) becomes $r_{2}-r_{1}=\underbrace{\left(
q_{1}-q_{2}\right)  }_{=0}n=0$ and thus $r_{2}=r_{1}$, so that $r_{1}=r_{2}$.
Combining this with $q_{1}=q_{2}$, we obtain $\left(  q_{1},r_{1}\right)
=\left(  q_{2},r_{2}\right)  $.

Now, forget that we have fixed $\left(  q_{1},r_{1}\right)  $ and $\left(
q_{2},r_{2}\right)  $. We thus have proven that if $\left(  q_{1}%
,r_{1}\right)  $ and $\left(  q_{2},r_{2}\right)  $ are two pairs $\left(
q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that
$u=qn+r$, then $\left(  q_{1},r_{1}\right)  =\left(  q_{2},r_{2}\right)  $. In
other words, any two pairs $\left(  q,r\right)  \in\mathbb{Z}\times\left\{
0,1,\ldots,n-1\right\}  $ such that $u=qn+r$ must be equal. In other words,
there exists at most one such pair. This proves Lemma
\ref{lem.ent.quorem.unique}.
\end{proof}

But we also need to prove Lemma \ref{lem.ent.quorem.exist}. This lemma can be
proven by induction on $u$, but not without some complications: Since it is
stated for all integers $u$ (rather than just for nonnegative or positive
integers), the classical induction principle (with an induction base and a
\textquotedblleft$u$ to $u+1$\textquotedblright\ step) cannot prove it
directly. Instead, we have to either add a \textquotedblleft$u$ to
$u-1$\textquotedblright\ step to our induction (resulting in a
\textquotedblleft two-sided induction\textquotedblright\ or \textquotedblleft
up- and down-induction\textquotedblright\ argument), or to treat the case of
negative $u$ separately. A proof using the first of these two methods can be
found in \cite[proof of Proposition 2.150]{detnotes} (where $n$ and $u$ are
denoted by $N$ and $n$). We shall instead give a proof using the second
method; thus, we first state the particular case of Lemma
\ref{lem.ent.quorem.exist} when $u$ is nonnegative:

\begin{lemma}
\label{lem.ent.quorem.existN}Let $n$ be a positive integer. Let $u\in
\mathbb{N}$. Then, there exists \textbf{at least one} pair $\left(
q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that
$u=qn+r$.
\end{lemma}

This lemma can be proven by induction on $u$ as in \cite[proof of Proposition
2.150]{detnotes}. Let us instead prove it by \textbf{strong} induction on $u$.
See \cite[\S 2.8]{detnotes} for an introduction to strong induction; in
particular, recall that a strong induction needs no induction base (but often
contains a case distinction in its \textquotedblleft induction
step\textquotedblright\ that, in some way, does give the first few values a
special treatment). The proof of Lemma \ref{lem.ent.quorem.existN} that we
give below follows a stupid but valid method of finding the pair $\left(
q,r\right)  $: Keep subtracting $n$ from $u$ until $u$ becomes $<n$; then $r$
will be the resulting number, whereas $q$ will be the number of times you have
subtracted $n$.

\begin{proof}
[Proof of Lemma \ref{lem.ent.quorem.existN}.]We proceed by strong induction on
$u$.

Let $U\in\mathbb{N}$. Assume (as the induction hypothesis) that Lemma
\ref{lem.ent.quorem.existN} holds for every $u\in\mathbb{N}$ satisfying $u<U$.
We must prove that Lemma \ref{lem.ent.quorem.existN} also holds for $u=U$. In
other words, we must prove that there exists \textbf{at least one} pair
$\left(  q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $
such that $U=qn+r$.

We are in one of the following two cases:

\textit{Case 1:} We have $U<n$.

\textit{Case 2:} We have $U\geq n$.

Let us first consider Case 1. In this case, we have $U<n$. Thus, $U\leq n-1$
(since $U$ and $n$ are integers), so that $U\in\left\{  0,1,\ldots
,n-1\right\}  $ (since $U\in\mathbb{N}$). Combining this with $0\in\mathbb{Z}%
$, we obtain $\left(  0,U\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots
,n-1\right\}  $. Hence, $\left(  0,U\right)  $ is a pair $\left(  q,r\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that $U=qn+r$
(since $U=0n+U$). Thus, there exists \textbf{at least one} pair $\left(
q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that
$U=qn+r$ (namely, $\left(  q,r\right)  =\left(  0,U\right)  $).

Let us now consider Case 2. In this case, we have $U\geq n$. Hence, $U-n\geq
0$, so that $U-n\in\mathbb{N}$ (remember that $\mathbb{N}=\left\{
0,1,2,\ldots\right\}  $). Also, $U-n<U$ (since $n$ is positive). But our
induction hypothesis said that Lemma \ref{lem.ent.quorem.existN} holds for
every $u\in\mathbb{N}$ satisfying $u<U$. Hence, in particular, Lemma
\ref{lem.ent.quorem.existN} holds for $u=U-n$ (since $U-n\in\mathbb{N}$ and
$U-n<U$). In other words, there exists \textbf{at least one} pair $\left(
q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that
$U-n=qn+r$. Fix such a pair and denote it by $\left(  q_{0},r_{0}\right)  $.
Thus, $\left(  q_{0},r_{0}\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots
,n-1\right\}  $ and $U-n=q_{0}n+r_{0}$.

From $U-n=q_{0}n+r_{0}$, we obtain $U=n+\left(  q_{0}n+r_{0}\right)  =\left(
q_{0}+1\right)  n+r_{0}$. Also, from $\left(  q_{0},r_{0}\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $, we obtain $q_{0}%
\in\mathbb{Z}$ and $r_{0}\in\left\{  0,1,\ldots,n-1\right\}  $, and thus
$\left(  q_{0}+1,r_{0}\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots
,n-1\right\}  $. Thus, the pair $\left(  q_{0}+1,r_{0}\right)  $ is a pair
$\left(  q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $
such that $U=qn+r$ (since $U=\left(  q_{0}+1\right)  n+r_{0}$). Therefore,
there exists \textbf{at least one} pair $\left(  q,r\right)  \in
\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that $U=qn+r$ (namely,
$\left(  q,r\right)  =\left(  q_{0}+1,r_{0}\right)  $).

Now, in each of the two Cases 1 and 2, we have shown that there exists
\textbf{at least one} pair $\left(  q,r\right)  \in\mathbb{Z}\times\left\{
0,1,\ldots,n-1\right\}  $ such that $U=qn+r$. Hence, this holds always. In
other words, Lemma \ref{lem.ent.quorem.existN} holds for $u=U$. This completes
the induction step; thus, Lemma \ref{lem.ent.quorem.existN} is proven by
strong induction.
\end{proof}

In order to derive Lemma \ref{lem.ent.quorem.exist} from Lemma
\ref{lem.ent.quorem.existN} (that is, to extend Lemma
\ref{lem.ent.quorem.existN} to the case of negative $u$), we shall need a
simple but important trick:

\begin{lemma}
\label{lem.ent.cong-to-nonneg}Let $n$ be a positive integer. Let
$u\in\mathbb{Z}$. Then, there exists a $v\in\mathbb{N}$ such that $u\equiv
v\operatorname{mod}n$.
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.cong-to-nonneg}.]We are in one of the following
two cases:

\textit{Case 1:} We have $u\geq0$.

\textit{Case 2:} We have $u<0$.

Let us first consider Case 1. In this case, we have $u\geq0$. Thus,
$u\in\mathbb{N}$. Also, $u\equiv u\operatorname{mod}n$ (by Proposition
\ref{prop.ent.mod.basics} \textbf{(a)}). Thus, there exists a $v\in\mathbb{N}$
such that $u\equiv v\operatorname{mod}n$ (namely, $v=u$). This proves Lemma
\ref{lem.ent.cong-to-nonneg} in Case 1.

Let us now consider Case 2. In this case, we have $u<0$. Hence, $-u>0$. Now,
$u-\left(  n-1\right)  \left(  -u\right)  =nu$ is divisible by $n$ (since
$u\in\mathbb{Z}$). In other words, $n\mid u-\left(  n-1\right)  \left(
-u\right)  $. In other words, $u\equiv\left(  n-1\right)  \left(  -u\right)
\operatorname{mod}n$. Moreover, $n\geq1$ (since $n$ is a positive integer), so
that $n-1\geq0$. We can multiply this inequality with $-u$ (since $-u>0$), and
thus obtain $\left(  n-1\right)  \left(  -u\right)  \geq0\left(  -u\right)
=0$. In other words, $\left(  n-1\right)  \left(  -u\right)  \in\mathbb{N}$.
Thus, there exists a $v\in\mathbb{N}$ such that $u\equiv v\operatorname{mod}n$
(namely, $v=\left(  n-1\right)  \left(  -u\right)  $). This proves Lemma
\ref{lem.ent.cong-to-nonneg} in Case 2.

We have now proven Lemma \ref{lem.ent.cong-to-nonneg} in both Cases 1 and 2;
hence, Lemma \ref{lem.ent.cong-to-nonneg} always holds.
\end{proof}

\begin{proof}
[Proof of Lemma \ref{lem.ent.quorem.exist}.]Lemma \ref{lem.ent.cong-to-nonneg}
shows that there exists a $v\in\mathbb{N}$ such that $u\equiv
v\operatorname{mod}n$. Consider this $v$.

Note that $n\mid u-v$ (since $u\equiv v\operatorname{mod}n$). In other words,
there exists an integer $c$ such that $u-v=nc$. Consider this $c$. From
$u-v=nc$, we obtain $u=v+nc$.

Lemma \ref{lem.ent.quorem.existN} (applied to $v$ instead of $u$) yields that
there exists \textbf{at least one} pair $\left(  q,r\right)  \in
\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that $v=qn+r$. Fix
such a pair, and denote it by $\left(  q_{0},r_{0}\right)  $. Thus, $\left(
q_{0},r_{0}\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ and
$v=q_{0}n+r_{0}$. Now,%
\[
u=\underbrace{v}_{=q_{0}n+r_{0}}+nc=\left(  q_{0}n+r_{0}\right)  +nc=\left(
q_{0}+c\right)  n+r_{0}.
\]
Also, from $\left(  q_{0},r_{0}\right)  \in\mathbb{Z}\times\left\{
0,1,\ldots,n-1\right\}  $, we obtain $q_{0}\in\mathbb{Z}$ and $r_{0}%
\in\left\{  0,1,\ldots,n-1\right\}  $, and thus $\left(  q_{0}+c,r_{0}\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $. Thus, the pair $\left(
q_{0}+c,r_{0}\right)  $ is a pair $\left(  q,r\right)  \in\mathbb{Z}%
\times\left\{  0,1,\ldots,n-1\right\}  $ such that $u=qn+r$ (since $u=\left(
q_{0}+c\right)  n+r_{0}$). Therefore, there exists \textbf{at least one} pair
$\left(  q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $
such that $u=qn+r$ (namely, $\left(  q,r\right)  =\left(  q_{0}+c,r_{0}%
\right)  $). This proves Lemma \ref{lem.ent.quorem.exist}.
\end{proof}

\begin{proof}
[Proof of Theorem \ref{thm.ent.quorem.full}.]Theorem \ref{thm.ent.quorem.full}
follows by combining Lemma \ref{lem.ent.quorem.exist} with Lemma
\ref{lem.ent.quorem.unique}.
\end{proof}

\begin{remark}
\label{rmk.ent.quo-rem.full.geo}We can visualize Theorem
\ref{thm.ent.quorem.full} as follows: Mark all the multiples of $n$ on the
real line. These multiples are evenly spaced points, with a distance of $n$
between any two neighboring multiples. Thus, they subdivide the real line into
infinitely many intervals of length $n$. More precisely, for each
$a\in\mathbb{Z}$, let $I_{a}$ be the interval $\left[  an,\left(  a+1\right)
n\right)  =\left\{  x\in\mathbb{R}\ \mid\ an\leq x<\left(  a+1\right)
n\right\}  $; then, every real belongs to exactly one of these intervals
$I_{a}$. (This is intuitively clear -- I am not saying this is a rigorous
proof.) Thus, in particular, $u$ belongs to $I_{q}$ for some $q\in\mathbb{Z}$.
This $q$ is precisely the $q$ in the unique pair $\left(  q,r\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ satisfying $u=qn+r$.
Moreover, the $r$ from this pair specifies the relative position of $u$ in the
interval $I_{q}$.

(Unfortunately, it is not clear to me whether this intuition can be turned
into a proper proof of Theorem \ref{thm.ent.quorem.full}, since it relies on
the fact that every real number belongs to exactly one of the intervals
$I_{a}$, which fact may well require Theorem \ref{thm.ent.quorem.full} for its proof.)
\end{remark}

The following properties of the quotient and the remainder are simple but will
be used all the time:

\begin{corollary}
\label{cor.ent.quo-rem.remmod}Let $n$ be a positive integer. Let
$u\in\mathbb{Z}$.

\textbf{(a)} Then, $u\%n\in\left\{  0,1,\ldots,n-1\right\}  $ and $u\%n\equiv
u\operatorname{mod}n$.

\textbf{(b)} We have $n\mid u$ if and only if $u\%n=0$.

\textbf{(c)} If $c\in\left\{  0,1,\ldots,n-1\right\}  $ is such that $c\equiv
u\operatorname{mod}n$, then $c=u\%n$.

\textbf{(d)} We have $u=\left(  u//n\right)  n+\left(  u\%n\right)  $.
\end{corollary}

Before we prove this corollary, let us explain its purpose. Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(a)} says that $u\%n$ is a number in the
set $\left\{  0,1,\ldots,n-1\right\}  $ that is congruent to $u$ modulo $n$.
Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(c)} says that $u\%n$ is the
\textbf{only} such number (as it says that any further such number $c$ must be
equal to $u\%n$). Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(b)} gives an
algorithm to check whether $n\mid u$ holds (namely, compute $u\%n$ and check
whether $u\%n=0$). Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(d)} is a
trivial consequence of the definition of quotient and remainder.

\begin{proof}
[Proof of Corollary \ref{cor.ent.quo-rem.remmod}.]Theorem
\ref{thm.ent.quorem.full} says that there is a unique pair $\left(
q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ such that
$u=qn+r$. Consider this pair $\left(  q,r\right)  $. The uniqueness of this
pair can be restated as follows: If $\left(  q^{\prime},r^{\prime}\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ is any further pair such
that $u=q^{\prime}n+r^{\prime}$, then%
\begin{equation}
\left(  q^{\prime},r^{\prime}\right)  =\left(  q,r\right)  .
\label{pf.cor.ent.quo-rem.remmod.uni}%
\end{equation}


Recall that $u\%n$ was defined to be $r$ (in Definition \ref{def.ent.quorem}
\textbf{(b)}). Thus, $u\%n=r$. Now, $n\mid qn=u-r$ (since $u=qn+r$). In other
words, $u\equiv r\operatorname{mod}n$. Hence, $r\equiv u\operatorname{mod}n$
(by Proposition \ref{prop.ent.mod.basics} \textbf{(c)}). This rewrites as
$u\%n\equiv u\operatorname{mod}n$ (since $r=u\%n$).

Furthermore, $u\%n=r\in\left\{  0,1,\ldots,n-1\right\}  $ (since $\left(
q,r\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $). This
completes the proof of Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(a)}.

Also, $u//n$ was defined to be $q$ (in Definition \ref{def.ent.quorem}
\textbf{(a)}). Hence, $u//n=q$. Now,%
\[
u=\underbrace{q}_{=u//n}n+\underbrace{r}_{=u\%n}=\left(  u//n\right)
n+\left(  u\%n\right)  .
\]
This proves Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(d)}.

\textbf{(b)} $\Longrightarrow:$ Assume that $n\mid u$. We must prove that
$u\%n=0$.

We have $n\mid u$. In other words, there exists some integer $w$ such that
$u=nw$. Consider this $w$.

We have $n-1\in\mathbb{N}$ (since $n$ is a positive integer), thus
$0\in\left\{  0,1,\ldots,n-1\right\}  $. Hence, $\left(  w,0\right)
\in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $ (since $w\in\mathbb{Z}%
$). Also, $u=nw=wn=wn+0$. Hence, (\ref{pf.cor.ent.quo-rem.remmod.uni})
(applied to $\left(  q^{\prime},r^{\prime}\right)  =\left(  w,0\right)  $)
yields $\left(  w,0\right)  =\left(  q,r\right)  $. In other words, $w=q$ and
$0=r$. Hence, $r=0$, so that $u\%n=r=0$. This proves the \textquotedblleft%
$\Longrightarrow$\textquotedblright\ implication of Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(b)}.

$\Longleftarrow:$ Assume that $u\%n=0$. We must prove that $n\mid u$.

We have $u=qn+\underbrace{r}_{=u\%n=0}=qn=nq$. Thus, $n\mid u$. This proves
the \textquotedblleft$\Longleftarrow$\textquotedblright\ implication of
Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(b)}.

\textbf{(c)} Let $c\in\left\{  0,1,\ldots,n-1\right\}  $ be such that $c\equiv
u\operatorname{mod}n$.

We have $c\equiv u\operatorname{mod}n$. In other words, $n\mid c-u$. In other
words, there exists some integer $w$ such that $c-u=nw$. Consider this $w$.

From $-w\in\mathbb{Z}$ and $c\in\left\{  0,1,\ldots,n-1\right\}  $, we obtain
$\left(  -w,c\right)  \in\mathbb{Z}\times\left\{  0,1,\ldots,n-1\right\}  $.
Also, from $c-u=nw$, we obtain $u=c-nw=\left(  -w\right)  n+c$. Hence,
(\ref{pf.cor.ent.quo-rem.remmod.uni}) (applied to $\left(  q^{\prime
},r^{\prime}\right)  =\left(  -w,c\right)  $) yields $\left(  -w,c\right)
=\left(  q,r\right)  $. In other words, $-w=q$ and $c=r$. Hence, $c=r=u\%n$.
This proves Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(c)}.
\end{proof}

\begin{exercise}
\label{exe.ent.quo-rem.mod=rem}Let $n$ be a positive integer. Let $u$ and $v$
be integers. Prove that $u\equiv v\operatorname{mod}n$ if and only if
$u\%n=v\%n$.
\end{exercise}

The following exercise provides an analogue of Theorem
\ref{thm.ent.quorem.full}, in which $r$ is required to be an integer
satisfying $\left\vert r\right\vert \leq n/2$ rather than an element of
$\left\{  0,1,\ldots,n-1\right\}  $. Note, however, that $r$ is not always
unique in this case.

\begin{exercise}
\label{exe.ent.quo-rem.minrem}Let $n$ be a positive integer. Let
$u\in\mathbb{Z}$.

\textbf{(a)} Prove that there exists a pair $\left(  q,r\right)  \in
\mathbb{Z}\times\mathbb{Z}$ such that $u=qn+r$ and $\left\vert r\right\vert
\leq n/2$.

\textbf{(b)} Prove that this pair is not unique in general (i.e., find $n$ and
$u$ for which it is not unique).
\end{exercise}

\begin{remark}
\label{rmk.ent.quo-rem.minrem.geo}There is a simple visualization that makes
Exercise \ref{exe.ent.quo-rem.minrem} \textbf{(a)} intuitively obvious: Mark
all the multiples of $n$ on the real line. These multiples are evenly spaced
points, with a distance of $n$ between any two neighboring multiples. Hence,
every point on the real line is at most a distance of $n/2$ away from the
closest multiple of $n$. Applying this to the point $u$, we conclude that $u$
is at most a distance of $n/2$ away from the closest multiple of $n$. In other
words, if $qn$ is the closest multiple of $n$ to $u$ (or one of the two
closest multiples of $n$, if $u$ is in the middle between two multiples), then
$\left\vert u-qn\right\vert \leq n/2$. Thus, if we set $r=u-qn$, then $u=qn+r$
and $\left\vert r\right\vert \leq n/2$. This proves Exercise
\ref{exe.ent.quo-rem.minrem} \textbf{(a)} intuitively.

This point of view also makes Exercise \ref{exe.ent.quo-rem.minrem}
\textbf{(b)} evident: When the point $u$ is exactly in the middle of one of
the length-$n$ intervals between multiples of $n$, then there are two
multiples of $n$ equally close to $u$, and we can pick either of them; hence,
the pair $\left(  q,r\right)  $ is not unique.
\end{remark}

\begin{convention}
\label{conv.ent.quo-rem.prec}The symbols $//$ and $\%$ will be granted higher
precedence (in the sense of
\href{https://en.wikipedia.org/wiki/Order_of_operations}{operator precedence})
than addition. This means that an expression of the form \textquotedblleft%
$c+a//n+b$\textquotedblright\ will always be interpreted as \textquotedblleft%
$c+\left(  a//n\right)  +b$\textquotedblright, rather than as
\textquotedblleft$\left(  c+a\right)  //\left(  n+b\right)  $%
\textquotedblright\ (or in any other way). Likewise, an expression of the form
\textquotedblleft$c+a\%n+b$\textquotedblright\ will always be interpreted as
\textquotedblleft$c+\left(  a\%n\right)  +b$\textquotedblright, rather than as
\textquotedblleft$\left(  c+a\right)  \%\left(  n+b\right)  $%
\textquotedblright.
\end{convention}

\begin{exercise}
\label{exe.ent.quo-rem.u+v}Let $u$ and $v$ be two integers. Let $n$ be a
positive integer.

\textbf{(a)} Prove that $u\%n+v\%n-\left(  u+v\right)  \%n\in\left\{
0,n\right\}  $.

\textbf{(b)} Prove that $\left(  u+v\right)  //n-u//n-v//n\in\left\{
0,1\right\}  $.
\end{exercise}

\subsection{Even and odd numbers}

Recall the following:

\begin{definition}
\label{def.ent.even-odd}Let $u$ be an integer.

\textbf{(a)} We say that $u$ is \textit{even} if $u$ is divisible by $2$.

\textbf{(b)} We say that $u$ is \textit{odd }if $u$ is not divisible by $2$.
\end{definition}

So an integer is either even or odd (but not both at the same time). The
following exercise collects various properties of even and odd integers:

\begin{exercise}
\label{exe.ent.even-odd.1}Let $u$ be an integer.

\textbf{(a)} Prove that $u$ is even if and only if $u\%2=0$.

\textbf{(b)} Prove that $u$ is odd if and only if $u\%2=1$.

\textbf{(c)} Prove that $u$ is even if and only if $u\equiv0\operatorname{mod}%
2$.

\textbf{(d)} Prove that $u$ is odd if and only if $u\equiv1\operatorname{mod}%
2$.

\textbf{(e)} Prove that $u$ is odd if and only if $u+1$ is even.

\textbf{(f)} Prove that exactly one of the two numbers $u$ and $u+1$ is even.

\textbf{(g)} Prove that $u\left(  u+1\right)  \equiv0\operatorname{mod}2$.

\textbf{(h)} Prove that $u^{2}\equiv-u\equiv u\operatorname{mod}2$.

\textbf{(i)} Let $v$ be a further integer. Prove that $u\equiv
v\operatorname{mod}2$ holds if and only if $u$ and $v$ are either both odd or
both even.
\end{exercise}

\begin{exercise}
\label{exe.ent.even-odd-sumsq}\textbf{(a)} Prove that each even integer $u$
satisfies $u^{2}\equiv0\operatorname{mod}4$.

\textbf{(b)} Prove that each odd integer $u$ satisfies $u^{2}\equiv
1\operatorname{mod}4$.

\textbf{(c)} Prove that no two integers $x$ and $y$ satisfy $x^{2}+y^{2}%
\equiv3\operatorname{mod}4$.

\textbf{(d)} Prove that if $x$ and $y$ are two integers satisfying
$x^{2}+y^{2}\equiv2\operatorname{mod}4$, then $x$ and $y$ are both odd.
\end{exercise}

Exercise \ref{exe.ent.even-odd-sumsq} \textbf{(c)} establishes our previous
experimental observation that an integer of the form $4k+3$ with integer $k$
(that is, an integer that is larger by $3$ than a multiple of $4$) can never
be written as a sum of two perfect squares.

\begin{center}
\textbf{2019-02-04 lecture}
\end{center}

\subsection{The floor function}

We shall now briefly introduce the floor function (following \cite{floor}), as
it is closely connected to division with remainder.

\begin{definition}
\label{def.ent.floor}Let $x$ be a real number. Then, $\left\lfloor
x\right\rfloor $ is defined to be the unique integer $n$ satisfying $n\leq
x<n+1$. This integer $\left\lfloor x\right\rfloor $ is called the
\textit{floor} of $x$, or the \textit{integer part} of $x$.
\end{definition}

\begin{remark}
\label{rmk.ent.floor}\textbf{(a)} Why is $\left\lfloor x\right\rfloor $
well-defined? I mean, why does the unique integer $n$ in Definition
\ref{def.ent.floor} exist, and why is it unique? This question is trickier
than it sounds and relies on the construction of real numbers. However, in the
case when $x$ is rational, the well-definedness of $\left\lfloor
x\right\rfloor $ follows from Proposition \ref{prop.ent.floor.quorem} below.

\textbf{(b)} What we call $\left\lfloor x\right\rfloor $ is typically called
$\left[  x\right]  $ in older books (such as \cite{NiZuMo91}). I suggest
avoiding the notation $\left[  x\right]  $ wherever possible; it has too many
different meanings (whereas $\left\lfloor x\right\rfloor $ almost always means
the floor of $x$).

\textbf{(c)} The map $\mathbb{R}\rightarrow\mathbb{Z},\ x\mapsto\left\lfloor
x\right\rfloor $ is called the \textit{floor function} or the \textit{greatest
integer function}.

There is also a \textit{ceiling function}, which sends each $x\in\mathbb{R}$
to the unique integer $n$ satisfying $n-1<x\leq n$; this latter integer is
called $\left\lceil x\right\rceil $. The two functions are connected by the
rule $\left\lceil x\right\rceil =-\left\lfloor -x\right\rfloor $ (for all
$x\in\mathbb{R}$).

The floor and the ceiling functions are some of the simplest examples of
discontinuous functions.

\textbf{(d)} Here are some examples of floors:%
\begin{align*}
\left\lfloor n\right\rfloor  &  =n\ \ \ \ \ \ \ \ \ \ \text{for every }%
n\in\mathbb{Z};\\
\left\lfloor 1.32\right\rfloor  &  =1;\ \ \ \ \ \ \ \ \ \ \left\lfloor
\pi\right\rfloor =3;\ \ \ \ \ \ \ \ \ \ \left\lfloor 0.98\right\rfloor =0;\\
\left\lfloor -2.3\right\rfloor  &  =-3;\ \ \ \ \ \ \ \ \ \ \left\lfloor
-0.4\right\rfloor =-1.
\end{align*}


\textbf{(e)} You might have the impression that $\left\lfloor x\right\rfloor $
is \textquotedblleft what remains from $x$ if the digits behind the comma are
removed\textquotedblright. This impression is highly imprecise. For one, it is
completely broken for negative $x$ (for example, $\left\lfloor
-2.3\right\rfloor $ is $-3$, not $-2$). But more importantly, the operation of
\textquotedblleft removing the digits behind the comma\textquotedblright\ from
a number is not well-defined; in fact, the periodic decimal representations
$0.999\ldots$ and $1.000\ldots$ belong to the same real number ($1$), but
removing their digits behind the comma leaves us with different integers.

\textbf{(f)} A related map is the map $\mathbb{R}\rightarrow\mathbb{Z}%
,\ x\mapsto\left\lfloor x+\dfrac{1}{2}\right\rfloor $. It sends each real $x$
to the integer that is closest to $x$, choosing the larger one in the case of
a tie. This is one of the many things that are commonly known as
\textquotedblleft rounding\textquotedblright\ a number.
\end{remark}

\begin{proposition}
\label{prop.ent.floor.quorem}Let $a$ and $b$ be integers such that $b>0$.
Then, $\left\lfloor \dfrac{a}{b}\right\rfloor $ is well-defined and equals
$a//b$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.floor.quorem}.]This is a rather easy and
neat exercise. A full proof can be found in \cite[proof of Proposition
1.1.3]{floor}.
\end{proof}

See \cite{floor} and \cite[\S 4.1]{NiZuMo91} for further properties of the
floor function.

\subsection{Common divisors, the Euclidean algorithm and the Bezout theorem}

\subsubsection{Divisors}

\begin{definition}
\label{def.ent.divisors.divisors}Let $b\in\mathbb{Z}$. The \textit{divisors}
of $b$ are defined as the integers that divide $b$.
\end{definition}

Be aware that some authors use a mildly different definition of
\textquotedblleft divisors\textquotedblright; namely, they additionally
require them to be positive. We don't make such a requirement.

For example, the divisors of $6$ are $-6,-3,-2,-1,1,2,3,6$. Of course, the
negative divisors of an integer $b$ are merely the reflections of the positive
divisors through the origin\footnote{\textquotedblleft Reflection through the
origin\textquotedblright\ is just a poetic way to say \textquotedblleft
negative\textquotedblright; i.e., the reflection of a number $a$ through the
origin is $-a$.} (this follows easily from Proposition \ref{prop.ent.div.1}
\textbf{(a)}); thus, the positive divisors are usually the only ones of interest.

Here are some basic properties of divisors:

\begin{proposition}
\label{prop.ent.divisors.find}\textbf{(a)} If $b\in\mathbb{Z}$, then $1$ and
$b$ are divisors of $b$.

\textbf{(b)} The divisors of $0$ are all the integers.

\textbf{(c)} Let $b\in\mathbb{Z}$ be nonzero. Then, all divisors of $b$ belong
to the set $\left\{  -\left\vert b\right\vert ,-\left\vert b\right\vert
+1,\ldots,\left\vert b\right\vert \right\}  \setminus\left\{  0\right\}  $.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.divisors.find}.]\textbf{(a)} Clearly,
$1\mid b$ (since $b=1b$), so that $1$ is a divisor of $b$. Also, $b\mid b$
(since $b=b\cdot1$), so that $b$ is a divisor of $b$.

\textbf{(b)} Each integer $a$ divides $0$ (since $0=a\cdot0$) and thus is a
divisor of $0$. This proves Proposition \ref{prop.ent.divisors.find}
\textbf{(b)}.

\textbf{(c)} Let $a$ be a divisor of $b$. Then, $a$ divides $b$. In other
words, $a\mid b$. Hence, Proposition \ref{prop.ent.div.1} \textbf{(b)} yields
$\left\vert a\right\vert \leq\left\vert b\right\vert $ (since $b\neq0$). But
$\left\vert a\right\vert \geq a$ (since $\left\vert x\right\vert \geq x$ for
each $x\in\mathbb{R}$), so that $a\leq\left\vert a\right\vert \leq\left\vert
b\right\vert $. Also, $\left\vert a\right\vert \geq-a$ (since $\left\vert
x\right\vert \geq-x$ for each $x\in\mathbb{R}$) and thus $-a\leq\left\vert
a\right\vert \leq\left\vert b\right\vert $, so that $a\geq-\left\vert
b\right\vert $. Combining this with $a\leq\left\vert b\right\vert $, we obtain
$-\left\vert b\right\vert \leq a\leq\left\vert b\right\vert $ and thus
$a\in\left\{  -\left\vert b\right\vert ,-\left\vert b\right\vert
+1,\ldots,\left\vert b\right\vert \right\}  $ (since $a$ is an integer).

From Example \ref{exa.ent.div.triv} \textbf{(c)}, we know that $0\mid b$ only
when $b=0$. Thus, we don't have $0\mid b$ (since $b\neq0$).

If we had $a=0$, then we would have $0=a\mid b$, which would contradict the
fact that we don't have $0\mid b$. Thus, we cannot have $a=0$. Hence, $a\neq
0$. Combining $a\in\left\{  -\left\vert b\right\vert ,-\left\vert b\right\vert
+1,\ldots,\left\vert b\right\vert \right\}  $ with $a\neq0$, we obtain
$a\in\left\{  -\left\vert b\right\vert ,-\left\vert b\right\vert
+1,\ldots,\left\vert b\right\vert \right\}  \setminus\left\{  0\right\}  $.

We have proven this for each divisor $a$ of $b$. Thus, we conclude that all
divisors of $b$ belong to the set $\left\{  -\left\vert b\right\vert
,-\left\vert b\right\vert +1,\ldots,\left\vert b\right\vert \right\}
\setminus\left\{  0\right\}  $. This proves Proposition
\ref{prop.ent.divisors.find} \textbf{(c)}.
\end{proof}

Thanks to Proposition \ref{prop.ent.divisors.find}, we have a method to find
all divisors of an integer $b$: If $b=0$, then Proposition
\ref{prop.ent.divisors.find} \textbf{(b)} directly yields the result;
otherwise, Proposition \ref{prop.ent.divisors.find} \textbf{(c)} shows that
there is only a finite set of numbers we have to check. When $b$ is large,
this is slow, but to some extent that is because the problem is
computationally hard (or at least suspected to be hard).

\subsubsection{Common divisors}

It is somewhat more interesting to consider the common divisors of two or more integers:

\begin{definition}
\label{def.ent.Div}Let $b_{1},b_{2},\ldots,b_{k}$ be integers. Then, the
\textit{common divisors} of $b_{1},b_{2},\ldots,b_{k}$ are defined to be the
integers $a$ that satisfy%
\begin{equation}
\left(  a\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,k\right\}  \right)
\label{eq.def.ent.Div.cond}%
\end{equation}
(in other words, that divide all of the integers $b_{1},b_{2},\ldots,b_{k}$).
We let $\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ denote
the set of these common divisors.
\end{definition}

Note that the concept of common divisors encompasses the concept of divisors:
The common divisors of a single integer $b$ are merely the divisors of $b$.
Thus, $\operatorname*{Div}\left(  b\right)  $ is the set of all divisors of
$b$ whenever $b\in\mathbb{Z}$. (Of course, speaking of \textquotedblleft
common divisors\textquotedblright\ of just one integer is like speaking of a
conspiracy of just one person. But the definition fits, and we algebraists
don't exclude cases just because they are ridiculous.)

(Also, the common divisors of an empty list of integers are all the integers,
because the requirement (\ref{eq.def.ent.Div.cond}) is vacuously true for
$k=0$. In other words, $\operatorname*{Div}\left(  {}\right)  =\mathbb{Z}$.)

Here are some more interesting examples of common divisors:

\begin{example}
\textbf{(a)} The common divisors of $6$ and $8$ are $-2,-1,1,2$. (In order to
see this, just observe that the divisors of $6$ are $-6,-3,-2,-1,1,2,3,6$,
whereas the divisors of $8$ are $-8,-4,-2,-1,1,2,4,8$; now you can find the
common divisors of $6$ and $8$ by taking the numbers common to these two
lists.) Thus,%
\[
\operatorname*{Div}\left(  6,8\right)  =\left\{  -2,-1,1,2\right\}  .
\]


\textbf{(b)} The common divisors of $6$ and $14$ are $-2,-1,1,2$ again. (In
order to see this, just observe that the divisors of $6$ are
$-6,-3,-2,-1,1,2,3,6$, whereas the divisors of $14$ are
$-14,-7,-2,-1,1,2,7,14$.)

\textbf{(c)} The common divisors of $6$, $10$ and $15$ are $-1$ and $1$. (In
order to see this, note that:

\begin{itemize}
\item The divisors of $6$ are $-6,-3,-2,-1,1,2,3,6$.

\item The divisors of $10$ are $-10,-5,-2,-1,1,2,5,10$.

\item The divisors of $15$ are $-15,-5,-3,-1,1,3,5,15$.
\end{itemize}

\noindent The only numbers common to these three lists are $-1$ and $1$.) However:

\begin{itemize}
\item The common divisors of $6$ and $10$ are $-2,-1,1,2$.

\item The common divisors of $6$ and $15$ are $-3,-1,1,3$.

\item The common divisors of $10$ and $15$ are $-5,-1,1,5$.
\end{itemize}

\noindent This illustrates the fact that three numbers can have pairwise
nontrivial common divisors (where \textquotedblleft
nontrivial\textquotedblright\ means \textquotedblleft distinct from $1$ and
$-1$\textquotedblright), but the only common divisors of all three of them may
still be just $1$ and $-1$.
\end{example}

\begin{proposition}
\label{prop.ent.Div.fin}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely many
integers that are not all $0$. Then, the set $\operatorname*{Div}\left(
b_{1},b_{2},\ldots,b_{k}\right)  $ has a largest element, and this largest
element is a positive integer.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.Div.fin}.]The integer $1$ satisfies
$\left(  1\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,k\right\}
\right)  $. Thus, $1$ is a common divisor of $b_{1},b_{2},\ldots,b_{k}$ (by
the definition of a \textquotedblleft common divisor\textquotedblright). In
other words, $1\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
$ (by the definition of $\operatorname*{Div}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $). Hence, the set $\operatorname*{Div}\left(  b_{1}%
,b_{2},\ldots,b_{k}\right)  $ is nonempty.

Moreover, it is easy to see that the set $\operatorname*{Div}\left(
b_{1},b_{2},\ldots,b_{k}\right)  $ is finite.

\begin{fineprint}
[\textit{Proof:} We have assumed that $b_{1},b_{2},\ldots,b_{k}$ are not all
$0$. In other words, there exists a $j\in\left\{  1,2,\ldots,k\right\}  $ such
that $b_{j}$ is nonzero. Consider such a $j$.

Let $d\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $. Thus,
$d$ is a common divisor of $b_{1},b_{2},\ldots,b_{k}$ (by the definition of
$\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $). In other
words, $d\mid b_{i}$ for all $i\in\left\{  1,2,\ldots,k\right\}  $ (by the
definition of \textquotedblleft common divisor\textquotedblright). Applying
this to $i=j$, we obtain $d\mid b_{j}$. Hence, $d$ is a divisor of $b_{j}$.
But Proposition \ref{prop.ent.divisors.find} \textbf{(c)} (applied to
$b=b_{j}$) shows that all divisors of $b_{j}$ belong to the set $\left\{
-\left\vert b_{j}\right\vert ,-\left\vert b_{j}\right\vert +1,\ldots
,\left\vert b_{j}\right\vert \right\}  \setminus\left\{  0\right\}  $. Hence,
$d$ must belong to this set (since $d$ is a divisor of $b_{j}$). In other
words, $d\in\left\{  -\left\vert b_{j}\right\vert ,-\left\vert b_{j}%
\right\vert +1,\ldots,\left\vert b_{j}\right\vert \right\}  \setminus\left\{
0\right\}  $.

Now, forget that we fixed $d$. We thus have shown that $d\in\left\{
-\left\vert b_{j}\right\vert ,-\left\vert b_{j}\right\vert +1,\ldots
,\left\vert b_{j}\right\vert \right\}  \setminus\left\{  0\right\}  $ for each
$d\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $. In other
words,
\[
\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  \subseteq\left\{
-\left\vert b_{j}\right\vert ,-\left\vert b_{j}\right\vert +1,\ldots
,\left\vert b_{j}\right\vert \right\}  \setminus\left\{  0\right\}  .
\]
Thus, the set $\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $
is finite (since the set $\left\{  -\left\vert b_{j}\right\vert ,-\left\vert
b_{j}\right\vert +1,\ldots,\left\vert b_{j}\right\vert \right\}
\setminus\left\{  0\right\}  $ is finite).]
\end{fineprint}

Now we know that the set $\operatorname*{Div}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $ is a nonempty finite set of integers. Thus, this set
$\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ has a largest
element (since every nonempty finite set of integers has a largest element).
It remains to prove that this largest element is a positive integer.

Let $g$ be this largest element. Thus, we must prove that $g$ is a positive
integer. Clearly, $g$ is an integer (since all elements of
$\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ are integers);
it thus remains to show that $g$ is positive.

The element $g$ is the largest element of the set $\operatorname*{Div}\left(
b_{1},b_{2},\ldots,b_{k}\right)  $, and thus is $\geq$ to every element of
this set. In other words, $g\geq x$ for each $x\in\operatorname*{Div}\left(
b_{1},b_{2},\ldots,b_{k}\right)  $. Applying this to $x=1$, we obtain $g\geq1$
(since $1\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $).
Hence, $g$ is positive. This completes the proof of Proposition
\ref{prop.ent.Div.fin}.
\end{proof}

The following exercise shows that the set $\operatorname*{Div}\left(
b_{1},b_{2},\ldots,b_{k}\right)  $ depends only on the \textbf{set} $\left\{
b_{1},b_{2},\ldots,b_{k}\right\}  $, but not on the numbers $b_{1}%
,b_{2},\ldots,b_{k}$ themselves. Thus, for example, any integers $a$, $b$ and
$c$ satisfy $\operatorname*{Div}\left(  a,b,c,a\right)  =\operatorname*{Div}%
\left(  c,a,b\right)  $ (since $\left\{  a,b,c,a\right\}  =\left\{
c,a,b\right\}  $) and $\operatorname*{Div}\left(  a,a,b,a\right)
=\operatorname*{Div}\left(  a,b,b\right)  $ (since $\left\{  a,a,b,a\right\}
=\left\{  a,b,b\right\}  $).

\begin{exercise}
\label{exe.ent.Div.set}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely many
integers. Let $c_{1},c_{2},\ldots,c_{\ell}$ be finitely many integers. Prove
that if%
\[
\left\{  b_{1},b_{2},\ldots,b_{k}\right\}  =\left\{  c_{1},c_{2}%
,\ldots,c_{\ell}\right\}  ,
\]
then%
\[
\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
=\operatorname*{Div}\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  .
\]

\end{exercise}

\subsubsection{Greatest common divisors}

Proposition \ref{prop.ent.Div.fin} allows us to make a crucial definition:

\begin{definition}
\label{def.ent.gcd.gcd}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely many
integers. The \textit{greatest common divisor} of $b_{1},b_{2},\ldots,b_{k}$
is defined as follows:

\begin{itemize}
\item If $b_{1},b_{2},\ldots,b_{k}$ are not all $0$, then it is defined as the
largest element of the set $\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  $. This largest element is well-defined (by Proposition
\ref{prop.ent.Div.fin}), and is a positive integer (by Proposition
\ref{prop.ent.Div.fin} again).

\item If $b_{1},b_{2},\ldots,b_{k}$ are all $0$, then it is defined to be $0$.
(This is a slight abuse of the word \textquotedblleft greatest common
divisor\textquotedblright, because $0$ is not actually the greatest among the
common divisors of $b_{1},b_{2},\ldots,b_{k}$ in this case. In fact, when
$b_{1},b_{2},\ldots,b_{k}$ are all $0$, \textbf{every} integer is a common
divisor of $b_{1},b_{2},\ldots,b_{k}$, so that there is no greatest among
these common divisors, because there is no \textquotedblleft greatest
integer\textquotedblright. Nevertheless, defining the greatest common divisor
of $b_{1},b_{2},\ldots,b_{k}$ to be $0$ in this case will prove to be a good
decision, as it will greatly reduce the number of exceptions in our results.)
\end{itemize}

Thus, in either case, this greatest common divisor is a nonnegative integer.
We denote it by $\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  $. (Some authors
also call it $\left(  b_{1},b_{2},\ldots,b_{k}\right)  $, which is rather
dangerous as the same notation stands for a $k$-tuple. We shall avoid this
notation at all cost, but you should be aware of it when reading
number-theoretical literature.)

We shall also use the word \textquotedblleft\textit{gcd}\textquotedblright\ as
shorthand for \textquotedblleft greatest common divisor\textquotedblright.
\end{definition}

The greatest common divisors you will most commonly see are those of two
integers. Indeed, any other gcd can be rewritten in terms of these: for
example,%
\[
\gcd\left(  a,b,c,d,e\right)  =\gcd\left(  a,\gcd\left(  b,\gcd\left(
c,\gcd\left(  d,e\right)  \right)  \right)  \right)
\]
for all $a,b,c,d,e\in\mathbb{Z}$. This is, in fact, a consequence of
Proposition \ref{thm.ent.gcd.uniprop-mul} \textbf{(d)} (which we will prove
later), applied several times.

First, let us observe several properties of greatest common divisors:

\begin{proposition}
\label{prop.ent.gcd.props1}\textbf{(a)} We have $\gcd\left(  a,0\right)
=\gcd\left(  a\right)  =\left\vert a\right\vert $ for all $a\in\mathbb{Z}$.

\textbf{(b)} We have $\gcd\left(  a,b\right)  =\gcd\left(  b,a\right)  $ for
all $a,b\in\mathbb{Z}$.

\textbf{(c)} We have $\gcd\left(  a,ua+b\right)  =\gcd\left(  a,b\right)  $
for all $a,b,u\in\mathbb{Z}$.

\textbf{(d)} If $a,b,c\in\mathbb{Z}$ satisfy $b\equiv c\operatorname{mod}a$,
then $\gcd\left(  a,b\right)  =\gcd\left(  a,c\right)  $.

\textbf{(e)} If $a,b\in\mathbb{Z}$ are such that $a$ is positive, then
$\gcd\left(  a,b\right)  =\gcd\left(  a,b\%a\right)  $.

\textbf{(f)} We have $\gcd\left(  a,b\right)  \mid a$ and $\gcd\left(
a,b\right)  \mid b$ for all $a,b\in\mathbb{Z}$.

\textbf{(g)} We have $\gcd\left(  -a,b\right)  =\gcd\left(  a,b\right)  $ for
all $a,b\in\mathbb{Z}$.

\textbf{(h)} We have $\gcd\left(  a,-b\right)  =\gcd\left(  a,b\right)  $ for
all $a,b\in\mathbb{Z}$.

\textbf{(i)} If $a,b\in\mathbb{Z}$ satisfy $a\mid b$, then $\gcd\left(
a,b\right)  =\left\vert a\right\vert $.

\textbf{(j)} The greatest common divisor of the empty list of integers is
$\gcd\left(  {}\right)  =0$.
\end{proposition}

Proposition \ref{prop.ent.gcd.props1} is not difficult and we could start
proving it right away. However, such a proof would require some annoying case
distinctions due to the special treatment that the \textquotedblleft%
$b_{1},b_{2},\ldots,b_{k}$ are all $0$\textquotedblright\ case required in
Definition \ref{def.ent.gcd.gcd}. Fortunately, we can circumnavigate these
annoyances by stating a simple rule for how the gcd of $k$ integers
$b_{1},b_{2},\ldots,b_{k}$ can be computed from their set of common divisors
(including the case when $b_{1},b_{2},\ldots,b_{k}$ are all $0$):

\begin{lemma}
\label{lem.ent.gcd.through-Div}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely many
integers. Then,%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =%
\begin{cases}
\max\left(  \operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\right)  , & \text{if }0\notin\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  ;\\
0, & \text{if }0\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
.
\end{cases}
\]
(Here, $\max S$ denotes the largest element of a set $S$ of integers, whenever
this largest element exists.)
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.gcd.through-Div}.]We are in one of the following
two cases:

\textit{Case 1:} The integers $b_{1},b_{2},\ldots,b_{k}$ are not all $0$.

\textit{Case 2:} The integers $b_{1},b_{2},\ldots,b_{k}$ are all $0$.

Let us consider Case 1 first. In this case, the integers $b_{1},b_{2}%
,\ldots,b_{k}$ are not all $0$. Hence, $\gcd\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $ is defined as the largest element of the set
$\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ (by Definition
\ref{def.ent.gcd.gcd}). In other words,
\begin{equation}
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =\max\left(  \operatorname*{Div}%
\left(  b_{1},b_{2},\ldots,b_{k}\right)  \right)  .
\label{pf.lem.ent.gcd.through-Div.c1.1}%
\end{equation}


On the other hand, $0\notin\operatorname*{Div}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $\ \ \ \ \footnote{\textit{Proof.} Assume the contrary. Thus,
$0\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $. In other
words, $0$ is a common divisor of $b_{1},b_{2},\ldots,b_{k}$ (by the
definition of $\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $).
In other words, $0\mid b_{i}$ for all $i\in\left\{  1,2,\ldots,k\right\}  $
(by the definition of \textquotedblleft common divisor\textquotedblright).
Thus, for all $i\in\left\{  1,2,\ldots,k\right\}  $, we have $b_{i}=0$ (since
$0\mid b_{i}$, so that $b_{i}=0c$ for some integer $c$; but this yields
$b_{i}=0c=0$). In other words, $b_{1},b_{2},\ldots,b_{k}$ are all $0$. But
this contradicts the fact that $b_{1},b_{2},\ldots,b_{k}$ are not all $0$.
This contradiction shows that our assumption was false, qed.}. Hence,%
\[%
\begin{cases}
\max\left(  \operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\right)  , & \text{if }0\notin\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  ;\\
0, & \text{if }0\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\end{cases}
=\max\left(  \operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\right)  .
\]
Comparing this with (\ref{pf.lem.ent.gcd.through-Div.c1.1}), we obtain%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =%
\begin{cases}
\max\left(  \operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\right)  , & \text{if }0\notin\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  ;\\
0, & \text{if }0\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
.
\end{cases}
\]
Hence, Lemma \ref{lem.ent.gcd.through-Div} is proven in Case 1.

Let us now consider Case 2. In this case, the integers $b_{1},b_{2}%
,\ldots,b_{k}$ are all $0$. Hence, $\gcd\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $ is defined as $0$ (by Definition \ref{def.ent.gcd.gcd}). In
other words,
\begin{equation}
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =0.
\label{pf.lem.ent.gcd.through-Div.c2.1}%
\end{equation}


On the other hand, $0\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $\ \ \ \ \footnote{\textit{Proof.} The integers $b_{1}%
,b_{2},\ldots,b_{k}$ are all $0$. In other words, $b_{i}=0$ for all
$i\in\left\{  1,2,\ldots,k\right\}  $. Hence, $0\mid b_{i}$ for all
$i\in\left\{  1,2,\ldots,k\right\}  $ (since each $i\in\left\{  1,2,\ldots
,k\right\}  $ satisfies $b_{i}=0=0\cdot0$). In other words, $0$ is a common
divisor of $b_{1},b_{2},\ldots,b_{k}$ (by the definition of \textquotedblleft
common divisor\textquotedblright). In other words, $0\in\operatorname*{Div}%
\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ (by the definition of
$\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $).}. Hence,%
\[%
\begin{cases}
\max\left(  \operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\right)  , & \text{if }0\notin\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  ;\\
0, & \text{if }0\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\end{cases}
=0.
\]
Comparing this with (\ref{pf.lem.ent.gcd.through-Div.c2.1}), we obtain%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =%
\begin{cases}
\max\left(  \operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\right)  , & \text{if }0\notin\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  ;\\
0, & \text{if }0\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
.
\end{cases}
\]
Hence, Lemma \ref{lem.ent.gcd.through-Div} is proven in Case 2.

We have now proven Lemma \ref{lem.ent.gcd.through-Div} in both Cases 1 and 2.
Thus, Lemma \ref{lem.ent.gcd.through-Div} always holds.
\end{proof}

A corollary of Lemma \ref{lem.ent.gcd.through-Div} is the following:

\begin{lemma}
\label{lem.ent.gcd.through-Divc}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely
many integers. Let $c_{1},c_{2},\ldots,c_{\ell}$ be finitely many integers. If%
\[
\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
=\operatorname*{Div}\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  ,
\]
then%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =\gcd\left(  c_{1},c_{2}%
,\ldots,c_{\ell}\right)  .
\]

\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.gcd.through-Divc}.]Assume that
$\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
=\operatorname*{Div}\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  $. Lemma
\ref{lem.ent.gcd.through-Div} yields%
\begin{align*}
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)   &  =%
\begin{cases}
\max\left(  \operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\right)  , & \text{if }0\notin\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  ;\\
0, & \text{if }0\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
\end{cases}
\\
&  =%
\begin{cases}
\max\left(  \operatorname*{Div}\left(  c_{1},c_{2},\ldots,c_{\ell}\right)
\right)  , & \text{if }0\notin\operatorname*{Div}\left(  c_{1},c_{2}%
,\ldots,c_{\ell}\right)  ;\\
0, & \text{if }0\in\operatorname*{Div}\left(  c_{1},c_{2},\ldots,c_{\ell
}\right)
\end{cases}
\end{align*}
(since $\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{k}\right)
=\operatorname*{Div}\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  $). But Lemma
\ref{lem.ent.gcd.through-Div} (applied to $c_{1},c_{2},\ldots,c_{\ell}$
instead of $b_{1},b_{2},\ldots,b_{k}$) yields%
\[
\gcd\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  =%
\begin{cases}
\max\left(  \operatorname*{Div}\left(  c_{1},c_{2},\ldots,c_{\ell}\right)
\right)  , & \text{if }0\notin\operatorname*{Div}\left(  c_{1},c_{2}%
,\ldots,c_{\ell}\right)  ;\\
0, & \text{if }0\in\operatorname*{Div}\left(  c_{1},c_{2},\ldots,c_{\ell
}\right)  .
\end{cases}
\]
Comparing these two equalities, we obtain $\gcd\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  =\gcd\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  $. This
proves Lemma \ref{lem.ent.gcd.through-Divc}.
\end{proof}

\begin{proof}
[Proof of Proposition \ref{prop.ent.gcd.props1}.]\textbf{(a)} Here is a sketch
of the proof: The number $0$ is a \textquotedblleft joker\textquotedblright%
\ when it comes to common divisors: For example, if $a\in\mathbb{Z}$, then the
common divisors of $a$ and $0$ are the same as the divisors of $a$, because
every integer divides $0$. Thus, if $a\in\mathbb{Z}$ is nonzero, then the
greatest common divisor of $a$ and $0$ is the greatest divisor of $a$, which
is $\left\vert a\right\vert $ (an easy consequence of Proposition
\ref{prop.ent.divisors.find} \textbf{(b)}).

For the sake of completeness, let us give a detailed proof of Proposition
\ref{prop.ent.gcd.props1} \textbf{(a)}:

\begin{fineprint}
Let $a\in\mathbb{Z}$. Definition \ref{def.ent.gcd.gcd} (specifically, its case
when $b_{1},b_{2},\ldots,b_{k}$ are all $0$) shows that $\gcd\left(
0,0\right)  =0$ and $\gcd\left(  0\right)  =0$. Combining this with
$\left\vert 0\right\vert =0$, we obtain $\gcd\left(  0,0\right)  =\gcd\left(
0\right)  =\left\vert 0\right\vert $. In other words, Proposition
\ref{prop.ent.gcd.props1} \textbf{(a)} holds if $a=0$. Thus, for the rest of
this proof, we WLOG assume that $a\neq0$. Hence, the two integers $a,0$ are
not all zero. Thus, $\gcd\left(  a,0\right)  $ is defined to be the largest
element of the set $\operatorname*{Div}\left(  a,0\right)  $ (by Definition
\ref{def.ent.gcd.gcd}). Likewise, $\gcd\left(  a\right)  $ is the largest
element of the set $\operatorname*{Div}\left(  a\right)  $.

We shall now prove that $\operatorname*{Div}\left(  a,0\right)
=\operatorname*{Div}\left(  a\right)  $. Indeed, for any integer $x$, we have
the following chain of equivalences:%
\begin{align*}
&  \ \left(  x\in\operatorname*{Div}\left(  a,0\right)  \right) \\
&  \Longleftrightarrow\ \left(  x\text{ is a common divisor of }a\text{ and
}0\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of
}\operatorname*{Div}\left(  a,0\right)  \right) \\
&  \Longleftrightarrow\ \left(  x\mid a\text{ and }x\mid0\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of a \textquotedblleft
common divisor\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  x\mid a\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }x\mid0\text{ always holds (since }0=x\cdot0\text{)}\right) \\
&  \Longleftrightarrow\ \left(  x\text{ is a common divisor of }a\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of a \textquotedblleft
common divisor\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  x\in\operatorname*{Div}\left(  a\right)
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }%
\operatorname*{Div}\left(  a\right)  \right)  .
\end{align*}
In other words, an integer belongs to $\operatorname*{Div}\left(  a,0\right)
$ if and only if it belongs to $\operatorname*{Div}\left(  a\right)  $. Thus,
$\operatorname*{Div}\left(  a,0\right)  =\operatorname*{Div}\left(  a\right)
$ (since both $\operatorname*{Div}\left(  a,0\right)  $ and
$\operatorname*{Div}\left(  a\right)  $ are sets of integers). Thus, Lemma
\ref{lem.ent.gcd.through-Divc} (applied to $\left(  a,0\right)  $ and $\left(
a\right)  $ instead of $\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ and
$\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  $) yields $\gcd\left(
a,0\right)  =\gcd\left(  a\right)  $.

For any integer $x$, we have the following chain of equivalences:
\begin{align*}
&  \ \left(  x\in\operatorname*{Div}\left(  a\right)  \right) \\
&  \Longleftrightarrow\ \left(  x\text{ is a common divisor of }a\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\operatorname*{Div}%
\left(  a\right)  \right) \\
&  \Longleftrightarrow\ \left(  x\mid a\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by the definition of a \textquotedblleft common
divisor\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  x\text{ is a divisor of }a\right)  .
\end{align*}
Thus, $\operatorname*{Div}\left(  a\right)  $ is the set of all divisors of
$a$.

Exercise \ref{exe.ent.div.aabs} \textbf{(b)} yields $\left\vert a\right\vert
\mid a$. In other words, $\left\vert a\right\vert $ is a divisor of $a$.

Moreover, $a$ is nonzero (since $a\neq0$). Hence, Proposition
\ref{prop.ent.divisors.find} \textbf{(b)} (applied to $b=a$) shows that all
divisors of $a$ belong to the set $\left\{  -\left\vert a\right\vert
,-\left\vert a\right\vert +1,\ldots,\left\vert a\right\vert \right\}
\setminus\left\{  0\right\}  $. Hence, they belong to the set $\left\{
-\left\vert a\right\vert ,-\left\vert a\right\vert +1,\ldots,\left\vert
a\right\vert \right\}  $, and thus are $\leq\left\vert a\right\vert $.

Recall that $\left\vert a\right\vert $ is a divisor of $a$. Since we also know
that all divisors of $a$ are $\leq\left\vert a\right\vert $, we can thus
conclude that $\left\vert a\right\vert $ is the \textbf{largest} divisor of
$a$. In other words, $\left\vert a\right\vert $ is the largest element of the
set $\operatorname*{Div}\left(  a\right)  $ (since $\operatorname*{Div}\left(
a\right)  $ is the set of all divisors of $a$). In other words, $\left\vert
a\right\vert $ is $\gcd\left(  a\right)  $ (since $\gcd\left(  a\right)  $ is
the largest element of the set $\operatorname*{Div}\left(  a\right)  $). Thus,
$\gcd\left(  a\right)  =\left\vert a\right\vert $. Combining this with
$\gcd\left(  a,0\right)  =\gcd\left(  a\right)  $, this yields $\gcd\left(
a,0\right)  =\gcd\left(  a\right)  =\left\vert a\right\vert $. Thus,
Proposition \ref{prop.ent.gcd.props1} \textbf{(a)} is finally proven.
\end{fineprint}

\textbf{(b)} For any integer $x$, we have the following chain of equivalences:%
\begin{align*}
&  \ \left(  x\in\operatorname*{Div}\left(  a,b\right)  \right) \\
&  \Longleftrightarrow\ \left(  x\text{ is a common divisor of }a\text{ and
}b\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of
}\operatorname*{Div}\left(  a,b\right)  \right) \\
&  \Longleftrightarrow\ \left(  x\mid a\text{ and }x\mid b\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of a \textquotedblleft
common divisor\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  x\mid b\text{ and }x\mid a\right) \\
&  \Longleftrightarrow\ \left(  x\text{ is a common divisor of }b\text{ and
}a\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of a \textquotedblleft
common divisor\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  x\in\operatorname*{Div}\left(  b,a\right)
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }%
\operatorname*{Div}\left(  b,a\right)  \right)  .
\end{align*}
In other words, an integer belongs to $\operatorname*{Div}\left(  a,b\right)
$ if and only if it belongs to $\operatorname*{Div}\left(  b,a\right)  $.
Thus, $\operatorname*{Div}\left(  a,b\right)  =\operatorname*{Div}\left(
b,a\right)  $ (since both $\operatorname*{Div}\left(  a,b\right)  $ and
$\operatorname*{Div}\left(  b,a\right)  $ are sets of integers). Thus, Lemma
\ref{lem.ent.gcd.through-Divc} (applied to $\left(  a,b\right)  $ and $\left(
b,a\right)  $ instead of $\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ and
$\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  $) yields $\gcd\left(
a,b\right)  =\gcd\left(  b,a\right)  $. This proves Proposition
\ref{prop.ent.gcd.props1} \textbf{(b)}.

Let us prove part \textbf{(d)} now, and then derive part \textbf{(c)} from it.

\textbf{(d)} Let $a,b,c\in\mathbb{Z}$ satisfy $b\equiv c\operatorname{mod}a$.
We must prove that $\gcd\left(  a,b\right)  =\gcd\left(  a,c\right)  $. To do
so, we shall first prove that $\operatorname*{Div}\left(  a,b\right)
=\operatorname*{Div}\left(  a,c\right)  $.

From $b\equiv c\operatorname{mod}a$, we obtain $c\equiv b\operatorname{mod}a$
(by Proposition \ref{prop.ent.mod.basics} \textbf{(c)}). Hence, our situation
is symmetric with respect to $b$ and $c$.

We shall now show that $\operatorname*{Div}\left(  a,b\right)  \subseteq
\operatorname*{Div}\left(  a,c\right)  $. Indeed, let $x\in\operatorname*{Div}%
\left(  a,b\right)  $. Then, $x$ is a common divisor of $a$ and $b$ (by the
definition of $\operatorname*{Div}\left(  a,b\right)  $). In other words,
$x\mid a$ and $x\mid b$ (by the definition of a \textquotedblleft common
divisor\textquotedblright). From $x\mid b$, we obtain $b\equiv
0\operatorname{mod}x$. But from $x\mid a$ and $c\equiv b\operatorname{mod}a$,
we obtain $c\equiv b\operatorname{mod}x$ (by Proposition
\ref{prop.ent.mod.basics} \textbf{(e)}, applied to $a$, $x$, $c$ and $b$
instead of $n$, $m$, $c$ and $b$). Thus, $c\equiv b\equiv0\operatorname{mod}%
x$, so that $x\mid c$. Combining $x\mid a$ and $x\mid c$, we see that $x$ is a
common divisor of $a$ and $c$ (by the definition of a \textquotedblleft common
divisor\textquotedblright). In other words, $x\in\operatorname*{Div}\left(
a,c\right)  $ (by the definition of $\operatorname*{Div}\left(  a,c\right)  $).

Now, forget that we fixed $x$. We thus have proven that $x\in
\operatorname*{Div}\left(  a,c\right)  $ for each $x\in\operatorname*{Div}%
\left(  a,b\right)  $. In other words, $\operatorname*{Div}\left(  a,b\right)
\subseteq\operatorname*{Div}\left(  a,c\right)  $.

The same argument (but with the roles of $b$ and $c$ swapped) shows that
$\operatorname*{Div}\left(  a,c\right)  \subseteq\operatorname*{Div}\left(
a,b\right)  $ (since our situation is symmetric with respect to $b$ and $c$).
Combining this with $\operatorname*{Div}\left(  a,b\right)  \subseteq
\operatorname*{Div}\left(  a,c\right)  $, we obtain $\operatorname*{Div}%
\left(  a,b\right)  =\operatorname*{Div}\left(  a,c\right)  $. Thus, Lemma
\ref{lem.ent.gcd.through-Divc} (applied to $\left(  a,b\right)  $ and $\left(
a,c\right)  $ instead of $\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ and
$\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  $) yields $\gcd\left(
a,b\right)  =\gcd\left(  a,c\right)  $. This proves Proposition
\ref{prop.ent.gcd.props1} \textbf{(d)}.

\textbf{(c)} Let $a,b,u\in\mathbb{Z}$. Then, $ua+b\equiv b\operatorname{mod}a$
(since $\left(  ua+b\right)  -b=ua$ is clearly divisible by $a$). Thus,
Proposition \ref{prop.ent.gcd.props1} \textbf{(d)} (applied to $ua+b$ and $b$
instead of $b$ and $c$) yields $\gcd\left(  a,ua+b\right)  =\gcd\left(
a,b\right)  $. This proves Proposition \ref{prop.ent.gcd.props1} \textbf{(c)}.

\textbf{(e)} Let $a,b\in\mathbb{Z}$ be such that $a$ is positive. Then,
$b\%a\equiv b\operatorname{mod}a$ (by Corollary \ref{cor.ent.quo-rem.remmod}
\textbf{(a)}, applied to $a$ and $b$ instead of $n$ and $u$), thus $b\equiv
b\%a\operatorname{mod}a$. Hence, $\gcd\left(  a,b\right)  =\gcd\left(
a,b\%a\right)  $ (by Proposition \ref{prop.ent.gcd.props1} \textbf{(d)},
applied to $c=b\%a$). This proves Proposition \ref{prop.ent.gcd.props1}
\textbf{(e)}.

\textbf{(f)} Let $a,b\in\mathbb{Z}$. We must prove that $\gcd\left(
a,b\right)  \mid a$ and $\gcd\left(  a,b\right)  \mid b$.

If the two integers $a,b$ are all $0$, then this is
obvious\footnote{\textit{Proof.} Assume that $a,b$ are all $0$. Then,
$a=0=\gcd\left(  a,b\right)  \cdot0$, so that $\gcd\left(  a,b\right)  \mid
a$; similarly, $\gcd\left(  a,b\right)  \mid b$. Hence, we have proven that
$\gcd\left(  a,b\right)  \mid a$ and $\gcd\left(  a,b\right)  \mid b$ if the
integers $a,b$ are all $0$.}. Hence, for the rest of this proof, we WLOG
assume that $a,b$ are not all $0$. Thus, $\gcd\left(  a,b\right)  $ is defined
to be the largest element of the set $\operatorname*{Div}\left(  a,b\right)  $
(by Definition \ref{def.ent.gcd.gcd}). Hence, $\gcd\left(  a,b\right)  $ is an
element of this set $\operatorname*{Div}\left(  a,b\right)  $. In other words,
$\gcd\left(  a,b\right)  $ is a common divisor of $a$ and $b$ (by the
definition of $\operatorname*{Div}\left(  a,b\right)  $). In other words,
$\gcd\left(  a,b\right)  \mid a$ and $\gcd\left(  a,b\right)  \mid b$. This
proves Proposition \ref{prop.ent.gcd.props1} \textbf{(f)}.

\textbf{(g)} Let $a,b\in\mathbb{Z}$. We must prove that $\gcd\left(
-a,b\right)  =\gcd\left(  a,b\right)  $. Again, we shall achieve this via
showing that $\operatorname*{Div}\left(  -a,b\right)  =\operatorname*{Div}%
\left(  a,b\right)  $.

First, we will show that $\operatorname*{Div}\left(  a,b\right)
\subseteq\operatorname*{Div}\left(  -a,b\right)  $. Indeed, let $x\in
\operatorname*{Div}\left(  a,b\right)  $. Then, $x$ is a common divisor of $a$
and $b$ (by the definition of $\operatorname*{Div}\left(  a,b\right)  $). In
other words, $x\mid a$ and $x\mid b$ (by the definition of a \textquotedblleft
common divisor\textquotedblright). We have $a\mid-a$ (since $-a=a\cdot\left(
-1\right)  $). Thus, $x\mid a\mid-a$. Combining $x\mid-a$ and $x\mid b$, we
see that $x$ is a common divisor of $-a$ and $b$ (by the definition of a
\textquotedblleft common divisor\textquotedblright). In other words,
$x\in\operatorname*{Div}\left(  -a,b\right)  $ (by the definition of
$\operatorname*{Div}\left(  -a,b\right)  $).

Now, forget that we fixed $x$. We thus have proven that $x\in
\operatorname*{Div}\left(  -a,b\right)  $ for each $x\in\operatorname*{Div}%
\left(  a,b\right)  $. In other words, $\operatorname*{Div}\left(  a,b\right)
\subseteq\operatorname*{Div}\left(  -a,b\right)  $.

The same argument (but applied to $-a$ instead of $a$) shows that
$\operatorname*{Div}\left(  -a,b\right)  \subseteq\operatorname*{Div}\left(
-\left(  -a\right)  ,b\right)  $. Since $-\left(  -a\right)  =a$, this
rewrites as $\operatorname*{Div}\left(  -a,b\right)  \subseteq
\operatorname*{Div}\left(  a,b\right)  $. Combining this with
$\operatorname*{Div}\left(  a,b\right)  \subseteq\operatorname*{Div}\left(
-a,b\right)  $, we obtain $\operatorname*{Div}\left(  -a,b\right)
=\operatorname*{Div}\left(  a,b\right)  $. Thus, Lemma
\ref{lem.ent.gcd.through-Divc} (applied to $\left(  -a,b\right)  $ and
$\left(  a,b\right)  $ instead of $\left(  b_{1},b_{2},\ldots,b_{k}\right)  $
and $\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  $) yields $\gcd\left(
-a,b\right)  =\gcd\left(  a,b\right)  $. This proves Proposition
\ref{prop.ent.gcd.props1} \textbf{(g)}.

\textbf{(h)} We can prove this similarly to how we just proved Proposition
\ref{prop.ent.gcd.props1} \textbf{(g)}, but it is easier to derive it from
what was already shown.

Let $a,b\in\mathbb{Z}$. Proposition \ref{prop.ent.gcd.props1} \textbf{(b)}
(applied to $-b$ instead of $b$) yields%
\begin{align*}
\gcd\left(  a,-b\right)   &  =\gcd\left(  -b,a\right)  =\gcd\left(
b,a\right)  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Proposition \ref{prop.ent.gcd.props1} \textbf{(g),}}\\
\text{applied to }b\text{ and }a\text{ instead of }a\text{ and }b
\end{array}
\right) \\
&  =\gcd\left(  a,b\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.ent.gcd.props1} \textbf{(b)}}\right)  .
\end{align*}
This proves Proposition \ref{prop.ent.gcd.props1} \textbf{(h)}.

\textbf{(i)} Let $a,b\in\mathbb{Z}$ satisfy $a\mid b$. From $a\mid b$, we
obtain $b\equiv0\operatorname{mod}a$. Hence, Proposition
\ref{prop.ent.gcd.props1} \textbf{(d)} (applied to $c=0$) yields $\gcd\left(
a,b\right)  =\gcd\left(  a,0\right)  =\left\vert a\right\vert $ (by
Proposition \ref{prop.ent.gcd.props1} \textbf{(a)}). This proves Proposition
\ref{prop.ent.gcd.props1} \textbf{(i)}.

\textbf{(j)} The empty list of integers $\left(  {}\right)  $ has the property
that all its entries are $0$ (indeed, this is vacuously true because it has no
entries at all). Thus, its greatest common divisor is defined to be $0$ (by
the \textquotedblleft If $b_{1},b_{2},\ldots,b_{k}$ are not all $0$%
\textquotedblright\ case of Definition \ref{def.ent.gcd.gcd}). In other words,
$\gcd\left(  {}\right)  =0$. This proves Proposition \ref{prop.ent.gcd.props1}
\textbf{(j)}.
\end{proof}

\begin{remark}
Proposition \ref{prop.ent.gcd.props1} \textbf{(c)} says that if we add a
multiple of $a$ to $b$, then $\gcd\left(  a,b\right)  $ does not change.
Similarly, if we add a multiple of $b$ to $a$, then $\gcd\left(  a,b\right)  $
does not change (i.e., we have $\gcd\left(  vb+a,b\right)  =\gcd\left(
a,b\right)  $ for all $a,b,v\in\mathbb{Z}$).

However, if we \textbf{simultaneously} add a multiple of $a$ to $b$ and a
multiple of $b$ to $a$, then $\gcd\left(  a,b\right)  $ may well change: i.e.,
we may have $\gcd\left(  vb+a,ua+b\right)  \neq\gcd\left(  a,b\right)  $ for
all $a,b,u,v\in\mathbb{Z}$. Examples are easy to find (just take $v=1$ and
$u=1$).
\end{remark}

Proposition \ref{prop.ent.gcd.props1} gives a quick way to compute
$\gcd\left(  a,b\right)  $ for two nonnegative integers $a$ and $b$, by
repeatedly applying division with remainder. For example, let us compute
$\gcd\left(  210,45\right)  $ as follows:%
\begin{align*}
\gcd\left(  210,45\right)   &  =\gcd\left(  45,210\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.ent.gcd.props1}
\textbf{(b)}}\right) \\
&  =\gcd\left(  45,\underbrace{210\%45}_{=30}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.ent.gcd.props1}
\textbf{(e)}}\right) \\
&  =\gcd\left(  45,30\right) \\
&  =\gcd\left(  30,45\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.ent.gcd.props1} \textbf{(b)}}\right) \\
&  =\gcd\left(  30,\underbrace{45\%30}_{=15}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.ent.gcd.props1}
\textbf{(e)}}\right) \\
&  =\gcd\left(  30,15\right) \\
&  =\gcd\left(  15,30\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.ent.gcd.props1} \textbf{(b)}}\right) \\
&  =\gcd\left(  15,\underbrace{30\%15}_{=0}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.ent.gcd.props1}
\textbf{(e)}}\right) \\
&  =\gcd\left(  15,0\right)  =\left\vert 15\right\vert
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.ent.gcd.props1}
\textbf{(a)}}\right) \\
&  =15.
\end{align*}
This method of computing $\gcd\left(  a,b\right)  $ is called the
\textit{Euclidean algorithm}, and is usually much faster than the divisors of
$a$ or the divisors of $b$ can be found!

The following exercise shows that the number $\gcd\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  $ depends only on the \textbf{set} $\left\{  b_{1}%
,b_{2},\ldots,b_{k}\right\}  $, but not on the numbers $b_{1},b_{2}%
,\ldots,b_{k}$ themselves. Thus, for example, any integers $a$, $b$ and $c$
satisfy $\gcd\left(  a,b,c,a\right)  =\gcd\left(  c,a,b\right)  $ (since
$\left\{  a,b,c,a\right\}  =\left\{  c,a,b\right\}  $) and $\gcd\left(
a,a,b,a\right)  =\gcd\left(  a,b,b\right)  $ (since $\left\{  a,a,b,a\right\}
=\left\{  a,b,b\right\}  $).

\begin{exercise}
\label{exe.ent.gcd.set}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely many
integers. Let $c_{1},c_{2},\ldots,c_{\ell}$ be finitely many integers. Prove
that if%
\[
\left\{  b_{1},b_{2},\ldots,b_{k}\right\}  =\left\{  c_{1},c_{2}%
,\ldots,c_{\ell}\right\}  ,
\]
then%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =\gcd\left(  c_{1},c_{2}%
,\ldots,c_{\ell}\right)  .
\]

\end{exercise}

\subsubsection{Bezout's theorem}

The following fact about gcds is one of the most important facts in number theory:

\begin{theorem}
\label{thm.ent.gcd.bezout}Let $a$ and $b$ be two integers. Then, there exist
integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that%
\[
\gcd\left(  a,b\right)  =xa+yb.
\]

\end{theorem}

Theorem \ref{thm.ent.gcd.bezout} is often stated as follows: \textquotedblleft
If $a$ and $b$ are two integers, then $\gcd\left(  a,b\right)  $ is a
$\mathbb{Z}$-linear combination of $a$ and $b$\textquotedblright. The notion
\textquotedblleft$\mathbb{Z}$-linear combination of $a$ and $b$%
\textquotedblright\ simply means \textquotedblleft a number of the form
$xa+yb$ with $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$\textquotedblright\ (this is
exactly the notion of a \textquotedblleft linear combination\textquotedblright%
\ in linear algebra, except that now the scalars must come from $\mathbb{Z}$),
so this is just a restatement of Theorem \ref{thm.ent.gcd.bezout}.

\begin{teachingnote}
The following proof of Bezout's theorem is not quite the fastest, nor does it
generalize to polynomial rings over fields. Maybe replace it by another, which
uses division with remainder and induction on $\left\vert a\right\vert
+\left\vert b\right\vert $ (so no need to split into three steps). This is
also needed because I refer to the Extended Euclidean algorithm in the
computational parts, but I never explain how it works.
\end{teachingnote}

Theorem \ref{thm.ent.gcd.bezout} is known as \textit{Bezout's theorem} (or
\textit{Bezout's identity})\footnote{or \textit{Bezout's theorem for integers}
if you want to be more precise (as there are similar theorems for other
objects)}. We shall prove it in several steps. The first step is to show it
when $a$ and $b$ are nonnegative:

\begin{lemma}
\label{lem.ent.gcd.bezout.++}Let $a\in\mathbb{N}$ and $b\in\mathbb{N}$. Then,
there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that%
\[
\gcd\left(  a,b\right)  =xa+yb.
\]

\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.gcd.bezout.++}.]The following proof uses a
strategy similar to the Euclidean algorithm (making one of $a$ and $b$ smaller
repeatedly until one of $a$ and $b$ becomes $0$), and can in fact be viewed as
a \textquotedblleft protocol\textquotedblright\ of the algorithm\footnote{or,
rather, of a more primitive version of the Euclidean algorithm, in which we
apply not the full power of Proposition \ref{prop.ent.gcd.props1} \textbf{(e)}
but only the identity $\gcd\left(  a,b\right)  =\gcd\left(  a,b-a\right)  $}.

We use strong induction on $a+b$. Thus, we fix an $n\in\mathbb{N}$, and assume
(as induction hypothesis) that Lemma \ref{lem.ent.gcd.bezout.++} holds
whenever $a+b<n$. We must now prove that Lemma \ref{lem.ent.gcd.bezout.++}
holds whenever $a+b=n$.

We have assumed that Lemma \ref{lem.ent.gcd.bezout.++} holds whenever $a+b<n$.
In other words, the following statement holds:

\begin{statement}
\textit{Statement 1:} Let $a\in\mathbb{N}$ and $b\in\mathbb{N}$ be such that
$a+b<n$. Then, there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such
that $\gcd\left(  a,b\right)  =xa+yb$.
\end{statement}

Now, we must prove that Lemma \ref{lem.ent.gcd.bezout.++} holds whenever
$a+b=n$. Let us first prove this in the case when $b\geq a$:

\begin{statement}
\textit{Statement 2:} Let $a\in\mathbb{N}$ and $b\in\mathbb{N}$ be such that
$a+b=n$ and $b\geq a$. Then, there exist integers $x\in\mathbb{Z}$ and
$y\in\mathbb{Z}$ such that $\gcd\left(  a,b\right)  =xa+yb$.
\end{statement}

[\textit{Proof of Statement 2:} We are in one of the following two cases:

\textit{Case 1:} We have $a=0$.

\textit{Case 2:} We have $a\neq0$.

Let us first consider Case 1. In this case, we have $a=0$. Now, Proposition
\ref{prop.ent.gcd.props1} \textbf{(a)} (applied to $b$ instead of $a$) yields
$\gcd\left(  b,0\right)  =\gcd\left(  b\right)  =\left\vert b\right\vert
\in\left\{  b,-b\right\}  $. In other words, $\gcd\left(  b,0\right)  =ub$ for
some $u\in\left\{  1,-1\right\}  $. Consider this $u$. Now, Proposition
\ref{prop.ent.gcd.props1} \textbf{(b)} yields%
\[
\gcd\left(  a,b\right)  =\gcd\left(  b,\underbrace{a}_{=0}\right)
=\gcd\left(  b,0\right)  =ub=0a+ub.
\]
Hence, there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that
$\gcd\left(  a,b\right)  =xa+yb$ (namely, $x=0$ and $y=u$). Thus, Statement 2
is proven in Case 1.

Let us next consider Case 2. In this case, we have $a\neq0$. Hence, $a>0$
(since $a\in\mathbb{N}$), so that $a+b>b$. Hence, $b<a+b=n$.

From $b\geq a$, we obtain $b-a\in\mathbb{N}$. Moreover, $a\in\mathbb{N}$ and
$b-a\in\mathbb{N}$ satisfy $a+\left(  b-a\right)  =b<n$. Therefore, we can
apply Statement 1 \textbf{to }$b-a$ \textbf{instead of }$b$. Thus we obtain
that there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that
$\gcd\left(  a,b-a\right)  =xa+y\left(  b-a\right)  $. Fix two such integers
$x$ and $y$, and denote them by $x_{0}$ and $y_{0}$. Thus, $x_{0}$ and $y_{0}$
are two integers such that $\gcd\left(  a,b-a\right)  =x_{0}a+y_{0}\left(
b-a\right)  $.

Also, Proposition \ref{prop.ent.gcd.props1} \textbf{(c)} (applied to $u=-1$)
yields $\gcd\left(  a,\left(  -1\right)  a+b\right)  =\gcd\left(  a,b\right)
$. Hence,%
\begin{align*}
\gcd\left(  a,b\right)   &  =\gcd\left(  a,\underbrace{\left(  -1\right)
a+b}_{=b-a}\right)  =\gcd\left(  a,b-a\right)  =x_{0}a+y_{0}\left(  b-a\right)
\\
&  =x_{0}a+y_{0}b-y_{0}a=\left(  x_{0}-y_{0}\right)  a+y_{0}b.
\end{align*}
Hence, there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that
$\gcd\left(  a,b\right)  =xa+yb$ (namely, $x=x_{0}-y_{0}$ and $y=y_{0}$).
Thus, Statement 2 is proven in Case 2.

We have now proven Statement 2 in both Cases 1 and 2. Hence, Statement 2 is
always proven.]

Now, we can prove that Lemma \ref{lem.ent.gcd.bezout.++} holds whenever
$a+b=n$:

\begin{statement}
\textit{Statement 3:} Let $a\in\mathbb{N}$ and $b\in\mathbb{N}$ be such that
$a+b=n$. Then, there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such
that $\gcd\left(  a,b\right)  =xa+yb$.
\end{statement}

[\textit{Proof of Statement 3:} We are in one of the following two cases:

\textit{Case 1:} We have $b\geq a$.

\textit{Case 2:} We have $b<a$.

Let us first consider Case 1. In this case, we have $b\geq a$. Hence,
Statement 2 shows that there exist integers $x\in\mathbb{Z}$ and
$y\in\mathbb{Z}$ such that $\gcd\left(  a,b\right)  =xa+yb$. Thus, Statement 3
is proven in Case 1.

Let us next consider Case 2. In this case, we have $b<a$. Hence, $a>b$, so
that $a\geq b$. This shows that we can apply Statement 2 \textbf{to }%
$b$\textbf{ and }$a$ \textbf{instead of }$a$ \textbf{and }$b$. Thus we obtain
that there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that
$\gcd\left(  b,a\right)  =xb+ya$. Fix two such integers $x$ and $y$, and
denote them by $x_{0}$ and $y_{0}$. Thus, $x_{0}$ and $y_{0}$ are two integers
such that $\gcd\left(  b,a\right)  =x_{0}b+y_{0}a$. Now, Proposition
\ref{prop.ent.gcd.props1} \textbf{(b)} yields $\gcd\left(  a,b\right)
=\gcd\left(  b,a\right)  =x_{0}b+y_{0}a=y_{0}a+x_{0}b$. Hence, there exist
integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that $\gcd\left(
a,b\right)  =xa+yb$ (namely, $x=y_{0}$ and $y=x_{0}$). Thus, Statement 3 is
proven in Case 2.

We have now proven Statement 3 in both Cases 1 and 2. Hence, Statement 3 is
always proven.]

By proving Statement 3, we have shown that Lemma \ref{lem.ent.gcd.bezout.++}
holds whenever $a+b=n$. This completes the induction step. Thus, Lemma
\ref{lem.ent.gcd.bezout.++} is proven by strong induction.
\end{proof}

Next, we shall prove Theorem \ref{thm.ent.gcd.bezout} when $a\in\mathbb{N}$
but $b$ may be negative:

\begin{lemma}
\label{lem.ent.gcd.bezout.+}Let $a\in\mathbb{N}$ and $b\in\mathbb{Z}$. Then,
there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that%
\[
\gcd\left(  a,b\right)  =xa+yb.
\]

\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.gcd.bezout.+}.]We are in one of the following two cases:

\textit{Case 1:} We have $b\geq0$.

\textit{Case 2:} We have $b<0$.

Let us first consider Case 1. In this case, we have $b\geq0$. Thus,
$b\in\mathbb{N}$ (since $b\in\mathbb{Z}$). Therefore, Lemma
\ref{lem.ent.gcd.bezout.++} shows that there exist integers $x\in\mathbb{Z}$
and $y\in\mathbb{Z}$ such that $\gcd\left(  a,b\right)  =xa+yb$. Thus, Lemma
\ref{lem.ent.gcd.bezout.+} is proven in Case 1.

Let us now consider Case 2. In this case, we have $b<0$. Hence, $-b>0$, so
that $-b\in\mathbb{N}$ (since $-b\in\mathbb{Z}$). Therefore, Lemma
\ref{lem.ent.gcd.bezout.++} (applied to $-b$ instead of $b$) shows that there
exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that $\gcd\left(
a,-b\right)  =xa+y\left(  -b\right)  $. Fix such integers, and denote them by
$x_{0}$ and $y_{0}$. Thus, $x_{0}\in\mathbb{Z}$ and $y_{0}\in\mathbb{Z}$ are
integers such that $\gcd\left(  a,-b\right)  =x_{0}a+y_{0}\left(  -b\right)  $.

Now, Proposition \ref{prop.ent.gcd.props1} \textbf{(h)} yields $\gcd\left(
a,-b\right)  =\gcd\left(  a,b\right)  $. Hence,%
\[
\gcd\left(  a,b\right)  =\gcd\left(  a,-b\right)  =x_{0}a+y_{0}\left(
-b\right)  =x_{0}a+\left(  -y_{0}\right)  b.
\]
Hence, there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that
$\gcd\left(  a,b\right)  =xa+yb$ (namely, $x=x_{0}$ and $y=-y_{0}$). Thus,
Lemma \ref{lem.ent.gcd.bezout.+} is proven in Case 2.

We have now proven Lemma \ref{lem.ent.gcd.bezout.+} in both Cases 1 and 2.
Hence, Lemma \ref{lem.ent.gcd.bezout.+} is proven.
\end{proof}

Now, we can prove the whole Theorem \ref{thm.ent.gcd.bezout}:

\begin{proof}
[Proof of Theorem \ref{thm.ent.gcd.bezout}.]Theorem \ref{thm.ent.gcd.bezout}
can be derived from Lemma \ref{lem.ent.gcd.bezout.+} in the same way as Lemma
\ref{lem.ent.gcd.bezout.+} was derived from Lemma \ref{lem.ent.gcd.bezout.++}
(except that this time, we have to distinguish between the cases $a\geq0$ and
$a<0$, and we have to use Proposition \ref{prop.ent.gcd.props1} \textbf{(g)}
instead of Proposition \ref{prop.ent.gcd.props1} \textbf{(h)}). Again, let us
give the detailed argument for the sake of completeness:

\begin{fineprint}
We are in one of the following two cases:

\textit{Case 1:} We have $a\geq0$.

\textit{Case 2:} We have $a<0$.

Let us first consider Case 1. In this case, we have $a\geq0$. Thus,
$a\in\mathbb{N}$ (since $a\in\mathbb{Z}$). Therefore, Lemma
\ref{lem.ent.gcd.bezout.+} shows that there exist integers $x\in\mathbb{Z}$
and $y\in\mathbb{Z}$ such that $\gcd\left(  a,b\right)  =xa+yb$. Thus, Theorem
\ref{thm.ent.gcd.bezout} is proven in Case 1.

Let us now consider Case 2. In this case, we have $a<0$. Hence, $-a>0$, so
that $-a\in\mathbb{N}$ (since $-a\in\mathbb{Z}$). Therefore, Lemma
\ref{lem.ent.gcd.bezout.+} (applied to $-a$ instead of $a$) shows that there
exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that $\gcd\left(
-a,b\right)  =x\left(  -a\right)  +yb$. Fix such integers, and denote them by
$x_{0}$ and $y_{0}$. Thus, $x_{0}\in\mathbb{Z}$ and $y_{0}\in\mathbb{Z}$ are
integers such that $\gcd\left(  -a,b\right)  =x_{0}\left(  -a\right)  +y_{0}b$.

Now, Proposition \ref{prop.ent.gcd.props1} \textbf{(g)} yields $\gcd\left(
-a,b\right)  =\gcd\left(  a,b\right)  $. Hence,%
\[
\gcd\left(  a,b\right)  =\gcd\left(  -a,b\right)  =x_{0}\left(  -a\right)
+y_{0}b=\left(  -x_{0}\right)  a+y_{0}b.
\]
Hence, there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that
$\gcd\left(  a,b\right)  =xa+yb$ (namely, $x=-x_{0}$ and $y=y_{0}$). Thus,
Theorem \ref{thm.ent.gcd.bezout} is proven in Case 2.

We have now proven Theorem \ref{thm.ent.gcd.bezout} in both Cases 1 and 2.
Hence, Theorem \ref{thm.ent.gcd.bezout} is proven.
\end{fineprint}
\end{proof}

\begin{exercise}
\label{exe.ent.gcd.an-1}Let $u$ be an integer.

\textbf{(a)} Prove that $u^{b}-1\equiv u^{a}-1\operatorname{mod}u^{b-a}-1$ for
any $a\in\mathbb{N}$ and $b\in\mathbb{N}$ satisfying $b\geq a$.

\textbf{(b)} Prove that $\gcd\left(  u^{a}-1,u^{b}-1\right)  =\left\vert
u^{\gcd\left(  a,b\right)  }-1\right\vert $ for all $a\in\mathbb{N}$ and
$b\in\mathbb{N}$.
\end{exercise}

\subsubsection{First applications of Bezout's theorem}

An important corollary of Theorem \ref{thm.ent.gcd.bezout} is the following fact:

\begin{theorem}
\label{thm.ent.gcd.uniprop}Let $a,b\in\mathbb{Z}$. Then:

\textbf{(a)} For each $m\in\mathbb{Z}$, we have the following logical
equivalence:%
\begin{equation}
\left(  m\mid a\ \text{and }m\mid b\right)  \ \Longleftrightarrow\ \left(
m\mid\gcd\left(  a,b\right)  \right)  . \label{eq.thm.ent.gcd.uniprop.equiv}%
\end{equation}


\textbf{(b)} The common divisors of $a$ and $b$ are precisely the divisors of
$\gcd\left(  a,b\right)  $.

\textbf{(c)} We have $\operatorname*{Div}\left(  a,b\right)
=\operatorname*{Div}\left(  \gcd\left(  a,b\right)  \right)  $.
\end{theorem}

The three parts of this theorem are saying the same thing from slightly
different perspectives; the importance of the theorem nevertheless justifies
this repetition. To prove the theorem, we first show the following:

\begin{lemma}
\label{lem.ent.gcd.uniprop}Let $m,a,b\in\mathbb{Z}$ be such that $m\mid a$ and
$m\mid b$. Then, $m\mid\gcd\left(  a,b\right)  $.
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.gcd.uniprop}.]Theorem \ref{thm.ent.gcd.bezout}
shows that there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such
that%
\begin{equation}
\gcd\left(  a,b\right)  =xa+yb. \label{pf.lem.ent.gcd.uniprop.1}%
\end{equation}
Consider these $x$ and $y$. Now, $m\mid a\mid xa$, so that $xa\equiv
0\operatorname{mod}m$. Also, $m\mid b\mid yb$, thus $yb\equiv
0\operatorname{mod}m$. Adding the congruences $xa\equiv0\operatorname{mod}m$
and $yb\equiv0\operatorname{mod}m$ together, we find $xa+yb\equiv
0+0=0\operatorname{mod}m$; in other words, $m\mid xa+yb$. In view of
(\ref{pf.lem.ent.gcd.uniprop.1}), this rewrites as $m\mid\gcd\left(
a,b\right)  $. This proves Lemma \ref{lem.ent.gcd.uniprop}.
\end{proof}

\begin{proof}
[Proof of Theorem \ref{thm.ent.gcd.uniprop}.]\textbf{(a)} Let $m\in\mathbb{Z}%
$. In order to prove (\ref{eq.thm.ent.gcd.uniprop.equiv}), we need to prove
the \textquotedblleft$\Longrightarrow$\textquotedblright\ and
\textquotedblleft$\Longleftarrow$\textquotedblright\ directions of the
equivalence (\ref{eq.thm.ent.gcd.uniprop.equiv}). But this is easy: The
\textquotedblleft$\Longrightarrow$\textquotedblright\ direction is just the
statement of Lemma \ref{lem.ent.gcd.uniprop}, whereas the \textquotedblleft%
$\Longleftarrow$\textquotedblright\ direction is trivial (to wit: if
$m\mid\gcd\left(  a,b\right)  $, then
\[
m\mid\gcd\left(  a,b\right)  \mid a\ \ \ \ \ \ \ \ \ \ \left(  \text{by
Proposition \ref{prop.ent.gcd.props1} \textbf{(e)}}\right)
\]
and%
\[
m\mid\gcd\left(  a,b\right)  \mid b\ \ \ \ \ \ \ \ \ \ \left(  \text{by
Proposition \ref{prop.ent.gcd.props1} \textbf{(e)}}\right)  ,
\]
and thus $\left(  m\mid a\ \text{and }m\mid b\right)  $). Hence, the
equivalence (\ref{eq.thm.ent.gcd.uniprop.equiv}) is proven. This proves
Theorem \ref{thm.ent.gcd.uniprop} \textbf{(a)}.

\textbf{(b)} The common divisors of $a$ and $b$ are precisely the integers $m$
that satisfy $\left(  m\mid a\text{ and }m\mid b\right)  $ (by the definition
of \textquotedblleft common divisor\textquotedblright). In view of the
equivalence (\ref{eq.thm.ent.gcd.uniprop.equiv}), this rewrites as follows:
The common divisors of $a$ and $b$ are precisely the integers $m$ that satisfy
$m\mid\gcd\left(  a,b\right)  $. In other words, the common divisors of $a$
and $b$ are precisely the divisors of $\gcd\left(  a,b\right)  $. This proves
Theorem \ref{thm.ent.gcd.uniprop} \textbf{(b)}.

\textbf{(c)} Recall that each $c\in\mathbb{Z}$ satisfies%
\begin{align*}
\operatorname*{Div}\left(  c\right)   &  =\left\{  \text{the common divisors
of }c\right\}  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of
}\operatorname*{Div}\left(  c\right)  \right) \\
&  =\left\{  \text{the integers }x\text{ such that }x\mid c\right\} \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of \textquotedblleft
common divisors\textquotedblright}\right) \\
&  =\left\{  \text{the divisors of }c\right\}  .
\end{align*}
Applying this to $c=\gcd\left(  a,b\right)  $, we obtain%
\begin{equation}
\operatorname*{Div}\left(  \gcd\left(  a,b\right)  \right)  =\left\{
\text{the divisors of }\gcd\left(  a,b\right)  \right\}  .
\label{pf.thm.ent.gcd.uniprop.c.1a}%
\end{equation}


The definition of $\operatorname*{Div}\left(  a,b\right)  $ yields%
\begin{align*}
\operatorname*{Div}\left(  a,b\right)   &  =\left\{  \text{the common divisors
of }a\text{ and }b\right\} \\
&  =\left\{  \text{the divisors of }\gcd\left(  a,b\right)  \right\}
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem \ref{thm.ent.gcd.uniprop}
\textbf{(b)}}\right) \\
&  =\operatorname*{Div}\left(  \gcd\left(  a,b\right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.thm.ent.gcd.uniprop.c.1a}%
)}\right)  .
\end{align*}
This proves Theorem \ref{thm.ent.gcd.uniprop} \textbf{(c)}.
\end{proof}

The following corollary of Theorem \ref{thm.ent.gcd.bezout} let us
\textquotedblleft combine\textquotedblright\ two divisibilities $a\mid c$ and
$b\mid c$. In fact, Proposition \ref{prop.ent.div.2} \textbf{(c)} would
already allow us to \textquotedblleft combine\textquotedblright\ them to form
$ab\mid cc=c^{2}$; but we can also \textquotedblleft combine\textquotedblright%
\ them to $ab\mid\gcd\left(  a,b\right)  \cdot c$ using the following fact:

\begin{theorem}
\label{thm.ent.gcd.combine}Let $a,b,c\in\mathbb{Z}$ satisfy $a\mid c$ and
$b\mid c$. Then, $ab\mid\gcd\left(  a,b\right)  \cdot c$.
\end{theorem}

\begin{example}
Let $a=6$ and $b=10$ and $c=30$. Then, $a=6\mid30=c$ and $b=10\mid30=c$. Thus,
Theorem \ref{thm.ent.gcd.combine} yields $ab\mid\gcd\left(  a,b\right)  \cdot
c$. And indeed, this is true, since $ab=6\cdot10\mid2\cdot30=\gcd\left(
a,b\right)  \cdot c$ (because $\gcd\left(  a,b\right)  =\gcd\left(
6,10\right)  =2$). Note that this latter divisibility is actually an equality:
we have $6\cdot10=2\cdot30$. Note also that we do \textbf{not} obtain $ab\mid
c$ (and indeed, this does not hold).
\end{example}

\begin{proof}
[Proof of Theorem \ref{thm.ent.gcd.combine}.]Theorem \ref{thm.ent.gcd.bezout}
yields that there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such
that $\gcd\left(  a,b\right)  =xa+yb$. Consider these $x$ and $y$.

We have $a\mid c$. In other words, there exists an integer $u$ such that
$c=au$. Consider this $u$.

We have $b\mid c$. In other words, there exists an integer $v$ such that
$c=bv$. Consider this $v$.

Now,%
\[
\underbrace{\gcd\left(  a,b\right)  }_{=xa+yb}\cdot c=\left(  xa+yb\right)
c=xa\underbrace{c}_{=bv}+yb\underbrace{c}_{=au}=xabv+ybau=ab\left(
xv+yu\right)  .
\]
Thus, there exists an integer $d$ such that $\gcd\left(  a,b\right)  \cdot
c=abd$ (namely, $d=xv+yu$). In other words, $ab\mid\gcd\left(  a,b\right)
\cdot c$. This proves Theorem \ref{thm.ent.gcd.combine}.
\end{proof}

Here is another corollary of Theorem \ref{thm.ent.gcd.bezout} whose usefulness
will become clearer later on:

\begin{theorem}
\label{thm.ent.gcd.cancel}Let $a,b,c\in\mathbb{Z}$ satisfy $a\mid bc$. Then,
$a\mid\gcd\left(  a,b\right)  \cdot c$.
\end{theorem}

At this point, you should see that Theorem \ref{thm.ent.gcd.cancel} allows
\textquotedblleft strengthening\textquotedblright\ divisibilities: You give it
a \textquotedblleft weak\textquotedblright\ divisibility $a\mid bc$, and
obtain a \textquotedblleft stronger\textquotedblright\ divisibility $a\mid
\gcd\left(  a,b\right)  \cdot c$ from it (stronger because $\gcd\left(
a,b\right)  $ is usually smaller than $b$).

\begin{proof}
[Proof of Theorem \ref{thm.ent.gcd.cancel}.]Theorem \ref{thm.ent.gcd.bezout}
yields that there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such
that $\gcd\left(  a,b\right)  =xa+yb$. Consider these $x$ and $y$.

We have $a\mid bc\mid ybc$; in other words, $ybc\equiv0\operatorname{mod}a$.
Also, $a\mid axc$, so that $axc\equiv0\operatorname{mod}a$. Adding the two
congruences $axc\equiv0\operatorname{mod}a$ and $ybc\equiv0\operatorname{mod}%
a$ together, we obtain $axc+ybc\equiv0+0=0\operatorname{mod}a$. In view of
$axc+ybc=\underbrace{\left(  xa+yb\right)  }_{=\gcd\left(  a,b\right)  }%
c=\gcd\left(  a,b\right)  \cdot c$, this rewrites as $\gcd\left(  a,b\right)
\cdot c\equiv0\operatorname{mod}a$. In other words, $a\mid\gcd\left(
a,b\right)  \cdot c$. This proves Theorem \ref{thm.ent.gcd.cancel}.
\end{proof}

\begin{corollary}
\label{cor.ent.gcd.sa,sb}Let $s,a,b\in\mathbb{Z}$. Then,
\[
\gcd\left(  sa,sb\right)  =\left\vert s\right\vert \gcd\left(  a,b\right)  .
\]

\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.ent.gcd.sa,sb}.]We shall prove that the two
integers $\gcd\left(  sa,sb\right)  $ and $s\gcd\left(  a,b\right)  $ mutually
divide each other (i.e., they satisfy $\gcd\left(  sa,sb\right)  \mid
s\gcd\left(  a,b\right)  $ and $s\gcd\left(  a,b\right)  \mid\gcd\left(
sa,sb\right)  $). Then, Exercise \ref{exe.ent.div.abba} will let us conclude
that $\left\vert \gcd\left(  sa,sb\right)  \right\vert =\left\vert
s\gcd\left(  a,b\right)  \right\vert $. This will then rewrite as $\gcd\left(
sa,sb\right)  =\left\vert s\right\vert \gcd\left(  a,b\right)  $, and we will
be done. (This trick is actually a common strategy for proving equalities
between gcds.)

For the sake of brevity, let us set $g=\gcd\left(  sa,sb\right)  $ and
$h=s\gcd\left(  a,b\right)  $. So our first goal is to prove that $g\mid h$
and $h\mid g$.

\textit{Proof of }$g\mid h$\textit{:} Theorem \ref{thm.ent.gcd.bezout} yields
that there exist integers $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that
$\gcd\left(  a,b\right)  =xa+yb$. Consider these $x$ and $y$.

Proposition \ref{prop.ent.gcd.props1} \textbf{(f)} (applied to $sa$ and $sb$
instead of $a$ and $b$) yields that $\gcd\left(  sa,sb\right)  \mid sa$ and
$\gcd\left(  sa,sb\right)  \mid sb$. From $g=\gcd\left(  sa,sb\right)  \mid
sa$, we obtain $g\mid sa\mid xsa$, thus $xsa\equiv0\operatorname{mod}g$.
Similarly, $ysb\equiv0\operatorname{mod}g$. Adding these two congruences
together, we find $xsa+ysb\equiv0\operatorname{mod}g$. Now,%
\[
h=s\underbrace{\gcd\left(  a,b\right)  }_{=xa+yb}=s\left(  xa+yb\right)
=xsa+ysb\equiv0\operatorname{mod}g.
\]
In other words, $g\mid h$. Thus, we have proven $g\mid h$.

\textit{Proof of }$h\mid g$\textit{:} Proposition \ref{prop.ent.gcd.props1}
\textbf{(f)} yields $\gcd\left(  a,b\right)  \mid a$ and $\gcd\left(
a,b\right)  \mid b$. Also, $s\mid s$. Hence, Proposition \ref{prop.ent.div.2}
\textbf{(c)} (applied to $s,\gcd\left(  a,b\right)  ,s,a$ instead of
$a_{1},a_{2},b_{1},b_{2}$) yields $s\gcd\left(  a,b\right)  \mid sa$.
Similarly, $s\gcd\left(  a,b\right)  \mid sb$. Hence, Lemma
\ref{lem.ent.gcd.uniprop} (applied to $s\gcd\left(  a,b\right)  $, $sa$ and
$sb$ instead of $m$, $a$ and $b$) yields $s\gcd\left(  a,b\right)  \mid
\gcd\left(  sa,sb\right)  $. In view of $g=\gcd\left(  sa,sb\right)  $ and
$h=s\gcd\left(  a,b\right)  $, this rewrites as $h\mid g$. So we have proven
$h\mid g$.

Now, Exercise \ref{exe.ent.div.abba} (applied to $g$ and $h$ instead of $a$
and $b$) yields $\left\vert g\right\vert =\left\vert h\right\vert $.

But recall that a gcd of any finitely many integers is nonnegative (by
Definition \ref{def.ent.gcd.gcd}). Hence, in particular, $\gcd\left(
a,b\right)  $ and $\gcd\left(  sa,sb\right)  $ are nonnegative. From
$g=\gcd\left(  sa,sb\right)  $, we obtain%
\[
\left\vert g\right\vert =\left\vert \gcd\left(  sa,sb\right)  \right\vert
=\gcd\left(  sa,sb\right)
\]
(since $\gcd\left(  sa,sb\right)  $ is nonnegative). Also, from $h=s\gcd
\left(  a,b\right)  $, we obtain%
\begin{align*}
\left\vert h\right\vert  &  =\left\vert s\gcd\left(  a,b\right)  \right\vert
=\left\vert s\right\vert \cdot\underbrace{\left\vert \gcd\left(  a,b\right)
\right\vert }_{\substack{=\gcd\left(  a,b\right)  \\\text{(since }\gcd\left(
a,b\right)  \\\text{is nonnegative)}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{eq.ent.div.abs(xy)})}\right) \\
&  =\left\vert s\right\vert \gcd\left(  a,b\right)  .
\end{align*}
Hence,
\[
\gcd\left(  sa,sb\right)  =\left\vert g\right\vert =\left\vert h\right\vert
=\left\vert s\right\vert \gcd\left(  a,b\right)  .
\]
This proves Corollary \ref{cor.ent.gcd.sa,sb}.
\end{proof}

\begin{exercise}
\label{exe.ent.gcd.div}Let $a_{1},a_{2},b_{1},b_{2}\in\mathbb{Z}$ satisfy
$a_{1}\mid b_{1}$ and $a_{2}\mid b_{2}$. Prove that%
\[
\gcd\left(  a_{1},a_{2}\right)  \mid\gcd\left(  b_{1},b_{2}\right)  .
\]

\end{exercise}

\begin{exercise}
\label{exe.ent.gcd.abs}Let $a,b\in\mathbb{Z}$.

\textbf{(a)} Prove that $\gcd\left(  a,\left\vert b\right\vert \right)
=\gcd\left(  a,b\right)  $.

\textbf{(b)} Prove that $\gcd\left(  \left\vert a\right\vert ,b\right)
=\gcd\left(  a,b\right)  $.

\textbf{(c)} Prove that $\gcd\left(  \left\vert a\right\vert ,\left\vert
b\right\vert \right)  =\gcd\left(  a,b\right)  $.
\end{exercise}

\subsubsection{gcds of multiple numbers}

\begin{teachingnote}
I am not sure how useful this section is for an algebra class. It probably is
used for the Smith normal form, but before that?
\end{teachingnote}

The following theorem generalizes some of the previous facts to gcds of
multiple integers:

\begin{theorem}
\label{thm.ent.gcd.uniprop-mul}Let $b_{1},b_{2},\ldots,b_{k}$ be integers.

\textbf{(a)} For each $m\in\mathbb{Z}$, we have the following logical
equivalence:%
\[
\left(  m\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,k\right\}  \right)
\ \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots
,b_{k}\right)  \right)  .
\]


\textbf{(b)} The common divisors of $b_{1},b_{2},\ldots,b_{k}$ are precisely
the divisors of $\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  $.

\textbf{(c)} We have $\operatorname*{Div}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  =\operatorname*{Div}\left(  \gcd\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  \right)  $.

\textbf{(d)} If $k>0$, then%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =\gcd\left(  \gcd\left(
b_{1},b_{2},\ldots,b_{k-1}\right)  ,b_{k}\right)  .
\]

\end{theorem}

\begin{teachingnote}
The following proof generalizes badly to more general rings (even
$\mathbb{Z}\left[  i\right]  $ maybe?), as it uses inequalities.
\end{teachingnote}

\begin{proof}
[Proof of Theorem \ref{thm.ent.gcd.uniprop-mul}.]Forget that we fixed
$b_{1},b_{2},\ldots,b_{k}$. Rather than prove the four parts of Theorem
\ref{thm.ent.gcd.uniprop-mul} separately, we shall prove them together as a package.

We shall proceed by induction on $k$:

\textit{Induction base:} Theorem \ref{thm.ent.gcd.uniprop-mul} holds for $k=0$.

\begin{fineprint}
[\textit{Proof:} This is a straightforward exercise in dealing with empty
sets, $0$-tuples and vacuous truths. For the sake of completeness, here is the
full argument:

Assume that $k=0$. We must prove that Theorem \ref{thm.ent.gcd.uniprop-mul} holds.

Let $b_{1},b_{2},\ldots,b_{k}$ be integers. Of course, these are $0$ integers,
since $k=0$.

We don't have $k>0$ (since $k=0$). Hence, Theorem
\ref{thm.ent.gcd.uniprop-mul} \textbf{(d)} is vacuously true.

All of $b_{1},b_{2},\ldots,b_{k}$ are $0$ (indeed, this is vacuously true).
Thus, $\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =0$ (by Definition
\ref{def.ent.gcd.gcd}).

For each $m\in\mathbb{Z}$, we have the logical equivalence%
\begin{align*}
&  \ \left(  m\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,k\right\}
\right) \\
&  \Longleftrightarrow\ \left(  \text{truth}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since there exists no }i\in\left\{
1,2,\ldots,k\right\}  \right) \\
&  \Longleftrightarrow\ \left(  m\mid0\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }m\mid0\text{ is always true}\right) \\
&  \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots
,b_{k}\right)  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }0=\gcd\left(
b_{1},b_{2},\ldots,b_{k}\right)  \right)  .
\end{align*}
This proves Theorem \ref{thm.ent.gcd.uniprop-mul} \textbf{(a)} (in the case
$k=0$, that is). Parts \textbf{(b)} and \textbf{(c)} of Theorem
\ref{thm.ent.gcd.uniprop-mul} are restatements of Theorem
\ref{thm.ent.gcd.uniprop-mul} \textbf{(a)} and can be derived from it in the
same way as we derived parts \textbf{(b)} and \textbf{(c)} of Theorem
\ref{thm.ent.gcd.uniprop} from Theorem \ref{thm.ent.gcd.uniprop} \textbf{(a)}.

Thus, all four parts of Theorem \ref{thm.ent.gcd.uniprop-mul} are proven for
$k=0$. This completes the induction base.]
\end{fineprint}

\textit{Induction step:} Let $\ell$ be a positive integer. Assume that Theorem
\ref{thm.ent.gcd.uniprop-mul} holds for $k=\ell-1$. We must prove that Theorem
\ref{thm.ent.gcd.uniprop-mul} holds for $k=\ell$.

We have assumed that Theorem \ref{thm.ent.gcd.uniprop-mul} holds for
$k=\ell-1$. In other words, the following statement holds:

\begin{statement}
\textit{Statement 1:} Let $b_{1},b_{2},\ldots,b_{\ell-1}$ be integers.

\textbf{(a)} For each $m\in\mathbb{Z}$, we have the following logical
equivalence:%
\[
\left(  m\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,\ell-1\right\}
\right)  \ \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2}%
,\ldots,b_{\ell-1}\right)  \right)  .
\]


\textbf{(b)} The common divisors of $b_{1},b_{2},\ldots,b_{\ell-1}$ are
precisely the divisors of $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  $.

\textbf{(c)} We have $\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{\ell
-1}\right)  =\operatorname*{Div}\left(  \gcd\left(  b_{1},b_{2},\ldots
,b_{\ell-1}\right)  \right)  $.

\textbf{(d)} If $\ell-1>0$, then%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  =\gcd\left(  \gcd\left(
b_{1},b_{2},\ldots,b_{\left(  \ell-1\right)  -1}\right)  ,b_{\ell-1}\right)
.
\]

\end{statement}

Recall that we must prove that Theorem \ref{thm.ent.gcd.uniprop-mul} holds for
$k=\ell$. In other words, we must prove the following statement:

\begin{statement}
\textit{Statement 2:} Let $b_{1},b_{2},\ldots,b_{\ell}$ be integers.

\textbf{(a)} For each $m\in\mathbb{Z}$, we have the following logical
equivalence:%
\[
\left(  m\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,\ell\right\}
\right)  \ \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2}%
,\ldots,b_{\ell}\right)  \right)  .
\]


\textbf{(b)} The common divisors of $b_{1},b_{2},\ldots,b_{\ell}$ are
precisely the divisors of $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $.

\textbf{(c)} We have $\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{\ell
}\right)  =\operatorname*{Div}\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{\ell
}\right)  \right)  $.

\textbf{(d)} If $\ell>0$, then%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  =\gcd\left(  \gcd\left(
b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  .
\]

\end{statement}

\textit{Proof of Statement 2:} \textbf{(d)} Let us begin with part
\textbf{(d)}. Assume that $\ell>0$ (though we already know that this is true).

Let $g=\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ and $h=\gcd\left(
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  $.

If the integers $b_{1},b_{2},\ldots,b_{\ell}$ are all $0$, then Statement 2
\textbf{(d)} holds\footnote{\textit{Proof.} Assume that $b_{1},b_{2}%
,\ldots,b_{\ell}$ are all $0$. Then, $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell
}\right)  =0$ (by Definition \ref{def.ent.gcd.gcd}). Moreover, $b_{1}%
,b_{2},\ldots,b_{\ell-1}$ are all $0$ (since $b_{1},b_{2},\ldots,b_{\ell}$ are
all $0$), and thus $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  =0$.
Finally, $b_{\ell}=0$ (since $b_{1},b_{2},\ldots,b_{\ell}$ are all $0$).
Comparing $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  =0$ with
$\gcd\left(  \underbrace{\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)
}_{=0},\underbrace{b_{\ell}}_{=0}\right)  =\gcd\left(  0,0\right)  =0$, we
obtain $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  =\gcd\left(
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  $. In
other words, Statement 2 \textbf{(d)} holds.}. Hence, for the rest of this
proof, we WLOG assume that the integers $b_{1},b_{2},\ldots,b_{\ell}$ are not
all $0$. Therefore, $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ is the
largest element of the set $\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{\ell}\right)  $ (by Definition \ref{def.ent.gcd.gcd}). In other
words, $g$ is the largest element of the set $\operatorname*{Div}\left(
b_{1},b_{2},\ldots,b_{\ell}\right)  $ (since $g=\gcd\left(  b_{1},b_{2}%
,\ldots,b_{\ell}\right)  $).

Furthermore, the two integers $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell
-1}\right)  $ and $b_{\ell}$ are not all $0$\ \ \ \ \footnote{\textit{Proof.}
Assume the contrary. Thus, both $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell
-1}\right)  $ and $b_{\ell}$ are $0$. Thus, in particular, $b_{\ell}=0$. If
the $\ell-1$ integers $b_{1},b_{2},\ldots,b_{\ell-1}$ were all $0$, then the
$\ell$ integers $b_{1},b_{2},\ldots,b_{\ell}$ would be all $0$ (since
$b_{\ell}=0$), which would contradict the fact that the integers $b_{1}%
,b_{2},\ldots,b_{\ell}$ are not all $0$. Hence, the $\ell-1$ integers
$b_{1},b_{2},\ldots,b_{\ell-1}$ are not all $0$. Thus, $\gcd\left(
b_{1},b_{2},\ldots,b_{\ell-1}\right)  $ is a positive integer (by Definition
\ref{def.ent.gcd.gcd}). Thus, $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell
-1}\right)  >0$, which contradicts the fact that $\gcd\left(  b_{1}%
,b_{2},\ldots,b_{\ell-1}\right)  $ is $0$. This contradiction shows that our
assumption was false, qed.}. Hence, $\gcd\left(  \gcd\left(  b_{1}%
,b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  $ is the largest element of
the set \newline$\operatorname*{Div}\left(  \gcd\left(  b_{1},b_{2}%
,\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  $ (by Definition
\ref{def.ent.gcd.gcd}). In other words, $h$ is the largest element of the set
$\operatorname*{Div}\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)
,b_{\ell}\right)  $ (since $h=\gcd\left(  \gcd\left(  b_{1},b_{2}%
,\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  $).

We intend to show that $g=h$. For that, it suffices to prove $g\leq h$ and
$h\leq g$.

\textit{Proof of }$g\leq h$\textit{:} Recall that $g$ is the largest element
of the set $\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $.
Therefore, $g\in\operatorname*{Div}\left(  b_{1},b_{2},\ldots,b_{\ell}\right)
$. In other words, $g$ is a common divisor of $b_{1},b_{2},\ldots,b_{\ell}$.
Hence, $g\mid b_{i}$ for each $i\in\left\{  1,2,\ldots,\ell\right\}  $. Thus,
in particular, $g\mid b_{i}$ for each $i\in\left\{  1,2,\ldots,\ell-1\right\}
$. But Statement 1 \textbf{(a)} (applied to $m=g$) shows that we have the
equivalence%
\[
\left(  g\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,\ell-1\right\}
\right)  \ \Longleftrightarrow\ \left(  g\mid\gcd\left(  b_{1},b_{2}%
,\ldots,b_{\ell-1}\right)  \right)  .
\]
Hence, we have $g\mid\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  $
(since we know that $g\mid b_{i}$ for all $i\in\left\{  1,2,\ldots
,\ell-1\right\}  $). Combining this with $g\mid b_{\ell}$, we conclude that
$g$ is a common divisor of $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)
$ and $b_{\ell}$. In other words, $g\in\operatorname*{Div}\left(  \gcd\left(
b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  $. Therefore, $g\leq
h$ (since $h$ is the largest element of the set $\operatorname*{Div}\left(
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  $).

\textit{Proof of }$h\leq g$\textit{:} We have%
\[
h=\gcd\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell
}\right)  \mid\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)
\]
(by Proposition \ref{prop.ent.gcd.props1} \textbf{(f)}, applied to
$a=\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  $ and $b=b_{\ell}$).
Also,%
\[
h=\gcd\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell
}\right)  \mid b_{\ell}%
\]
(by Proposition \ref{prop.ent.gcd.props1} \textbf{(f)}, applied to
$a=\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  $ and $b=b_{\ell}$).

But Statement 1 \textbf{(a)} (applied to $m=h$) shows that we have the
equivalence%
\[
\left(  h\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,\ell-1\right\}
\right)  \ \Longleftrightarrow\ \left(  h\mid\gcd\left(  b_{1},b_{2}%
,\ldots,b_{\ell-1}\right)  \right)  .
\]
Thus, we have $\left(  h\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots
,\ell-1\right\}  \right)  $ (since we have $h\mid\gcd\left(  b_{1}%
,b_{2},\ldots,b_{\ell-1}\right)  $).

This divisibility $h\mid b_{i}$ holds not only for all $i\in\left\{
1,2,\ldots,\ell-1\right\}  $, but also for $i=\ell$ (because $h\mid b_{\ell}%
$). Thus, we conclude that $h\mid b_{i}$ for all $i\in\left\{  1,2,\ldots
,\ell\right\}  $. In other words, $h$ is a common divisor of $b_{1}%
,b_{2},\ldots,b_{\ell}$. In other words, $h\in\operatorname*{Div}\left(
b_{1},b_{2},\ldots,b_{\ell}\right)  $. Thus, $h\leq g$ (since $g$ is the
largest element of the set $\operatorname*{Div}\left(  b_{1},b_{2}%
,\ldots,b_{\ell}\right)  $).

Combining $h\leq g$ with $g\leq h$, we obtain $g=h$. In other words,
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  =\gcd\left(  \gcd\left(
b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)
\]
(since $g=\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ and $h=\gcd\left(
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  $). Hence,
Statement 2 \textbf{(d)} is proven.

\textbf{(a)} Let $m\in\mathbb{Z}$. Then, we have the equivalence%
\begin{align*}
&  \ \left(  m\mid b_{i}\text{ for all }i\in\left\{  1,2,\ldots,\ell\right\}
\right) \\
&  \Longleftrightarrow\ \left(  \underbrace{\left(  m\mid b_{i}\text{ for all
}i\in\left\{  1,2,\ldots,\ell-1\right\}  \right)  }%
_{\substack{\Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2}%
,\ldots,b_{\ell-1}\right)  \right)  \\\text{(by Statement 1 \textbf{(a)})}%
}}\text{ and }m\mid b_{\ell}\right) \\
&  \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots,b_{\ell
-1}\right)  \text{ and }m\mid b_{\ell}\right) \\
&  \Longleftrightarrow\ \left(  m\mid\underbrace{\gcd\left(  \gcd\left(
b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right)  }_{\substack{=\gcd
\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  \\\text{(by Statement 2
\textbf{(d)}, which we have just proved)}}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem \ref{thm.ent.gcd.uniprop}
\textbf{(a)}, applied to }a=\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)
\text{ and }b=b_{\ell}\right) \\
&  \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots,b_{\ell
}\right)  \right)  .
\end{align*}
Thus, Statement 2 \textbf{(a)} follows.

Statement 2 \textbf{(b)} is a restatement of Statement 2 \textbf{(a)} (in the
same way that Theorem \ref{thm.ent.gcd.uniprop} \textbf{(b)} is a restatement
of Theorem \ref{thm.ent.gcd.uniprop} \textbf{(a)}).

Statement 2 \textbf{(c)} is a restatement of Statement 2 \textbf{(b)} (in the
same way that Theorem \ref{thm.ent.gcd.uniprop} \textbf{(c)} is a restatement
of Theorem \ref{thm.ent.gcd.uniprop} \textbf{(b)}).

We are thus done proving Statement 2.

In other words, we have proven that Theorem \ref{thm.ent.gcd.uniprop-mul}
holds for $k=\ell$. This completes the induction step. Thus, Theorem
\ref{thm.ent.gcd.uniprop-mul} is proven by induction.
\end{proof}

Theorem \ref{thm.ent.gcd.uniprop-mul} \textbf{(d)} is the reason why most
properties of gcds of multiple numbers can be derived from corresponding
properties of gcds of two numbers. For example, we can easily prove the
following analogue of Corollary \ref{cor.ent.gcd.sa,sb} for gcds of three numbers:

\begin{exercise}
\label{exe.ent.gcd.sa,sb,sc}Let $s,a,b,c\in\mathbb{Z}$. Prove that
$\gcd\left(  sa,sb,sc\right)  =\left\vert s\right\vert \gcd\left(
a,b,c\right)  $.
\end{exercise}

More generally, Corollary \ref{cor.ent.gcd.sa,sb} can be generalized to any
number of integers:

\begin{exercise}
\label{exe.ent.gcd.sak}Let $s\in\mathbb{Z}$, and let $a_{1},a_{2},\ldots
,a_{k}$ be integers. Prove that $\gcd\left(  sa_{1},sa_{2},\ldots
,sa_{k}\right)  =\left\vert s\right\vert \gcd\left(  a_{1},a_{2},\ldots
,a_{k}\right)  $.
\end{exercise}

Bezout's theorem (Theorem \ref{thm.ent.gcd.bezout}) also holds for any finite
number of integers:

\begin{theorem}
\label{thm.ent.gcd.bezout-mul}Let $b_{1},b_{2},\ldots,b_{k}$ be integers.
Then, there exist integers $x_{1},x_{2},\ldots,x_{k}$ such that%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =x_{1}b_{1}+x_{2}b_{2}%
+\cdots+x_{k}b_{k}.
\]

\end{theorem}

Once again, we can restate Theorem \ref{thm.ent.gcd.bezout-mul} by using the
concept of a $\mathbb{Z}$-linear combination. Let us define this concept finally:

\begin{definition}
Let $b_{1},b_{2},\ldots,b_{k}$ be numbers. A $\mathbb{Z}$\textit{-linear
combination} of $b_{1},b_{2},\ldots,b_{k}$ shall mean a number of the form
$x_{1}b_{1}+x_{2}b_{2}+\cdots+x_{k}b_{k}$, where $x_{1},x_{2},\ldots,x_{k}$
are integers.
\end{definition}

Thus, Theorem \ref{thm.ent.gcd.bezout-mul} can be restated as follows:

\begin{theorem}
\label{thm.ent.gcd.bezout-mul'}Let $b_{1},b_{2},\ldots,b_{k}$ be integers.
Then, $\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ is a $\mathbb{Z}$-linear
combination of $b_{1},b_{2},\ldots,b_{k}$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.gcd.bezout-mul'}.]We shall prove this by
induction on $k$:

\textit{Induction base:} The empty list $\left(  {}\right)  $ satisfies
$\gcd\left(  {}\right)  =0$ (by Definition \ref{def.ent.gcd.gcd}, since all
entries of the empty list are $0$). But $0$ is a $\mathbb{Z}$-linear
combination of an empty list of numbers, because $0=\left(  \text{empty
sum}\right)  $. In other words, $\gcd\left(  {}\right)  $ is a $\mathbb{Z}%
$-linear combination of an empty list of numbers (since $\gcd\left(
{}\right)  =0$). But this is precisely the claim of Theorem
\ref{thm.ent.gcd.bezout-mul'} for $k=0$. Thus, Theorem
\ref{thm.ent.gcd.bezout-mul'} holds for $k=0$. This completes the induction base.

\textit{Induction step:} Let $\ell$ be a positive integer. Assume that Theorem
\ref{thm.ent.gcd.bezout-mul'} holds for $k=\ell-1$. We must prove that Theorem
\ref{thm.ent.gcd.bezout-mul'} holds for $k=\ell$.

We have assumed that Theorem \ref{thm.ent.gcd.bezout-mul'} holds for
$k=\ell-1$. In other words, the following statement holds:

\begin{statement}
\textit{Statement 1:} Let $b_{1},b_{2},\ldots,b_{\ell-1}$ be integers. Then,
$\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  $ is a $\mathbb{Z}$-linear
combination of $b_{1},b_{2},\ldots,b_{\ell-1}$.
\end{statement}

Our goal is to prove that Theorem \ref{thm.ent.gcd.bezout-mul'} holds for
$k=\ell$. In other words, we must prove the following statement:

\begin{statement}
\textit{Statement 2:} Let $b_{1},b_{2},\ldots,b_{\ell}$ be integers. Then,
$\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ is a $\mathbb{Z}$-linear
combination of $b_{1},b_{2},\ldots,b_{\ell}$.
\end{statement}

\textit{Proof of Statement 2:} Statement 1 shows that $\gcd\left(  b_{1}%
,b_{2},\ldots,b_{\ell-1}\right)  $ is a $\mathbb{Z}$-linear combination of
$b_{1},b_{2},\ldots,b_{\ell-1}$. In other words, there exist $\ell-1$ integers
$y_{1},y_{2},\ldots,y_{\ell-1}$ such that%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  =y_{1}b_{1}+y_{2}%
b_{2}+\cdots+y_{\ell-1}b_{\ell-1}.
\]
Consider these $y_{1},y_{2},\ldots,y_{\ell-1}$.

Furthermore, Theorem \ref{thm.ent.gcd.bezout} (applied to $a=\gcd\left(
b_{1},b_{2},\ldots,b_{\ell-1}\right)  $ and $b=b_{\ell}$) yields that there
exist two integers $x$ and $y$ such that%
\[
\gcd\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell
}\right)  =x\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  +yb_{\ell}.
\]
Consider these $x$ and $y$.

Now, $\ell>0$; thus, Theorem \ref{thm.ent.gcd.uniprop-mul} \textbf{(d)}
(applied to $k=\ell$) yields%
\begin{align*}
\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)   &  =\gcd\left(  \gcd\left(
b_{1},b_{2},\ldots,b_{\ell-1}\right)  ,b_{\ell}\right) \\
&  =x\underbrace{\gcd\left(  b_{1},b_{2},\ldots,b_{\ell-1}\right)  }%
_{=y_{1}b_{1}+y_{2}b_{2}+\cdots+y_{\ell-1}b_{\ell-1}}+yb_{\ell}\\
&  =x\left(  y_{1}b_{1}+y_{2}b_{2}+\cdots+y_{\ell-1}b_{\ell-1}\right)
+yb_{\ell}\\
&  =xy_{1}b_{1}+xy_{2}b_{2}+\cdots+xy_{\ell-1}b_{\ell-1}+yb_{\ell}.
\end{align*}
This is clearly a $\mathbb{Z}$-linear combination of the $b_{1},b_{2}%
,\ldots,b_{\ell}$. Thus, $\gcd\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ is
a $\mathbb{Z}$-linear combination of $b_{1},b_{2},\ldots,b_{\ell}$. So
Statement 2 is proven.

In other words, we have proven that Theorem \ref{thm.ent.gcd.bezout-mul'}
holds for $k=\ell$. This completes the induction step. Thus, Theorem
\ref{thm.ent.gcd.bezout-mul'} is proven by induction.
\end{proof}

\begin{proof}
[Proof of Theorem \ref{thm.ent.gcd.bezout-mul}.]We have just proven Theorem
\ref{thm.ent.gcd.bezout-mul'}, which is a restatement of Theorem
\ref{thm.ent.gcd.bezout-mul}. Thus, Theorem \ref{thm.ent.gcd.bezout-mul} is
also proven.
\end{proof}

For future reference, let us restate Theorem \ref{thm.ent.gcd.uniprop-mul}
\textbf{(a)} as follows:

\begin{corollary}
\label{cor.ent.gcd.uniprop-mula}Let $b_{1},b_{2},\ldots,b_{k}$ be integers.
For each $m\in\mathbb{Z}$, we have the following logical equivalence:%
\[
\left(  m\mid b_{1}\text{ and }m\mid b_{2}\text{ and }\cdots\text{ and }m\mid
b_{k}\right)  \ \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1}%
,b_{2},\ldots,b_{k}\right)  \right)  .
\]

\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.ent.gcd.uniprop-mula}.]Let $m\in\mathbb{Z}$.
Then, we have the following chain of equivalences:%
\begin{align*}
&  \ \left(  m\mid b_{1}\text{ and }m\mid b_{2}\text{ and }\cdots\text{ and
}m\mid b_{k}\right) \\
&  \Longleftrightarrow\ \left(  m\mid b_{i}\text{ for all }i\in\left\{
1,2,\ldots,k\right\}  \right) \\
&  \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots
,b_{k}\right)  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem
\ref{thm.ent.gcd.uniprop-mul} \textbf{(a)}}\right)  .
\end{align*}
This proves Corollary \ref{cor.ent.gcd.uniprop-mula}.
\end{proof}

\begin{theorem}
\label{thm.ent.gcd.split}Let $b_{1},b_{2},\ldots,b_{k}$ be integers, and let
$c_{1},c_{2},\ldots,c_{\ell}$ be integers. Then,%
\begin{align*}
&  \gcd\left(  b_{1},b_{2},\ldots,b_{k},c_{1},c_{2},\ldots,c_{\ell}\right) \\
&  =\gcd\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  ,\gcd\left(
c_{1},c_{2},\ldots,c_{\ell}\right)  \right)  .
\end{align*}

\end{theorem}

Our proof of this theorem will rely on a simple trick, which we state as a lemma:

\begin{lemma}
\label{lem.ent.gcd.yoneda}Let $a$ and $b$ be two integers.

\textbf{(a)} If each $m\in\mathbb{Z}$ satisfies the implication $\left(  m\mid
a\right)  \Longrightarrow\left(  m\mid b\right)  $, then $a\mid b$.

\textbf{(b)} If each $m\in\mathbb{Z}$ satisfies the equivalence $\left(  m\mid
a\right)  \Longleftrightarrow\left(  m\mid b\right)  $, then $\left\vert
a\right\vert =\left\vert b\right\vert $.
\end{lemma}

Lemma \ref{lem.ent.gcd.yoneda} \textbf{(b)} says that the divisors of an
integer $a$ uniquely determine $\left\vert a\right\vert $ (that is, they
uniquely determine $a$ up to sign). Thus, when you want to prove that two
integers have the same absolute values, it suffices to prove that they have
the same divisors. If you know that your two integers are nonnegative, then
you can prove this way that they are equal (since their absolute values are
just themselves). This is exactly how we will prove that the left and right
hand sides in Theorem \ref{thm.ent.gcd.split} are equal.

\begin{proof}
[Proof of Lemma \ref{lem.ent.gcd.yoneda}.]\textbf{(a)} Assume that each
$m\in\mathbb{Z}$ satisfies the implication $\left(  m\mid a\right)
\Longrightarrow\left(  m\mid b\right)  $. Then, applying this to $m=a$, we
obtain the implication $\left(  a\mid a\right)  \Longrightarrow\left(  a\mid
b\right)  $. Since $a\mid a$ holds, we thus obtain $a\mid b$. This proves
Lemma \ref{lem.ent.gcd.yoneda} \textbf{(a)}.

\textbf{(b)} Assume that each $m\in\mathbb{Z}$ satisfies the equivalence
$\left(  m\mid a\right)  \Longleftrightarrow\left(  m\mid b\right)  $. Thus,
each $m\in\mathbb{Z}$ satisfies the implication $\left(  m\mid a\right)
\Longrightarrow\left(  m\mid b\right)  $ (since this implication is part of
the equivalence we just assumed). Thus, Lemma \ref{lem.ent.gcd.yoneda}
\textbf{(a)} yields $a\mid b$.

Recall again that each $m\in\mathbb{Z}$ satisfies the equivalence $\left(
m\mid a\right)  \Longleftrightarrow\left(  m\mid b\right)  $. Thus, each
$m\in\mathbb{Z}$ satisfies the implication $\left(  m\mid b\right)
\Longrightarrow\left(  m\mid a\right)  $ (since this implication is also part
of the equivalence). Hence, Lemma \ref{lem.ent.gcd.yoneda} \textbf{(a)}
(applied to $b$ and $a$ instead of $a$ and $b$) yields $b\mid a$.

Hence, Exercise \ref{exe.ent.div.abba} yields $\left\vert a\right\vert
=\left\vert b\right\vert $. This proves Lemma \ref{lem.ent.gcd.yoneda}
\textbf{(b)}.
\end{proof}

Lemma \ref{lem.ent.gcd.yoneda} is a simple case of what is known in category
theory as the \textit{Yoneda lemma}.

\begin{proof}
[Proof of Theorem \ref{thm.ent.gcd.split}.]Let $m\in\mathbb{Z}$. Corollary
\ref{cor.ent.gcd.uniprop-mula} (applied to $k+\ell$ and \newline$\left(
b_{1},b_{2},\ldots,b_{k},c_{1},c_{2},\ldots,c_{\ell}\right)  $ instead of $k$
and $\left(  b_{1},b_{2},\ldots,b_{k}\right)  $) shows that we have the
following equivalence:%
\begin{align*}
&  \ \left(  m\mid b_{1}\text{ and }m\mid b_{2}\text{ and }\cdots\text{ and
}m\mid b_{k}\text{ and }m\mid c_{1}\text{ and }m\mid c_{2}\text{ and }%
\cdots\text{ and }m\mid c_{\ell}\right) \\
&  \Longleftrightarrow\ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots
,b_{k},c_{1},c_{2},\ldots,c_{\ell}\right)  \right)  .
\end{align*}
Hence, we have the following chain of equivalences:%
\begin{align*}
&  \ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots,b_{k},c_{1},c_{2}%
,\ldots,c_{\ell}\right)  \right) \\
\Longleftrightarrow\  &  \left(  m\mid b_{1}\text{ and }m\mid b_{2}\text{ and
}\cdots\text{ and }m\mid b_{k}\text{ and }m\mid c_{1}\text{ and }m\mid
c_{2}\text{ and }\cdots\text{ and }m\mid c_{\ell}\right) \\
\Longleftrightarrow\  &  \left(  \underbrace{\left(  m\mid b_{i}\text{ for all
}i\in\left\{  1,2,\ldots,k\right\}  \right)  }_{\substack{\Longleftrightarrow
\ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  \right)
\\\text{(by Theorem \ref{thm.ent.gcd.uniprop-mul} \textbf{(a)})}}}\text{ and
}\underbrace{\left(  m\mid c_{i}\text{ for all }i\in\left\{  1,2,\ldots
,\ell\right\}  \right)  }_{\substack{\Longleftrightarrow\ \left(  m\mid
\gcd\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  \right)  \\\text{(by Theorem
\ref{thm.ent.gcd.uniprop-mul} \textbf{(a)},}\\\text{applied to }\ell\text{ and
}\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  \\\text{instead of }k\text{ and
}\left(  b_{1},b_{2},\ldots,b_{k}\right)  \text{)}}}\right) \\
\Longleftrightarrow\  &  \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots
,b_{k}\right)  \text{ and }m\mid\gcd\left(  c_{1},c_{2},\ldots,c_{\ell
}\right)  \right) \\
\Longleftrightarrow\  &  \left(  m\mid\gcd\left(  \gcd\left(  b_{1}%
,b_{2},\ldots,b_{k}\right)  ,\gcd\left(  c_{1},c_{2},\ldots,c_{\ell}\right)
\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Theorem \ref{thm.ent.gcd.uniprop} \textbf{(a)},}\\
\text{applied to }a=\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  \text{ and
}b=\gcd\left(  c_{1},c_{2},\ldots,c_{\ell}\right)
\end{array}
\right)  .
\end{align*}


Now, forget that we fixed $m$. We thus have shown that each $m\in\mathbb{Z}$
satisfies the equivalence%
\begin{align*}
&  \ \left(  m\mid\gcd\left(  b_{1},b_{2},\ldots,b_{k},c_{1},c_{2}%
,\ldots,c_{\ell}\right)  \right) \\
&  \Longleftrightarrow\ \left(  m\mid\gcd\left(  \gcd\left(  b_{1}%
,b_{2},\ldots,b_{k}\right)  ,\gcd\left(  c_{1},c_{2},\ldots,c_{\ell}\right)
\right)  \right)  .
\end{align*}
Hence, Lemma \ref{lem.ent.gcd.yoneda} \textbf{(b)} (applied to $a=\gcd\left(
b_{1},b_{2},\ldots,b_{k},c_{1},c_{2},\ldots,c_{\ell}\right)  $ and
\newline$b=\gcd\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)
,\gcd\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  \right)  $) yields%
\begin{align}
&  \left\vert \gcd\left(  b_{1},b_{2},\ldots,b_{k},c_{1},c_{2},\ldots,c_{\ell
}\right)  \right\vert \nonumber\\
&  =\left\vert \gcd\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)
,\gcd\left(  c_{1},c_{2},\ldots,c_{\ell}\right)  \right)  \right\vert .
\label{pf.thm.ent.gcd.split.abs-equal}%
\end{align}


But a gcd of integers is always nonnegative (by Definition
\ref{def.ent.gcd.gcd}); thus, the absolute value of a gcd is always this gcd
itself. Therefore, we can remove the absolute value signs on both sides of
(\ref{pf.thm.ent.gcd.split.abs-equal}). We thus obtain%
\[
\gcd\left(  b_{1},b_{2},\ldots,b_{k},c_{1},c_{2},\ldots,c_{\ell}\right)
=\gcd\left(  \gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  ,\gcd\left(
c_{1},c_{2},\ldots,c_{\ell}\right)  \right)  .
\]
This proves Theorem \ref{thm.ent.gcd.split}.
\end{proof}

\subsubsection{On converses of Bezout's theorem}

Some words of warning are in order. Theorem \ref{thm.ent.gcd.bezout} says that
if $a$ and $b$ are two integers, then $\gcd\left(  a, b \right)  $ is a
$\mathbb{Z}$-linear combination of $a$ and $b$. Note the indefinite article
``a'' here: There are (usually) many $\mathbb{Z}$-linear combinations of $a$
and $b$, but only one gcd. It is definitely not true that every $\mathbb{Z}%
$-linear combination of $a$ and $b$ must be $\gcd\left(  a, b \right)  $.
However, all these $\mathbb{Z}$-linear combinations are \textbf{multiples} of
the gcd, as the following (simple) proposition says:

\begin{proposition}
\label{prop.ent.gcd.bezout-conv}Let $a$ and $b$ be two integers. Then, any
integers $x$ and $y$ satisfy $\gcd\left(  a, b \right)  \mid xa + yb$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.gcd.bezout-conv}.]Let $x$ and $y$ be
integers. Let $g = \gcd\left(  a, b \right)  $. Thus, $g = \gcd\left(  a, b
\right)  \mid a$ (by Proposition \ref{prop.ent.gcd.props1} \textbf{(f)}).
Hence, $g \mid a \mid xa$ (since $xa = ax$). In other words, $xa \equiv0
\mod g$. Similarly, $yb \equiv0 \mod g$. Adding these two congruences
together, we obtain $xa + yb \equiv0 + 0 = 0 \mod g$. In other words, $g \mid
xa + yb$. In other words, $\gcd\left(  a, b \right)  \mid xa + yb$ (since $g =
\gcd\left(  a, b \right)  $). This proves Proposition
\ref{prop.ent.gcd.bezout-conv}.
\end{proof}

A similar proposition holds for $\mathbb{Z}$-linear combinations of any number
of integers $b_{1},b_{2},\ldots,b_{k}$.

\begin{center}
\textbf{2019-02-06 lecture}
\end{center}

\subsection{Coprime integers}

\subsubsection{Definition}

The concept of a gcd leads to one of the most important notions of number theory:

\begin{definition}
\label{def.ent.coprime.coprime}Let $a$ and $b$ be two integers. We say that
$a$ is \textit{coprime} to $b$ if and only if $\gcd\left(  a,b\right)  =1$.
\end{definition}

Instead of \textquotedblleft coprime\textquotedblright, some authors say
\textquotedblleft relatively prime\textquotedblright\ or even
\textquotedblleft prime\textquotedblright\ (but the latter language risks
confusion with a more standard notion of \textquotedblleft
prime\textquotedblright\ that we will see later on.)

\begin{example}
\label{exa.ent.coprime.1}\textbf{(a)} The number $2$ is coprime to $3$, since
$\gcd\left(  2,3\right)  =1$.

\textbf{(b)} The number $6$ is not coprime to $15$, since $\gcd\left(
6,15\right)  =3\neq1$.

\textbf{(c)} Let $a$ be an integer. We claim (as a generalization of part
\textbf{(a)}) that the number $a$ is coprime to $a+1$. To prove this, we note
that%
\begin{align*}
\gcd\left(  a,\underbrace{a}_{=1a}+1\right)   &  =\gcd\left(  a,1a+1\right)
=\gcd\left(  a,1\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.ent.gcd.props1}
\textbf{(c)}, applied to }u=1\text{ and }b=1\right) \\
&  \mid1\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.ent.gcd.props1} \textbf{(e)}, applied to }b=1\right)  ,
\end{align*}
and thus $\gcd\left(  a,a+1\right)  =1$ (by Exercise \ref{exe.ent.div.g|1},
since $\gcd\left(  a,a+1\right)  $ is a nonnegative integer), which means that
$a$ is coprime to $a+1$.

\textbf{(d)} Let $a$ be an integer. When is $a$ coprime to $a+2$? If we try to
compute $\gcd\left(  a,a+2\right)  $, we find%
\begin{align*}
\gcd\left(  a,\underbrace{a}_{=1a}+2\right)   &  =\gcd\left(  a,1a+2\right)
=\gcd\left(  a,2\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.ent.gcd.props1}
\textbf{(c)}, applied to }u=1\text{ and }b=2\right)  .
\end{align*}
It remains to find $\gcd\left(  a,2\right)  $. Proposition
\ref{prop.ent.gcd.props1} \textbf{(e)} (applied to $b=2$) yields $\gcd\left(
a,2\right)  \mid a$ and $\gcd\left(  a,2\right)  \mid2$. Since $\gcd\left(
a,2\right)  $ is a nonnegative integer and is a divisor of $2$ (because
$\gcd\left(  a,2\right)  \mid2$), we see that $\gcd\left(  a,2\right)  $ must
be either $1$ or $2$ (since the only nonnegative divisors of $2$ are $1$ and
$2$). If $a$ is even, then $2$ is a common divisor of $a$ and $2$, and thus
must be the greatest common divisor of $a$ and $2$ (because a common divisor
of $a$ and $2$ cannot be greater than $2$); in other words, we have
$\gcd\left(  a,2\right)  =2$ in this case. On the other hand, if $a$ is odd,
then $2$ is not a common divisor of $a$ and $2$ (since $2$ does not divide
$a$), and thus cannot be the greatest common divisor of $a$ and $2$; hence, in
this case, we have $\gcd\left(  a,2\right)  \neq2$ and thus $\gcd\left(
a,2\right)  =1$. Summarizing, we conclude that%
\[
\gcd\left(  a,2\right)  =%
\begin{cases}
2, & \text{if }a\text{ is even};\\
1, & \text{if }a\text{ is odd.}%
\end{cases}
\]
Now, recall that $\gcd\left(  a,a+2\right)  =\gcd\left(  a,2\right)  =%
\begin{cases}
2, & \text{if }a\text{ is even};\\
1, & \text{if }a\text{ is odd.}%
\end{cases}
$ Hence, $a$ is coprime to $a+2$ if and only if $a$ is odd.
\end{example}

Following the book \cite{GKP}, we introduce a slightly quaint notation:

\begin{definition}
\label{def.ent.coprime.perp}Let $a$ and $b$ be two integers. We write
\textquotedblleft$a\perp b$\textquotedblright\ to signify that $a$ is coprime
to $b$.
\end{definition}

Note that the \textquotedblleft$\perp$\textquotedblright\ relation is symmetric:

\begin{proposition}
\label{prop.ent.coprime.perp-symm}Let $a$ and $b$ be two integers. Then,
$a\perp b$ if and only if $b\perp a$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.coprime.perp-symm}.]We have the following
chain of equivalences:%
\begin{align*}
\left(  a\perp b\right)  \  &  \Longleftrightarrow\ \left(  a\text{ is coprime
to }b\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of
\textquotedblleft}\perp\text{\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  \gcd\left(  a,b\right)  =1\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of \textquotedblleft
coprime\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  \gcd\left(  b,a\right)  =1\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since Proposition \ref{prop.ent.gcd.props1} \textbf{(b)}}\\
\text{yields }\gcd\left(  a,b\right)  =\gcd\left(  b,a\right)
\end{array}
\right) \\
&  \Longleftrightarrow\ \left(  b\text{ is coprime to }a\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of \textquotedblleft
coprime\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  b\perp a\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by the definition of \textquotedblleft}\perp\text{\textquotedblright%
}\right)  .
\end{align*}
This proves Proposition \ref{prop.ent.coprime.perp-symm}.
\end{proof}

\begin{definition}
Let $a$ and $b$ be two integers. Proposition \ref{prop.ent.coprime.perp-symm}
shows that $a$ is coprime to $b$ if and only if $b$ is coprime to $a$. Hence,
we shall sometimes use a more symmetric terminology for this situation: We
shall say that \textquotedblleft$a$ and $b$ \textit{are coprime}%
\textquotedblright\ to mean that $a$ is coprime to $b$ (or, equivalently, that
$b$ is coprime to $a$).
\end{definition}

\begin{exercise}
\label{exe.ent.coprime.01}Let $a\in\mathbb{Z}$. Prove the following:

\textbf{(a)} We have $1\perp a$.

\textbf{(b)} We have $0\perp a$ if and only if $\left\vert a\right\vert =1$.
\end{exercise}

\subsubsection{Properties of coprime integers}

We can now state multiple theorems about coprime numbers. The first one states
that we can \textquotedblleft cancel\textquotedblright\ a factor $b$ from a
divisibility $a\mid bc$ as long as this factor is coprime to $a$:

\begin{theorem}
\label{thm.ent.coprime.cancel}Let $a,b,c\in\mathbb{Z}$ satisfy $a\mid bc$ and
$a\perp b$. Then, $a\mid c$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.coprime.cancel}.]We have $a\perp b$; in other
words, $a$ is coprime to $b$ (by Definition \ref{def.ent.coprime.perp}). In
other words, $\gcd\left(  a,b\right)  =1$ (by the definition of
\textquotedblleft coprime\textquotedblright). Now, Theorem
\ref{thm.ent.gcd.cancel} yields $a\mid\underbrace{\gcd\left(  a,b\right)
}_{=1}\cdot c=c$. This proves Theorem \ref{thm.ent.coprime.cancel}.
\end{proof}

I like to think of Theorem \ref{thm.ent.coprime.combine} as a way of removing
\textquotedblleft unsolicited guests\textquotedblright\ from divisibilities.
Indeed, it says that we can remove the factor $b$ from $a\mid bc$ if we know
that $b$ is \textquotedblleft unrelated\textquotedblright\ (i.e., coprime) to
$a$.

The next theorem lets us \textquotedblleft combine\textquotedblright\ two
divisibilities $a\mid c$ and $b\mid c$ to $ab\mid c$ as long as $a$ and $b$
are coprime:

\begin{theorem}
\label{thm.ent.coprime.combine}Let $a,b,c\in\mathbb{Z}$ satisfy $a\mid c$ and
$b\mid c$ and $a\perp b$. Then, $ab\mid c$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.coprime.combine}.]We have $a\perp b$; in other
words, $a$ is coprime to $b$ (by Definition \ref{def.ent.coprime.perp}). In
other words, $\gcd\left(  a,b\right)  =1$ (by the definition of
\textquotedblleft coprime\textquotedblright). Now, Theorem
\ref{thm.ent.gcd.combine} yields $ab\mid\underbrace{\gcd\left(  a,b\right)
}_{=1}\cdot c=c$. This proves Theorem \ref{thm.ent.coprime.combine}.
\end{proof}

Theorem \ref{thm.ent.coprime.combine} can be restated as follows: If $a$ and
$b$ are two coprime divisors of an integer $c$, then $ab$ is also a divisor of
$c$. This is often helpful when proving divisibilities where the left hand
side (i.e., the number in front of the \textquotedblleft$\mid$%
\textquotedblright\ sign) can be split into a product of two mutually coprime
factors. Similar reasoning works with several coprime factors (see Exercise
\ref{exe.ent.coprime.combinek} below).

The next theorem (still part of the fallout of Bezout's theorem) is important,
but we will not truly appreciate it until later:

\begin{theorem}
\label{thm.ent.coprime.modinv}Let $a,n\in\mathbb{Z}$.

\textbf{(a)} There exists a $b\in\mathbb{Z}$ such that $ab\equiv\gcd\left(
a,n\right)  \operatorname{mod}n$.

\textbf{(b)} If $a\perp n$, then there exists an $a^{\prime}\in\mathbb{Z}$
such that $aa^{\prime}\equiv1\operatorname{mod}n$.

\textbf{(c)} If there exists an $a^{\prime}\in\mathbb{Z}$ such that
$aa^{\prime}\equiv1\operatorname{mod}n$, then $a\perp n$.
\end{theorem}

If $a,n\in\mathbb{Z}$, then an integer $a^{\prime}\in\mathbb{Z}$ satisfying
$aa^{\prime}\equiv1\operatorname{mod}n$ is called a \textit{modular inverse}
of $a$ modulo $n$. The word \textquotedblleft modular
inverse\textquotedblright\ is chosen in analogy to the usual concept of an
\textquotedblleft inverse\textquotedblright\ in $\mathbb{Z}$ (which stands for
an integer $a^{\prime}\in\mathbb{Z}$ satisfying $aa^{\prime}=1$; this exists
if and only if $a$ equals $1$ or $-1$). Theorem \ref{thm.ent.coprime.modinv}
\textbf{(b)} shows that such a modular inverse always exists when $a\perp n$;
Theorem \ref{thm.ent.coprime.modinv} \textbf{(c)} is the converse of this
statement (i.e., it says that if a modular inverse of $a$ modulo $n$ exists,
then $a\perp n$).

\begin{proof}
[Proof of Theorem \ref{thm.ent.coprime.modinv}.]\textbf{(a)} Theorem
\ref{thm.ent.gcd.bezout} (applied to $b=n$) yields that there exist integers
$x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ such that $\gcd\left(  a,n\right)
=xa+yn$. Consider these $x$ and $y$. We have $ax=xa\equiv
xa+yn\operatorname{mod}n$ (since $xa-\left(  xa+yn\right)  =-yn=n\left(
-y\right)  $ is clearly divisible by $n$). Thus, $ax\equiv xa+yn=\gcd\left(
a,n\right)  \operatorname{mod}n$. Thus, there exists a $a^{\prime}%
\in\mathbb{Z}$ such that $aa^{\prime}\equiv\left(  a,n\right)
\operatorname{mod}n$ (namely, $a^{\prime}=x$). This proves Theorem
\ref{thm.ent.coprime.modinv} \textbf{(a)}.

\textbf{(b)} Assume that $a\perp n$. In other words, $a$ is coprime to $n$ (by
Definition \ref{def.ent.coprime.perp}). In other words, $\gcd\left(
a,n\right)  =1$ (by the definition of \textquotedblleft
coprime\textquotedblright). Now, Theorem \ref{thm.ent.coprime.modinv}
\textbf{(a)} yields that there exists a $a^{\prime}\in\mathbb{Z}$ such that
$aa^{\prime}\equiv\gcd\left(  a,n\right)  \operatorname{mod}n$. In view of
$\gcd\left(  a,n\right)  =1$, this rewrites as follows: There exists an
$a^{\prime}\in\mathbb{Z}$ such that $aa^{\prime}\equiv1\operatorname{mod}n$.
This proves Theorem \ref{thm.ent.coprime.modinv} \textbf{(b)}.

\textbf{(c)} Assume that there exists an $a^{\prime}\in\mathbb{Z}$ such that
$aa^{\prime}\equiv1\operatorname{mod}n$. Consider this $a^{\prime}$.

Proposition \ref{prop.ent.gcd.props1} \textbf{(f)} yields $\gcd\left(
a,n\right)  \mid a$ and $\gcd\left(  a,n\right)  \mid n$. Set $g=\gcd\left(
a,n\right)  $. Then, $g$ is a nonnegative integer.

Now, $g=\gcd\left(  a,n\right)  \mid a\mid aa^{\prime}$, so that $aa^{\prime
}\equiv0\operatorname{mod}g$. But also $g=\gcd\left(  a,n\right)  \mid n$.
Hence, from $aa^{\prime}\equiv1\operatorname{mod}n$, we obtain $aa^{\prime
}\equiv1\operatorname{mod}g$ (by Proposition \ref{prop.ent.mod.basics}
\textbf{(e)}, applied to $g$, $aa^{\prime}$ and $1$ instead of $m$, $a$ and
$b$). Hence, $1\equiv aa^{\prime}\equiv0\operatorname{mod}g$. Equivalently,
$g\mid1-0=1$. Hence, $g=1$ (by Exercise \ref{exe.ent.div.g|1}, since $g$ is a
nonnegative integer). Thus, $\gcd\left(  a,n\right)  =g=1$. In other words,
$a$ is coprime to $n$. In other words, $a\perp n$. This proves Theorem
\ref{thm.ent.coprime.modinv} \textbf{(c)}.
\end{proof}

\begin{theorem}
\label{thm.ent.coprime.ab-to-c}Let $a,b,c\in\mathbb{Z}$ such that $a\perp c$
and $b\perp c$. Then, $ab\perp c$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.coprime.ab-to-c}.]Theorem
\ref{thm.ent.coprime.modinv} \textbf{(b)} (applied to $n=c$) yields that there
exists an $a^{\prime}\in\mathbb{Z}$ such that $aa^{\prime}\equiv
1\operatorname{mod}c$. Consider this $a^{\prime}$.

Theorem \ref{thm.ent.coprime.modinv} \textbf{(b)} (applied to $b$ and $c$
instead of $a$ and $n$) yields that there exists a $b^{\prime}\in\mathbb{Z}$
such that $bb^{\prime}\equiv1\operatorname{mod}c$. Consider this $b^{\prime}$.

Multiplying the two congruences $aa^{\prime}\equiv1\operatorname{mod}c$ and
$bb^{\prime}\equiv1\operatorname{mod}c$, we obtain $\left(  aa^{\prime
}\right)  \left(  bb^{\prime}\right)  \equiv1\cdot1=1\operatorname{mod}c$.

Now, define the integers $r=ab$ and $s=a^{\prime}b^{\prime}$. Then,
$\underbrace{r}_{=ab}\underbrace{s}_{=a^{\prime}b^{\prime}}=\left(  ab\right)
\left(  a^{\prime}b^{\prime}\right)  =\left(  aa^{\prime}\right)  \left(
bb^{\prime}\right)  \equiv1\operatorname{mod}c$. Hence, there exists an
$r^{\prime}\in\mathbb{Z}$ such that $rr^{\prime}\equiv1\operatorname{mod}c$
(namely, $r^{\prime}=s$). Thus, Theorem \ref{thm.ent.coprime.modinv}
\textbf{(c)} (applied to $r$ and $c$ instead of $a$ and $n$) yields that
$r\perp c$. In view of $r=ab$, this rewrites as $ab\perp c$. This proves
Theorem \ref{thm.ent.coprime.ab-to-c}.
\end{proof}

Let us generalize Theorem \ref{thm.ent.coprime.ab-to-c} to products of several
numbers instead of just the two numbers $a$ and $b$:

\begin{exercise}
\label{exe.ent.coprime.ab-to-ck}Let $c\in\mathbb{Z}$. Let $a_{1},a_{2}%
,\ldots,a_{k}$ be integers such that each $i\in\left\{  1,2,\ldots,k\right\}
$ satisfies $a_{i}\perp c$. Prove that $a_{1}a_{2}\cdots a_{k}\perp c$.
\end{exercise}

We can similarly generalize Theorem \ref{thm.ent.coprime.combine} to show that
the product of several mutually coprime divisors of an integer $c$ must again
be a divisor of $c$:

\begin{exercise}
\label{exe.ent.coprime.combinek}Let $c\in\mathbb{Z}$. Let $b_{1},b_{2}%
,\ldots,b_{k}$ be integers that are mutually coprime (i.e., they satisfy
$b_{i}\perp b_{j}$ for all $i\neq j$). Assume that $b_{i}\mid c$ for each
$i\in\left\{  1,2,\ldots,k\right\}  $. Prove that $b_{1}b_{2}\cdots b_{k}\mid
c$.
\end{exercise}

\begin{exercise}
\label{exe.ent.coprime.powers}Let $a,b\in\mathbb{Z}$ be such that $a\perp b$.
Let $n,m\in\mathbb{N}$. Prove that $a^{n}\perp b^{m}$.
\end{exercise}

The above results have one important application to congruences. Recall that
if $a,b,c$ are integers satisfying $ab=ac$, then we can \textquotedblleft
cancel\textquotedblright\ $a$ from the equality $ab=ac$ to obtain $b=c$ as
long as $a$ is nonzero. Something similar is true for congruences modulo $n$,
but the condition \textquotedblleft$a$ is nonzero\textquotedblright\ has to be
replaced by \textquotedblleft$a$ is coprime to $n$\textquotedblright:

\begin{lemma}
\label{lem.ent.coprime.cancel}Let $a,b,c,n$ be integers such that $a\perp n$
and $ab\equiv ac\operatorname{mod}n$. Then, $b\equiv c\operatorname{mod}n$.
\end{lemma}

Lemma \ref{lem.ent.coprime.cancel} says that we can cancel an integer $a$ from
a congruence $ab\equiv ac\operatorname{mod}n$ as long as $a$ is coprime to
$n$. Let us give two proofs of this lemma, to illustrate the uses of some of
the previous results:

\begin{proof}
[First proof of Lemma \ref{lem.ent.coprime.cancel}.]We have $ab\equiv
ac\operatorname{mod}n$. In other words, $n\mid ab-ac=a\left(  b-c\right)  $.
But Proposition \ref{prop.ent.coprime.perp-symm} (applied to $n$ instead of
$b$) shows that $a\perp n$ if and only if $n\perp a$. Thus, we have $n\perp a$
(since $a\perp n$).

Thus, we know that $n\mid a\left(  b-c\right)  $ and $n\perp a$. Hence,
Theorem \ref{thm.ent.coprime.cancel} (applied to $n$, $a$ and $b-c$ instead of
$a$, $b$ and $c$) yields $n\mid b-c$. In other words, $b\equiv
c\operatorname{mod}n$. This proves Lemma \ref{lem.ent.coprime.cancel}.
\end{proof}

\begin{proof}
[Second proof of Lemma \ref{lem.ent.coprime.cancel}.]Theorem
\ref{thm.ent.coprime.modinv} \textbf{(b)} yields that there exists an
$a^{\prime}\in\mathbb{Z}$ such that $aa^{\prime}\equiv1\operatorname{mod}n$
(since $a\perp n$). Consider this $a^{\prime}$. Now, let us multiply the
(trivial) congruence $a^{\prime}\equiv a^{\prime}\operatorname{mod}n$ with the
congruence $ab\equiv ac\operatorname{mod}n$. We thus find%
\[
a^{\prime}ab\equiv\underbrace{a^{\prime}a}_{\equiv1\operatorname{mod}n}%
c\equiv1c=c\operatorname{mod}n.
\]
Hence,
\[
c\equiv\underbrace{a^{\prime}a}_{\equiv1\operatorname{mod}n}b\equiv
1b=b\operatorname{mod}n.
\]
In other words, $b\equiv c\operatorname{mod}n$. This proves Lemma
\ref{lem.ent.coprime.cancel}.
\end{proof}

For future use, let us restate Exercise \ref{exe.ent.coprime.ab-to-ck} in a
form that uses \textquotedblleft unordered\textquotedblright\ finite products
$\prod_{i\in I}b_{i}$ instead of $a_{1}a_{2}\cdots a_{k}$:

\begin{exercise}
\label{exe.ent.coprime.ab-to-cI}Let $c\in\mathbb{Z}$. Let $I$ be a finite set.
For each $i\in I$, let $b_{i}$ be an integer such that $b_{i}\perp c$. Prove
that $\prod_{i\in I}b_{i}\perp c$.
\end{exercise}

\begin{exercise}
\label{exe.ent.coprime.b==c}Let $a,b,c$ be three integers such that $a\equiv
b\operatorname{mod}c$. Prove that if $a\perp c$, then $b\perp c$.
\end{exercise}

\begin{exercise}
\label{exe.ent.coprime.b-a}Let $a,b\in\mathbb{Z}$. Prove that $b-a\perp b$
holds if and only if $a\perp b$.
\end{exercise}

\subsubsection{An application to sums of powers}

Let us show an application of Theorem \ref{thm.ent.coprime.combine}. First, we
shall prove a simple lemma:

\begin{lemma}
\label{lem.ent.xd-yd}Let $d\in\mathbb{N}$. Let $x$ and $y$ be integers.

\textbf{(a)} We have $x-y\mid x^{d}-y^{d}$.

\textbf{(b)} We have $x+y\mid x^{d}+y^{d}$ if $d$ is odd.
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.xd-yd}.]\textbf{(a)} Here are two ways of proving this:

\textit{First proof of Lemma \ref{lem.ent.xd-yd} \textbf{(a)}:} We have
$x\equiv y\operatorname{mod}x-y$ (since $x-y\mid x-y$). Thus, Exercise
\ref{exe.ent.mod.basics.k-power} (applied to $n=x-y$, $a=x$, $b=y$ and $k=d$)
yields $x^{d}\equiv y^{d}\operatorname{mod}x-y$. In other words, $x-y\mid
x^{d}-y^{d}$. This proves Lemma \ref{lem.ent.xd-yd} \textbf{(a)}.

\textit{Second proof of Lemma \ref{lem.ent.xd-yd} \textbf{(a)}:} Recall that%
\begin{equation}
\left(  a-b\right)  \left(  a^{k-1}+a^{k-2}b+a^{k-3}b^{2}+\cdots
+ab^{k-2}+b^{k-1}\right)  =a^{k}-b^{k} \label{pf.lem.ent.xd-yd.1}%
\end{equation}
for every $a,b\in\mathbb{Q}$ and $k\in\mathbb{N}$. (This is a well-known
identity, and it appears (with $k$ renamed as $n$) as the first half of
Exercise 1 on
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw0s.pdf}{homework set
\#0}.) Applying this identity to $a=x$, $b=y$ and $k=d$, we obtain%
\[
\left(  x-y\right)  \left(  x^{d-1}+x^{d-2}y+x^{d-3}y^{2}+\cdots
+xy^{d-2}+y^{d-1}\right)  =x^{d}-y^{d}.
\]
Thus, $x-y\mid x^{d}-y^{d}$ (since $x^{d-1}+x^{d-2}y+x^{d-3}y^{2}%
+\cdots+xy^{d-2}+y^{d-1}$ is an integer). This proves Lemma
\ref{lem.ent.xd-yd} \textbf{(a)}.

\textbf{(b)} Assume that $d$ is odd. Thus, $\left(  -1\right)  ^{d}=-1$. Now,
Lemma \ref{lem.ent.xd-yd} \textbf{(a)} (applied to $-y$ instead of $y$) yields
$x-\left(  -y\right)  \mid x^{d}-\left(  -y\right)  ^{d}$. Since $x-\left(
-y\right)  =x+y$ and $x^{d}-\underbrace{\left(  -y\right)  ^{d}}_{=\left(
-1\right)  ^{d}y^{d}}=x^{d}-\underbrace{\left(  -1\right)  ^{d}}_{=-1}%
y^{d}=x^{d}-\left(  -1\right)  y^{d}=x^{d}+y^{d}$, this rewrites as $x+y\mid
x^{d}+y^{d}$. This proves Lemma \ref{lem.ent.xd-yd} \textbf{(b)}.
\end{proof}

Next, let us recall a basic fact from combinatorics (the \textquotedblleft
Little Gauss\textquotedblright\ sum):

\begin{proposition}
\label{prop.ent.1+2+...+n}Let $n\in\mathbb{N}$. Then,
\[
1+2+\cdots+n=\dfrac{n\left(  n+1\right)  }{2}.
\]

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.1+2+...+n}.]Here is one of several equally
valid arguments:%
\begin{align*}
2\cdot\left(  1+2+\cdots+n\right)   &  =\left(  1+2+\cdots+n\right)
+\underbrace{\left(  1+2+\cdots+n\right)  }_{\substack{=n+\left(  n-1\right)
+\cdots+1\\\text{(here, we have reversed}\\\text{the order of the addends)}%
}}\\
&  =\underbrace{\left(  1+2+\cdots+n\right)  }_{=\sum_{k=1}^{n}k}%
+\underbrace{\left(  n+\left(  n-1\right)  +\cdots+1\right)  }_{=\sum
_{k=1}^{n}\left(  n+1-k\right)  }\\
&  =\sum_{k=1}^{n}k+\sum_{k=1}^{n}\left(  n+1-k\right)  =\sum_{k=1}%
^{n}\underbrace{\left(  k+\left(  n+1-k\right)  \right)  }_{=n+1}\\
&  =\sum_{k=1}^{n}\left(  n+1\right)  =n\left(  n+1\right)  .
\end{align*}
Thus, $1+2+\cdots+n=\dfrac{n\left(  n+1\right)  }{2}$, so that Proposition
\ref{prop.ent.1+2+...+n} is proven.
\end{proof}

Proposition \ref{prop.ent.1+2+...+n} tells us what the sum $1+2+\cdots+n$ of
the first $n$ positive integers is. One might also ask what the sum
$1^{2}+2^{2}+\cdots+n^{2}$ of their squares is, and similarly for higher
powers. While this is tangential to our course, let us collect some formulas
for this:

\begin{proposition}
\label{prop.ent.1d+2d+...+nd-for-5}Let $n\in\mathbb{N}$. Then:

\textbf{(a)} We have $1+2+\cdots+n=\dfrac{1}{2}n\left(  n+1\right)  $.

\textbf{(b)} We have $1^{2}+2^{2}+\cdots+n^{2}=\dfrac{1}{6}n\left(
n+1\right)  \left(  2n+1\right)  $.

\textbf{(c)} We have $1^{3}+2^{3}+\cdots+n^{3}=\dfrac{1}{4}n^{2}\left(
n+1\right)  ^{2}$.

\textbf{(d)} We have $1^{4}+2^{4}+\cdots+n^{4}=\dfrac{1}{30}n\left(
2n+1\right)  \left(  n+1\right)  \left(  3n+3n^{2}-1\right)  $.

\textbf{(e)} We have $1^{5}+2^{5}+\cdots+n^{5}=\dfrac{1}{12}n^{2}\left(
n+1\right)  ^{2}\left(  2n+2n^{2}-1\right)  $.
\end{proposition}

Each part of Proposition \ref{prop.ent.1d+2d+...+nd-for-5} can be
straightforwardly proven by induction on $n$; we don't need ingenious
arguments like the one we gave above for Proposition \ref{prop.ent.1+2+...+n}
(and in fact, such arguments cannot always be found).

\begin{fineprint}
You probably see a pattern in Proposition \ref{prop.ent.1d+2d+...+nd-for-5}:
It appears that for each positive integer $d$, there exists some polynomial
$p_{d}\left(  x\right)  $ of degree $d+1$ with rational coefficients such that
each $n\in\mathbb{N}$ satisfies $1^{d}+2^{d}+\cdots+n^{d}=p_{d}\left(
n\right)  $. This is indeed the case. Indeed, this is proven (e.g.) in
\cite[Proposition 23.2]{Galvin} and in \cite[Theorem 3.7]{lucas}. The
polynomial $p_{d}\left(  x\right)  $ is uniquely determined for each $d$, and
can be explicitly computed via the formula%
\[
p_{d}\left(  x\right)  =\sum_{k=1}^{d}k!%
%TCIMACRO{\QDATOPD{\{}{\}}{d}{k}}%
%BeginExpansion
\genfrac{\{}{\}}{0pt}{0}{d}{k}%
%EndExpansion
\dbinom{x+1}{k+1},
\]
where $\dbinom{x+1}{k+1}=\dfrac{\left(  x+1\right)  x\left(  x-1\right)
\cdots\left(  x-k+1\right)  }{\left(  k+1\right)  !}$ and where $%
%TCIMACRO{\QDATOPD{\{}{\}}{d}{k}}%
%BeginExpansion
\genfrac{\{}{\}}{0pt}{0}{d}{k}%
%EndExpansion
$ is a \textit{Stirling number of the 2nd kind}. Without going into the
details of what Stirling numbers of the 2nd kind are, let me say that $k!%
%TCIMACRO{\QDATOPD{\{}{\}}{d}{k}}%
%BeginExpansion
\genfrac{\{}{\}}{0pt}{0}{d}{k}%
%EndExpansion
$ is the number of surjective maps from $\left\{  1,2,\ldots,d\right\}  $ to
$\left\{  1,2,\ldots,k\right\}  $. For example,%
\begin{align*}
p_{2}\left(  x\right)   &  =\sum_{k=1}^{2}k!%
%TCIMACRO{\QDATOPD{\{}{\}}{2}{k}}%
%BeginExpansion
\genfrac{\{}{\}}{0pt}{0}{2}{k}%
%EndExpansion
\dbinom{x+1}{k+1}=\underbrace{1!%
%TCIMACRO{\QDATOPD{\{}{\}}{2}{1}}%
%BeginExpansion
\genfrac{\{}{\}}{0pt}{0}{2}{1}%
%EndExpansion
}_{=1}\dbinom{x+1}{2}+\underbrace{2!%
%TCIMACRO{\QDATOPD{\{}{\}}{2}{2}}%
%BeginExpansion
\genfrac{\{}{\}}{0pt}{0}{2}{2}%
%EndExpansion
}_{=2}\dbinom{x+1}{3}\\
&  =\dbinom{x+1}{2}+2\dbinom{x+1}{3}=\dfrac{\left(  x+1\right)  x}{2}%
+2\cdot\dfrac{\left(  x+1\right)  x\left(  x-1\right)  }{6}\\
&  =\dfrac{1}{6}x\left(  x+1\right)  \left(  2x+1\right)  ,
\end{align*}
and thus%
\[
1^{2}+2^{2}+\cdots+n^{2}=p_{2}\left(  n\right)  =\dfrac{1}{6}n\left(
n+1\right)  \left(  2n+1\right)  \ \ \ \ \ \ \ \ \ \ \text{for each }%
n\in\mathbb{N}.
\]
This recovers the claim of Proposition \ref{prop.ent.1d+2d+...+nd-for-5}
\textbf{(b)}. The combinatorial proof presented in \cite[Proposition
23.2]{Galvin} is highly recommended reading for anyone interested in this kind
of formulas.

Let us note that the polynomials $p_{d}\left(  x\right)  $ do \textbf{not}
have integer coefficients, but nevertheless all their values $p_{d}\left(
n\right)  $ for $n\in\mathbb{N}$ are integers.
\end{fineprint}

Let us now show the power of Theorem \ref{thm.ent.coprime.combine} on the
following exercise:

\begin{exercise}
\label{exe.ent.coprime.1+2+...+n}Let $n\in\mathbb{N}$. Let $d$ be an odd
positive integer. Prove that%
\[
1+2+\cdots+n\mid1^{d}+2^{d}+\cdots+n^{d}.
\]


[\textbf{Hint:} Use Proposition \ref{prop.ent.1+2+...+n} to reduce the claim
to proving that $n\left(  n+1\right)  \mid2\left(  1^{d}+2^{d}+\cdots
+n^{d}\right)  $. But Theorem \ref{thm.ent.coprime.combine} shows that in
order to prove this, it suffices to prove $n\mid2\left(  1^{d}+2^{d}%
+\cdots+n^{d}\right)  $ and $n+1\mid2\left(  1^{d}+2^{d}+\cdots+n^{d}\right)
$, because $n\perp n+1$.]
\end{exercise}

\subsubsection{More properties of gcds and coprimality}

The following is a random collection of further exercises on gcds.

\begin{exercise}
\label{exe.ent.coprime.bezout-conv} Let $a,b,x,y$ be integers such that
$xa+yb=1$. Prove that $a\perp b$.
\end{exercise}

\begin{exercise}
\label{exe.ent.coprime.gcdgcd1}Let $u,v,x,y\in\mathbb{Z}$. Prove that
$\gcd\left(  u,v\right)  \cdot\gcd\left(  x,y\right)  =\gcd\left(
ux,uy,vx,vy\right)  $.
\end{exercise}

\begin{exercise}
\label{exe.ent.coprime.gcdgcd2}Let $a,b,c\in\mathbb{Z}$.

\textbf{(a)} Prove that $\gcd\left(  a,b\right)  \cdot\gcd\left(  a,c\right)
=\gcd\left(  ag,bc\right)  $, where $g=\gcd\left(  a,b,c\right)  $.

\textbf{(b)} Prove that $\gcd\left(  a,b\right)  \cdot\gcd\left(  a,c\right)
=\gcd\left(  a,bc\right)  $ if $b\perp c$.
\end{exercise}

\begin{exercise}
\label{exe.ent.coprime.a/g}Let $a$ and $b$ be two integers that are not both
zero. Let $g=\gcd\left(  a,b\right)  $. Prove that $\dfrac{a}{g}$ and
$\dfrac{b}{g}$ are integers satisfying $\dfrac{a}{g}\perp\dfrac{b}{g}$.
\end{exercise}

\begin{exercise}
\label{exe.ent.gcd.akbk}Let $a$ and $b$ be two integers. Let $k\in\mathbb{N}$.
Prove that $\gcd\left(  a^{k},b^{k}\right)  =\left(  \gcd\left(  a,b\right)
\right)  ^{k}$.
\end{exercise}

The next exercise is simply claiming the well-known fact that any rational
number can be written as a reduced fraction:

\begin{exercise}
\label{exe.ent.coprime.frac-red}Let $r\in\mathbb{Q}$. Prove that there exist
two \textbf{coprime} integers $a$ and $b$ satisfying $r=a/b$.
\end{exercise}

As an application of some of the preceding results, we can prove that certain
numbers are irrational:

\begin{exercise}
\label{exe.ent.coprime.sqrtu+sqrtv}Prove the following:

\textbf{(a)} If a positive integer $u$ is not a perfect square\footnotemark,
then $\sqrt{u}$ is irrational.

\textbf{(b)} If $u$ and $v$ are two positive integers, then $\sqrt{u}+\sqrt
{v}$ is irrational unless both $u$ and $v$ are perfect squares.
\end{exercise}

\footnotetext{A \textit{perfect square} means the square of an integer.}%
Exercise \ref{exe.ent.coprime.sqrtu+sqrtv} invites a rather natural
generalization: If $u_{1},u_{2},\ldots,u_{k}$ are several positive integers
that are not all perfect squares, then must $\sqrt{u_{1}}+\sqrt{u_{2}}%
+\cdots+\sqrt{u_{k}}$ always be irrational? It turns out that the answer is
\textquotedblleft yes\textquotedblright, but this is not as easy to prove
anymore as the two cases $k=1$ and $k=2$ that we handled in Exercise
\ref{exe.ent.coprime.sqrtu+sqrtv}. Proofs of the general version can be found
in \cite{Boreic08} (actually, a stronger statement is proven there, although
it takes some work to derive ours from it).

Let us generalize Exercise \ref{exe.ent.coprime.gcdgcd1} a bit:

\begin{exercise}
\label{exe.ent.coprime.gcdgcd1k}Let $x,y\in\mathbb{Z}$, and let $a_{1}%
,a_{2},\ldots,a_{k}$ be finitely many integers. Prove that
\[
\gcd\left(  a_{1},a_{2},\ldots,a_{k}\right)  \cdot\gcd\left(  x,y\right)
=\gcd\left(  a_{1}x,a_{2}x,\ldots,a_{k}x,a_{1}y,a_{2}y,\ldots,a_{k}y\right)
.
\]

\end{exercise}

We can extend this exercise further to several integers instead of $x$ and
$y$, but this extension would be notationally awkward, so we only state it for
the case of three integers:

\begin{exercise}
\label{exe.ent.coprime.gcdgcd1k3}Let $x,y,z\in\mathbb{Z}$, and let
$a_{1},a_{2},\ldots,a_{k}$ be finitely many integers. Prove that
\begin{align*}
&  \gcd\left(  a_{1},a_{2},\ldots,a_{k}\right)  \cdot\gcd\left(  x,y,z\right)
\\
&  =\gcd\left(  a_{1}x,a_{2}x,\ldots,a_{k}x,a_{1}y,a_{2}y,\ldots,a_{k}%
y,a_{1}z,a_{2}z,\ldots,a_{k}z\right)  .
\end{align*}

\end{exercise}

We leave it to the reader to state and solve an exercise generalizing Exercise
\ref{exe.ent.coprime.gcdgcd1k} and Exercise \ref{exe.ent.coprime.gcdgcd1k3}.

\begin{exercise}
\label{exe.ent.coprime.gcd-distrib1}Let $a,b,c\in\mathbb{Z}$. Prove that%
\[
\gcd\left(  b,c\right)  \cdot\gcd\left(  c,a\right)  \cdot\gcd\left(
a,b\right)  =\gcd\left(  a,b,c\right)  \cdot\gcd\left(  bc,ca,ab\right)  .
\]

\end{exercise}

\begin{center}
\textbf{2019-02-08 lecture}
\end{center}

\subsection{Lowest common multiples}

\begin{teachingnote}
I don't think this section is actually used anywhere later in this course.
\end{teachingnote}

Common multiples are, in a sense, a \textquotedblleft mirror
version\textquotedblright\ of common divisors. Here is their definition:

\begin{definition}
\label{def.ent.Mul}Let $b_{1},b_{2},\ldots,b_{k}$ be integers. Then, the
\textit{common multiples} of $b_{1},b_{2},\ldots,b_{k}$ are defined to be the
integers $a$ that satisfy%
\[
\left(  b_{i}\mid a\text{ for all }i\in\left\{  1,2,\ldots,k\right\}  \right)
.
\]
(In other words, a \textit{common multiple} of $b_{1},b_{2},\ldots,b_{k}$ is
an integer that is a multiple of each of $b_{1},b_{2},\ldots,b_{k}$.) We let
$\operatorname*{Mul}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ denote the set
of these common multiples.
\end{definition}

\begin{example}
The common multiples of $4,6$ are $\ldots,-36,-24,-12,0,12,24,36,\ldots$, that
is, all multiples of $12$.

The common multiples of $1,2,3$ are all multiples of $6$.
\end{example}

Note that the common multiples of a single integer $b$ are simply the
multiples of $b$. (Also, the common multiples of an empty list of integers are
all the integers; in other words, $\operatorname*{Mul}\left(  {}\right)
=\mathbb{Z}$.)

Note that the definition of common multiples of $b_{1},b_{2},\ldots,b_{k}$
(Definition \ref{def.ent.Mul}) is the same as the definition of common
divisors of $b_{1},b_{2},\ldots,b_{k}$ except that the divisibility has been
flipped (i.e., it says \textquotedblleft$b_{i}\mid a$\textquotedblright%
\ instead of \textquotedblleft$a\mid b_{i}$\textquotedblright). This is why
common multiples are a \textquotedblleft mirror version\textquotedblright\ of
common divisors. This analogy is not perfect -- in particular, (for example)
two nonzero integers have infinitely many common multiples but only finitely
many common divisors. We shall now introduce lowest common multiples, which
correspond to greatest common divisors in this analogy. However, we have to
prove a simple proposition first:

\begin{proposition}
\label{prop.ent.Mul.exi}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely many
nonzero integers. Then, the set $\operatorname*{Mul}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  $ has a smallest positive element.
\end{proposition}

Proposition \ref{prop.ent.Mul.exi} is similar to Proposition
\ref{prop.ent.Div.fin} (and will play a similar role), but note the
differences: It requires \textbf{all} of $b_{1},b_{2},\ldots,b_{k}$ to be
nonzero (unlike Proposition \ref{prop.ent.Div.fin}, which needed only one of
them to be nonzero), and it does not claim finiteness of any set.

\begin{proof}
[Proof of Proposition \ref{prop.ent.Mul.exi}.]We claim that%
\begin{equation}
\left\vert b_{1}b_{2}\cdots b_{k}\right\vert \in\operatorname*{Mul}\left(
b_{1},b_{2},\ldots,b_{k}\right)  . \label{pf.prop.ent.Mul.exi.1}%
\end{equation}


\textit{Proof of (\ref{pf.prop.ent.Mul.exi.1}):} Let $i\in\left\{
1,2,\ldots,k\right\}  $. Then, the product $b_{1}b_{2}\cdots b_{k}$ can be
written as%
\[
b_{1}b_{2}\cdots b_{k}=b_{i}\cdot\left(  b_{1}b_{2}\cdots b_{i-1}%
b_{i+1}b_{i+2}\cdots b_{k}\right)  ,
\]
and thus is divisible by $b_{i}$. In other words, $b_{i}\mid b_{1}b_{2}\cdots
b_{k}$. But Exercise \ref{exe.ent.div.aabs} \textbf{(a)} (applied to
$a=b_{1}b_{2}\cdots b_{k}$) yields $b_{1}b_{2}\cdots b_{k}\mid\left\vert
b_{1}b_{2}\cdots b_{k}\right\vert $. Altogether, $b_{i}\mid b_{1}b_{2}\cdots
b_{k}\mid\left\vert b_{1}b_{2}\cdots b_{k}\right\vert $.

Now forget that we fixed $i$. We thus have proven that $b_{i}\mid\left\vert
b_{1}b_{2}\cdots b_{k}\right\vert $ for all $i\in\left\{  1,2,\ldots
,k\right\}  $. In other words, $\left\vert b_{1}b_{2}\cdots b_{k}\right\vert $
is a common multiple of $b_{1},b_{2},\ldots,b_{k}$ (by the definition of a
\textquotedblleft common multiple\textquotedblright). In other words,
$\left\vert b_{1}b_{2}\cdots b_{k}\right\vert \in\operatorname*{Mul}\left(
b_{1},b_{2},\ldots,b_{k}\right)  $. This proves (\ref{pf.prop.ent.Mul.exi.1}).]

We know that $b_{1},b_{2},\ldots,b_{k}$ are nonzero integers. Hence, their
product $b_{1}b_{2}\cdots b_{k}$ is a nonzero integer as well. Thus, its
absolute value $\left\vert b_{1}b_{2}\cdots b_{k}\right\vert $ is a positive
integer. Hence, $\left\vert b_{1}b_{2}\cdots b_{k}\right\vert $ is a positive
element of $\operatorname*{Mul}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $
(since (\ref{pf.prop.ent.Mul.exi.1}) shows that it is an element of
$\operatorname*{Mul}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $). Thus, the set
$\operatorname*{Mul}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ has a positive
element. Therefore, this set $\operatorname*{Mul}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  $ has a \textbf{smallest} positive element as
well\footnote{Here we are using the following basic fact: If a set of integers
$S$ has a positive element, then it has a \textbf{smallest} positive element
as well. (To prove this fact, you can fix a positive element $s\in S$, which
exists by assumption; then, the set $\left\{  1,2,\ldots,s\right\}  \cap S$ is
finite and nonempty (since it contains $s$), and thus clearly has a smallest
element; now you can easily check that its smallest element must also be the
smallest positive element of $S$.)}. This proves Proposition
\ref{prop.ent.Mul.exi}.
\end{proof}

\begin{definition}
\label{def.ent.lcm.lcm}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely many
integers. The \textit{lowest common multiple} of $b_{1},b_{2},\ldots,b_{k}$ is
defined as follows:

\begin{itemize}
\item If $b_{1},b_{2},\ldots,b_{k}$ are all nonzero, then it is defined as the
smallest positive element of the set $\operatorname*{Mul}\left(  b_{1}%
,b_{2},\ldots,b_{k}\right)  $. This smallest positive element is well-defined
(by Proposition \ref{prop.ent.Mul.exi}), and is a positive integer (obviously).

\item If $b_{1},b_{2},\ldots,b_{k}$ are not all nonzero (i.e., at least one of
$b_{1},b_{2},\ldots,b_{k}$ is zero), then it is defined to be $0$.
\end{itemize}

Thus, in either case, this lowest common multiple is a nonnegative integer. We
denote it by $\operatorname{lcm}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $.
(Some authors also call it $\left[  b_{1},b_{2},\ldots,b_{k}\right]  $.)

We shall also use the word \textquotedblleft\textit{lcm}\textquotedblright\ as
shorthand for \textquotedblleft lowest common multiple\textquotedblright.
\end{definition}

Some authors say \textquotedblleft\textit{least common multiple}%
\textquotedblright\ instead of \textquotedblleft lowest common
multiple\textquotedblright.

We are slightly abusing the word \textquotedblleft lowest common
multiple\textquotedblright, of course; it would be more precise to say
\textquotedblleft lowest \textbf{positive} common multiple\textquotedblright,
and even this would only hold for the case when $b_{1},b_{2},\ldots,b_{k}$ are
all nonzero. Taken literally, a \textquotedblleft lowest common
multiple\textquotedblright\ of $2$ and $3$ would not exist, since $2$ and $3$
have infinitely many negative common multiples.

Note that the lcm of a single number is the absolute value of this number:
i.e., we have $\operatorname{lcm}\left(  a\right)  =\left\vert a\right\vert $
for each $a\in\mathbb{Z}$. (This is easy to prove.) Also, the lcm of an empty
list of numbers is $1$: that is, $\operatorname{lcm}\left(  {}\right)  =1$.

We observe a trivial property of lcms, which (for the sake of brevity) we only
state for two integers $a$ and $b$ despite it holding for any number of
integers (with the same proof):

\begin{proposition}
\label{prop.ent.lcm.divides}Let $a,b\in\mathbb{Z}$.

\textbf{(a)} We have $0\in\operatorname*{Mul}\left(  a,b\right)  $.

\textbf{(b)} We have $\operatorname{lcm}\left(  a,b\right)  \in
\operatorname*{Mul}\left(  a,b\right)  $.

\textbf{(c)} We have $a\mid\operatorname{lcm}\left(  a,b\right)  $ and
$b\mid\operatorname{lcm}\left(  a,b\right)  $.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.lcm.divides}.]\textbf{(a)} The integer $0$
clearly satisfies $\left(  a\mid0\text{ and }b\mid0\right)  $. In other words,
$0$ is a common multiple of $a$ and $b$ (by the definition of a
\textquotedblleft common multiple\textquotedblright). In other words,
$0\in\operatorname*{Mul}\left(  a,b\right)  $ (by the definition of
$\operatorname*{Mul}\left(  a,b\right)  $). This proves Proposition
\ref{prop.ent.lcm.divides} \textbf{(a)}.

\textbf{(b)} If the two integers $a$ and $b$ are not all nonzero, then
Proposition \ref{prop.ent.lcm.divides} \textbf{(b)}
holds\footnote{\textit{Proof.} Assume that the two integers $a$ and $b$ are
not all nonzero. Hence, Definition \ref{def.ent.lcm.lcm} shows that
$\operatorname{lcm}\left(  a,b\right)  =0\in\operatorname*{Mul}\left(
a,b\right)  $ (by Proposition \ref{prop.ent.lcm.divides} \textbf{(a)}). Thus,
Proposition \ref{prop.ent.lcm.divides} \textbf{(b)} holds.}. Hence, for the
rest of this proof, we WLOG assume that the two integers $a$ and $b$ are all
nonzero. Thus, Definition \ref{def.ent.lcm.lcm} yields that
$\operatorname{lcm}\left(  a,b\right)  $ is the smallest positive element of
the set $\operatorname*{Mul}\left(  a,b\right)  $. Hence, $\operatorname{lcm}%
\left(  a,b\right)  \in\operatorname*{Mul}\left(  a,b\right)  $. This proves
Proposition \ref{prop.ent.lcm.divides} \textbf{(b)}.

\textbf{(c)} Proposition \ref{prop.ent.lcm.divides} \textbf{(b)} yields
$\operatorname{lcm}\left(  a,b\right)  \in\operatorname*{Mul}\left(
a,b\right)  $. In other words, $\operatorname{lcm}\left(  a,b\right)  $ is a
common multiple of $a$ and $b$ (by the definition of $\operatorname*{Mul}%
\left(  a,b\right)  $). In other words, we have $\left(  a\mid
\operatorname{lcm}\left(  a,b\right)  \text{ and }b\mid\operatorname{lcm}%
\left(  a,b\right)  \right)  $ (by the definition of \textquotedblleft common
multiple\textquotedblright). This proves Proposition
\ref{prop.ent.lcm.divides} \textbf{(c)}.
\end{proof}

The following theorem yields a good way of computing lcms of two numbers
(since we already know how to compute gcds via the Euclidean algorithm):

\begin{theorem}
\label{thm.ent.lcm.gcd*lcm}Let $a,b\in\mathbb{Z}$. Then, $\gcd\left(
a,b\right)  \cdot\operatorname{lcm}\left(  a,b\right)  =\left\vert
ab\right\vert $.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.lcm.gcd*lcm}.]If at least one of the two
numbers $a$ and $b$ is $0$, then Theorem \ref{thm.ent.lcm.gcd*lcm}
holds\footnote{\textit{Proof.} Assume that at least one of the two numbers $a$
and $b$ is $0$. Thus, the product $ab$ is $0$. Hence, $ab=0$, so that
$\left\vert ab\right\vert =0$.
\par
On the other hand, the two numbers $a,b$ are not all nonzero (since at least
one of the two numbers $a$ and $b$ is $0$). Hence, Definition
\ref{def.ent.lcm.lcm} shows that $\operatorname{lcm}\left(  a,b\right)  =0$.
Comparing $\gcd\left(  a,b\right)  \cdot\underbrace{\operatorname{lcm}\left(
a,b\right)  }_{=0}=0$ with $\left\vert ab\right\vert =0$, we obtain
$\gcd\left(  a,b\right)  \cdot\operatorname{lcm}\left(  a,b\right)
=\left\vert ab\right\vert $. In other words, Theorem \ref{thm.ent.lcm.gcd*lcm}
holds.}. Hence, for the rest of this proof, we WLOG assume that none of the
two numbers $a$ and $b$ is $0$. In other words, $a$ and $b$ are nonzero. Thus,
Definition \ref{def.ent.lcm.lcm} yields that $\operatorname{lcm}\left(
a,b\right)  $ is the smallest positive element of the set $\operatorname*{Mul}%
\left(  a,b\right)  $. Also, $\gcd\left(  a,b\right)  $ is a positive integer
(since $a$ and $b$ are nonzero) and thus nonzero. Hence, we can define
$c\in\mathbb{Q}$ by $c=\dfrac{ab}{\gcd\left(  a,b\right)  }$. Consider this
$c$. From $c=\dfrac{ab}{\gcd\left(  a,b\right)  }$, we obtain $ab=\gcd\left(
a,b\right)  \cdot c$.

Let $d=\left\vert c\right\vert $. The number $c=\dfrac{ab}{\gcd\left(
a,b\right)  }$ is nonzero (since $a$ and $b$ are nonzero). Hence, its absolute
value $\left\vert c\right\vert $ is positive. In other words, $d$ is positive
(since $d=\left\vert c\right\vert $). From $ab=\gcd\left(  a,b\right)  \cdot
c$, we obtain%
\begin{align}
\left\vert ab\right\vert  &  =\left\vert \gcd\left(  a,b\right)  \cdot
c\right\vert =\underbrace{\left\vert \gcd\left(  a,b\right)  \right\vert
}_{\substack{=\gcd\left(  a,b\right)  \\\text{(since }\gcd\left(  a,b\right)
\text{ is positive)}}}\cdot\underbrace{\left\vert c\right\vert }%
_{=d}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{eq.ent.div.abs(xy)}), applied to
}\gcd\left(  a,b\right)  \text{ and }c\text{ instead of }x\text{ and }y\right)
\nonumber\\
&  =\gcd\left(  a,b\right)  \cdot d. \label{pf.thm.ent.lcm.gcd*lcm.1}%
\end{align}
Solving this for $d$, we find $d=\dfrac{\left\vert ab\right\vert }{\gcd\left(
a,b\right)  }$ (since $\gcd\left(  a,b\right)  $ is nonzero).

We have $\gcd\left(  a,b\right)  \mid b$ (by Proposition
\ref{prop.ent.gcd.props1} \textbf{(f)}). Thus, $\dfrac{b}{\gcd\left(
a,b\right)  }$ is an integer. Now, $c=\dfrac{ab}{\gcd\left(  a,b\right)
}=a\cdot\dfrac{b}{\gcd\left(  a,b\right)  }$ is the product of two integers
(since $a$ and $\dfrac{b}{\gcd\left(  a,b\right)  }$ are integers). Therefore,
$c$ itself is an integer. Thus, $d$ is an integer as well (since $d=\left\vert
c\right\vert $). Moreover, $c=a\cdot\dfrac{b}{\gcd\left(  a,b\right)  }$ shows
that $a\mid c$ (since $\dfrac{b}{\gcd\left(  a,b\right)  }$ is an integer).
But Exercise \ref{exe.ent.div.aabs} \textbf{(a)} (applied to $c$ instead of
$a$) yields $c\mid\left\vert c\right\vert $ (this means \textquotedblleft$c$
divides $\left\vert c\right\vert $\textquotedblright). In other words, $c\mid
d$ (since $d=\left\vert c\right\vert $). Hence, $a\mid c\mid d$.

So we have proven that $a\mid d$. Similarly, $b\mid d$. Thus, we know that
$\left(  a\mid d\text{ and }b\mid d\right)  $. In other words, $d$ is a common
multiple of $a$ and $b$ (by the definition of a \textquotedblleft common
multiple\textquotedblright). In other words, $d\in\operatorname*{Mul}\left(
a,b\right)  $ (by the definition of $\operatorname*{Mul}\left(  a,b\right)
$). Thus, $d$ is a positive element of the set $\operatorname*{Mul}\left(
a,b\right)  $ (since $d\in\operatorname*{Mul}\left(  a,b\right)  $).

We shall now show that $d$ is the smallest positive element of this set.
Indeed, let $x$ be any positive element of $\operatorname*{Mul}\left(
a,b\right)  $. We are going to prove that $x\geq d$.

In fact, $x\in\operatorname*{Mul}\left(  a,b\right)  $. In other words, $x$ is
a common multiple of $a$ and $b$. In other words, we have $\left(  a\mid
x\text{ and }b\mid x\right)  $. Hence, Theorem \ref{thm.ent.gcd.combine}
(applied to $x$ instead of $c$) yields $ab\mid\gcd\left(  a,b\right)  \cdot
x$. Both numbers $\gcd\left(  a,b\right)  $ and $x$ are positive; hence, their
product $\gcd\left(  a,b\right)  \cdot x$ is positive as well, and thus we
have $\gcd\left(  a,b\right)  \cdot x\neq0$. Hence, Proposition
\ref{prop.ent.div.1} \textbf{(b)} (applied to $ab$ and $\gcd\left(
a,b\right)  \cdot x$ instead of $a$ and $b$) yields $\left\vert ab\right\vert
\leq\left\vert \gcd\left(  a,b\right)  \cdot x\right\vert =\gcd\left(
a,b\right)  \cdot x$ (since $\gcd\left(  a,b\right)  \cdot x$ is positive).
Thus,%
\[
\gcd\left(  a,b\right)  \cdot x\geq\left\vert ab\right\vert =\gcd\left(
a,b\right)  \cdot d\ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.thm.ent.lcm.gcd*lcm.1})}\right)  .
\]
We can divide this inequality by $\gcd\left(  a,b\right)  $ (since
$\gcd\left(  a,b\right)  $ is positive), and thus obtain $x\geq d$.

Now, forget that we fixed $x$. We thus have proven that each positive element
$x$ of the set $\operatorname*{Mul}\left(  a,b\right)  $ satisfies $x\geq d$.
Hence, $d$ is the \textbf{smallest} positive element of the set
$\operatorname*{Mul}\left(  a,b\right)  $ (since we already know that $d$ is a
positive element of the set $\operatorname*{Mul}\left(  a,b\right)  $). In
other words, $d$ is $\operatorname{lcm}\left(  a,b\right)  $ (since
$\operatorname{lcm}\left(  a,b\right)  $ is the smallest positive element of
the set $\operatorname*{Mul}\left(  a,b\right)  $). In other words,
$d=\operatorname{lcm}\left(  a,b\right)  $. Hence,
(\ref{pf.thm.ent.lcm.gcd*lcm.1}) becomes $\left\vert ab\right\vert
=\gcd\left(  a,b\right)  \cdot\underbrace{d}_{=\operatorname{lcm}\left(
a,b\right)  }=\gcd\left(  a,b\right)  \cdot\operatorname{lcm}\left(
a,b\right)  $. This proves Theorem \ref{thm.ent.lcm.gcd*lcm}.
\end{proof}

Next, we state an analogue of Theorem \ref{thm.ent.gcd.uniprop} (with all
divisibilities flipped):

\begin{theorem}
\label{thm.ent.lcm.uniprop}Let $a,b\in\mathbb{Z}$. Then:

\textbf{(a)} For each $m\in\mathbb{Z}$, we have the following logical
equivalence:%
\begin{equation}
\left(  a\mid m\ \text{and }b\mid m\right)  \ \Longleftrightarrow\ \left(
\operatorname{lcm}\left(  a,b\right)  \mid m\right)  .
\label{eq.thm.ent.lcm.uniprop.equiv}%
\end{equation}


\textbf{(b)} The common multiples of $a$ and $b$ are precisely the multiples
of $\operatorname{lcm}\left(  a,b\right)  $.

\textbf{(c)} We have $\operatorname*{Mul}\left(  a,b\right)
=\operatorname*{Mul}\left(  \operatorname{lcm}\left(  a,b\right)  \right)  $.
\end{theorem}

Again, the three parts of this theorem are saying the same thing from slightly
different perspectives. Our proof of Theorem \ref{thm.ent.lcm.uniprop} will
rely on the following lemma:

\begin{lemma}
\label{lem.ent.lcm.uniprop}Let $m,a,b\in\mathbb{Z}$ be such that $a\mid m$ and
$b\mid m$. Then, $\operatorname{lcm}\left(  a,b\right)  \mid m$.
\end{lemma}

Lemma \ref{lem.ent.lcm.uniprop} is similar to Lemma \ref{lem.ent.gcd.uniprop},
but its proof is not:

\begin{proof}
[Proof of Lemma \ref{lem.ent.lcm.uniprop}.]If at least one of the two numbers
$a$ and $b$ is $0$, then Lemma \ref{lem.ent.lcm.uniprop}
holds\footnote{\textit{Proof.} Assume that at least one of the two numbers $a$
and $b$ is $0$. In other words, $a=0$ or $b=0$. Let us WLOG assume that $a=0$
(since the proof in the case $b=0$ is analogous). We have $a\mid m$, thus
$0=a\mid m$.
\par
On the other hand, the two numbers $a,b$ are not all nonzero (since at least
one of the two numbers $a$ and $b$ is $0$). Hence, Definition
\ref{def.ent.lcm.lcm} shows that $\operatorname{lcm}\left(  a,b\right)
=0=a\mid m$. In other words, Lemma \ref{lem.ent.lcm.uniprop} holds.}. Hence,
for the rest of this proof, we WLOG assume that none of the two numbers $a$
and $b$ is $0$. In other words, $a$ and $b$ are nonzero. Thus, Definition
\ref{def.ent.lcm.lcm} yields that $\operatorname{lcm}\left(  a,b\right)  $ is
the smallest positive element of the set $\operatorname*{Mul}\left(
a,b\right)  $. Set $n=\operatorname{lcm}\left(  a,b\right)  $. Thus, $n$ is
the smallest positive element of the set $\operatorname*{Mul}\left(
a,b\right)  $ (since $\operatorname{lcm}\left(  a,b\right)  $ is the smallest
positive element of the set $\operatorname*{Mul}\left(  a,b\right)  $).
Therefore, $n$ is a positive integer and belongs to $\operatorname*{Mul}%
\left(  a,b\right)  $.

Now, $n$ is a common multiple of $a$ and $b$ (since $n$ belongs to
$\operatorname*{Mul}\left(  a,b\right)  $). In other words, we have $\left(
a\mid n\text{ and }b\mid n\right)  $.

Our goal is to prove that $\operatorname{lcm}\left(  a,b\right)  \mid m$. In
other words, our goal is to prove that $n\mid m$ (since $n=\operatorname{lcm}%
\left(  a,b\right)  $). Assume the contrary. Thus, we don't have $n\mid m$.
Hence, we don't have $m\%n=0$ (because Corollary \ref{cor.ent.quo-rem.remmod}
\textbf{(b)} (applied to $u=m$) shows that we have $n\mid m$ if and only if
$m\%n=0$). In other words, we have $m\%n\neq0$.

Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(a)} (applied to $u=m$) yields
that $m\%n\in\left\{  0,1,\ldots,n-1\right\}  $ and $m\%n\equiv
m\operatorname{mod}n$. Combining $m\%n\in\left\{  0,1,\ldots,n-1\right\}  $
with $m\%n\neq0$, we obtain $m\%n\in\left\{  0,1,\ldots,n-1\right\}
\setminus\left\{  0\right\}  =\left\{  1,2,\ldots,n-1\right\}  $. Hence,
$m\%n$ is a positive integer and satisfies $m\%n\leq n-1<n$.

From $m\%n\equiv m\operatorname{mod}n$ and $a\mid n$, we obtain $m\%n\equiv
m\operatorname{mod}a$ (by Proposition \ref{prop.ent.mod.basics} \textbf{(e)},
applied to $a$, $m\%n$ and $m$ instead of $m$, $a$ and $b$). But
$m\equiv0\operatorname{mod}a$ (since $a\mid m$). Thus, $m\%n\equiv
m\equiv0\operatorname{mod}a$. In other words, $a\mid m\%n$. Similarly, $b\mid
m\%n$.

So we have proven that $\left(  a\mid m\%n\text{ and }b\mid m\%n\right)  $. In
other words, $m\%n$ is a common multiple of $a$ and $b$. In other words,
$m\%n\in\operatorname*{Mul}\left(  a,b\right)  $. Therefore, $m\%n$ is a
positive element of $\operatorname*{Mul}\left(  a,b\right)  $ (since $m\%n$ is
positive). Thus, $m\%n\geq n$ (since $n$ is the \textbf{smallest} positive
element of $\operatorname*{Mul}\left(  a,b\right)  $). This contradicts the
fact that $m\%n<n$. This contradiction shows that our assumption was false.
Hence, Lemma \ref{lem.ent.lcm.uniprop} is proven.
\end{proof}

\begin{proof}
[Proof of Theorem \ref{thm.ent.lcm.uniprop}.]\textbf{(a)} Let $m\in\mathbb{Z}%
$. In order to prove (\ref{eq.thm.ent.lcm.uniprop.equiv}), we need to prove
the \textquotedblleft$\Longrightarrow$\textquotedblright\ and
\textquotedblleft$\Longleftarrow$\textquotedblright\ directions of the
equivalence (\ref{eq.thm.ent.lcm.uniprop.equiv}). But this is easy: The
\textquotedblleft$\Longrightarrow$\textquotedblright\ direction is just the
statement of Lemma \ref{lem.ent.lcm.uniprop}, whereas the \textquotedblleft%
$\Longleftarrow$\textquotedblright\ direction is trivial (to wit: if
$\operatorname{lcm}\left(  a,b\right)  \mid m$, then%
\begin{align*}
a  &  \mid\operatorname{lcm}\left(  a,b\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by Proposition \ref{prop.ent.lcm.divides} \textbf{(c)}}\right) \\
&  \mid m
\end{align*}
and%
\begin{align*}
b  &  \mid\operatorname{lcm}\left(  a,b\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by Proposition \ref{prop.ent.lcm.divides} \textbf{(c)}}\right) \\
&  \mid m
\end{align*}
and thus $\left(  a\mid m\ \text{and }b\mid m\right)  $). Hence, the
equivalence (\ref{eq.thm.ent.lcm.uniprop.equiv}) is proven. This proves
Theorem \ref{thm.ent.lcm.uniprop} \textbf{(a)}.

\textbf{(b)} Theorem \ref{thm.ent.lcm.uniprop} \textbf{(b)} can be derived
from Theorem \ref{thm.ent.lcm.uniprop} \textbf{(a)} in the same way as Theorem
\ref{thm.ent.gcd.uniprop} \textbf{(b)} was derived from Theorem
\ref{thm.ent.gcd.uniprop} \textbf{(a)} (after the necessary changes are made
-- such as flipping all divisibility relations and replacing \textquotedblleft
divisor\textquotedblright\ by \textquotedblleft multiple\textquotedblright).

\textbf{(c)} Theorem \ref{thm.ent.lcm.uniprop} \textbf{(c)} can be derived
from Theorem \ref{thm.ent.lcm.uniprop} \textbf{(b)} in the same way as Theorem
\ref{thm.ent.gcd.uniprop} \textbf{(c)} was derived from Theorem
\ref{thm.ent.gcd.uniprop} \textbf{(b)} (after the necessary changes are made
-- such as flipping all divisibility relations and replacing \textquotedblleft
divisor\textquotedblright\ by \textquotedblleft multiple\textquotedblright).
\end{proof}

Our next claim is an analogue of Theorem \ref{thm.ent.gcd.uniprop-mul}:

\begin{theorem}
\label{thm.ent.lcm.uniprop-mul}Let $b_{1},b_{2},\ldots,b_{k}$ be integers.

\textbf{(a)} For each $m\in\mathbb{Z}$, we have the following logical
equivalence:%
\[
\left(  b_{i}\mid m\text{ for all }i\in\left\{  1,2,\ldots,k\right\}  \right)
\ \Longleftrightarrow\ \left(  \operatorname{lcm}\left(  b_{1},b_{2}%
,\ldots,b_{k}\right)  \mid m\right)  .
\]


\textbf{(b)} The common multiples of $b_{1},b_{2},\ldots,b_{k}$ are precisely
the multiples of $\operatorname{lcm}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $.

\textbf{(c)} We have $\operatorname*{Mul}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  =\operatorname*{Mul}\left(  \operatorname{lcm}\left(
b_{1},b_{2},\ldots,b_{k}\right)  \right)  $.

\textbf{(d)} If $k>0$, then%
\[
\operatorname{lcm}\left(  b_{1},b_{2},\ldots,b_{k}\right)  =\operatorname{lcm}%
\left(  \operatorname{lcm}\left(  b_{1},b_{2},\ldots,b_{k-1}\right)
,b_{k}\right)  .
\]

\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.lcm.uniprop-mul} (sketched).]It is not hard to
transform our above proof of Theorem \ref{thm.ent.gcd.uniprop-mul} into a
proof of Theorem \ref{thm.ent.lcm.uniprop-mul}. To do so, we need (of course)
to flip the divisibility relations and replace \textquotedblleft
divisor\textquotedblright\ by \textquotedblleft multiple\textquotedblright%
\ and \textquotedblleft$\gcd$\textquotedblright\ by \textquotedblleft%
$\operatorname{lcm}$\textquotedblright. (Some more changes need to be made as
well -- for example, the induction base needs to be handled differently, and
the WLOG assumption that \textquotedblleft the integers $b_{1},b_{2}%
,\ldots,b_{\ell}$ are not all $0$\textquotedblright\ needs to be replaced by a
WLOG assumption that \textquotedblleft the integers $b_{1},b_{2}%
,\ldots,b_{\ell}$ are all nonzero\textquotedblright. Also, \textquotedblleft
largest element\textquotedblright\ needs to be replaced by \textquotedblleft
smallest positive element\textquotedblright. But these are fairly
straightforward changes; the main thrust of the argument remains unchanged.)
\end{proof}

\begin{exercise}
\label{exe.ent.lcm.props1}Let $a,b\in\mathbb{Z}$.

\textbf{(a)} Prove that $\operatorname{lcm}\left(  a,b\right)
=\operatorname{lcm}\left(  b,a\right)  $.

\textbf{(b)} Prove that $\operatorname{lcm}\left(  -a,b\right)
=\operatorname{lcm}\left(  a,b\right)  $.

\textbf{(c)} Prove that $\operatorname{lcm}\left(  a,-b\right)
=\operatorname{lcm}\left(  a,b\right)  $.

\textbf{(d)} If $a\mid b$, then $\operatorname{lcm}\left(  a,b\right)
=\left\vert b\right\vert $.

\textbf{(e)} Let $s\in\mathbb{Z}$. Prove that $\operatorname{lcm}\left(
sa,sb\right)  =\left\vert s\right\vert \operatorname{lcm}\left(  a,b\right)  $.
\end{exercise}

\begin{exercise}
\label{exe.ent.lcm.lcmabc}Let $a,b,c$ be three integers.

\textbf{(a)} Prove that $\gcd\left(  a,b,c\right)  \cdot\operatorname{lcm}%
\left(  bc,ca,ab\right)  =\left\vert abc\right\vert $.

\textbf{(b)} Prove that $\operatorname{lcm}\left(  a,b,c\right)  \cdot
\gcd\left(  bc,ca,ab\right)  =\left\vert abc\right\vert $.
\end{exercise}

\subsection{The Chinese remainder theorem (elementary form)}

\begin{theorem}
\label{thm.ent.crt1}Let $m$ and $n$ be two coprime integers. Let
$a,b\in\mathbb{Z}$.

\textbf{(a)} There exists an integer $x\in\mathbb{Z}$ such that%
\[
\left(  x\equiv a\operatorname{mod}m\text{ and }x\equiv b\operatorname{mod}%
n\right)  .
\]


\textbf{(b)} If $x_{1}$ and $x_{2}$ are two such integers $x$, then
$x_{1}\equiv x_{2}\operatorname{mod}mn$.
\end{theorem}

Theorem \ref{thm.ent.crt1} is known as the \textit{Chinese remainder theorem}.
More precisely, there is a sizeable cloud of results that share this name;
Theorem \ref{thm.ent.crt1} is one of the most elementary and basic of these
results. A more general result is Theorem \ref{thm.ent.crt1k} further below.
However, the strongest and most general \textquotedblleft Chinese remainder
theorems\textquotedblright\ rely on concept from abstract algebra such as
rings and ideals; it will take us a while to get to them.

Theorem \ref{thm.ent.crt1} has gotten its name from the fact that
\href{https://en.wikipedia.org/wiki/Chinese_remainder_theorem#History}{a first
glimpse of it appears in \textquotedblleft Master Sun's Mathematical
Manual\textquotedblright\ from the 3rd century AD}; it took centuries until it
become a theorem with proof and precise statement.

The claim of Theorem \ref{thm.ent.crt1} \textbf{(b)} is often restated as
\textquotedblleft This integer $x$ (i.e., the integer $x$ satisfying $\left(
x\equiv a\operatorname{mod}m\text{ and }x\equiv b\operatorname{mod}n\right)
$) is unique modulo $mn$\textquotedblright. The \textquotedblleft modulo
$mn$\textquotedblright\ here signifies that what we are not claiming literal
uniqueness (which would mean that if $x_{1}$ and $x_{2}$ are two such integers
$x$, then $x_{1}=x_{2}$), but merely claiming a weaker form (namely, that if
$x_{1}$ and $x_{2}$ are two such integers $x$, then $x_{1}\equiv
x_{2}\operatorname{mod}mn$).

\begin{example}
Theorem \ref{thm.ent.crt1} \textbf{(a)} (applied to $m=5$, $n=6$ and $a=3$ and
$b=2$) shows that there exists an integer $x\in\mathbb{Z}$ such that%
\[
\left(  x\equiv3\operatorname{mod}5\text{ and }x\equiv2\operatorname{mod}%
6\right)  .
\]
We will soon find such an integer, after we have proved Theorem
\ref{thm.ent.crt1}.
\end{example}

\begin{proof}
[Proof of Theorem \ref{thm.ent.crt1}.]The integers $m$ and $n$ are coprime. In
other words, $m\perp n$, so that $n\perp m$ (by Proposition
\ref{prop.ent.coprime.perp-symm}).

\textbf{(a)} Theorem \ref{thm.ent.coprime.modinv} \textbf{(b)} (applied to $m$
instead of $a$) shows that there exists a $m^{\prime}\in\mathbb{Z}$ such that
$mm^{\prime}\equiv1\operatorname{mod}n$.

Similarly, there exists an $n^{\prime}\in\mathbb{Z}$ such that $nn^{\prime
}\equiv1\operatorname{mod}m$ (since $m$ and $n$ play symmetric roles in
Theorem \ref{thm.ent.crt1}).

Now, set $x_{0}=nn^{\prime}a+mm^{\prime}b$. Then,%
\[
x_{0}=\underbrace{nn^{\prime}}_{\equiv1\operatorname{mod}m}%
a+\underbrace{mm^{\prime}b}_{\equiv0\operatorname{mod}m}\equiv
1a+0=a\operatorname{mod}m
\]
(here, we have used the Principle of substitutivity for congruences, which we
described in Section \ref{sect.ent.subst-mod}) and similarly $x_{0}\equiv
b\operatorname{mod}n$. Thus, there exists an integer $x\in\mathbb{Z}$ such
that $\left(  x\equiv a\operatorname{mod}m\text{ and }x\equiv
b\operatorname{mod}n\right)  $ (namely, $x=x_{0}$). This proves Theorem
\ref{thm.ent.crt1} \textbf{(a)}.

\textbf{(b)} Let $x_{1}$ and $x_{2}$ be two such integers $x$. We want to
prove that $x_{1}\equiv x_{2}\operatorname{mod}mn$.

We know that $x_{1}$ is an integer $x$ such that $\left(  x\equiv
a\operatorname{mod}m\text{ and }x\equiv b\operatorname{mod}n\right)  $. Thus,
$x_{1}\equiv a\operatorname{mod}m$ and $x_{1}\equiv b\operatorname{mod}n$.

In particular, $x_{1}\equiv a\operatorname{mod}m$, and similarly $x_{2}\equiv
a\operatorname{mod}m$. Thus, $x_{1}\equiv a\equiv x_{2}\operatorname{mod}m$,
so that $m\mid x_{1}-x_{2}$. Similarly, $n\mid x_{1}-x_{2}$. Since $m\perp n$,
we thus obtain $mn\mid x_{1}-x_{2}$ (by Theorem \ref{thm.ent.coprime.combine},
applied to $m$, $n$ and $x_{1}-x_{2}$ instead of $a$, $b$ and $c$). In other
words, $x_{1}\equiv x_{2}\operatorname{mod}mn$. This proves Theorem
\ref{thm.ent.crt1}.
\end{proof}

\begin{noncompile}
Theorem \ref{thm.ent.crt1} is (the simplest form of) the \textit{Chinese
Remainder Theorem} (Sunzi, 3rd century AD).
\end{noncompile}

\begin{example}
Assume that we want to find an $x\in\mathbb{Z}$ such that%
\[
\left(  x\equiv3\operatorname{mod}5\text{ and }x\equiv2\operatorname{mod}%
6\right)  .
\]
To compute such an $x$, let us follow the proof of Theorem \ref{thm.ent.crt1}
\textbf{(a)} above.

We need a modular inverse $5^{\prime}$ of $5$ modulo $6$. Such an inverse is
$5$, since $5\cdot5\equiv1\operatorname{mod}6$. (In this particular case,
finding this modular inverse was easy, because all we had to do is to test the
$6$ numbers $0,1,2,3,4,5$; it is clear that a modular inverse of $a$ modulo
$m$, if it exists, can be found within the set $\left\{  0,1,\ldots
,m-1\right\}  $. In general, there is
\href{https://en.wikipedia.org/wiki/Modular_multiplicative_inverse#Computation}{a
quick way to find a modular inverse of an integer $a$ modulo an integer $m$
using the \textquotedblleft Extended Euclidean algorithm\textquotedblright}.)

We need a modular inverse $6^{\prime}$ of $6$ modulo $5$. Such an inverse is
$1$, since $6\cdot1\equiv1\operatorname{mod}5$.

Now, the proof of Theorem \ref{thm.ent.crt1} \textbf{(a)} tells us that
$x_{0}=6\cdot6^{\prime}\cdot3+5\cdot5^{\prime}\cdot2$ is an integer
$x\in\mathbb{Z}$ such that $\left(  x\equiv3\operatorname{mod}5\text{ and
}x\equiv2\operatorname{mod}6\right)  $. This $x_{0}$ is%
\[
6\cdot6^{\prime}\cdot3+5\cdot5^{\prime}\cdot2=6\cdot1\cdot3+5\cdot5\cdot2=68.
\]
So we have found an $x\in\mathbb{Z}$ such that $\left(  x\equiv
3\operatorname{mod}5\text{ and }x\equiv2\operatorname{mod}6\right)  $, namely
$x=68$. (We can easily check this: $68\equiv3\operatorname{mod}5$ since
$68-3=5\cdot13$; and $68\equiv2\operatorname{mod}6$ since $68-2=6\cdot11$.)
\end{example}

There is also a version of Theorem \ref{thm.ent.crt1} for multiple integers:

\begin{theorem}
\label{thm.ent.crt1k}Let $m_{1},m_{2},\ldots,m_{k}$ be $k$ mutually coprime
integers. Let $a_{1},a_{2},\ldots,a_{k}\in\mathbb{Z}$.

\textbf{(a)} There exists an integer $x$ such that
\begin{equation}
\left(  x\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,k\right\}  \right)  . \label{eq.thm.ent.crt1k.1}%
\end{equation}


\textbf{(b)} If $x_{1}$ and $x_{2}$ are two such integers $x$, then
$x_{1}\equiv x_{2}\operatorname{mod}m_{1}m_{2}\cdots m_{k}$.
\end{theorem}

Again, Theorem \ref{thm.ent.crt1k} \textbf{(b)} is often stated in the form
\textquotedblleft This integer $x$ is unique modulo $m_{1}m_{2}\cdots m_{k}%
$\textquotedblright.

Clearly, Theorem \ref{thm.ent.crt1} is the particular case of Theorem
\ref{thm.ent.crt1k} obtained for $k=2$.

\begin{proof}
[Proof of Theorem \ref{thm.ent.crt1k}.]Forget that we fixed $k$ and
$m_{1},m_{2},\ldots,m_{k}$ and $a_{1},a_{2},\ldots,a_{k}$.

\textbf{(a)} We shall prove Theorem \ref{thm.ent.crt1k} \textbf{(a)} by
induction on $k$:

\textit{Induction base:} Let us check that Theorem \ref{thm.ent.crt1k}
\textbf{(a)} holds for $k=0$. Indeed, if $k=0$, then Theorem
\ref{thm.ent.crt1k} \textbf{(a)} states the following:

\begin{statement}
\textit{Claim 0:} Let $m_{1},m_{2},\ldots,m_{0}$ be $0$ mutually coprime
integers. Let $a_{1},a_{2},\ldots,a_{0}\in\mathbb{Z}$. There exists an integer
$x$ such that
\begin{equation}
\left(  x\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,0\right\}  \right)  . \label{pf.thm.ent.crt1k.a.c0.claim}%
\end{equation}

\end{statement}

But Claim 0 is true, because (\ref{pf.thm.ent.crt1k.a.c0.claim}) is vacuously
true\footnote{since there exists no $i\in\left\{  1,2,\ldots,0\right\}  $} for
\textbf{any} integer $x$ (so we can take, for example, $x=0$). In other words,
Theorem \ref{thm.ent.crt1k} \textbf{(a)} holds for $k=0$; thus, the induction
base is complete.

Needless to say, Claim 0 is not an interesting statement, but it is a
perfectly valid induction base! (But you are free to check the case $k=1$ by
hand -- its proof is almost as easy as that for $k=0$.)

\textit{Induction step:} Let $\ell$ be a positive integer. Assume that Theorem
\ref{thm.ent.crt1k} \textbf{(a)} holds for $k=\ell-1$. We must now prove that
Theorem \ref{thm.ent.crt1k} \textbf{(a)} holds for $k=\ell$.

We have assumed that Theorem \ref{thm.ent.crt1k} \textbf{(a)} holds for
$k=\ell-1$. In other words, the following claim holds:

\begin{statement}
\textit{Claim 1:} Let $m_{1},m_{2},\ldots,m_{\ell-1}$ be $\ell-1$ mutually
coprime integers. Let $a_{1},a_{2},\ldots,a_{\ell-1}\in\mathbb{Z}$. There
exists an integer $x$ such that
\begin{equation}
\left(  x\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,\ell-1\right\}  \right)  . \label{pf.thm.ent.crt1k.a.c1.claim}%
\end{equation}

\end{statement}

We must prove that Theorem \ref{thm.ent.crt1k} \textbf{(a)} holds for $k=\ell
$. In other words, we must prove the following claim:

\begin{statement}
\textit{Claim 2:} Let $m_{1},m_{2},\ldots,m_{\ell}$ be $\ell$ mutually coprime
integers. Let $a_{1},a_{2},\ldots,a_{\ell}\in\mathbb{Z}$. There exists an
integer $x$ such that
\begin{equation}
\left(  x\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,\ell\right\}  \right)  . \label{pf.thm.ent.crt1k.a.c2.claim}%
\end{equation}

\end{statement}

[\textit{Proof of Claim 2:} The main idea of this proof is to combine Claim 1
(applied to $m_{1},m_{2},\ldots,m_{\ell-1}$) with Theorem \ref{thm.ent.crt1}
(applied to the coprime integers $m_{1}m_{2}\cdots m_{\ell-1}$ and $m_{\ell}%
$). In details:

The $\ell$ integers $m_{1},m_{2},\ldots,m_{\ell}$ are mutually coprime. Thus,
the $\ell-1$ integers $m_{1},m_{2},\ldots,m_{\ell-1}$ are mutually coprime.
Hence, Claim 1 shows that there exists an integer $x$ such that
\[
\left(  x\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,\ell-1\right\}  \right)  .
\]
Consider this $x$, and denote it by $u$. Thus, $u$ is an integer such that%
\begin{equation}
\left(  u\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,\ell-1\right\}  \right)  . \label{pf.thm.ent.crt1k.a.c2.pf.u}%
\end{equation}


Define an integer $m=m_{1}m_{2}\cdots m_{\ell-1}$.

The integers $m$ and $m_{\ell}$ are coprime\footnote{\textit{Proof.} Recall
that the $\ell$ integers $m_{1},m_{2},\ldots,m_{\ell}$ are mutually coprime.
In other words, $m_{i}\perp m_{j}$ for any $i,j\in\left\{  1,2,\ldots
,\ell\right\}  $ satisfying $i\neq j$. Applying this to $j=\ell$, we conclude
that $m_{i}\perp m_{\ell}$ for any $i\in\left\{  1,2,\ldots,\ell\right\}  $
satisfying $i\neq\ell$. In other words, $m_{i}\perp m_{\ell}$ for any
$i\in\left\{  1,2,\ldots,\ell-1\right\}  $ (since the numbers $i\in\left\{
1,2,\ldots,\ell\right\}  $ satisfying $i\neq\ell$ are precisely the numbers
$i\in\left\{  1,2,\ldots,\ell-1\right\}  $). In other words, each
$i\in\left\{  1,2,\ldots,\ell-1\right\}  $ satisfies $m_{i}\perp m_{\ell}$.
Hence, Exercise \ref{exe.ent.coprime.ab-to-ck} (applied to $c=m_{\ell}$,
$k=\ell-1$ and $a_{i}=m_{i}$) yields that $m_{1}m_{2}\cdots m_{\ell-1}\perp
m_{\ell}$. This rewrites as $m\perp m_{\ell}$ (since $m=m_{1}m_{2}\cdots
m_{\ell-1}$). In other words, the integers $m$ and $m_{\ell}$ are coprime.}.
Hence, Theorem \ref{thm.ent.crt1} \textbf{(a)} (applied to $n=m_{\ell}$, $a=u$
and $b=a_{\ell}$) yields that there exists an integer $x\in\mathbb{Z}$ such
that%
\[
\left(  x\equiv u\operatorname{mod}m\text{ and }x\equiv a_{\ell}%
\operatorname{mod}m_{\ell}\right)  .
\]
Consider this $x$, and denote it by $v$. Thus, $v$ is an integer such that%
\[
\left(  v\equiv u\operatorname{mod}m\text{ and }v\equiv a_{\ell}%
\operatorname{mod}m_{\ell}\right)  .
\]


Now, let $i\in\left\{  1,2,\ldots,\ell-1\right\}  $. Then,
\[
m=m_{1}m_{2}\cdots m_{\ell-1}=m_{i}\cdot\left(  m_{1}m_{2}\cdots
m_{i-1}m_{i+1}m_{i+2}\cdots m_{\ell-1}\right)  ;
\]
thus, $m_{i}\mid m$ (since $m_{1}m_{2}\cdots m_{i-1}m_{i+1}m_{i+2}\cdots
m_{\ell-1}$ is an integer). But as we just have shown, we have $v\equiv
u\operatorname{mod}m$. Hence, Proposition \ref{prop.ent.mod.basics}
\textbf{(e)} (applied to $v$, $u$, $m$ and $m_{i}$ instead of $a$, $b$, $n$
and $m$) yields $v\equiv u\operatorname{mod}m_{i}$ (since $m_{i}\mid m$).
Hence,
\[
v\equiv u\equiv a_{i}\operatorname{mod}m_{i}\ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{pf.thm.ent.crt1k.a.c2.pf.u})}\right)  .
\]


Now, forget that we fixed $i$. We thus have proven the congruence $v\equiv
a_{i}\operatorname{mod}m_{i}$ for each $i\in\left\{  1,2,\ldots,\ell
-1\right\}  $. But this congruence also holds for $i=\ell$ (since $v\equiv
a_{\ell}\operatorname{mod}m_{\ell}$). Hence, this congruence holds for all
$i\in\left\{  1,2,\ldots,\ell\right\}  $. In other words, we have%
\[
v\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,\ell\right\}  \text{.}%
\]
Thus, there exists an integer $x$ such that
\[
\left(  x\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,\ell\right\}  \right)
\]
(namely, $x=v$). This proves Claim 2.]

We have now proven Claim 2. In other words, Theorem \ref{thm.ent.crt1k}
\textbf{(a)} is true for $k=\ell$. Thus, the induction step is complete, so we
have proven Theorem \ref{thm.ent.crt1k} \textbf{(a)} by induction.

\textbf{(b)} Let $k$ and $m_{1},m_{2},\ldots,m_{k}$ and $a_{1},a_{2}%
,\ldots,a_{k}$ be as in Theorem \ref{thm.ent.crt1k}. Let $x_{1}$ and $x_{2}$
be two integers $x$ such that (\ref{eq.thm.ent.crt1k.1}). We must prove that
$x_{1}\equiv x_{2}\operatorname{mod}m_{1}m_{2}\cdots m_{k}$.

We know that $x_{1}$ is an integer $x$ such that (\ref{eq.thm.ent.crt1k.1}).
In other words, $x_{1}$ is an integer and has the property that%
\begin{equation}
\left(  x_{1}\equiv a_{i}\operatorname{mod}m_{i}\text{ for all }i\in\left\{
1,2,\ldots,k\right\}  \right)  . \label{pf.thm.ent.crt1k.b.x1}%
\end{equation}
Now, let $i\in\left\{  1,2,\ldots,k\right\}  $. Then,
(\ref{pf.thm.ent.crt1k.b.x1}) yields $x_{1}\equiv a_{i}\operatorname{mod}%
m_{i}$. Similarly, $x_{2}\equiv a_{i}\operatorname{mod}m_{i}$. Hence,
$x_{1}\equiv a_{i}\equiv x_{2}\operatorname{mod}m_{i}$. In other words,
$m_{i}\mid x_{1}-x_{2}$.

Now, forget that we fixed $i$. We thus have shown that $m_{i}\mid x_{1}-x_{2}$
for each $i\in\left\{  1,2,\ldots,k\right\}  $. Hence, Exercise
\ref{exe.ent.coprime.combinek} (applied to $c=x_{1}-x_{2}$ and $b_{i}=m_{i}$)
shows that $m_{1}m_{2}\cdots m_{k}\mid x_{1}-x_{2}$ (since $m_{1},m_{2}%
,\ldots,m_{k}$ are mutually coprime). In other words, $x_{1}\equiv
x_{2}\operatorname{mod}m_{1}m_{2}\cdots m_{k}$. This proves Theorem
\ref{thm.ent.crt1k} \textbf{(b)}.
\end{proof}

\subsection{Primes}

\subsubsection{Definition and the Sieve of Eratosthenes}

\begin{definition}
\label{def.ent.prime}Let $p$ be an integer greater than $1$. We say that $p$
is \textit{prime} if the only positive divisors of $p$ are $1$ and $p$. A
prime integer is often just called \textit{a prime}.
\end{definition}

Note that we required $p$ to be greater than $1$ here. Thus, $1$ does not
count as prime even though its only positive divisor is $1$ itself.

\begin{example}
\label{exa.ent.prime.1}\textbf{(a)} The only positive divisors of $7$ are $1$
and $7$. Thus, $7$ is a prime.

\textbf{(b)} The positive divisors of $14$ are $1$, $2$, $7$ and $14$. These
are more than just $1$ and $14$. Thus, $14$ is not a prime.

\textbf{(c)} None of the numbers $4,6,8,10,12,14,16,\ldots$ (that is, the
multiples of $2$ that are larger than $2$) is a prime. Indeed, if $p$ is any
of the numbers, then $p$ has a positive divisor other than $1$ and $p$
(namely, $2$), and therefore does not meet the definition of \textquotedblleft
prime\textquotedblright.

\textbf{(d)} None of the numbers $6,9,12,15,18,\ldots$ (that is, the multiples
of $3$ that are larger than $3$) is a prime. Indeed, if $p$ is any of the
numbers, then $p$ has a positive divisor other than $1$ and $p$ (namely, $3$),
and therefore does not meet the definition of \textquotedblleft
prime\textquotedblright.
\end{example}

Parts \textbf{(c)} and \textbf{(d)} of Example \ref{exa.ent.prime.1} suggest a
method for finding all primes up to a given integer:

\begin{example}
Let us say we want to find all primes that are $\leq30$.

\textit{Step 1:} All such primes must lie in $\left\{  2,3,\ldots,30\right\}
$ (since a prime is always an integer greater than $1$); thus, let us first
write down all elements of $\left\{  2,3,\ldots,30\right\}  $:%
\[%
\begin{array}
[c]{cccccccccc}
& 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20\\
21 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 29 & 30
\end{array}
.
\]
(We are using a table just in order to fit these elements on a page.)

We now plan to remove non-prime numbers from this table until only primes are left.

\textit{Step 2:} First, let us remove all multiples of $2$ that are larger
than $2$ from our table, because none of them is a prime (see Example
\ref{exa.ent.prime.1} \textbf{(c)}). We thus are left with%
\[%
\begin{array}
[c]{cccccccccc}
& 2 & 3 &  & 5 &  & 7 &  & 9 & \\
11 &  & 13 &  & 15 &  & 17 &  & 19 & \\
21 &  & 23 &  & 25 &  & 27 &  & 29 &
\end{array}
.
\]


\textit{Step 3:} Next, let us remove all multiples of $3$ that are larger than
$3$ from our table, because none of them is a prime (see Example
\ref{exa.ent.prime.1} \textbf{(d)}). We thus are left with%
\[%
\begin{array}
[c]{cccccccccc}
& 2 & 3 &  & 5 &  & 7 &  &  & \\
11 &  & 13 &  &  &  & 17 &  & 19 & \\
&  & 23 &  & 25 &  &  &  & 29 &
\end{array}
.
\]
(Note that some of these multiples have already been removed in Step 2.)

\textit{Step 4:} Next, let us remove all multiples of $4$ that are larger than
$4$ from our table, because none of them is a prime (for similar reasons). It
turns out that this does not change the table at all, because all such
multiples have already been removed in Step 2. This is not a coincidence:
Since $4$ itself has been removed, we know that $4$ was a multiple of some
number $d<4$ (in this case, $d=2$) whose multiples have been removed;
therefore, all multiples of $4$ are also multiples of $d$ and thus have been
removed along with $4$.

\textit{Step 5:} Next, let us remove all multiples of $5$ that are larger than
$5$ from our table, because none of them is a prime (for similar reasons). We
thus are left with%
\[%
\begin{array}
[c]{cccccccccc}
& 2 & 3 &  & 5 &  & 7 &  &  & \\
11 &  & 13 &  &  &  & 17 &  & 19 & \\
&  & 23 &  &  &  &  &  & 29 &
\end{array}
.
\]


\textit{Step 6:} Next, let us remove all multiples of $6$ that are larger than
$6$ from our table, because none of them is a prime. Just as Step 4, this does
not change the table, since all such multiples have already been removed in
Step 2.

\textit{Step 7:} Next, let us remove all multiples of $7$ that are larger than
$7$ from our table, because none of them is a prime. Again, this does not
change the table, since all such multiples have already been removed.

Proceed likewise until Step 30, at which point the table has become%
\[%
\begin{array}
[c]{cccccccccc}
& 2 & 3 &  & 5 &  & 7 &  &  & \\
11 &  & 13 &  &  &  & 17 &  & 19 & \\
&  & 23 &  &  &  &  &  & 29 &
\end{array}
.
\]
(You are reading it right: None of the steps from Step 6 to Step 30 causes any
changes to the table, since all multiples that these steps attempt to remove
have already been removed beforehand.)

The resulting table has the following property: If $p$ is an element of this
table, then $p$ cannot be a multiple of any $d\in\left\{  2,3,\ldots
,p-1\right\}  $ (because if it was such a multiple, then it would have been
removed from the table in Step $d$ or earlier). In other words, if $p$ is an
element of this table, then $p$ cannot have any divisor $d\in\left\{
2,3,\ldots,p-1\right\}  $. In other words, if $p$ is an element of this table,
then the only positive divisors of $p$ are $1$ and $p$. In other words, if $p$
is an element of this table, then $p$ is prime. Conversely, any prime $\leq30$
is in our table, since the only numbers we have removed from the table were
guaranteed to be non-prime. Thus, the table now contains all the primes
$\leq30$ and only them. So we conclude that the primes $\leq30$ are
$2,3,5,7,11,13,17,19,23,29$.

This method of finding primes is known as the \textbf{sieve of Eratosthenes}.
We could have made it more efficient using the following two tricks:

\begin{itemize}
\item If a number $d\in\left\{  2,3,\ldots,30\right\}  $ has been removed from
the table before Step $d$, then we know immediately that Step $d$ will not
change the table (because all multiples of $d$ have already been removed
before this step). Thus, we do not need to make this step.

\item If $d\in\left\{  2,3,\ldots,30\right\}  $ satisfies $d^{2}>30$, then
Step $d$ will not change the table\footnotemark. Thus, we only need to take
the Steps $d$ with $d^{2}\leq30$.
\end{itemize}

Together, these tricks tell us that the only steps we need to take are the
Steps 2, 3 and 5.
\end{example}

\footnotetext{\textit{Proof.} Let $d\in\left\{  2,3,\ldots,30\right\}  $ be
such that $d^{2}>30$. We must show that Step $d$ will not change the table.
\par
Indeed, at Step $d$, we remove all multiples of $d$ that are larger than $d$
from our table. But all these multiples (at least the ones that appear in our
table) have already been removed from this table before Step $d$.
\par
Here is why: Let $m\in\left\{  2,3,\ldots,30\right\}  $ be a multiple of $d$
that is larger than $d$. Then, $d\mid m$ (since $m$ is a multiple of $d$) and
thus $m/d\in\mathbb{Z}$. Hence, $m/d$ is a positive integer (since $m/d$ is
clearly positive) and $m/d>1$ (since $m$ is larger than $d$). Furthermore,
$m/d\mid m$ (since $m=\left(  m/d\right)  d$), so that $m$ is a multiple of
$m/d$. But $d>1$ (since $d\in\left\{  2,3,\ldots,30\right\}  $) and thus
$m/d<m$. In other words, $m>m/d$. Hence, $m$ is a multiple of $m/d$ that is
larger than $m/d$.
\par
Furthermore, $d^{2}>30\geq m$ (since $m\in\left\{  2,3,\ldots,30\right\}  $).
Dividing both sides of this inequality by $d$, we obtain $d>m/d$. Hence,
$m/d<d$, so that $m/d\in\left\{  2,3,\ldots,d-1\right\}  $ (since $m/d>1$).
Thus, before Step $d$ begins, Step $m/d$ has already happened. Of course, Step
$m/d$ has removed $m$ from the table (since $m$ is a multiple of $m/d$ that is
larger than $m/d$). Therefore, the number $m$ has already been removed from
the table before Step $d$.
\par
Now, forget that we fixed $m$. We thus have shown that if $m\in\left\{
2,3,\ldots,30\right\}  $ is a multiple of $d$ that is larger than $d$, then
$m$ $m$ has already been removed from the table before Step $d$. In other
words, all multiples of $d$ that we try to remove at Step $d$ have already
been removed before Step $d$. Therefore, Step $d$ does not change our table.}

\begin{center}
\textbf{2019-02-11 lecture}
\end{center}

\subsubsection{Basic properties of primes}

\begin{proposition}
\label{prop.ent.prime.each-i-coprime}Let $p$ be a prime. Then, each
$i\in\left\{  1,2,\ldots,p-1\right\}  $ is coprime to $p$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.each-i-coprime}.]Let $i\in\left\{
1,2,\ldots,p-1\right\}  $. We must prove that $i$ is coprime to $p$.

From $i\in\left\{  1,2,\ldots,p-1\right\}  $, we obtain $1\leq i\leq p-1$ and
thus $i\geq1>0$, so that $i\neq0$. Hence, $i$ and $p$ are not all zero. Also,
$\left\vert i\right\vert =i$ (since $i>0$).

Also, $\gcd\left(  i,p\right)  $ is a positive integer (since $i$ and $p$ are
not all zero). Thus, $\left\vert \gcd\left(  i,p\right)  \right\vert
=\gcd\left(  i,p\right)  $.

Proposition \ref{prop.ent.gcd.props1} \textbf{(f)} (applied to $a=i$ and
$b=p$) shows that $\gcd\left(  i,p\right)  \mid i$ and $\gcd\left(
i,p\right)  \mid p$. From $\gcd\left(  i,p\right)  \mid i$ and $i\neq0$, we
obtain $\left\vert \gcd\left(  i,p\right)  \right\vert \leq\left\vert
i\right\vert $ (by Exercise \ref{prop.ent.div.1} \textbf{(b)}, applied to
$a=\gcd\left(  i,p\right)  $ and $b=i$). In view of $\left\vert \gcd\left(
i,p\right)  \right\vert =\gcd\left(  i,p\right)  $ and $\left\vert
i\right\vert =i$, this rewrites as $\gcd\left(  i,p\right)  \leq i$. Hence,
$\gcd\left(  i,p\right)  \leq i\leq p-1<p$ and therefore $\gcd\left(
i,p\right)  \neq p$.

We know that $p$ is prime. In other words, the only positive divisors of $p$
are $1$ and $p$ (by the definition of \textquotedblleft
prime\textquotedblright).

The integer $\gcd\left(  i,p\right)  $ is a positive divisor of $p$ (since
$\gcd\left(  i,p\right)  $ is positive and satisfies $\gcd\left(  i,p\right)
\mid p$), and thus must be either $1$ or $p$ (since the only positive divisors
of $p$ are $1$ and $p$). Since we know that $\gcd\left(  i,p\right)  \neq p$,
we thus conclude that $\gcd\left(  i,p\right)  =1$. In other words, $i$ is
coprime to $p$ (by the definition of \textquotedblleft
coprime\textquotedblright). This proves Proposition
\ref{prop.ent.prime.each-i-coprime}.
\end{proof}

Note that this proposition characterizes primes: If $p>1$ is an integer such
that each $i\in\left\{  1,2,\ldots,p-1\right\}  $ is coprime to $p$, then $p$
is prime. (The proof of this is left as an easy exercise.)

\begin{proposition}
\label{prop.ent.prime.div-or-coprime}Let $p$ be a prime. Let $a\in\mathbb{Z}$.
Then, either $p\mid a$ or $p\perp a$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.div-or-coprime}.]Assume the
contrary. Thus, neither $p\mid a$ nor $p\perp a$.

We know that $p$ is prime. In other words, $p$ is an integer greater than $1$
such that the only positive divisors of $p$ are $1$ and $p$ (by the definition
of \textquotedblleft prime\textquotedblright).

In particular, $p$ is greater than $1$. Hence, $p>1>0$, so that $p\neq0$.
Hence, $a$ and $p$ are not all zero. Thus, $\gcd\left(  a,p\right)  $ is a
positive integer.

Proposition \ref{prop.ent.gcd.props1} \textbf{(f)} (applied to $b=p$) shows
that $\gcd\left(  a,p\right)  \mid a$ and $\gcd\left(  a,p\right)  \mid p$. If
we had $\gcd\left(  a,p\right)  =p$, then we would obtain $p=\gcd\left(
a,p\right)  \mid a$, which would contradict the fact that we do not have
$p\mid a$. Hence, we cannot have $\gcd\left(  a,p\right)  =p$. In other words,
we have $\gcd\left(  a,p\right)  \neq p$.

The integer $\gcd\left(  a,p\right)  $ is a positive divisor of $p$ (since
$\gcd\left(  a,p\right)  $ is positive and satisfies $\gcd\left(  a,p\right)
\mid p$), and thus must be either $1$ or $p$ (since the only positive divisors
of $p$ are $1$ and $p$). Since we know that $\gcd\left(  a,p\right)  \neq p$,
we thus conclude that $\gcd\left(  a,p\right)  =1$. But Proposition
\ref{prop.ent.gcd.props1} \textbf{(b)} (applied to $b=p$) yields $\gcd\left(
a,p\right)  =\gcd\left(  p,a\right)  $. Thus, $\gcd\left(  p,a\right)
=\gcd\left(  a,p\right)  =1$. In other words, $p$ is coprime to $a$ (by the
definition of \textquotedblleft coprime\textquotedblright). In other words,
$p\perp a$. This contradicts the fact that we don't have $p\perp a$.

This contradiction shows that our assumption was false. Hence, Proposition
\ref{prop.ent.prime.div-or-coprime} is proven.
\end{proof}

We note that a converse of Proposition \ref{prop.ent.prime.div-or-coprime}
holds as well: If $p>1$ is an integer such that each $a\in\mathbb{Z}$
satisfies either $p\mid a$ or $p\perp a$, then $p$ is a prime. This is easy to
prove and left to the reader.

\begin{exercise}
\label{exe.ent.prime.dist=cop}Let $p$ and $q$ be two distinct primes. Prove
that $p\perp q$.
\end{exercise}

\begin{theorem}
\label{thm.ent.prime.pab}Let $p$ be a prime. Let $a,b\in\mathbb{Z}$ such that
$p\mid ab$. Then, $p\mid a$ or $p\mid b$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.prime.pab}.]Assume the contrary. Thus, neither
$p\mid a$ nor $p\mid b$.

Proposition \ref{prop.ent.prime.div-or-coprime} yields that either $p\mid a$
or $p\perp a$. Hence, $p\perp a$ (since $p\mid a$ does not hold). But $p\mid
ab$. Hence, Theorem \ref{thm.ent.coprime.cancel} (applied to $p$, $a$ and $b$
instead of $a$, $b$ and $c$) yields $p\mid b$. This contradicts the fact that
we don't have $p\mid b$.

This contradiction shows that our assumption was false. Hence, Theorem
\ref{thm.ent.prime.pab} is proven.
\end{proof}

Again, Theorem \ref{thm.ent.prime.pab} has a converse:

\begin{exercise}
\label{exe.ent.prime.pab-conv}Let $p>1$ be an integer. Assume that for every
$a,b\in\mathbb{Z}$ satisfying $p\mid ab$, we must have $p\mid a$ or $p\mid b$.
Prove that $p$ is prime.
\end{exercise}

There is also a version of Theorem \ref{thm.ent.prime.pab} for products of
multiple integers:

\begin{proposition}
\label{prop.ent.prime.pabk}Let $p$ be a prime. Let $a_{1},a_{2},\ldots,a_{k}$
be integers such that $p\mid a_{1}a_{2}\cdots a_{k}$. Then, $p\mid a_{i}$ for
some $i\in\left\{  1,2,\ldots,k\right\}  $.
\end{proposition}

We could prove Proposition \ref{prop.ent.prime.pabk} by induction on $k$. But
here is a more direct argument:

\begin{fineprint}
\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.pabk}.]Assume the contrary. Thus,
there exists no $i\in\left\{  1,2,\ldots,k\right\}  $ such that $p\mid a_{i}$.
In other words, for each $i\in\left\{  1,2,\ldots,k\right\}  $, we have%
\begin{equation}
\left(  \text{not }p\mid a_{i}\right)  . \label{pf.prop.ent.prime.pabk.1}%
\end{equation}


Now, let $i\in\left\{  1,2,\ldots,k\right\}  $. Then, we don't have $p\mid
a_{i}$ (by (\ref{pf.prop.ent.prime.pabk.1})). But Proposition
\ref{prop.ent.prime.div-or-coprime} (applied to $a=a_{i}$) shows that either
$p\mid a_{i}$ or $p\perp a_{i}$. Hence, we have $p\perp a_{i}$ (since we don't
have $p\mid a_{i}$). In other words, $a_{i}\perp p$ (by Proposition
\ref{prop.ent.coprime.perp-symm}).

Now, forget that we fixed $i$. We thus have proven that each $i\in\left\{
1,2,\ldots,k\right\}  $ satisfies $a_{i}\perp p$. Hence, Exercise
\ref{exe.ent.coprime.ab-to-ck} (applied to $c=p$) yields $a_{1}a_{2}\cdots
a_{k}\perp p$. In other words, $a_{1}a_{2}\cdots a_{k}$ is coprime to $p$. In
other words, $\gcd\left(  a_{1}a_{2}\cdots a_{k},p\right)  =1$. Hence,
Proposition \ref{prop.ent.gcd.props1} \textbf{(b)} yields $\gcd\left(
p,a_{1}a_{2}\cdots a_{k}\right)  =\gcd\left(  a_{1}a_{2}\cdots a_{k},p\right)
=1$.

But $p$ is prime; thus, $p>1$. Hence, $p$ is positive. Recall that $p\mid
a_{1}a_{2}\cdots a_{k}$; thus, Proposition \ref{prop.ent.gcd.props1}
\textbf{(i)} (applied to $a=p$ and $b=a_{1}a_{2}\cdots a_{k}$) yields
$\gcd\left(  p,a_{1}a_{2}\cdots a_{k}\right)  =\left\vert p\right\vert =p$
(since $p$ is positive). Comparing this with $\gcd\left(  p,a_{1}a_{2}\cdots
a_{k}\right)  =1$, we obtain $p=1$. This contradicts $p>1$. This contradiction
shows that our assumption was wrong. This proves Proposition
\ref{prop.ent.prime.pabk}.
\end{proof}
\end{fineprint}

\begin{exercise}
\label{exe.ent.prime.coprime-to-pk}Let $p$ be a prime. Let $k$ be a positive
integer. Let $a\in\mathbb{Z}$. Prove that $a\perp p^{k}$ holds if and only if
$p\nmid a$.
\end{exercise}

\subsubsection{Prime factorization I}

The next simple proposition says that every integer $n>1$ is divisible by at
least one prime:

\begin{proposition}
\label{prop.ent.prime.ex-pri-div}Let $n>1$ be an integer. Then, there exists
at least one prime $p$ such that $p\mid n$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.ex-pri-div}.]Clearly, $n$ is a
divisor of $n$ such that $n>1$. Thus, there exists a divisor $q$ of $n$ such
that $q>1$ (namely, $q=n$). Let $d$ be the \textbf{smallest} such
divisor\footnote{This exists, because the set of possible candidates is
nonempty (by the previous sentence) and finite.}. Thus, $d$ is a divisor of
$n$ and satisfies $d>1$. The integer $d$ is positive (since $d>1>0$) and
satisfies $d\mid n$ (since $d$ is a divisor of $n$).

We claim that $d$ is a prime.

\begin{fineprint}
[\textit{Proof:} Let $e$ be any positive divisor of $d$. Assume (for the sake
of contradiction) that $e\notin\left\{  1,d\right\}  $. Thus, $e\neq1$ and
$e\neq d$. Now, $e$ is a divisor of $d$; thus, $e\mid d\mid n$. In other
words, $e$ is a divisor of $n$. Also, $e>1$ (because $e$ is positive and
$e\neq1$). Hence, $e$ is a divisor $q$ of $n$ such that $q>1$.

But $d$ was defined as the \textbf{smallest} divisor $q$ of $n$ such that
$q>1$. Hence, any such divisor is $\geq d$. In other words, any divisor $q$ of
$n$ such that $q>1$ must satisfy $q\geq d$. Applying this to $q=e$, we
conclude that $e\geq d$ (since $e$ is a divisor $q$ of $n$ such that $q>1$).
Combined with $e\neq d$, this yields $e>d$.

But $e\mid d$ and $d\neq0$ (since $d>1>0$). Hence, $\left\vert e\right\vert
\leq\left\vert d\right\vert $ (by Exercise \ref{prop.ent.div.1} \textbf{(b)},
applied to $a=e$ and $b=d$). Since $e$ is positive, we have $\left\vert
e\right\vert =e$, so that $e=\left\vert e\right\vert \leq\left\vert
d\right\vert =d$ (since $d$ is positive). This contradicts $e>d$. This
contradiction shows that our assumption (that $e\notin\left\{  1,d\right\}  $)
was false. Thus, we have proven that $e\in\left\{  1,d\right\}  $. In other
worde, $e$ is either $1$ or $d$.

Now, forget that we fixed $e$. We thus have proven that if $e$ is any positive
divisor of $d$, then $e\in\left\{  1,d\right\}  $. In other words, any
positive divisor of $d$ is either $1$ or $d$. Thus, the only positive divisors
of $d$ are $1$ and $d$ (since $1$ and $d$ clearly \textbf{are} positive
divisors of $d$). In other words, $d$ is prime (by the definition of
\textquotedblleft prime\textquotedblright).]
\end{fineprint}

So we know that $d\mid n$, and that $d$ is prime. Hence, there exists at least
one prime $p$ such that $p\mid n$ (namely, $p=d$). This proves Proposition
\ref{prop.ent.prime.ex-pri-div}.
\end{proof}

\begin{definition}
Let $n$ be an integer. A \textit{prime factor} of $n$ means a prime $p$ such
that $p\mid n$. Some say \textquotedblleft prime divisor\textquotedblright%
\ instead of \textquotedblleft prime factor\textquotedblright.
\end{definition}

Thus, Proposition \ref{prop.ent.prime.ex-pri-div} says that each integer $n>1$
has at least one prime divisor.

\begin{proposition}
\label{prop.ent.prime.fac-ex}Let $n$ be a positive integer. Then, $n$ can be
written as a product of finitely many primes.
\end{proposition}

\begin{example}
\label{exa.ent.prime.fac-ex}\textbf{(a)} The integer $60$ can be written as a
product of four primes: namely, $60=2\cdot2\cdot3\cdot5$.

\textbf{(b)} The integer $1$ is the product of $0$ many primes (because a
product of $0$ many primes is the empty product, which is defined to be $1$).
\end{example}

\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.fac-ex}.]We shall prove Proposition
\ref{prop.ent.prime.fac-ex} by strong induction on $n$. Thus, we fix a
positive integer $N$, and we assume (as the induction hypothesis) that
Proposition \ref{prop.ent.prime.fac-ex} holds whenever $n<N$. We must now
prove that Proposition \ref{prop.ent.prime.fac-ex} holds for $n=N$. In other
words, we must prove that $N$ can be written as a product of finitely many primes.

If $N=1$, then this is obvious (because $1$ is a product of $0$ many
primes\footnote{See Example \ref{exa.ent.prime.fac-ex} \textbf{(b)}.}). Thus,
for the rest of this proof, we WLOG assume that $N\neq1$. Hence, $N>1$ (since
$N$ is a positive integer). Therefore, Proposition
\ref{prop.ent.prime.ex-pri-div} (applied to $n=N$) shows that there exists at
least one prime $p$ such that $p\mid N$. Consider this $p$.

We have $p\mid N$. In other words, there exists an integer $c$ such that
$N=pc$. Consider this $c$. We have $p>1$ (since $p$ is prime); thus, $p$ is
positive. Hence, $p\neq0$. Thus, solving the equality $N=pc$ for $c$, we find
$c=N/\underbrace{p}_{>1}<N/1$ (since $N$ is positive), so that $c<N/1=N$. But
our induction hypothesis says that Proposition \ref{prop.ent.prime.fac-ex}
holds whenever $n<N$. Hence, we can apply Proposition
\ref{prop.ent.prime.fac-ex} to $n=c$ (since $c<N$). We thus conclude that $c$
can be written as a product of finitely many primes. In other words, there
exist primes $q_{1},q_{2},\ldots,q_{k}$ such that $c=q_{1}q_{2}\cdots q_{k}$.
Consider these $q_{1},q_{2},\ldots,q_{k}$.

But%
\[
N=p\underbrace{c}_{=q_{1}q_{2}\cdots q_{k}}=pq_{1}q_{2}\cdots q_{k}.
\]
Hence, $N$ can be written as a product of finitely many primes (namely, of the
primes $p,q_{1},q_{2},\ldots,q_{k}$). In other words, Proposition
\ref{prop.ent.prime.fac-ex} holds for $n=N$. This completes the induction
step. Hence, Proposition \ref{prop.ent.prime.fac-ex} is proven by strong induction.
\end{proof}

Proposition \ref{prop.ent.prime.fac-ex} shows that every positive integer $n$
can be represented as a product of finitely many primes. Such a representation
-- or, more precisely, the list of the primes it contains -- will be called
the \textit{prime factorization} of $n$. Rigorously speaking, this means that
we make the following definition:

\begin{definition}
Let $n$ be a positive integer. A \textit{prime factorization} of $n$ means a
tuple $\left(  p_{1},p_{2},\ldots,p_{k}\right)  $ of primes such that
$n=p_{1}p_{2}\cdots p_{k}$.
\end{definition}

Keep in mind that \textquotedblleft tuple\textquotedblright\ always means
\textquotedblleft ordered tuple\textquotedblright\ unless we say otherwise.

\begin{example}
\textbf{(a)} The prime factorizations of $12$ are%
\[
\left(  2,2,3\right)  ,\ \ \ \ \ \ \ \ \ \ \left(  2,3,2\right)
,\ \ \ \ \ \ \ \ \ \ \left(  3,2,2\right)  .
\]
Indeed, these three $3$-tuples are prime factorizations of $12$ because
$12=2\cdot2\cdot3=2\cdot3\cdot2=3\cdot2\cdot2$. It is not hard to check that
they are the only prime factorizations of $12$.

\textbf{(b)} If $p$ is a prime, then the only prime factorization of $p$ is
the $1$-tuple $\left(  p\right)  $.

\textbf{(c)} If $p$ is a prime and $i\in\mathbb{N}$, then the only prime
factorization of $p^{i}$ is the $i$-tuple $\left(  \underbrace{p,p,\ldots
,p}_{i\text{ times}}\right)  $. This is not quite obvious at this point
(though it is not hard to derive from Proposition \ref{prop.ent.prime.pabk}).

\textbf{(d)} The only prime factorization of $1$ is the $0$-tuple $\left(
{}\right)  $.
\end{example}

This example suggests that all prime factorizations of a given positive
integer $n$ are equal to each other up to the order of their entries (i.e.,
are permutations of each other). This is indeed true, and we are going to
prove this soon (in Theorem \ref{thm.ent.prime.fac-uni} below).

\subsubsection{Permutations}

First of all: what is a \textquotedblleft permutation\textquotedblright, and
what exactly does \textquotedblleft equal to each other up to the order of
their entries\textquotedblright\ mean?

Informally speaking, a permutation of a tuple\footnote{Recall: a prime
factorization is a tuple.} $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ is a
tuple obtained from $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ by rearranging
its entries (without inserting new entries, or removing or duplicating
existing entries). To be rigorous, we need to encode this rearrangement via a
bijective map $\sigma:\left\{  1,2,\ldots,k\right\}  \rightarrow\left\{
1,2,\ldots,k\right\}  $ which will tell us which entry of our original tuple
will go to which position in the rearranged tuple. Such bijective maps, too,
are called permutations -- but permutations of sets, not of tuples. So let us
first define permutations of a set, and then use this to define permutations
of a tuple:

\begin{definition}
\label{def.comb.tuples.perm-set}Let $A$ be a set. A \textit{permutation} of
$A$ means a bijective map $A\rightarrow A$.
\end{definition}

\begin{example}
\textbf{(a)} The map $\left\{  1,2,3,4\right\}  \rightarrow\left\{
1,2,3,4\right\}  $ that sends $1,2,3,4$ to $3,1,4,2$ (respectively) is a
permutation of $\left\{  1,2,3,4\right\}  $.

\textbf{(b)} The map $\left\{  1,2,3\right\}  \rightarrow\left\{
1,2,3\right\}  $ that sends $1,2,3$ to $2,3,1$ (respectively) is a permutation
of $\left\{  1,2,3\right\}  $.

\textbf{(c)} For each set $A$, the identity map $\operatorname*{id}%
:A\rightarrow A$ is a permutation of $A$.
\end{example}

Thus, we have defined permutations of a set. We shall later study such
permutations in more detail, at least for finite sets $A$.

Now we can define permutations of a tuple:

\begin{definition}
\label{def.comb.tuples.perm-tup}Let $\left(  p_{1},p_{2},\ldots,p_{k}\right)
$ be a $k$-tuple. A \textit{permutation} of $\left(  p_{1},p_{2},\ldots
,p_{k}\right)  $ means a $k$-tuple of the form $\left(  p_{\sigma\left(
1\right)  },p_{\sigma\left(  2\right)  },\ldots,p_{\sigma\left(  k\right)
}\right)  $ where $\sigma$ is a permutation of the set $\left\{
1,2,\ldots,k\right\}  $. A \textit{permutation} of $\left(  p_{1},p_{2}%
,\ldots,p_{k}\right)  $ is also known as a \textit{rearrangement} of $\left(
p_{1},p_{2},\ldots,p_{k}\right)  $.
\end{definition}

\begin{example}
\textbf{(a)} The $4$-tuple $\left(  1,3,1,2\right)  $ is a permutation of the
$4$-tuple $\left(  3,2,1,1\right)  $. In fact, if we denote the $4$-tuple
$\left(  3,2,1,1\right)  $ by $\left(  p_{1},p_{2},p_{3},p_{4}\right)  $, then
there exists a permutation $\sigma$ of the set $\left\{  1,2,3,4\right\}  $
such that $\left(  1,3,1,2\right)  =\left(  p_{\sigma\left(  1\right)
},p_{\sigma\left(  2\right)  },p_{\sigma\left(  3\right)  },p_{\sigma\left(
4\right)  }\right)  $. (Actually, there exist two such permutations $\sigma$:
One of them sends $1,2,3,4$ to $3,1,4,2$, while the other sends $1,2,3,4$ to
$4,1,3,2$.)

\textbf{(b)} Any $k$-tuple is a permutation of itself. Indeed, if $\left(
p_{1},p_{2},\ldots,p_{k}\right)  $ is any $k$-tuple, then $\left(  p_{1}%
,p_{2},\ldots,p_{k}\right)  =\left(  p_{\sigma\left(  1\right)  }%
,p_{\sigma\left(  2\right)  },\ldots,p_{\sigma\left(  k\right)  }\right)  $ if
we let $\sigma$ be the identity map $\operatorname*{id}:\left\{
1,2,\ldots,k\right\}  \rightarrow\left\{  1,2,\ldots,k\right\}  $.
\end{example}

The following fact is easy and fundamental:

\begin{proposition}
\label{prop.comb.tuples.perm.symm}Let $\left(  p_{1},p_{2},\ldots
,p_{k}\right)  $ be a $k$-tuple. If $\left(  q_{1},q_{2},\ldots,q_{k}\right)
$ is a permutation of $\left(  p_{1},p_{2},\ldots,p_{k}\right)  $, then
$\left(  p_{1},p_{2},\ldots,p_{k}\right)  $ is a permutation of $\left(
q_{1},q_{2},\ldots,q_{k}\right)  $.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.comb.tuples.perm.symm}.]If you don't insist on
formalization, this is obvious: Any rearrangement of the entries of a
$k$-tuple can be undone by another rearrangement (which places the entries
back in their old positions). Thus, $\left(  p_{1},p_{2},\ldots,p_{k}\right)
$ can be obtained from $\left(  q_{1},q_{2},\ldots,q_{k}\right)  $ by
rearranging the entries.

\begin{fineprint}
Here is a formal proof:

Assume that $\left(  q_{1},q_{2},\ldots,q_{k}\right)  $ is a permutation of
$\left(  p_{1},p_{2},\ldots,p_{k}\right)  $. In other words, the $k$-tuple
$\left(  q_{1},q_{2},\ldots,q_{k}\right)  $ has the form $\left(
p_{\sigma\left(  1\right)  },p_{\sigma\left(  2\right)  },\ldots
,p_{\sigma\left(  k\right)  }\right)  $ for some permutation $\sigma$ of the
set $\left\{  1,2,\ldots,k\right\}  $ (by Definition
\ref{def.comb.tuples.perm-tup}). Consider this $\sigma$, and denote it by
$\tau$. Thus, $\tau$ is a permutation of the set $\left\{  1,2,\ldots
,k\right\}  $ and has the property that $\left(  q_{1},q_{2},\ldots
,q_{k}\right)  =\left(  p_{\tau\left(  1\right)  },p_{\tau\left(  2\right)
},\ldots,p_{\tau\left(  k\right)  }\right)  $.

Now, $\tau$ is a permutation of the set $\left\{  1,2,\ldots,k\right\}  $. In
other words, $\tau$ is a bijective map $\left\{  1,2,\ldots,k\right\}
\rightarrow\left\{  1,2,\ldots,k\right\}  $ (by Definition
\ref{def.comb.tuples.perm-set}). So the map $\tau$ is bijective, hence
invertible. Thus, its inverse $\tau^{-1}$ is well-defined and is also
invertible\footnote{And its inverse is $\left(  \tau^{-1}\right)  ^{-1}=\tau
$.}, hence bijective. So we know that $\tau^{-1}$ is a bijective map $\left\{
1,2,\ldots,k\right\}  \rightarrow\left\{  1,2,\ldots,k\right\}  $. In other
words, $\tau^{-1}$ is a permutation of the set $\left\{  1,2,\ldots,k\right\}
$ (by Definition \ref{def.comb.tuples.perm-set}).

We have $\left(  q_{1},q_{2},\ldots,q_{k}\right)  =\left(  p_{\tau\left(
1\right)  },p_{\tau\left(  2\right)  },\ldots,p_{\tau\left(  k\right)
}\right)  $. In other words,
\begin{equation}
q_{i}=p_{\tau\left(  i\right)  }\ \ \ \ \ \ \ \ \ \ \text{for each }%
i\in\left\{  1,2,\ldots,k\right\}  . \label{pf.prop.comb.tuples.perm.symm.1}%
\end{equation}
Hence, for each $j\in\left\{  1,2,\ldots,k\right\}  $, we have%
\begin{align*}
q_{\tau^{-1}\left(  j\right)  }  &  =p_{\tau\left(  \tau^{-1}\left(  j\right)
\right)  }\ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.prop.comb.tuples.perm.symm.1}), applied to }i=\tau^{-1}\left(
j\right)  \right) \\
&  =p_{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\tau\left(  \tau^{-1}\left(
j\right)  \right)  =j\right)  .
\end{align*}
In other words, $\left(  q_{\tau^{-1}\left(  1\right)  },q_{\tau^{-1}\left(
2\right)  },\ldots,q_{\tau^{-1}\left(  k\right)  }\right)  =\left(
p_{1},p_{2},\ldots,p_{k}\right)  $. Hence, the $k$-tuple $\left(  p_{1}%
,p_{2},\ldots,p_{k}\right)  $ has the form $\left(  q_{\sigma\left(  1\right)
},q_{\sigma\left(  2\right)  },\ldots,q_{\sigma\left(  k\right)  }\right)  $
for some permutation $\sigma$ of the set $\left\{  1,2,\ldots,k\right\}  $
(namely, $\sigma=\tau^{-1}$). In other words, the $k$-tuple $\left(
p_{1},p_{2},\ldots,p_{k}\right)  $ is a permutation of the $k$-tuple $\left(
q_{1},q_{2},\ldots,q_{k}\right)  $ (by Definition
\ref{def.comb.tuples.perm-tup}). This proves Proposition
\ref{prop.comb.tuples.perm.symm}.
\end{fineprint}
\end{proof}

Now, we can say what we mean when we say that two tuples differ only in the
order of their entries:

\begin{definition}
We say that two tuples \textit{differ only in the order of their entries} if
they are permutations of each other.
\end{definition}

The next lemma that we shall use is a basic fact from elementary combinatorics:

\begin{lemma}
\label{lem.comb.tuples.mult=perm}Let $P$ be a set. Let $\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  $ and $\left(  b_{1},b_{2},\ldots,b_{\ell}\right)
$ be two tuples of elements of $P$. Assume that for each $p\in P$, we have%
\begin{align}
&  \left(  \text{the number of times }p\text{ appears in }\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  \right) \nonumber\\
&  =\left(  \text{the number of times }p\text{ appears in }\left(  b_{1}%
,b_{2},\ldots,b_{\ell}\right)  \right)  .
\label{eq.lem.comb.tuples.mult=perm.ass}%
\end{align}
Then, the two tuples $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ and $\left(
b_{1},b_{2},\ldots,b_{\ell}\right)  $ differ only in the order of their
entries (i.e., are permutations of each other). (In other words, we have
$k=\ell$, and there exists a permutation$\ \sigma$ of the set $\left\{
1,2,\ldots,\ell\right\}  $ such that $\left(  a_{1},a_{2},\ldots,a_{k}\right)
=\left(  b_{\sigma\left(  1\right)  },b_{\sigma\left(  2\right)  }%
,\ldots,b_{\sigma\left(  \ell\right)  }\right)  $.)
\end{lemma}

Lemma \ref{lem.comb.tuples.mult=perm} is an intuitively obvious fact: It says
that if two tuples (of any objects -- e.g., numbers) have the property that
any object occurs as often in the first tuple as it does in the second tuple,
then the two tuples differ only in the order of their entries. From the formal
point of view, though, it is a statement that needs proof. Let us merely
sketch how such a proof can be obtained, without going into the details:

\begin{fineprint}
\begin{proof}
[Proof of Lemma \ref{lem.comb.tuples.mult=perm} (sketched).]We can WLOG assume
that the set $P$ is finite (since otherwise, we can replace $P$ by the finite
subset $\left\{  a_{1},a_{2},\ldots,a_{k},b_{1},b_{2},\ldots,b_{\ell}\right\}
$, without breaking the assumption that $\left(  a_{1},a_{2},\ldots
,a_{k}\right)  $ and $\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ are two
tuples of elements of $P$). Assume this (at least if you don't want to use the
Axiom of Choice\footnote{I don't.}).

For each $p\in P$, define two sets%
\begin{align*}
A_{p}  &  =\left\{  i\in\left\{  1,2,\ldots,k\right\}  \ \mid\ a_{i}%
=p\right\}  ;\\
B_{p}  &  =\left\{  j\in\left\{  1,2,\ldots,\ell\right\}  \ \mid
\ b_{j}=p\right\}  .
\end{align*}
The equation (\ref{eq.lem.comb.tuples.mult=perm.ass}) then says that
$\left\vert A_{p}\right\vert =\left\vert B_{p}\right\vert $ for each $p\in P$.
Hence, for each $p\in P$, there exists a bijection $\phi_{p}:A_{p}\rightarrow
B_{p}$ (because if two sets have the same size, then there exists a bijection
between them). Pick such a bijection $\phi_{p}$ for each $p\in P$. (This does
not require the Axiom of Choice, since $P$ is finite.)

Now, define a map $\sigma:\left\{  1,2,\ldots,k\right\}  \rightarrow\left\{
1,2,\ldots,\ell\right\}  $ as follows: For each $i\in\left\{  1,2,\ldots
,k\right\}  $, set $\sigma\left(  i\right)  =\phi_{p}\left(  i\right)  $,
where $p=a_{i}$. Thus, for each $p\in P$, the map $\sigma$ sends each $i\in
A_{p}$ to an element of $B_{p}$ (because if $i\in A_{p}$, then $a_{i}=p$, and
thus the definition of $\sigma$ yields $\sigma\left(  i\right)  =\phi
_{p}\left(  i\right)  \in B_{p}$.)

It is not hard to see that this map $\sigma$ is a bijection. (Its inverse map
sends each $j\in\left\{  1,2,\ldots,\ell\right\}  $ to $\phi_{p}^{-1}\left(
j\right)  $, where $p=b_{j}$.) Thus, we have found a bijection from $\left\{
1,2,\ldots,k\right\}  $ to $\left\{  1,2,\ldots,\ell\right\}  $. This shows
that the sets $\left\{  1,2,\ldots,k\right\}  $ and $\left\{  1,2,\ldots
,\ell\right\}  $ have the same size; in other words, $k=\ell$. Thus, the
bijection $\sigma$ is actually a bijection from $\left\{  1,2,\ldots
,\ell\right\}  $ to $\left\{  1,2,\ldots,\ell\right\}  $. In other words,
$\sigma$ is a permutation of the set $\left\{  1,2,\ldots,\ell\right\}  $.

Finally, it is easy to see that $\left(  a_{1},a_{2},\ldots,a_{k}\right)
=\left(  b_{\sigma\left(  1\right)  },b_{\sigma\left(  2\right)  }%
,\ldots,b_{\sigma\left(  \ell\right)  }\right)  $. (Indeed, let $i\in\left\{
1,2,\ldots,k\right\}  $, and set $p=a_{i}$; then, the definition of $\sigma$
yields $\sigma\left(  i\right)  =\phi_{p}\left(  i\right)  \in B_{p}$ and
therefore $b_{\sigma\left(  i\right)  }=a_{i}$. Since this holds for each $i$,
we thus conclude that $\left(  b_{\sigma\left(  1\right)  },b_{\sigma\left(
2\right)  },\ldots,b_{\sigma\left(  k\right)  }\right)  =\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  $. Thus, $\left(  a_{1},a_{2},\ldots,a_{k}\right)
=\left(  b_{\sigma\left(  1\right)  },b_{\sigma\left(  2\right)  }%
,\ldots,b_{\sigma\left(  k\right)  }\right)  =\left(  b_{\sigma\left(
1\right)  },b_{\sigma\left(  2\right)  },\ldots,b_{\sigma\left(  \ell\right)
}\right)  $ (since $k=\ell$).) Thus, we have found a permutation $\sigma$ of
the set $\left\{  1,2,\ldots,\ell\right\}  $ such that $\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  =\left(  b_{\sigma\left(  1\right)  }%
,b_{\sigma\left(  2\right)  },\ldots,b_{\sigma\left(  \ell\right)  }\right)
$. In other words, the two tuples $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $
and $\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ are permutations of each
other. This proves Lemma \ref{lem.comb.tuples.mult=perm}.
\end{proof}
\end{fineprint}

Lemma \ref{lem.comb.tuples.mult=perm} has a converse that is much simpler:

\begin{lemma}
\label{lem.comb.tuples.mult=perm.conv}Let $P$ be a set. Let $\left(
a_{1},a_{2},\ldots,a_{k}\right)  $ and $\left(  b_{1},b_{2},\ldots,b_{\ell
}\right)  $ be two tuples of elements of $P$. Assume that these two tuples
$\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ and $\left(  b_{1},b_{2}%
,\ldots,b_{\ell}\right)  $ differ only in the order of their entries (i.e.,
are permutations of each other). Then, for each $p\in P$, we have%
\begin{align*}
&  \left(  \text{the number of times }p\text{ appears in }\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  \right) \\
&  =\left(  \text{the number of times }p\text{ appears in }\left(  b_{1}%
,b_{2},\ldots,b_{\ell}\right)  \right)  .
\end{align*}

\end{lemma}

We leave the proof of this lemma to the reader.

\subsubsection{$p$-valuations}

Now, let us come back to number theory. We first claim that a nonzero integer
$n$ can only be divisible by finitely many powers of a given prime $p$. More precisely:

\begin{lemma}
\label{lem.ent.prime.vp-wd}Let $p$ be a prime. Let $n$ be a nonzero integer.
Then, there exists a largest $m\in\mathbb{N}$ such that $p^{m}\mid n$.
\end{lemma}

The proof of this lemma will rely on a simple inequality, which we leave as an exercise:

\begin{exercise}
\label{exe.ent.prime.vp-lem}Let $p$ be an integer such that $p>1$. Prove that
$p^{k}>k$ for each $k\in\mathbb{N}$.
\end{exercise}

\begin{proof}
[Proof of Lemma \ref{lem.ent.prime.vp-wd}.]We know that $p$ is a prime. Thus,
$p$ is an integer and $p>1$ (by the definition of a \textquotedblleft
prime\textquotedblright). This is all we shall need from our assumption that
$p$ is prime.

Let $W$ be the set of all $m\in\mathbb{N}$ satisfying $p^{m}\mid n$. Then, $W$
is a set of integers. Moreover, $0$ is an $m\in\mathbb{N}$ satisfying
$p^{m}\mid n$ (since $p^{0}=1\mid n$); in other words, $0\in W$ (by the
definition of $W$). Hence, the set $W$ is nonempty.

Let $u=\left\vert n\right\vert $. Thus, $u\in\mathbb{N}$.

Exercise \ref{exe.ent.prime.vp-lem} yields that $p^{k}>k$ for each
$k\in\mathbb{N}$. Thus, each $g\in W$ satisfies $g\in\left\{  0,1,\ldots
,u-1\right\}  $\ \ \ \ \footnote{\textit{Proof.} Let $g\in W$. Thus, $g$ is an
$m\in\mathbb{N}$ satisfying $p^{m}\mid n$ (by the definition of $W$). In other
words, $g\in\mathbb{N}$ and $p^{g}\mid n$. Also, $n\neq0$ (since $n$ is
nonzero). Hence, Proposition \ref{prop.ent.div.1} \textbf{(b)} (applied to
$a=p^{g}$ and $b=n$) yields $\left\vert p^{g}\right\vert \leq\left\vert
n\right\vert =u$. But $p$ is positive (since $p>1>0$); thus, $p^{g}$ is
positive. Hence, $\left\vert p^{g}\right\vert =p^{g}$. Thus, $p^{g}=\left\vert
p^{g}\right\vert \leq u$. But recall that $p^{k}>k$ for each $k\in\mathbb{N}$.
Applying this to $k=g$, we find $p^{g}>g$. Hence, $g<p^{g}\leq u$, so that
$g\in\left\{  0,1,\ldots,u-1\right\}  $ (since $g\in\mathbb{N}$). Qed.}. In
other words, $W\subseteq\left\{  0,1,\ldots,u-1\right\}  $. Hence, the set $W$
is finite (since the set $\left\{  0,1,\ldots,u-1\right\}  $ is finite). Thus,
$W$ is a finite nonempty set of integers. Therefore, the set $W$ has a largest
element. In view of how $W$ was defined, this can be restated as follows:
There exists a largest $m\in\mathbb{N}$ such that $p^{m}\mid n$. This proves
Lemma \ref{lem.ent.prime.vp-wd}.
\end{proof}

\begin{definition}
\label{def.ent.prime.vp}Let $p$ be a prime.

\textbf{(a)} Let $n$ be a nonzero integer. Then, $v_{p}\left(  n\right)  $
shall denote the largest $m\in\mathbb{N}$ such that $p^{m}\mid n$. This is
well-defined (by Lemma \ref{lem.ent.prime.vp-wd}). This nonnegative integer
$v_{p}\left(  n\right)  $ will be called the $p$\textit{-valuation} (or the
$p$\textit{-adic valuation}) of $n$.

\textbf{(b)} We extend this definition of $v_{p}\left(  n\right)  $ to the
case of $n=0$ as follows: Set $v_{p}\left(  0\right)  =\infty$, where $\infty$
is a new symbol. This symbol $\infty$ is supposed to model \textquotedblleft
positive infinity\textquotedblright; in particular, we take it to satisfy the
following rules:

\begin{itemize}
\item We have $k+\infty=\infty+k=\infty$ for all integers $k$.

\item We have $\infty+\infty=\infty$.

\item Each integer $k$ satisfies $k<\infty$ and $\infty>k$ (and thus
$k\leq\infty$ and $\infty\geq k$).

\item No integer $k$ satisfies $k\geq\infty$ or $\infty\leq k$ (or $k>\infty$
or $\infty<k$).

\item If $S$ is a nonempty set of integers, then $\min\left(  S\cup\left\{
\infty\right\}  \right)  =\min S$ (provided that $\min S$ exists).

\item If $S$ is any set of integers, then $\max\left(  S\cup\left\{
\infty\right\}  \right)  =\infty$.
\end{itemize}

(Note, however, that $\infty$ is not supposed to be a \textquotedblleft first
class citizen\textquotedblright\ of the number system. In particular,
$\infty-\infty$ is not defined. More generally, $k-\infty$ is never defined,
whatever $k$ is. Indeed, any definition of $k-\infty$ would break some of the
familiar rules of arithmetic. The only operations that we shall subject
$\infty$ to are addition, minimum and maximum.)
\end{definition}

Note that the rules for the symbol $\infty$ yield that%
\[
k+\infty=\infty+k=\max\left\{  k,\infty\right\}  =\infty
\]
and%
\[
\min\left\{  k,\infty\right\}  =k
\]
for each $k\in\mathbb{Z}\cup\left\{  \infty\right\}  $. It is not hard to see
that basic properties of inequalities (such as \textquotedblleft if $a\leq b$
and $b\leq c$, then $a\leq c$\textquotedblright) and of addition (such as
\textquotedblleft$\left(  a+b\right)  +c=a+\left(  b+c\right)  $%
\textquotedblright) and of the interplay between inequalities and addition
(such as \textquotedblleft if $a\leq b$, then $a+c\leq b+c$\textquotedblright)
are still valid in $\mathbb{Z}\cup\left\{  \infty\right\}  $ (that is, they
still hold if we plug $\infty$ for one or more of the variables). However, of
course, we cannot \textquotedblleft cancel\textquotedblright\ $\infty$ from
equalities (i.e., we cannot cancel $\infty$ from $a+\infty=b+\infty$ to obtain
$a=b$) or inequalities.

\begin{example}
\label{exa.ent.prime.vp}\textbf{(a)} We have $v_{5}\left(  50\right)  =2$.
Indeed, $2$ is the largest $m\in\mathbb{N}$ such that $5^{m}\mid50$ (because
$5^{2}=25\mid50$ but $5^{3}=125\nmid50$).

\textbf{(b)} We have $v_{5}\left(  51\right)  =0$. Indeed, $0$ is the largest
$m\in\mathbb{N}$ such that $5^{m}\mid51$ (because $5^{0}=1\mid51$ but
$5^{1}=5\nmid51$).

\textbf{(c)} We have $v_{5}\left(  55\right)  =1$. Indeed, $1$ is the largest
$m\in\mathbb{N}$ such that $5^{m}\mid55$ (because $5^{1}=5\mid55$ but
$5^{2}=25\nmid55$).

\textbf{(d)} We have $v_{5}\left(  0\right)  =\infty$ (by Definition
\ref{def.ent.prime.vp} \textbf{(b)}).
\end{example}

Definition \ref{def.ent.prime.vp} \textbf{(a)} can be restated in the
following more intuitive way: Given a prime $p$ and a nonzero integer $n$, we
let $v_{p}\left(  n\right)  $ be the number of times we can divide $n$ by $p$
without leaving $\mathbb{Z}$. Definition \ref{def.ent.prime.vp} \textbf{(b)}
is consistent with this picture, because we can clearly divide $0$ by $p$
infinitely often without leaving $\mathbb{Z}$. From this point of view, the
following lemma should be obvious:

\begin{lemma}
\label{lem.ent.prime.vp-def}Let $p$ be a prime. Let $i\in\mathbb{N}$. Let
$n\in\mathbb{Z}$. Then, $p^{i}\mid n$ if and only if $v_{p}\left(  n\right)
\geq i$.
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.prime.vp-def}.]First, let us notice that
$p^{i}\mid0$. Also, Definition \ref{def.ent.prime.vp} \textbf{(b)} yields
$v_{p}\left(  0\right)  =\infty\geq i$ (according to our rules for the symbol
$\infty$). Hence, both statements $\left(  p^{i}\mid0\right)  $ and $\left(
v_{p}\left(  0\right)  \geq i\right)  $ hold. Thus, $p^{i}\mid0$ if and only
if $v_{p}\left(  0\right)  \geq i$. In other words, Lemma
\ref{lem.ent.prime.vp-def} holds if $n=0$. Thus, for the rest of this proof,
we WLOG assume that $n\neq0$. Hence, $n$ is nonzero. Thus, $v_{p}\left(
n\right)  $ is the largest $m\in\mathbb{N}$ such that $p^{m}\mid n$ (by
Definition \ref{def.ent.prime.vp} \textbf{(a)}). Hence, $v_{p}\left(
n\right)  $ itself is an $m\in\mathbb{N}$ such that $p^{m}\mid n$. In other
words, $v_{p}\left(  n\right)  \in\mathbb{N}$ and $p^{v_{p}\left(  n\right)
}\mid n$.

We must prove that $p^{i}\mid n$ if and only if $v_{p}\left(  n\right)  \geq
i$. Let us prove the \textquotedblleft$\Longrightarrow$\textquotedblright\ and
\textquotedblleft$\Longleftarrow$\textquotedblright\ directions of this
\textquotedblleft if and only if\textquotedblright\ statement separately:

$\Longrightarrow:$ Assume that $p^{i}\mid n$. We must prove that $v_{p}\left(
n\right)  \geq i$.

The integer $i$ is an $m\in\mathbb{N}$ such that $p^{m}\mid n$ (since
$p^{i}\mid n$). But $v_{p}\left(  n\right)  $ is the \textbf{largest} such $m$
(by Definition \ref{def.ent.prime.vp} \textbf{(a)}). Hence, $v_{p}\left(
n\right)  \geq i$. This proves the \textquotedblleft$\Longrightarrow
$\textquotedblright\ direction of Lemma \ref{lem.ent.prime.vp-def}.

$\Longleftarrow:$ Assume that $v_{p}\left(  n\right)  \geq i$. We must prove
that $p^{i}\mid n$.

We have $v_{p}\left(  n\right)  \geq i$, thus $i\leq v_{p}\left(  n\right)  $.
Hence, Exercise \ref{exe.ent.div.powers} (applied to $p$, $i$ and
$v_{p}\left(  n\right)  $ instead of $n$, $a$ and $b$) yields $p^{i}\mid
p^{v_{p}\left(  n\right)  }$. Thus, $p^{i}\mid p^{v_{p}\left(  n\right)  }\mid
n$.

Hence, we have proven $p^{i}\mid n$. This proves the \textquotedblleft%
$\Longleftarrow$\textquotedblright\ direction of Lemma
\ref{lem.ent.prime.vp-def}.
\end{proof}

\begin{corollary}
\label{cor.ent.prime.vp-0}Let $p$ be a prime. Let $n\in\mathbb{Z}$. Then,
$v_{p}\left(  n\right)  =0$ if and only if $p\nmid n$.
\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.ent.prime.vp-0}.]$\Longrightarrow:$ Assume that
$v_{p}\left(  n\right)  =0$. We must prove that $p\nmid n$.

We don't have $v_{p}\left(  n\right)  \geq1$ (since $v_{p}\left(  n\right)
=0<1$). But Lemma \ref{lem.ent.prime.vp-def} (applied to $i=1$) shows that
$p^{1}\mid n$ if and only if $v_{p}\left(  n\right)  \geq1$. Hence, we don't
have $p^{1}\mid n$ (since we don't have $v_{p}\left(  n\right)  \geq1$). In
other words, we have $p^{1}\nmid n$. In other words, $p\nmid n$ (since
$p=p^{1}$). This proves the \textquotedblleft$\Longrightarrow$%
\textquotedblright\ direction of Corollary \ref{cor.ent.prime.vp-0}.

$\Longleftarrow:$ Assume that $p\nmid n$. We must prove that $v_{p}\left(
n\right)  =0$.

We don't have $p\mid n$ (since $p\nmid n$). In other words, we don't have
$p^{1}\mid n$ (since $p^{1}=p$). But Lemma \ref{lem.ent.prime.vp-def} (applied
to $i=1$) shows that $p^{1}\mid n$ if and only if $v_{p}\left(  n\right)
\geq1$. Hence, we don't have $v_{p}\left(  n\right)  \geq1$ (since we don't
have $p^{1}\mid n$). In other words, $v_{p}\left(  n\right)  <1$.

If we had $n=0$, then we would have $p\mid0=n$, which would contradict $p\nmid
n$. Hence, we don't have $n=0$. Thus, $p$ is nonzero. Hence, Definition
\ref{def.ent.prime.vp} \textbf{(a)} shows that $v_{p}\left(  n\right)
\in\mathbb{N}$. In light of this, we can conclude $v_{p}\left(  n\right)  =0$
from $v_{p}\left(  n\right)  <1$. This proves the \textquotedblleft%
$\Longleftarrow$\textquotedblright\ direction of Corollary
\ref{cor.ent.prime.vp-0}.
\end{proof}

Here is another property of $p$-valuations that is useful in their study:

\begin{lemma}
\label{lem.ent.prime.vp-copr}Let $p$ be a prime. Let $n\in\mathbb{Z}$ be
nonzero. Then:

\textbf{(a)} There exists a nonzero integer $u$ such that $u\perp p$ and
$n=up^{v_{p}\left(  n\right)  }$.

\textbf{(b)} If $i\in\mathbb{N}$ and $w\in\mathbb{Z}$ are such that $w\perp p$
and $n=wp^{i}$, then $v_{p}\left(  n\right)  =i$.
\end{lemma}

Before we prove this formally, let us show the idea behind this lemma. Recall
that, given a prime $p$ and a nonzero integer $n$, the number $v_{p}\left(
n\right)  $ counts how often we can divide $n$ by $p$ without leaving
$\mathbb{Z}$. What happens after we have divided $n$ by $p$ this many times?
We get a number $u$ that is still an integer, but is no longer divisible by
$p$, and thus must be coprime to $p$ (by Proposition
\ref{prop.ent.prime.div-or-coprime}). This is what Lemma
\ref{lem.ent.prime.vp-copr} \textbf{(a)} says. Lemma
\ref{lem.ent.prime.vp-copr} \textbf{(b)} is a converse statement: It says that
if we divide $n$ by $p$ some number of times (say, $i$ times) and obtain an
integer coprime to $p$, then $i$ must be $v_{p}\left(  n\right)  $.

\begin{proof}
[Proof of Lemma \ref{lem.ent.prime.vp-copr}.]Definition \ref{def.ent.prime.vp}
\textbf{(a)} shows that $v_{p}\left(  n\right)  $ is the largest
$m\in\mathbb{N}$ such that $p^{m}\mid n$. Hence, $v_{p}\left(  n\right)  $
itself is an $m\in\mathbb{N}$ such that $p^{m}\mid n$. In other words,
$v_{p}\left(  n\right)  \in\mathbb{N}$ and $p^{v_{p}\left(  n\right)  }\mid n$.

Thus, in particular, $p^{v_{p}\left(  n\right)  }\mid n$. In other words,
there exists an integer $c$ such that $n=p^{v_{p}\left(  n\right)  }c$.
Consider this $c$. We have $n=p^{v_{p}\left(  n\right)  }c=cp^{v_{p}\left(
n\right)  }$.

Assume (for the sake of contradiction) that $p\mid c$. Thus, there exists an
integer $d$ such that $c=pd$. Consider this $d$. Now,%
\[
n=p^{v_{p}\left(  n\right)  }\underbrace{c}_{=pd}=\underbrace{p^{v_{p}\left(
n\right)  }p}_{=p^{v_{p}\left(  n\right)  +1}}d=p^{v_{p}\left(  n\right)
+1}d.
\]
Hence, $p^{v_{p}\left(  n\right)  +1}\mid n$ (since $d$ is an integer). In
other words, $v_{p}\left(  n\right)  +1$ is an $m\in\mathbb{N}$ such that
$p^{m}\mid n$. But we know that $v_{p}\left(  n\right)  $ is the
\textbf{largest} such $m$ (by Definition \ref{def.ent.prime.vp} \textbf{(a)}).
Hence, we conclude that $v_{p}\left(  n\right)  \geq v_{p}\left(  n\right)
+1$. But this is clearly absurd. This contradiction shows that our assumption
(that $p\mid c$) was wrong. Hence, we do not have $p\mid c$.

But Proposition \ref{prop.ent.prime.div-or-coprime} (applied to $a=c$) shows
that either $p\mid c$ or $p\perp c$. Hence, $p\perp c$ (since we do not have
$p\mid c$). In other words, $c\perp p$ (because of Proposition
\ref{prop.ent.coprime.perp-symm}).

If we had $c=0$, then we would have $n=p^{v_{p}\left(  n\right)
}\underbrace{c}_{=0}=0$, which would contradict the fact that $n$ is nonzero.
Hence, we cannot have $c=0$. Thus, $c$ is nonzero.

Now, we know that $c$ is a nonzero integer satisfying $c\perp p$ and
$n=cp^{v_{p}\left(  n\right)  }$. Hence, there exists a nonzero integer $u$
such that $u\perp p$ and $n=up^{v_{p}\left(  n\right)  }$ (namely, $u=c$).
This proves Lemma \ref{lem.ent.prime.vp-copr} \textbf{(a)}.

\textbf{(b)} Let $i\in\mathbb{N}$ and $w\in\mathbb{Z}$ be such that $w\perp p$
and $n=wp^{i}$. We must prove that $v_{p}\left(  n\right)  =i$.

From $w\perp p$, we obtain $p\perp w$ (by Proposition
\ref{prop.ent.coprime.perp-symm}). In other words, $\gcd\left(  p,w\right)
=1$.

We have $n=wp^{i}=p^{i}w$ and thus $p^{i}\mid n$ (since $w$ is an integer).
But Lemma \ref{lem.ent.prime.vp-def} yields that $p^{i}\mid n$ if and only if
$v_{p}\left(  n\right)  \geq i$. Hence, we have $v_{p}\left(  n\right)  \geq
i$ (since we have $p^{i}\mid n$).

Now, we shall prove that $v_{p}\left(  n\right)  \leq i$. Indeed, assume the
contrary. Thus, $v_{p}\left(  n\right)  >i$, so that $v_{p}\left(  n\right)
\geq i+1$ (since $v_{p}\left(  n\right)  $ and $i$ are integers). But Lemma
\ref{lem.ent.prime.vp-def} (applied to $i+1$ instead of $i$) shows that
$p^{i+1}\mid n$ if and only if $v_{p}\left(  n\right)  \geq i+1$. Thus, we
have $p^{i+1}\mid n$ (since we have $v_{p}\left(  n\right)  \geq i+1$). In
other words, $pp^{i}\mid wp^{i}$ (since $p^{i+1}=pp^{i}$ and $n=wp^{i}$). But
$p$ is a prime; thus, $p>1>0$ and therefore $p\neq0$. Hence, $p^{i}\neq0$.
Thus, Exercise \ref{exe.ent.div.acbc} (applied to $p$, $w$ and $p^{i}$ instead
of $a$, $b$ and $c$) shows that $p\mid w$ holds if and only if $pp^{i}\mid
wp^{i}$. Hence, $p\mid w$ holds (since $pp^{i}\mid wp^{i}$ holds). Thus,
Proposition \ref{prop.ent.gcd.props1} \textbf{(i)} (applied to $p$ and $w$
instead of $a$ and $b$) yields $\gcd\left(  p,w\right)  =\left\vert
p\right\vert =p$ (since $p>0$). Comparing this with $\gcd\left(  p,w\right)
=1$, we find $p=1$. This contradicts $p>1$.

This contradiction shows that our assumption was false. Hence, $v_{p}\left(
n\right)  \leq i$ is proven. Combining this with $v_{p}\left(  n\right)  \geq
i$, we obtain $v_{p}\left(  n\right)  =i$. This proves Lemma
\ref{lem.ent.prime.vp-copr} \textbf{(b)}.
\end{proof}

The next property of $p$-adic valuations is crucial, as it reveals how they
can be computed and bounded:

\begin{theorem}
\label{thm.ent.prime.vp-ring}Let $p$ be a prime.

\textbf{(a)} We have $v_{p}\left(  ab\right)  =v_{p}\left(  a\right)
+v_{p}\left(  b\right)  $ for any two integers $a$ and $b$.

\textbf{(b)} We have $v_{p}\left(  a+b\right)  \geq\min\left\{  v_{p}\left(
a\right)  ,v_{p}\left(  b\right)  \right\}  $ for any two integers $a$ and $b$.

\textbf{(c)} We have $v_{p}\left(  1\right)  =0$.

\textbf{(d)} We have $v_{p}\left(  q\right)  =%
\begin{cases}
1, & \text{if }q=p;\\
0, & \text{if }q\neq p
\end{cases}
$ for any prime $q$.
\end{theorem}

Note that Theorem \ref{thm.ent.prime.vp-ring} \textbf{(a)} gives a formula for
$v_{p}\left(  ab\right)  $ in terms of $v_{p}\left(  a\right)  $ and
$v_{p}\left(  b\right)  $, but there is no such formula for $v_{p}\left(
a+b\right)  $ (since $v_{p}\left(  a\right)  $ and $v_{p}\left(  b\right)  $
do not uniquely determine $v_{p}\left(  a+b\right)  $). Thus, Theorem
\ref{thm.ent.prime.vp-ring} \textbf{(b)} only gives a bound.

\begin{proof}
[Proof of Theorem \ref{thm.ent.prime.vp-ring}.]\textbf{(a)} Let $a$ and $b$ be
two integers. We must prove that $v_{p}\left(  ab\right)  =v_{p}\left(
a\right)  +v_{p}\left(  b\right)  $.

If $a=0$, then this is true\footnote{\textit{Proof.} Assume that $a=0$. Then,
$\underbrace{a}_{=0}b=0$ and thus $v_{p}\left(  ab\right)  =v_{p}\left(
0\right)  =\infty$ (by Definition \ref{def.ent.prime.vp} \textbf{(b)}). Also,
from $a=0$, we obtain $v_{p}\left(  a\right)  =v_{p}\left(  0\right)  =\infty
$. Hence, $\underbrace{v_{p}\left(  a\right)  }_{=\infty}+v_{p}\left(
b\right)  =\infty+v_{p}\left(  b\right)  =\infty$ (since $\infty+k=\infty$ for
each $k\in\mathbb{Z}\cup\left\{  \infty\right\}  $). Comparing this with
$v_{p}\left(  ab\right)  =\infty$, we obtain $v_{p}\left(  ab\right)
=v_{p}\left(  a\right)  +v_{p}\left(  b\right)  $. This is exactly what we
wanted to prove.}. Thus, for the rest of the proof of Theorem
\ref{thm.ent.prime.vp-ring} \textbf{(a)}, we WLOG assume that $a\neq0$. For
similar reasons, we WLOG assume that $b\neq0$.

The integer $a$ is nonzero (since $a\neq0$). Thus, Lemma
\ref{lem.ent.prime.vp-copr} \textbf{(b)} (applied to $n=a$) shows that there
exists a nonzero integer $u$ such that $u\perp p$ and $a=up^{v_{p}\left(
a\right)  }$. Consider this $u$, and denote it by $x$. Thus, $x$ is a nonzero
integer such that $x\perp p$ and $a=xp^{v_{p}\left(  a\right)  }$.

The integer $b$ is nonzero (since $b\neq0$). Thus, Lemma
\ref{lem.ent.prime.vp-copr} \textbf{(a)} (applied to $n=b$) shows that there
exists a nonzero integer $u$ such that $u\perp p$ and $b=up^{v_{p}\left(
b\right)  }$. Consider this $u$, and denote it by $y$. Thus, $y$ is a nonzero
integer such that $y\perp p$ and $b=yp^{v_{p}\left(  b\right)  }$.

We have $x\perp p$ and $y\perp p$. Thus, Theorem \ref{thm.ent.coprime.ab-to-c}
(applied to $x$, $y$ and $p$ instead of $a$, $b$ and $c$) shows that $xy\perp
p$.

The integer $ab$ is nonzero (since $a\neq0$ and $b\neq0$).

Furthermore, multiplying the equalities $a=xp^{v_{p}\left(  a\right)  }$ and
$b=yp^{v_{p}\left(  b\right)  }$, we obtain%
\[
ab=\left(  xp^{v_{p}\left(  a\right)  }\right)  \left(  yp^{v_{p}\left(
b\right)  }\right)  =\left(  xy\right)  \underbrace{\left(  p^{v_{p}\left(
a\right)  }p^{v_{p}\left(  b\right)  }\right)  }_{=p^{v_{p}\left(  a\right)
+v_{p}\left(  b\right)  }}=\left(  xy\right)  p^{v_{p}\left(  a\right)
+v_{p}\left(  b\right)  }.
\]
Thus, Lemma \ref{lem.ent.prime.vp-copr} \textbf{(b)} (applied to $n=ab$,
$i=v_{p}\left(  a\right)  +v_{p}\left(  b\right)  $ and $w=xy$) shows that
$v_{p}\left(  ab\right)  =v_{p}\left(  a\right)  +v_{p}\left(  b\right)  $
(since $v_{p}\left(  a\right)  +v_{p}\left(  b\right)  \in\mathbb{N}$ and
$xy\in\mathbb{Z}$ and $xy\perp p$). This proves Theorem
\ref{thm.ent.prime.vp-ring} \textbf{(a)}.

\textbf{(b)} Let $a$ and $b$ be two integers. We must prove that $v_{p}\left(
a+b\right)  \geq\min\left\{  v_{p}\left(  a\right)  ,v_{p}\left(  b\right)
\right\}  $.

If $a=0$, then this is true\footnote{\textit{Proof.} Assume that $a=0$. Then,
$v_{p}\left(  \underbrace{a}_{=0}+b\right)  =v_{p}\left(  b\right)  \geq
\min\left\{  v_{p}\left(  a\right)  ,v_{p}\left(  b\right)  \right\}  $ (since
any element of a set is $\geq$ to the minimum of this set). This is exactly
what we wanted to prove.}. Thus, for the rest of the proof of Theorem
\ref{thm.ent.prime.vp-ring} \textbf{(b)}, we WLOG assume that $a\neq0$. For
similar reasons, we WLOG assume that $b\neq0$.

The integer $a$ is nonzero (since $a\neq0$). Thus, $v_{p}\left(  a\right)
\in\mathbb{N}$ (by Definition \ref{def.ent.prime.vp} \textbf{(a)}). Similarly,
$v_{p}\left(  b\right)  \in\mathbb{N}$.

Let $m=\min\left\{  v_{p}\left(  a\right)  ,v_{p}\left(  b\right)  \right\}
$. Thus, $m\in\mathbb{N}$ (since $v_{p}\left(  a\right)  \in\mathbb{N}$ and
$v_{p}\left(  b\right)  \in\mathbb{N}$).

We have $m=\min\left\{  v_{p}\left(  a\right)  ,v_{p}\left(  b\right)
\right\}  \leq v_{p}\left(  a\right)  $; in other words, $v_{p}\left(
a\right)  \geq m$. But Lemma \ref{lem.ent.prime.vp-def} (applied to $n=a$ and
$i=m$) shows that $p^{m}\mid a$ if and only if $v_{p}\left(  a\right)  \geq
m$. Hence, we have $p^{m}\mid a$ (since $v_{p}\left(  a\right)  \geq m$). In
other words, $a\equiv0\operatorname{mod}p^{m}$. Similarly, $b\equiv
0\operatorname{mod}p^{m}$. Adding these two congruences together, we obtain
$a+b\equiv0+0=0\operatorname{mod}p^{m}$. In other words, $p^{m}\mid a+b$.

But Lemma \ref{lem.ent.prime.vp-def} (applied to $n=a+b$ and $i=m$) shows that
$p^{m}\mid a+b$ if and only if $v_{p}\left(  a+b\right)  \geq m$. Hence, we
have $v_{p}\left(  a+b\right)  \geq m$ (since $p^{m}\mid a+b$). Thus,
$v_{p}\left(  a+b\right)  \geq m=\min\left\{  v_{p}\left(  a\right)
,v_{p}\left(  b\right)  \right\}  $. This proves Theorem
\ref{thm.ent.prime.vp-ring} \textbf{(b)}.

\textbf{(c)} Exercise \ref{exe.ent.coprime.01} \textbf{(a)} (applied to $a=p$)
yields $1\perp p$. Also, $1=1\cdot p^{0}$. Thus, Lemma
\ref{lem.ent.prime.vp-copr} \textbf{(b)} (applied to $n=1$, $i=0$ and $w=1$)
yields $v_{p}\left(  1\right)  =0$. This proves Theorem
\ref{thm.ent.prime.vp-ring} \textbf{(c)}.

\textbf{(d)} Let $q$ be a prime. We must prove that $v_{p}\left(  q\right)  =%
\begin{cases}
1, & \text{if }q=p;\\
0, & \text{if }q\neq p
\end{cases}
$.

We are in one of the following two cases:

\textit{Case 1:} We have $q=p$.

\textit{Case 2:} We have $q\neq p$.

Let us first consider Case 1. In this case, we have $q=p$. But Exercise
\ref{exe.ent.coprime.01} \textbf{(a)} (applied to $a=p$) yields $1\perp p$.
Also, $p=1\cdot p^{1}$. Thus, Lemma \ref{lem.ent.prime.vp-copr} \textbf{(b)}
(applied to $n=p$, $i=1$ and $w=1$) yields $v_{p}\left(  p\right)  =1$. From
$q=p$, we obtain $v_{p}\left(  q\right)  =v_{p}\left(  p\right)  =1$.
Comparing this with
\[%
\begin{cases}
1, & \text{if }q=p;\\
0, & \text{if }q\neq p
\end{cases}
=1\ \ \ \ \ \ \ \ \ \ \left(  \text{since }q=p\right)  ,
\]
we obtain $v_{p}\left(  q\right)  =%
\begin{cases}
1, & \text{if }q=p;\\
0, & \text{if }q\neq p
\end{cases}
$. Hence, Theorem \ref{thm.ent.prime.vp-ring} \textbf{(d)} is proven in Case 1.

Let us now consider Case 2. In this case, we have $q\neq p$. Thus, the primes
$q$ and $p$ are distinct. Hence, Exercise \ref{exe.ent.prime.dist=cop}
(applied to $q$ and $p$ instead of $p$ and $q$) yields $q\perp p$. Also,
$q=q\cdot p^{0}$ (since $p^{0}=1$). Thus, Lemma \ref{lem.ent.prime.vp-copr}
\textbf{(b)} (applied to $n=q$, $i=0$ and $w=q$) yields $v_{p}\left(
q\right)  =0$. Comparing this with
\[%
\begin{cases}
1, & \text{if }q=p;\\
0, & \text{if }q\neq p
\end{cases}
=0\ \ \ \ \ \ \ \ \ \ \left(  \text{since }q\neq p\right)  ,
\]
we obtain $v_{p}\left(  q\right)  =%
\begin{cases}
1, & \text{if }q=p;\\
0, & \text{if }q\neq p
\end{cases}
$. Hence, Theorem \ref{thm.ent.prime.vp-ring} \textbf{(d)} is proven in Case 2.

We have now proven Theorem \ref{thm.ent.prime.vp-ring} \textbf{(d)} in each of
the two Cases 1 and 2. Thus, Theorem \ref{thm.ent.prime.vp-ring} \textbf{(d)}
is always proven.
\end{proof}

\begin{corollary}
\label{cor.ent.prime.vp-ringk}Let $p$ be a prime. Let $a_{1},a_{2}%
,\ldots,a_{k}$ be $k$ integers. Then, $v_{p}\left(  a_{1}a_{2}\cdots
a_{k}\right)  =v_{p}\left(  a_{1}\right)  +v_{p}\left(  a_{2}\right)
+\cdots+v_{p}\left(  a_{k}\right)  $.
\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.ent.prime.vp-ringk}.]This follows
straightforwardly by induction on $k$, using Theorem
\ref{thm.ent.prime.vp-ring} \textbf{(a)} (as well as Theorem
\ref{thm.ent.prime.vp-ring} \textbf{(c)} for the induction base). We leave the
details to the reader, who has seen this sort of proof several times already.
\end{proof}

\begin{exercise}
\label{exe.ent.prime.vp-abs}Let $p$ be a prime. Let $n\in\mathbb{Z}$. Prove
that $v_{p}\left(  \left\vert n\right\vert \right)  =v_{p}\left(  n\right)  $.
\end{exercise}

\begin{exercise}
\label{exe.ent.prime.vp-pow}Let $p$ be a prime. Let $a\in\mathbb{Z}$ and
$k\in\mathbb{N}$. Prove that $v_{p}\left(  a^{k}\right)  =kv_{p}\left(
a\right)  $.
\end{exercise}

\begin{exercise}
\label{exe.ent.prime.p1a1puau}Let $p_{1},p_{2},\ldots,p_{u}$ be finitely many
distinct primes. Let $a_{1},a_{2},\ldots,a_{u}$ be nonnegative integers.

\textbf{(a)} Prove that $v_{p_{i}}\left(  p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots
p_{u}^{a_{u}}\right)  =a_{i}$ for each $i\in\left\{  1,2,\ldots,u\right\}  $.

\textbf{(b)} Prove that $v_{p}\left(  p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots
p_{u}^{a_{u}}\right)  =0$ for each prime $p$ satisfying $p\notin\left\{
p_{1},p_{2},\ldots,p_{u}\right\}  $.
\end{exercise}

\subsubsection{Prime factorization II}

\begin{proposition}
\label{prop.ent.prime.mult-in-pf}Let $n$ be a positive integer. Let $\left(
a_{1},a_{2},\ldots,a_{k}\right)  $ be a prime factorization of $n$. Let $p$ be
a prime. Then,%
\begin{align*}
&  \left(  \text{the number of times }p\text{ appears in the tuple }\left(
a_{1},a_{2},\ldots,a_{k}\right)  \right) \\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,k\right\}  \text{
such that }a_{i}=p\right) \\
&  =v_{p}\left(  n\right)  .
\end{align*}

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.mult-in-pf}.]We have assumed that
$\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ is a prime factorization of $n$.
Thus, $a_{1},a_{2},\ldots,a_{k}$ are primes satisfying $n=a_{1}a_{2}\cdots
a_{k}$. Hence, for each $i\in\left\{  1,2,\ldots,k\right\}  $, the integer
$a_{i}$ is prime and thus satisfies%
\begin{equation}
v_{p}\left(  a_{i}\right)  =%
\begin{cases}
1, & \text{if }a_{i}=p;\\
0, & \text{if }a_{i}\neq p
\end{cases}
\label{pf.prop.ent.prime.mult-in-pf.1}%
\end{equation}
(by Theorem \ref{thm.ent.prime.vp-ring} \textbf{(d)}, applied to $q=a_{i}$).

From $n=a_{1}a_{2}\cdots a_{k}$, we obtain%
\begin{align*}
v_{p}\left(  n\right)   &  =v_{p}\left(  a_{1}a_{2}\cdots a_{k}\right) \\
&  =v_{p}\left(  a_{1}\right)  +v_{p}\left(  a_{2}\right)  +\cdots
+v_{p}\left(  a_{k}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Corollary
\ref{cor.ent.prime.vp-ringk}}\right) \\
&  =\underbrace{\sum_{i=1}^{k}}_{=\sum_{i\in\left\{  1,2,\ldots,k\right\}  }%
}\underbrace{v_{p}\left(  a_{i}\right)  }_{\substack{=%
\begin{cases}
1, & \text{if }a_{i}=p;\\
0, & \text{if }a_{i}\neq p
\end{cases}
\\\text{(by (\ref{pf.prop.ent.prime.mult-in-pf.1}))}}}=\sum_{i\in\left\{
1,2,\ldots,k\right\}  }%
\begin{cases}
1, & \text{if }a_{i}=p;\\
0, & \text{if }a_{i}\neq p
\end{cases}
\\
&  =\sum_{\substack{i\in\left\{  1,2,\ldots,k\right\}  ;\\a_{i}=p}%
}\underbrace{%
\begin{cases}
1, & \text{if }a_{i}=p;\\
0, & \text{if }a_{i}\neq p
\end{cases}
}_{\substack{=1\\\text{(since }a_{i}=p\text{)}}}+\sum_{\substack{i\in\left\{
1,2,\ldots,k\right\}  ;\\a_{i}\neq p}}\underbrace{%
\begin{cases}
1, & \text{if }a_{i}=p;\\
0, & \text{if }a_{i}\neq p
\end{cases}
}_{\substack{=0\\\text{(since }a_{i}\neq p\text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since each }i\in\left\{  1,2,\ldots,k\right\}  \text{ satisfies either
}a_{i}=p\text{ or }a_{i}\neq p\\
\text{(but not both)}%
\end{array}
\right) \\
&  =\sum_{\substack{i\in\left\{  1,2,\ldots,k\right\}  ;\\a_{i}=p}%
}1+\underbrace{\sum_{\substack{i\in\left\{  1,2,\ldots,k\right\}  ;\\a_{i}\neq
p}}0}_{=0}=\sum_{\substack{i\in\left\{  1,2,\ldots,k\right\}  ;\\a_{i}=p}}1\\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,k\right\}  \text{
such that }a_{i}=p\right)  \cdot1\\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,k\right\}  \text{
such that }a_{i}=p\right) \\
&  =\left(  \text{the number of times }p\text{ appears in }\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  \right)  .
\end{align*}
This proves Proposition \ref{prop.ent.prime.mult-in-pf}.
\end{proof}

We are finally ready to prove the so-called \textit{Fundamental Theorem of
Arithmetic}:

\begin{theorem}
\label{thm.ent.prime.fac-uni}Let $n$ be a positive integer.

\textbf{(a)} There exists a prime factorization of $n$.

\textbf{(b)} Any two such factorizations differ only in the order of their
entries (i.e., are permutations of each other).
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.prime.fac-uni}.]\textbf{(a)} Proposition
\ref{prop.ent.prime.fac-ex} shows that $n$ can be written as a product of
finitely many primes. In other words, there exist finitely many primes
$p_{1},p_{2},\ldots,p_{k}$ such that $n=p_{1}p_{2}\cdots p_{k}$. Consider
these primes. Thus, $\left(  p_{1},p_{2},\ldots,p_{k}\right)  $ is a prime
factorization of $n$ (by the definition of \textquotedblleft prime
factorization\textquotedblright). Hence, there exists a prime factorization of
$n$. This proves Theorem \ref{thm.ent.prime.fac-uni} \textbf{(a)}.

\textbf{(b)} Let $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ and $\left(
b_{1},b_{2},\ldots,b_{\ell}\right)  $ be two prime factorizations of $n$. We
must prove that $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ and $\left(
b_{1},b_{2},\ldots,b_{\ell}\right)  $ differ only in the order of their
entries (i.e., are permutations of each other).

Let $P$ be the set of all primes. Note that $\left(  a_{1},a_{2},\ldots
,a_{k}\right)  $ and $\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ are prime
factorizations of $n$. Hence, $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ and
$\left(  b_{1},b_{2},\ldots,b_{\ell}\right)  $ are tuples of primes, i.e.,
tuples of elements of $P$.

Let $p\in P$. Thus, $p$ is a prime (by the definition of $P$). Hence,
Proposition \ref{prop.ent.prime.mult-in-pf} shows that%
\begin{align*}
&  \left(  \text{the number of times }p\text{ appears in the tuple }\left(
a_{1},a_{2},\ldots,a_{k}\right)  \right) \\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,k\right\}  \text{
such that }a_{i}=p\right) \\
&  =v_{p}\left(  n\right)  .
\end{align*}
Similarly,%
\begin{align*}
&  \left(  \text{the number of times }p\text{ appears in the tuple }\left(
b_{1},b_{2},\ldots,b_{\ell}\right)  \right) \\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,\ell\right\}  \text{
such that }b_{i}=p\right) \\
&  =v_{p}\left(  n\right)  .
\end{align*}
Comparing these two equalities, we conclude that
\begin{align}
&  \left(  \text{the number of times }p\text{ appears in }\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  \right) \nonumber\\
&  =\left(  \text{the number of times }p\text{ appears in }\left(  b_{1}%
,b_{2},\ldots,b_{\ell}\right)  \right)  . \label{pf.thm.ent.prime.fac-uni.b.1}%
\end{align}


Now, forget that we fixed $p$. We thus have proven
(\ref{pf.thm.ent.prime.fac-uni.b.1}) for each $p\in P$. Hence, Lemma
\ref{lem.comb.tuples.mult=perm} shows that the tuples $\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  $ and $\left(  b_{1},b_{2},\ldots,b_{\ell}\right)
$ differ only in the order of their entries (i.e., are permutations of each
other). This completes our proof of Theorem \ref{thm.ent.prime.fac-uni}
\textbf{(b)}.
\end{proof}

\subsubsection{The canonical factorization}

You have seen finite products such as\footnote{Here and in the following, $n!$
denotes the product $1\cdot2\cdot\cdots\cdot n$ whenever $n\in\mathbb{N}$.
Thus, in particular,
\begin{align*}
0!  &  =\left(  \text{empty product}\right)
=1,\ \ \ \ \ \ \ \ \ \ 1!=1,\ \ \ \ \ \ \ \ \ \ 2!=1\cdot2=2,\\
3!  &  =1\cdot2\cdot3=6,\ \ \ \ \ \ \ \ \ \ 4!=1\cdot2\cdot3\cdot
4=24,\ \ \ \ \ \ \ \ \ \ 5!=1\cdot2\cdot3\cdot4\cdot5=120.
\end{align*}
}
\begin{align*}
\prod_{i\in\left\{  1,2,3,4,5\right\}  }i  &  =1\cdot2\cdot3\cdot
4\cdot5=5!=120\ \ \ \ \ \ \ \ \ \ \text{and}\\
\prod_{i\in\left\{  3,5,7\right\}  }\left(  i^{2}+1\right)   &  =\left(
3^{2}+1\right)  \cdot\left(  5^{2}+1\right)  \cdot\left(  7^{2}+1\right)
=13000.
\end{align*}
Sometimes, infinite products (i.e., products ranging over infinite sets) also
make sense. Many examples of well-defined infinite products arise from
analysis and have to do with convergence. Here, we are doing algebra and thus
shall only consider a very elementary, non-analytic meaning of convergence.
Namely, we will consider infinite products that have only finitely many
factors different from $1$. For example, the product $2\cdot7\cdot
4\cdot\underbrace{1\cdot1\cdot1\cdot1\cdot\cdots}_{\text{infinitely many
}1\text{'s}}$ is of such form. It is easy to give a meaning to such products:
Just throw away all the $1$'s (since multiplying by $1$ does not change a
number) and take the product of the remaining (finitely many) numbers. So, for
example, our product $2\cdot7\cdot4\cdot\underbrace{1\cdot1\cdot1\cdot
1\cdot\cdots}_{\text{infinitely many }1\text{'s}}$ should evaluate to
$2\cdot7\cdot4=56$.

This is indeed a meaningful and useful definition. For example, the set of all
prime numbers is infinite (by Theorem \ref{thm.ent.prime.infin} below), but
nevertheless, for each nonzero integer $n$, the product $\prod_{p\text{
prime}}p^{v_{p}\left(  n\right)  }$ (where the \textquotedblleft%
$\prod_{p\text{ prime}}$\textquotedblright\ symbol means a product ranging
over all primes $p$) is well-defined due to having only finitely many factors
different from $1$:

\begin{lemma}
\label{lem.ent.prime.vpn=0}Let $n$ be a nonzero integer.

\textbf{(a)} We have $v_{p}\left(  n\right)  =0$ for every prime $p>\left\vert
n\right\vert $. (Note that \textquotedblleft for every prime $p>\left\vert
n\right\vert $\textquotedblright\ is shorthand for \textquotedblleft for every
prime $p$ satisfying $p>\left\vert n\right\vert $\textquotedblright.)

\textbf{(b)} The product $\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }$
has only finitely many factors different from $1$. (Here and in the following,
the \textquotedblleft$\prod_{p\text{ prime}}$\textquotedblright\ symbol means
a product ranging over all primes $p$.)
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.prime.vpn=0}.]\textbf{(a)} Let $p$ be a prime
such that $p>\left\vert n\right\vert $. We must prove that $v_{p}\left(
n\right)  =0$.

We have $p>1$ (since $p$ is prime); thus, $p>1>0$ and therefore $\left\vert
p\right\vert =p>\left\vert n\right\vert $.

We have $n\neq0$ (since $n$ is nonzero). Thus, if we had $p\mid n$, then we
would have $\left\vert p\right\vert \leq\left\vert n\right\vert $ (by
Proposition \ref{prop.ent.div.1} \textbf{(b)}, applied to $a=p$ and $b=n$),
which would contradict $\left\vert p\right\vert >\left\vert n\right\vert $.
Thus, we cannot have $p\mid n$. In other words, we have $p\nmid n$.

But Corollary \ref{cor.ent.prime.vp-0} yields that $v_{p}\left(  n\right)  =0$
if and only if $p\nmid n$. Hence, $v_{p}\left(  n\right)  =0$ (since $p\nmid
n$). This proves Lemma \ref{lem.ent.prime.vpn=0} \textbf{(a)}.

\textbf{(b)} For every prime $p>\left\vert n\right\vert $, we have
$v_{p}\left(  n\right)  =0$ (by Lemma \ref{lem.ent.prime.vpn=0} \textbf{(a)})
and thus $p^{v_{p}\left(  n\right)  }=p^{0}=1$. Thus, all but finitely many
primes $p$ satisfy $p^{v_{p}\left(  n\right)  }=1$ (since all but finitely
many primes $p$ satisfy $p>\left\vert n\right\vert $). Therefore, all but
finitely many factors of the product $\prod_{p\text{ prime}}p^{v_{p}\left(
n\right)  }$ are $1$. In other words, the product $\prod_{p\text{ prime}%
}p^{v_{p}\left(  n\right)  }$ has only finitely many factors different from
$1$. This proves Lemma \ref{lem.ent.prime.vpn=0} \textbf{(b)}.
\end{proof}

\begin{corollary}
\label{cor.ent.prime.can-fac}Let $n$ be a positive integer. Then,%
\[
n=\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }.
\]


Here, the infinite product $\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }$
is well-defined (according to Lemma \ref{lem.ent.prime.vpn=0} \textbf{(b)}).
\end{corollary}

This expression $n=\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }$ is
called the \textit{canonical factorization} of $n$.

\begin{proof}
[Proof of Corollary \ref{cor.ent.prime.can-fac}.]Theorem
\ref{thm.ent.prime.fac-uni} \textbf{(a)} shows that there exists a prime
factorization of $n$. Consider such a factorization, and denote it by $\left(
a_{1},a_{2},\ldots,a_{k}\right)  $. Thus, $\left(  a_{1},a_{2},\ldots
,a_{k}\right)  $ is a prime factorization of $n$; in other words, $a_{1}%
,a_{2},\ldots,a_{k}$ are primes satisfying $n=a_{1}a_{2}\cdots a_{k}$. For
each prime $p$, we have%
\begin{equation}
\left(  \text{the number of }i\in\left\{  1,2,\ldots,k\right\}  \text{ such
that }a_{i}=p\right)  =v_{p}\left(  n\right)
\label{pf.cor.ent.prime.can-fac.1}%
\end{equation}
(by Proposition \ref{prop.ent.prime.mult-in-pf}). Now,%
\begin{align*}
n  &  =a_{1}a_{2}\cdots a_{k}=\prod_{i\in\left\{  1,2,\ldots,k\right\}  }%
a_{i}\\
&  =\prod_{p\text{ prime}}\prod_{\substack{i\in\left\{  1,2,\ldots,k\right\}
;\\a_{i}=p}}\underbrace{a_{i}}_{=p}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we have split our product into smaller}\\
\text{products, according to the value of }a_{i}\text{;}\\
\text{this is allowed, since each }a_{i}\text{ is a prime}%
\end{array}
\right) \\
&  =\prod_{p\text{ prime}}\underbrace{\prod_{\substack{i\in\left\{
1,2,\ldots,k\right\}  ;\\a_{i}=p}}p}_{=p^{\left(  \text{the number of }%
i\in\left\{  1,2,\ldots,k\right\}  \text{ such that }a_{i}=p\right)  }}\\
&  =\prod_{p\text{ prime}}\underbrace{p^{\left(  \text{the number of }%
i\in\left\{  1,2,\ldots,k\right\}  \text{ such that }a_{i}=p\right)  }%
}_{\substack{=p^{v_{p}\left(  n\right)  }\\\text{(by
(\ref{pf.cor.ent.prime.can-fac.1}))}}}\\
&  =\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }.
\end{align*}
This proves Corollary \ref{cor.ent.prime.can-fac}.
\end{proof}

The next exercise says that a nonnegative integer $n$ is uniquely determined
by the family $\left(  v_{p}\left(  n\right)  \right)  _{p\text{ prime}}$ of
its $p$-valuations for all primes $p$:

\begin{exercise}
\label{exe.ent.prime.vp=vp}Let $n$ and $m$ be two nonnegative integers. Assume
that
\begin{equation}
v_{p}\left(  n\right)  =v_{p}\left(  m\right)  \ \ \ \ \ \ \ \ \ \ \text{for
every prime }p. \label{eq.exe.ent.prime.vp=vp.ass}%
\end{equation}
Prove that $n=m$.
\end{exercise}

\begin{corollary}
\label{cor.ent.prime.can-facZ}Let $n$ be a nonzero integer. Then,%
\[
\left\vert n\right\vert =\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }.
\]


Here, the infinite product $\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }$
is well-defined (according to Lemma \ref{lem.ent.prime.vpn=0} \textbf{(b)}).
\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.ent.prime.can-facZ}.]The integer $\left\vert
n\right\vert $ is positive (since $n$ is nonzero). Hence, Corollary
\ref{cor.ent.prime.can-fac} (applied to $\left\vert n\right\vert $ instead of
$n$) yields%
\[
\left\vert n\right\vert =\prod_{p\text{ prime}}\underbrace{p^{v_{p}\left(
\left\vert n\right\vert \right)  }}_{\substack{=p^{v_{p}\left(  n\right)
}\\\text{(since Exercise \ref{exe.ent.prime.vp-abs}}\\\text{yields }%
v_{p}\left(  \left\vert n\right\vert \right)  =v_{p}\left(  n\right)
\text{)}}}=\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }.
\]
This proves Corollary \ref{cor.ent.prime.can-facZ}.
\end{proof}

We can furthermore use $p$-adic valuations to check divisibility of integers:

\begin{proposition}
\label{prop.ent.prime.n|m}Let $n$ and $m$ be integers. Then, $n\mid m$ if and
only if each prime $p$ satisfies $v_{p}\left(  n\right)  \leq v_{p}\left(
m\right)  $.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.n|m}.]If $m=0$, then Proposition
\ref{prop.ent.prime.n|m} is true\footnote{\textit{Proof.} Assume that $m=0$.
Thus, each prime $p$ satisfies $v_{p}\left(  \underbrace{m}_{=0}\right)
=v_{p}\left(  0\right)  =\infty$ (by Definition \ref{def.ent.prime.vp}
\textbf{(b)}) and thus $v_{p}\left(  m\right)  =\infty\geq v_{p}\left(
n\right)  $, so that $v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $.
Also, $n\mid0=m$. Thus, the statements \textquotedblleft$n\mid m$%
\textquotedblright\ and \textquotedblleft each prime $p$ satisfies
$v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $\textquotedblright\ are
both true. Hence, $n\mid m$ if and only if each prime $p$ satisfies
$v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $. In other words,
Proposition \ref{prop.ent.prime.n|m} is true. Qed.}. Hence, for the rest of
this proof, we WLOG assume that $m\neq0$. Therefore, $m$ is nonzero. Hence,
$v_{p}\left(  m\right)  \in\mathbb{N}$ (by Definition \ref{def.ent.prime.vp}
\textbf{(a)}), so that $v_{p}\left(  m\right)  <\infty$.

If $n=0$, then Proposition \ref{prop.ent.prime.n|m} is
true\footnote{\textit{Proof.} Assume that $n=0$. Thus, each prime $p$
satisfies $v_{p}\left(  \underbrace{n}_{=0}\right)  =v_{p}\left(  0\right)
=\infty$ (by Definition \ref{def.ent.prime.vp} \textbf{(b)}) and thus
$v_{p}\left(  m\right)  <\infty=v_{p}\left(  n\right)  $. Applying this to
$p=2$, we obtain $v_{2}\left(  m\right)  <v_{2}\left(  n\right)  $ (since $2$
is a prime). Hence, we don't have $v_{2}\left(  n\right)  \leq v_{2}\left(
m\right)  $. Thus, the statement \textquotedblleft each prime $p$ satisfies
$v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $\textquotedblright\ is
false (since $p=2$ is a counterexample).
\par
If we had $n\mid m$, then there would be an integer $c$ such that $m=nc$. This
would then lead to $m=\underbrace{n}_{=0}c=0$, which would contradict $m\neq
0$. Hence, we cannot have $n\mid m$. Thus, the statements \textquotedblleft%
$n\mid m$\textquotedblright\ and \textquotedblleft each prime $p$ satisfies
$v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $\textquotedblright\ are
both false. Hence, $n\mid m$ if and only if each prime $p$ satisfies
$v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $. In other words,
Proposition \ref{prop.ent.prime.n|m} is true. Qed.}. Hence, for the rest of
this proof, we WLOG assume that $n\neq0$. Therefore, $n$ is nonzero.

The statement of Proposition \ref{prop.ent.prime.n|m} does not change if we
replace $n$ and $m$ by $\left\vert n\right\vert $ and $\left\vert m\right\vert
$, respectively\footnote{Indeed, the statement \textquotedblleft$n\mid
m$\textquotedblright\ does not change (since Proposition \ref{prop.ent.div.1}
\textbf{(a)} yields that we have $n\mid m$ if and only if $\left\vert
n\right\vert \mid\left\vert m\right\vert $), and the statement
\textquotedblleft each prime $p$ satisfies $v_{p}\left(  n\right)  \leq
v_{p}\left(  m\right)  $\textquotedblright\ does not change either (because
Exercise \ref{exe.ent.prime.vp-abs} shows that $v_{p}\left(  \left\vert
n\right\vert \right)  =v_{p}\left(  n\right)  $ and $v_{p}\left(  \left\vert
m\right\vert \right)  =v_{p}\left(  m\right)  $).}. Hence, we can WLOG assume
that $n$ and $m$ are nonnegative. Assume this. Then, $n\geq0$, so that $n>0$
(since $n$ is nonzero). Hence, $n$ is a positive integer. Thus, Corollary
\ref{cor.ent.prime.can-fac} yields%
\begin{equation}
n=\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }.
\label{pf.prop.ent.prime.n|m.n=}%
\end{equation}
Similarly,%
\begin{equation}
m=\prod_{p\text{ prime}}p^{v_{p}\left(  m\right)  }.
\label{pf.prop.ent.prime.n|m.m=}%
\end{equation}


Our goal is to prove that $n\mid m$ if and only if each prime $p$ satisfies
$v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $. We shall now prove the
\textquotedblleft$\Longleftarrow$\textquotedblright\ and \textquotedblleft%
$\Longrightarrow$\textquotedblright\ directions of this \textquotedblleft if
and only if\textquotedblright\ statement separately.

$\Longleftarrow:$ Assume that each prime $p$ satisfies $v_{p}\left(  n\right)
\leq v_{p}\left(  m\right)  $. We must prove that $n\mid m$.

The product $\prod_{p\text{ prime}}p^{v_{p}\left(  m\right)  -v_{p}\left(
n\right)  }$ is well-defined\footnote{\textit{Proof. }Let $p$ be a prime such
that $p>\left\vert m\right\vert $. Then, $v_{p}\left(  m\right)  =0$ (by Lemma
\ref{lem.ent.prime.vpn=0} \textbf{(a)}, applied to $m$ instead of $n$), so
that $v_{p}\left(  m\right)  -\underbrace{v_{p}\left(  n\right)  }_{\geq0}\leq
v_{p}\left(  m\right)  =0$. On the other hand, $v_{p}\left(  n\right)  \leq
v_{p}\left(  m\right)  $ (since we assumed that each prime $p$ satisfies
$v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $); thus, $v_{p}\left(
m\right)  -v_{p}\left(  n\right)  \geq0$. Combining this with $v_{p}\left(
m\right)  -v_{p}\left(  n\right)  \leq0$, we obtain $v_{p}\left(  m\right)
-v_{p}\left(  n\right)  =0$. Hence, $p^{v_{p}\left(  m\right)  -v_{p}\left(
n\right)  }=p^{0}=1$.
\par
Now, forget that we fixed $p$. We thus have proven that every prime
$p>\left\vert m\right\vert $ satisfies $p^{v_{p}\left(  m\right)
-v_{p}\left(  n\right)  }=1$. Hence, all but finitely many primes $p$ satisfy
$p^{v_{p}\left(  m\right)  -v_{p}\left(  n\right)  }=1$ (since all but
finitely many primes $p$ satisfy $p>\left\vert m\right\vert $). In other
words, the product $\prod_{p\text{ prime}}p^{v_{p}\left(  m\right)
-v_{p}\left(  n\right)  }$ has only finitely many factors different from $1$.
Hence, this product is well-defined.}.

We have assumed that each prime $p$ satisfies $v_{p}\left(  n\right)  \leq
v_{p}\left(  m\right)  $. In other words, each prime $p$ satisfies
$v_{p}\left(  m\right)  -v_{p}\left(  n\right)  \geq0$ and therefore
$p^{v_{p}\left(  m\right)  -v_{p}\left(  n\right)  }\in\mathbb{Z}$. Hence, the
product $\prod_{p\text{ prime}}p^{v_{p}\left(  m\right)  -v_{p}\left(
n\right)  }$ is a product of integers, and thus itself an integer. Let us
denote this product by $c$. Thus,%
\begin{equation}
c=\prod_{p\text{ prime}}p^{v_{p}\left(  m\right)  -v_{p}\left(  n\right)  }.
\label{pf.prop.ent.prime.n|m.c=}%
\end{equation}
Thus, $c$ is an integer (since we have just shown that $\prod_{p\text{ prime}%
}p^{v_{p}\left(  m\right)  -v_{p}\left(  n\right)  }$ is an integer).
Multiplying the equalities (\ref{pf.prop.ent.prime.n|m.n=}) and
(\ref{pf.prop.ent.prime.n|m.c=}), we obtain%
\begin{align*}
nc  &  =\left(  \prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }\right)
\left(  \prod_{p\text{ prime}}p^{v_{p}\left(  m\right)  -v_{p}\left(
n\right)  }\right)  =\prod_{p\text{ prime}}\underbrace{\left(  p^{v_{p}\left(
n\right)  }p^{v_{p}\left(  m\right)  -v_{p}\left(  n\right)  }\right)
}_{\substack{=p^{v_{p}\left(  n\right)  +\left(  v_{p}\left(  m\right)
-v_{p}\left(  n\right)  \right)  }=p^{v_{p}\left(  m\right)  }\\\text{(since
}v_{p}\left(  n\right)  +\left(  v_{p}\left(  m\right)  -v_{p}\left(
n\right)  \right)  =v_{p}\left(  m\right)  \text{)}}}\\
&  =\prod_{p\text{ prime}}p^{v_{p}\left(  m\right)  }%
=m\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.prop.ent.prime.n|m.m=}%
)}\right)  .
\end{align*}
In other words, $m=nc$. Hence, $n\mid m$. This completes the proof of the
\textquotedblleft$\Longleftarrow$\textquotedblright\ direction of Proposition
\ref{prop.ent.prime.n|m}.

$\Longrightarrow:$ Assume that $n\mid m$. We must prove that each prime $p$
satisfies $v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $.

So let $p$ be a prime. Recall that $n\mid m$. In other words, there exists
some integer $b$ such that $m=nb$. Consider this $b$. Now,%
\begin{align*}
v_{p}\left(  \underbrace{m}_{=nb}\right)   &  =v_{p}\left(  nb\right)
=v_{p}\left(  n\right)  +\underbrace{v_{p}\left(  b\right)  }_{\geq
0}\ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem \ref{thm.ent.prime.vp-ring}
\textbf{(a)}, applied to }a=n\right) \\
&  \geq v_{p}\left(  n\right)  ,
\end{align*}
so that $v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $. Now, forget
that we fixed $p$. We thus have proven that each prime $p$ satisfies
$v_{p}\left(  n\right)  \leq v_{p}\left(  m\right)  $. This completes the
proof of the \textquotedblleft$\Longrightarrow$\textquotedblright\ direction
of Proposition \ref{prop.ent.prime.n|m}.
\end{proof}

Let us extract one of the steps of our above proof into a separate lemma,
since we shall use the same reasoning later on:

\begin{lemma}
\label{lem.ent.prime.prod|prod}For each prime $p$, let $a_{p}$ and $b_{p}$ be
nonnegative integers such that
\begin{equation}
a_{p}\leq b_{p}. \label{eq.lem.ent.prime.prod|prod.apbp}%
\end{equation}
Assume that all but finitely many primes $p$ satisfy $b_{p}=0$. Then, the
products $\prod_{p\text{ prime}}p^{a_{p}}$ and $\prod_{p\text{ prime}}%
p^{b_{p}}$ are both well-defined and satisfy $\prod_{p\text{ prime}}p^{a_{p}%
}\mid\prod_{p\text{ prime}}p^{b_{p}}$.
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.prime.prod|prod}.]This is going to be really
boring: The well-definedness part is all about bookkeeping finiteness
information, whereas the $\prod_{p\text{ prime}}p^{a_{p}}\mid\prod_{p\text{
prime}}p^{b_{p}}$ claim is proven just as we proved the \textquotedblleft%
$\Longleftarrow$\textquotedblright\ direction of Proposition
\ref{prop.ent.prime.n|m}. For the sake of completeness, let us nevertheless
give the complete proof:

\begin{fineprint}
All but finitely many primes $p$ satisfy $b_{p}=0$. In other words, there
exists some finite set $S$ of primes such that every prime $p\notin S$
satisfies
\begin{equation}
b_{p}=0. \label{pf.lem.ent.prime.prod|prod.1}%
\end{equation}
Consider this $S$. Clearly, all but finitely many primes $p$ satisfy $p\notin
S$ (since $S$ is finite).

Now, every prime $p\notin S$ satisfies
\begin{equation}
a_{p}=0 \label{pf.lem.ent.prime.prod|prod.2}%
\end{equation}
\ \footnote{\textit{Proof.} Let $p\notin S$ be a prime. Then,
(\ref{eq.lem.ent.prime.prod|prod.apbp}) yields $a_{p}\leq b_{p}=0$ (by
(\ref{pf.lem.ent.prime.prod|prod.1})). Thus, $a_{p}=0$ (since $a_{p}$ is a
nonnegative integer), qed.}. Hence, all but finitely many primes $p$ satisfy
$a_{p}=0$ (since all but finitely many primes $p$ satisfy $p\notin S$). Thus,
all but finitely many primes $p$ satisfy $p^{a_{p}}=p^{0}=1$. In other words,
only finitely many primes $p$ satisfy $p^{a_{p}}\neq1$. In other words, only
finitely many factors of the product $\prod_{p\text{ prime}}p^{a_{p}}$ are
different from $1$. Hence, this product $\prod_{p\text{ prime}}p^{a_{p}}$ is well-defined.

Also, all but finitely many primes $p$ satisfy $b_{p}=0$. Therefore, all but
finitely many primes $p$ satisfy $p^{b_{p}}=p^{0}=1$. In other words, only
finitely many primes $p$ satisfy $p^{b_{p}}\neq1$. In other words, only
finitely many factors of the product $\prod_{p\text{ prime}}p^{b_{p}}$ are
different from $1$. Hence, this product $\prod_{p\text{ prime}}p^{b_{p}}$ is well-defined.

The product $\prod_{p\text{ prime}}p^{b_{p}-a_{p}}$ is
well-defined\footnote{\textit{Proof. }Every prime $p\notin S$ satisfies
$\underbrace{b_{p}}_{\substack{=0\\\text{(by
(\ref{pf.lem.ent.prime.prod|prod.1}))}}}-\underbrace{a_{p}}%
_{\substack{=0\\\text{(by (\ref{pf.lem.ent.prime.prod|prod.2}))}}}=0-0=0$ and
therefore $p^{b_{p}-a_{p}}=p^{0}=1$. Thus, all but finitely many primes $p$
satisfy $p^{b_{p}-a_{p}}=1$ (since all but finitely many primes $p$ satisfy
$p\notin S$). In other words, only finitely many primes $p$ satisfy
$p^{b_{p}-a_{p}}\neq1$. In other words, only finitely many factors of the
product $\prod_{p\text{ prime}}p^{b_{p}-a_{p}}$ are different from $1$. Hence,
this product $\prod_{p\text{ prime}}p^{b_{p}-a_{p}}$ is well-defined.}. Denote
this product by $c$.

For each prime $p$, we have $b_{p}-a_{p}\geq0$ (by
(\ref{eq.lem.ent.prime.prod|prod.apbp})) and thus $b_{p}-a_{p}\in\mathbb{N}$.
Hence, for each prime $p$, the number $p^{b_{p}-a_{p}}$ is an integer.
Therefore, $\prod_{p\text{ prime}}p^{b_{p}-a_{p}}$ is a product of integers,
and thus itself an integer. In other words, $c$ is an integer (since
$c=\prod_{p\text{ prime}}p^{b_{p}-a_{p}}$).

But from $c=\prod_{p\text{ prime}}p^{b_{p}-a_{p}}$, we obtain%
\[
\left(  \prod_{p\text{ prime}}p^{a_{p}}\right)  c=\left(  \prod_{p\text{
prime}}p^{a_{p}}\right)  \left(  \prod_{p\text{ prime}}p^{b_{p}-a_{p}}\right)
=\prod_{p\text{ prime}}\underbrace{\left(  p^{a_{p}}p^{b_{p}-a_{p}}\right)
}_{=p^{a_{p}+\left(  b_{p}-a_{p}\right)  }=p^{b_{p}}}=\prod_{p\text{ prime}%
}p^{b_{p}}.
\]
Thus, $\prod_{p\text{ prime}}p^{a_{p}}\mid\prod_{p\text{ prime}}p^{b_{p}}$
(since $c$ is an integer). This completes the proof of Lemma
\ref{lem.ent.prime.prod|prod}.
\end{fineprint}
\end{proof}

\begin{corollary}
\label{cor.ent.prime.vp-of-can}For each prime $p$, let $b_{p}$ be a
nonnegative integer. Assume that all but finitely many primes $p$ satisfy
$b_{p}=0$. Let $n=\prod_{p\text{ prime}}p^{b_{p}}$. Then,%
\[
v_{q}\left(  n\right)  =b_{q}\ \ \ \ \ \ \ \ \ \ \text{for each prime }q.
\]

\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.ent.prime.vp-of-can}.]The product $\prod_{p\text{
prime}}p^{b_{p}}$ is well-defined. (This can be shown just as in the proof of
Lemma \ref{lem.ent.prime.prod|prod}.) Now, choose a list $\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  $ of primes that contains each prime $p$ exactly
$b_{p}$ times. (Such a list clearly exists: For example, we can pick%
\[
\left(  \underbrace{2,2,\ldots,2}_{b_{2}\text{ times}},\underbrace{3,3,\ldots
,3}_{b_{3}\text{ times}},\underbrace{5,5,\ldots,5}_{b_{5}\text{ times}}%
,\ldots\right)  .
\]
This is indeed a finite list, since all but finitely many primes $p$ satisfy
$b_{p}=0$.)

Now, the list $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ contains each prime
$p$ exactly $b_{p}$ times (and no other entries). Hence, the product
$a_{1}a_{2}\cdots a_{k}$ of the entries of this list contains each prime $p$
exactly $b_{p}$ times as a factor (and no other factors). Thus, this product
equals $\prod_{p\text{ prime}}p^{b_{p}}$. In other words, $a_{1}a_{2}\cdots
a_{k}=\prod_{p\text{ prime}}p^{b_{p}}$. Hence,%
\[
n=\prod_{p\text{ prime}}p^{b_{p}}=a_{1}a_{2}\cdots a_{k}.
\]
Thus, $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ is a prime factorization of
$n$ (since $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ is a tuple of primes).

Let $q$ be a prime. Proposition \ref{prop.ent.prime.mult-in-pf} (applied to
$p=q$) yields%
\begin{align*}
&  \left(  \text{the number of times }q\text{ appears in the tuple }\left(
a_{1},a_{2},\ldots,a_{k}\right)  \right) \\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,k\right\}  \text{
such that }a_{i}=q\right) \\
&  =v_{q}\left(  n\right)  .
\end{align*}
Thus,%
\[
v_{q}\left(  n\right)  =\left(  \text{the number of times }q\text{ appears in
the tuple }\left(  a_{1},a_{2},\ldots,a_{k}\right)  \right)  =b_{q}%
\]
(since the list $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $ contains each
prime $p$ exactly $b_{p}$ times, and thus contains the prime $q$ exactly
$b_{q}$ times). This proves Corollary \ref{cor.ent.prime.vp-of-can}.
\end{proof}

\begin{exercise}
\label{exe.ent.prime.modpvp}Let $n$ be a nonzero integer. Let $a$ and $b$ be
two integers. Assume that%
\begin{equation}
a\equiv b\operatorname{mod}p^{v_{p}\left(  n\right)  }%
\ \ \ \ \ \ \ \ \ \ \text{for every prime }p.
\label{eq.exe.ent.prime.modpvp.ass}%
\end{equation}
Prove that $a\equiv b\operatorname{mod}n$.
\end{exercise}

\begin{center}
\textbf{2019-02-13 lecture}
\end{center}

Canonical factorizations can also be used to describe gcds and lcms:

\begin{proposition}
\label{prop.ent.prime.gcd}Let $n$ and $m$ be two nonzero integers. Then,%
\begin{equation}
\gcd\left(  n,m\right)  =\prod_{p\text{ prime}}p^{\min\left\{  v_{p}\left(
n\right)  ,v_{p}\left(  m\right)  \right\}  }
\label{eq.prop.ent.prime.gcd.gcd}%
\end{equation}
and%
\begin{equation}
\operatorname{lcm}\left(  n,m\right)  =\prod_{p\text{ prime}}p^{\max\left\{
v_{p}\left(  n\right)  ,v_{p}\left(  m\right)  \right\}  }.
\label{eq.prop.ent.prime.gcd.lcm}%
\end{equation}

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.gcd}.]If $p$ is any prime, then
$v_{p}\left(  n\right)  $ and $v_{p}\left(  m\right)  $ are nonnegative
integers (since $n$ and $m$ are nonzero), and thus so are $\min\left\{
v_{p}\left(  n\right)  ,v_{p}\left(  m\right)  \right\}  $ and $\max\left\{
v_{p}\left(  n\right)  ,v_{p}\left(  m\right)  \right\}  $.

It is easy to see that the infinite products $\prod_{p\text{ prime}}%
p^{\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)  \right\}  }$
and \newline$\prod_{p\text{ prime}}p^{\max\left\{  v_{p}\left(  n\right)
,v_{p}\left(  m\right)  \right\}  }$ are well-defined\footnote{\textit{Proof.}
Let $p$ be a prime such that $p>\max\left\{  \left\vert m\right\vert
,\left\vert n\right\vert \right\}  $. Thus, $p>\max\left\{  \left\vert
m\right\vert ,\left\vert n\right\vert \right\}  \geq\left\vert m\right\vert $
and therefore $v_{p}\left(  m\right)  =0$ (by Lemma \ref{lem.ent.prime.vpn=0}
\textbf{(a)}, applied to $m$ instead of $n$). Similarly, $v_{p}\left(
n\right)  =0$. Hence, $\max\left\{  \underbrace{v_{p}\left(  n\right)  }%
_{=0},\underbrace{v_{p}\left(  m\right)  }_{=0}\right\}  =\max\left\{
0,0\right\}  =0$ and therefore $p^{\max\left\{  v_{p}\left(  n\right)
,v_{p}\left(  m\right)  \right\}  }=p^{0}=1$.
\par
Now, forget that we fixed $p$. We thus have proven that every prime
$p>\max\left\{  \left\vert m\right\vert ,\left\vert n\right\vert \right\}  $
satisfies $p^{\max\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  }=1$. Hence, all but finitely many primes $p$ satisfy $p^{\max
\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)  \right\}  }=1$ (since
all but finitely many primes $p$ satisfy $p>\max\left\{  \left\vert
m\right\vert ,\left\vert n\right\vert \right\}  $). In other words, the
product $\prod_{p\text{ prime}}p^{\max\left\{  v_{p}\left(  n\right)
,v_{p}\left(  m\right)  \right\}  }$ has only finitely many factors different
from $1$. Hence, this product is well-defined. Similarly, we can show that the
product $\prod_{p\text{ prime}}p^{\min\left\{  v_{p}\left(  n\right)
,v_{p}\left(  m\right)  \right\}  }$ is well-defined.}.

Define two nonnegative integers%
\begin{equation}
g=\prod\limits_{p\text{ prime}}p^{\min\left\{  v_{p}\left(  n\right)
,v_{p}\left(  m\right)  \right\}  }\ \ \ \ \ \ \ \ \ \ \text{and}%
\ \ \ \ \ \ \ \ \ \ h=\gcd\left(  n,m\right)  .
\label{pf.prop.ent.prime.gcd.g=h=}%
\end{equation}


Note that $h=\gcd\left(  n,m\right)  $ is a positive integer (since $n$ and
$m$ are nonzero) and thus nonzero. Thus, $v_{p}\left(  h\right)  $ is a
nonnegative integer for each prime $p$.

Corollary \ref{cor.ent.prime.can-facZ} yields $\left\vert n\right\vert
=\prod\limits_{p\text{ prime}}p^{v_{p}\left(  n\right)  }$. But each prime $p$
satisfies \newline$\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  \leq v_{p}\left(  n\right)  $ (since the minimum of a set is $\leq$
to any element of the set). Hence, Lemma \ref{lem.ent.prime.prod|prod}
(applied to $a_{p}=\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  $ and $b_{p}=v_{p}\left(  n\right)  $) yields $\prod\limits_{p\text{
prime}}p^{\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  }\mid\prod\limits_{p\text{ prime}}p^{v_{p}\left(  n\right)  }$. This
rewrites as $g\mid\left\vert n\right\vert $ (since $g=\prod\limits_{p\text{
prime}}p^{\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  }$ and $\left\vert n\right\vert =\prod\limits_{p\text{ prime}%
}p^{v_{p}\left(  n\right)  }$). Hence, $g\mid\left\vert n\right\vert \mid n$
(by Exercise \ref{exe.ent.div.aabs} \textbf{(b)}). Similarly, $g\mid m$. Thus,
$\left(  g\mid n\text{ and }g\mid m\right)  $. Hence, Lemma
\ref{lem.ent.gcd.uniprop} (applied to $g$, $n$ and $m$ instead of $m$, $a$ and
$b$) yields $g\mid\gcd\left(  n,m\right)  =h$.

On the other hand, Proposition \ref{prop.ent.prime.n|m} (applied to $h$ and
$n$ instead of $n$ and $m$) shows that $h\mid n$ if and only if each prime $p$
satisfies $v_{p}\left(  h\right)  \leq v_{p}\left(  n\right)  $. Thus, each
prime $p$ satisfies $v_{p}\left(  h\right)  \leq v_{p}\left(  n\right)  $.

Now, fix any prime $p$. Then, $v_{p}\left(  h\right)  \leq v_{p}\left(
n\right)  $ (as we have just seen) and $v_{p}\left(  h\right)  \leq
v_{p}\left(  m\right)  $ (similarly). Combining these two inequalities, we
obtain%
\[
v_{p}\left(  h\right)  \leq\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(
m\right)  \right\}
\]
(since $\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)  \right\}
$ must be one of the two numbers $v_{p}\left(  n\right)  $ and $v_{p}\left(
m\right)  $, but we have just seen that $v_{p}\left(  h\right)  $ is $\leq$ to
each of these two numbers).

Now, forget that we fixed $p$. We thus have show that each prime $p$ satisfies
$v_{p}\left(  h\right)  \leq\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(
m\right)  \right\}  $. Hence, Lemma \ref{lem.ent.prime.prod|prod} (applied to
$a_{p}=v_{p}\left(  h\right)  $ and $b_{p}=\min\left\{  v_{p}\left(  n\right)
,v_{p}\left(  m\right)  \right\}  $) yields $\prod\limits_{p\text{ prime}%
}p^{v_{p}\left(  h\right)  }\mid\prod\limits_{p\text{ prime}}p^{\min\left\{
v_{p}\left(  n\right)  ,v_{p}\left(  m\right)  \right\}  }$. But $h$ is
positive; hence, Corollary \ref{cor.ent.prime.can-fac} (applied to $h$ instead
of $n$) yields%
\[
h=\prod\limits_{p\text{ prime}}p^{v_{p}\left(  h\right)  }\mid\prod
\limits_{p\text{ prime}}p^{\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(
m\right)  \right\}  }=g.
\]


Thus, we know that $g\mid h$ and $h\mid g$. Hence, Exercise
\ref{exe.ent.div.abba} (applied to $a=g$ and $b=h$) yields $\left\vert
g\right\vert =\left\vert h\right\vert $. But $g$ is nonnegative; thus,
$\left\vert g\right\vert =g$. Hence, $g=\left\vert g\right\vert =\left\vert
h\right\vert =h$ (since $h$ is positive). In view of
(\ref{pf.prop.ent.prime.gcd.g=h=}), this rewrites as $\prod\limits_{p\text{
prime}}p^{\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  }=\gcd\left(  n,m\right)  $. This proves
(\ref{eq.prop.ent.prime.gcd.gcd}).

The proof of (\ref{eq.prop.ent.prime.gcd.lcm}) is entirely analogous to the
proof of (\ref{eq.prop.ent.prime.gcd.gcd}) we just gave: We merely need to
flip all divisibilities and inequalities and replace \textquotedblleft$\min
$\textquotedblright\ by \textquotedblleft$\max$\textquotedblright\ everywhere,
and use Lemma \ref{lem.ent.lcm.uniprop} instead of Lemma
\ref{lem.ent.gcd.uniprop}
\end{proof}

\begin{example}
For this example, set $n=3^{2}\cdot5\cdot7^{8}$ and $m=2\cdot3^{3}\cdot7^{2}$.
Let us compute $\gcd\left(  n,m\right)  $ and $\operatorname{lcm}\left(
n,m\right)  $ using Proposition \ref{prop.ent.prime.gcd}.

From $n=3^{2}\cdot5\cdot7^{8}$, we obtain (using Corollary
\ref{cor.ent.prime.vp-of-can}) that%
\begin{align*}
v_{3}\left(  n\right)   &  =2,\ \ \ \ \ \ \ \ \ \ v_{5}\left(  n\right)
=1,\ \ \ \ \ \ \ \ \ \ v_{7}\left(  n\right)
=8,\ \ \ \ \ \ \ \ \ \ \text{and}\\
v_{p}\left(  n\right)   &  =0\text{ for each prime }p\notin\left\{
3,5,7\right\}  .
\end{align*}
Similarly, from $m=2\cdot3^{3}\cdot7^{2}$, we obtain%
\begin{align*}
v_{2}\left(  m\right)   &  =1,\ \ \ \ \ \ \ \ \ \ v_{3}\left(  m\right)
=3,\ \ \ \ \ \ \ \ \ \ v_{7}\left(  m\right)
=2,\ \ \ \ \ \ \ \ \ \ \text{and}\\
v_{p}\left(  n\right)   &  =0\text{ for each prime }p\notin\left\{
2,3,7\right\}  .
\end{align*}
Now, (\ref{eq.prop.ent.prime.gcd.gcd}) yields%
\begin{align*}
&  \gcd\left(  n,m\right) \\
&  =\prod_{p\text{ prime}}p^{\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(
m\right)  \right\}  }\\
&  =\underbrace{2^{\min\left\{  v_{2}\left(  n\right)  ,v_{2}\left(  m\right)
\right\}  }}_{=2^{\min\left\{  0,1\right\}  }=2^{0}}\cdot\underbrace{3^{\min
\left\{  v_{3}\left(  n\right)  ,v_{3}\left(  m\right)  \right\}  }}%
_{=3^{\min\left\{  2,3\right\}  }=3^{2}}\cdot\underbrace{5^{\min\left\{
v_{5}\left(  n\right)  ,v_{5}\left(  m\right)  \right\}  }}_{=5^{\min\left\{
1,0\right\}  }=5^{0}}\\
&  \ \ \ \ \ \ \ \ \ \ \cdot\underbrace{7^{\min\left\{  v_{7}\left(  n\right)
,v_{7}\left(  m\right)  \right\}  }}_{=7^{\min\left\{  8,2\right\}  }=7^{2}%
}\cdot\prod_{\substack{p\text{ prime;}\\p\notin\left\{  2,3,5,7\right\}
}}\underbrace{p^{\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  }}_{\substack{=1\\\text{(since }v_{p}\left(  n\right)  =0\text{ and
}v_{p}\left(  m\right)  =0\\\text{and thus }\min\left\{  v_{p}\left(
n\right)  ,v_{p}\left(  m\right)  \right\}  =\min\left\{  0,0\right\}
=0\text{)}}}\\
&  =2^{0}\cdot3^{2}\cdot5^{0}\cdot7^{2}=3^{2}\cdot7^{2}.
\end{align*}
Likewise, (\ref{eq.prop.ent.prime.gcd.lcm}) yields%
\begin{align*}
&  \operatorname{lcm}\left(  n,m\right) \\
&  =\prod_{p\text{ prime}}p^{\max\left\{  v_{p}\left(  n\right)  ,v_{p}\left(
m\right)  \right\}  }\\
&  =\underbrace{2^{\max\left\{  v_{2}\left(  n\right)  ,v_{2}\left(  m\right)
\right\}  }}_{=2^{\max\left\{  0,1\right\}  }=2^{1}}\cdot\underbrace{3^{\max
\left\{  v_{3}\left(  n\right)  ,v_{3}\left(  m\right)  \right\}  }}%
_{=3^{\max\left\{  2,3\right\}  }=3^{3}}\cdot\underbrace{5^{\max\left\{
v_{5}\left(  n\right)  ,v_{5}\left(  m\right)  \right\}  }}_{=5^{\max\left\{
1,0\right\}  }=5^{1}}\\
&  \ \ \ \ \ \ \ \ \ \ \cdot\underbrace{7^{\max\left\{  v_{7}\left(  n\right)
,v_{7}\left(  m\right)  \right\}  }}_{=7^{\max\left\{  8,2\right\}  }=7^{8}%
}\cdot\prod_{\substack{p\text{ prime;}\\p\notin\left\{  2,3,5,7\right\}
}}\underbrace{p^{\max\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  }}_{\substack{=1\\\text{(since }v_{p}\left(  n\right)  =0\text{ and
}v_{p}\left(  m\right)  =0\\\text{and thus }\max\left\{  v_{p}\left(
n\right)  ,v_{p}\left(  m\right)  \right\}  =\max\left\{  0,0\right\}
=0\text{)}}}\\
&  =2^{1}\cdot3^{3}\cdot5^{1}\cdot7^{8}.
\end{align*}

\end{example}

Proposition \ref{prop.ent.prime.gcd} can be generalized to the case of $k$
integers $b_{1},b_{2},\ldots,b_{k}$ instead of two integers $n,m$:

\begin{proposition}
\label{prop.ent.prime.gcd-k}Let $b_{1},b_{2},\ldots,b_{k}$ be finitely many
nonzero integers, with $k>0$. Then,%
\begin{equation}
\gcd\left(  b_{1},b_{2},\ldots,b_{k}\right)  =\prod_{p\text{ prime}}%
p^{\min\left\{  v_{p}\left(  b_{1}\right)  ,v_{p}\left(  b_{2}\right)
,\ldots,v_{p}\left(  b_{k}\right)  \right\}  }
\label{eq.prop.ent.prime.gcd-k.gcd}%
\end{equation}
an%
\begin{equation}
\operatorname{lcm}\left(  b_{1},b_{2},\ldots,b_{k}\right)  =\prod_{p\text{
prime}}p^{\max\left\{  v_{p}\left(  b_{1}\right)  ,v_{p}\left(  b_{2}\right)
,\ldots,v_{p}\left(  b_{k}\right)  \right\}  }.
\label{eq.prop.ent.prime.gcd-k.lcm}%
\end{equation}

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.prime.gcd-k}.]The proof of Proposition
\ref{prop.ent.prime.gcd-k} is analogous to the proof of Proposition
\ref{prop.ent.prime.gcd}, with two minor exceptions:

\begin{itemize}
\item Instead of applying Lemma \ref{lem.ent.gcd.uniprop} (in the proof of
(\ref{eq.prop.ent.prime.gcd-k.gcd})), we now have to apply the analogous claim
for $k$ integers\footnote{Namely: Let $m\in\mathbb{Z}$ and let $b_{1}%
,b_{2},\ldots,b_{k}$ be integers such that $\left(  m\mid b_{i}\text{ for all
}i\in\left\{  1,2,\ldots,k\right\}  \right)  $. Then, $m\mid\gcd\left(
b_{1},b_{2},\ldots,b_{k}\right)  $.}. The latter claim follows from Theorem
\ref{thm.ent.gcd.uniprop-mul} \textbf{(a)}.

\item Instead of applying Lemma \ref{lem.ent.lcm.uniprop} (in the proof of
(\ref{eq.prop.ent.prime.gcd-k.lcm})), we now have to apply the analogous claim
for $k$ integers\footnote{Namely: Let $m\in\mathbb{Z}$ and let $b_{1}%
,b_{2},\ldots,b_{k}$ be integers such that $\left(  b_{i}\mid m\text{ for all
}i\in\left\{  1,2,\ldots,k\right\}  \right)  $. Then, $\operatorname{lcm}%
\left(  b_{1},b_{2},\ldots,b_{k}\right)  \mid m$.}. The latter claim follows
from Theorem \ref{thm.ent.lcm.uniprop-mul} \textbf{(a)}. Alternatively,
instead of applying this claim, we can argue as follows: Setting
$g=\prod_{p\text{ prime}}p^{\max\left\{  v_{p}\left(  b_{1}\right)
,v_{p}\left(  b_{2}\right)  ,\ldots,v_{p}\left(  b_{k}\right)  \right\}  }$
and $h=\operatorname{lcm}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $, we see
that $\left(  b_{i}\mid g\text{ for all }i\in\left\{  1,2,\ldots,k\right\}
\right)  $ (by an argument analogous to the one we used to show $\left(  g\mid
n\text{ and }g\mid m\right)  $ in the original proof of
(\ref{eq.prop.ent.prime.gcd.gcd})). Thus, $g$ is a common multiple of
$b_{1},b_{2},\ldots,b_{k}$. In other words, $g\in\operatorname*{Mul}\left(
b_{1},b_{2},\ldots,b_{k}\right)  $. Hence, $g$ is a positive element of
$\operatorname*{Mul}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $ (since $g$ is
positive). Hence, $g\geq\operatorname{lcm}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $ (since $\operatorname{lcm}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $ is the \textbf{smallest} positive element of
$\operatorname*{Mul}\left(  b_{1},b_{2},\ldots,b_{k}\right)  $). In other
words, $g\geq h$ (since $h=\operatorname{lcm}\left(  b_{1},b_{2},\ldots
,b_{k}\right)  $). On the other hand, we prove $g\mid h$ (similarly to how we
proved $h\mid g$ in the original proof of (\ref{eq.prop.ent.prime.gcd.gcd})).
Thus, Proposition \ref{prop.ent.div.1} \textbf{(b)} (applied to $g$ and $h$
instead of $a$ and $b$) yields $\left\vert g\right\vert \leq\left\vert
h\right\vert $ (since $h\neq0$). Since $g$ is positive, we have $\left\vert
g\right\vert =g$ and thus $g=\left\vert g\right\vert \leq\left\vert
h\right\vert =h$ (since $h$ is positive). Combining this with $g\geq h$, we
obtain $g=h$. As before, this completes the proof of
(\ref{eq.prop.ent.prime.gcd-k.lcm}).
\end{itemize}
\end{proof}

We can use Propositions \ref{prop.ent.prime.gcd} and
\ref{prop.ent.prime.gcd-k} to reprove certain facts about lcms and gcds. For
example, let us prove Theorem \ref{thm.ent.lcm.gcd*lcm} and solve Exercise
\ref{exe.ent.lcm.lcmabc}:

\begin{fineprint}
\begin{proof}
[Second proof of Theorem \ref{thm.ent.lcm.gcd*lcm} (sketched).]WLOG assume
that $a$ and $b$ are nonzero (since otherwise, the claim of Theorem
\ref{thm.ent.lcm.gcd*lcm} easily reduces to $0=0$). Then, $ab$ is nonzero as
well. Hence, Corollary \ref{cor.ent.prime.can-facZ} (applied to $n=ab$) yields%
\[
\left\vert ab\right\vert =\prod_{p\text{ prime}}p^{v_{p}\left(  ab\right)  }.
\]
Now, Proposition \ref{prop.ent.prime.gcd} yields%
\begin{align*}
\gcd\left(  a,b\right)   &  =\prod_{p\text{ prime}}p^{\min\left\{
v_{p}\left(  a\right)  ,v_{p}\left(  b\right)  \right\}  }%
\ \ \ \ \ \ \ \ \ \ \text{and}\\
\operatorname{lcm}\left(  a,b\right)   &  =\prod_{p\text{ prime}}%
p^{\max\left\{  v_{p}\left(  a\right)  ,v_{p}\left(  b\right)  \right\}  }.
\end{align*}
Multiplying these two equalities, we get%
\begin{align*}
\gcd\left(  a,b\right)  \cdot\operatorname{lcm}\left(  a,b\right)   &
=\left(  \prod_{p\text{ prime}}p^{\min\left\{  v_{p}\left(  a\right)
,v_{p}\left(  b\right)  \right\}  }\right)  \cdot\left(  \prod_{p\text{
prime}}p^{\max\left\{  v_{p}\left(  a\right)  ,v_{p}\left(  b\right)
\right\}  }\right) \\
&  =\prod_{p\text{ prime}}\underbrace{\left(  p^{\min\left\{  v_{p}\left(
a\right)  ,v_{p}\left(  b\right)  \right\}  }p^{\max\left\{  v_{p}\left(
a\right)  ,v_{p}\left(  b\right)  \right\}  }\right)  }_{\substack{=p^{\min
\left\{  v_{p}\left(  a\right)  ,v_{p}\left(  b\right)  \right\}
+\max\left\{  v_{p}\left(  a\right)  ,v_{p}\left(  b\right)  \right\}
}\\=p^{v_{p}\left(  a\right)  +v_{p}\left(  b\right)  }\\\text{(since }%
\min\left\{  u,v\right\}  +\max\left\{  u,v\right\}  =u+v\text{ for any reals
}u,v\text{)}}}\\
&  =\prod_{p\text{ prime}}\underbrace{p^{v_{p}\left(  a\right)  +v_{p}\left(
b\right)  }}_{\substack{=p^{v_{p}\left(  ab\right)  }\\\text{(since }%
v_{p}\left(  a\right)  +v_{p}\left(  b\right)  =v_{p}\left(  ab\right)
\\\text{(by Theorem \ref{thm.ent.prime.vp-ring} \textbf{(a)}))}}%
}=\prod_{p\text{ prime}}p^{v_{p}\left(  ab\right)  }=\left\vert ab\right\vert
.
\end{align*}
Hence, Theorem \ref{thm.ent.lcm.gcd*lcm} is proven again.

See Section \ref{sect.sols.exe.ent.lcm.lcmabc.2} for a second solution to
Exercise \ref{exe.ent.lcm.lcmabc} using Propositions \ref{prop.ent.prime.gcd}
and \ref{prop.ent.prime.gcd-k} (and a slightly more general result that can be
proven in the same way).
\end{proof}
\end{fineprint}

\begin{exercise}
\label{exe.ent.prime.gcd.1}Let $n$ and $m$ be two integers. Let $p$ be a prime.

\textbf{(a)} Prove that $v_{p}\left(  \gcd\left(  n,m\right)  \right)
=\min\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)  \right\}  $.

\textbf{(b)} Prove that $v_{p}\left(  \operatorname{lcm}\left(  n,m\right)
\right)  =\max\left\{  v_{p}\left(  n\right)  ,v_{p}\left(  m\right)
\right\}  $.
\end{exercise}

\begin{exercise}
\label{exe.ent.prime.gcd.distrib}Let $a,b,c$ be three integers.

\textbf{(a)} Prove that $\gcd\left(  a,\operatorname{lcm}\left(  b,c\right)
\right)  =\operatorname{lcm}\left(  \gcd\left(  a,b\right)  ,\gcd\left(
a,c\right)  \right)  $.

\textbf{(b)} Prove that $\operatorname{lcm}\left(  a,\gcd\left(  b,c\right)
\right)  =\gcd\left(  \operatorname{lcm}\left(  a,b\right)
,\operatorname{lcm}\left(  a,c\right)  \right)  $.
\end{exercise}

The two parts of Exercise \ref{exe.ent.prime.gcd.distrib} can be regarded as
\textquotedblleft distributivity laws\textquotedblright, but for the binary
operations $\gcd$ and $\operatorname{lcm}$ (or $\operatorname{lcm}$ and $\gcd
$, respectively) instead of $+$ and $\cdot$.

\subsubsection{Coprimality through prime factors}

\begin{proposition}
\label{prop.ent.coprime.via-primes}Let $n$ and $m$ be two integers. Then,
$n\perp m$ if and only if there exists no prime $p$ that divides both $n$ and
$m$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.coprime.via-primes}.]$\Longrightarrow:$
Assume that $n\perp m$. We must prove that there exists no prime $p$ that
divides both $n$ and $m$.

Let $p$ be a prime that divides both $n$ and $m$. Thus, $p\mid n$ and $p\mid
m$. Hence, $p\mid\gcd\left(  n,m\right)  $ (by Lemma \ref{lem.ent.gcd.uniprop}%
, applied to $p$, $n$ and $m$ instead of $m$, $a$ and $b$). But $\gcd\left(
n,m\right)  =1$ (since $n\perp m$). Hence, $p\mid\gcd\left(  n,m\right)  =1$.
Hence, Proposition \ref{prop.ent.div.1} \textbf{(b)} (applied to $a=p$ and
$b=1$) yields $\left\vert p\right\vert \leq\left\vert 1\right\vert =1$.

But $p$ is a prime; thus, $p>1>0$, so that $\left\vert p\right\vert =p$ and
thus $p=\left\vert p\right\vert \leq1$. This contradicts $p>1$.

Now, forget that we fixed $p$. We thus have obtained a contradiction for each
prime $p$ that divides both $n$ and $m$. Hence, there exists no prime $p$ that
divides both $n$ and $m$. This proves the \textquotedblleft$\Longrightarrow
$\textquotedblright\ direction of Proposition
\ref{prop.ent.coprime.via-primes}.

$\Longleftarrow:$ Assume that there exists no prime $p$ that divides both $n$
and $m$. We must prove that $n\perp m$.

Assume the contrary. Thus, we don't have $n\perp m$. In other words, we don't
have $\gcd\left(  n,m\right)  =1$. In other words, $\gcd\left(  n,m\right)
\neq1$. Hence, there exists at least one prime $p$ such that $p\mid\gcd\left(
n,m\right)  $\ \ \ \ \footnote{\textit{Proof.} This is obvious if $\gcd\left(
n,m\right)  =0$ (because in that case, we can take $p=2$, or any other prime).
Thus, for the rest of this proof, we WLOG assume that $\gcd\left(  n,m\right)
\neq0$. Thus, $\gcd\left(  n,m\right)  >1$ (since $\gcd\left(  n,m\right)  $
is a nonnegative integer satisfying $\gcd\left(  n,m\right)  \neq0$ and
$\gcd\left(  n,m\right)  \neq1$). Hence, Proposition
\ref{prop.ent.prime.ex-pri-div} (applied to $\gcd\left(  n,m\right)  $ instead
of $n$) yields that there exists at least one prime $p$ such that $p\mid
\gcd\left(  n,m\right)  $. Qed.}. Consider this $p$.

We have $p\mid\gcd\left(  n,m\right)  \mid n$ and $p\mid\gcd\left(
n,m\right)  \mid m$. Thus, the prime $p$ divides both $n$ and $m$. This
contradicts the assumption that there exists no prime $p$ that divides both
$n$ and $m$.

This contradiction shows that our assumption was false. Hence, $n\perp m$ is
proven. This proves the \textquotedblleft$\Longleftarrow$\textquotedblright%
\ direction of Proposition \ref{prop.ent.coprime.via-primes}.
\end{proof}

\begin{corollary}
\label{cor.ent.coprime.orthogonal}Let $n$ and $m$ be two nonzero integers. Then:

\textbf{(a)} The infinite sum $\sum_{p\text{ prime}}v_{p}\left(  n\right)
v_{p}\left(  m\right)  $ is well-defined (i.e., all but finitely many primes
$p$ satisfy $v_{p}\left(  n\right)  v_{p}\left(  m\right)  =0$).

\textbf{(b)} We have $n\perp m$ if and only if
\[
\sum_{p\text{ prime}}v_{p}\left(  n\right)  v_{p}\left(  m\right)  =0.
\]

\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.ent.coprime.orthogonal} (sketched).]\textbf{(a)}
For every prime $p>\left\vert n\right\vert $, we have $v_{p}\left(  n\right)
=0$ (by Lemma \ref{lem.ent.prime.vpn=0} \textbf{(a)}) and thus
$\underbrace{v_{p}\left(  n\right)  }_{=0}v_{p}\left(  m\right)  =0$. Now,
Corollary \ref{cor.ent.coprime.orthogonal} \textbf{(a)} follows easily.

\textbf{(b)} A sum of nonnegative reals is $0$ if and only if each of its
addends is $0$. Thus, the sum $\sum_{p\text{ prime}}v_{p}\left(  n\right)
v_{p}\left(  m\right)  $ is $0$ if and only if we have $\left(  v_{p}\left(
n\right)  v_{p}\left(  m\right)  =0\text{ for all primes }p\right)  $ (because
all the addends $v_{p}\left(  n\right)  v_{p}\left(  m\right)  $ of our sum
are nonnegative reals). Hence, we have the following chain of equivalences:%
\begin{align*}
&  \left(  \sum_{p\text{ prime}}v_{p}\left(  n\right)  v_{p}\left(  m\right)
=0\right) \\
&  \Longleftrightarrow\ \left(  v_{p}\left(  n\right)  v_{p}\left(  m\right)
=0\text{ for all primes }p\right) \\
&  \Longleftrightarrow\ \left(  \left(  v_{p}\left(  n\right)  =0\text{ or
}v_{p}\left(  m\right)  =0\right)  \text{ for all primes }p\right) \\
&  \Longleftrightarrow\ \left(  \left(  p\nmid n\text{ or }p\nmid m\right)
\text{ for all primes }p\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since Corollary \ref{cor.ent.prime.vp-0} yields the}\\
\text{equivalences }\left(  v_{p}\left(  n\right)  =0\right)
\Longleftrightarrow\left(  p\nmid n\right)  \text{ and }\left(  v_{p}\left(
m\right)  =0\right)  \Longleftrightarrow\left(  p\nmid m\right) \\
\text{for each prime }p
\end{array}
\right) \\
&  \Longleftrightarrow\ \left(  \text{there exists no prime }p\text{ such that
}\left(  p\mid n\text{ and }p\mid m\right)  \right) \\
&  \Longleftrightarrow\ \left(  \text{there exists no prime }p\text{ that
divides both }n\text{ and }m\right) \\
&  \Longleftrightarrow\ \left(  n\perp m\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by Proposition \ref{prop.ent.coprime.via-primes}}\right)  .
\end{align*}
This proves Corollary \ref{cor.ent.coprime.orthogonal} \textbf{(b)}.
\end{proof}

Corollary \ref{cor.ent.coprime.orthogonal} \textbf{(b)} is the reason for the
notation \textquotedblleft$\perp$\textquotedblright\ that we are using for
coprimality. In fact, when $n$ is a positive integer, we can regard the
$p$-valuations $v_{p}\left(  n\right)  $ as the \textquotedblleft
coordinates\textquotedblright\ of $n$ in an (infinite-dimensional) Cartesian
coordinate system. Then, the sum $\sum_{p\text{ prime}}v_{p}\left(  n\right)
v_{p}\left(  m\right)  $ in Corollary \ref{cor.ent.coprime.orthogonal} is
something like a \textquotedblleft%
\href{https://en.wikipedia.org/wiki/Dot_product}{dot product}%
\textquotedblright\ between $n$ and $m$. Thus, Corollary
\ref{cor.ent.coprime.orthogonal} \textbf{(b)} shows that two integers $n$ and
$m$ are coprime if and only if their \textquotedblleft dot
product\textquotedblright\ is $0$. But for vectors in a Euclidean space, the
dot product is $0$ if and only if the vectors are orthogonal. Thus, coprime
integers are like orthogonal vectors. Of course, this analogy should be taken
with a grain of salt; in particular, our \textquotedblleft dot
product\textquotedblright\ is far from being bilinear\footnote{Or, rather, it
is bilinear \textbf{with respect to multiplication}: If we denote
$\sum_{p\text{ prime}}v_{p}\left(  n\right)  v_{p}\left(  m\right)  $ by
$\left\langle n,m\right\rangle $, then we have%
\[
\left\langle n_{1}n_{2},m\right\rangle =\left\langle n_{1},m\right\rangle
+\left\langle n_{2},m\right\rangle \ \ \ \ \ \ \ \ \ \ \text{and}%
\ \ \ \ \ \ \ \ \ \ \left\langle n,m_{1}m_{2}\right\rangle =\left\langle
n,m_{1}\right\rangle +\left\langle n,m_{2}\right\rangle
\]
for arbitrary integers $n_{1},n_{2},m,n,m_{1},m_{2}$.}.

\subsubsection{There are infinitely many primes}

\begin{theorem}
\label{thm.ent.prime.infin}There are infinitely many primes.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.ent.prime.infin}.]The following proof is a classic,
appearing in Euclid's \textit{Elements}:

Let $\left(  p_{1},p_{2},\ldots,p_{k}\right)  $ be any finite list of primes.
We shall find a new prime distinct from each of $p_{1},p_{2},\ldots,p_{k}$.

Indeed, $p_{1},p_{2},\ldots,p_{k}$ are primes, and thus are integers $>1$ (by
the definition of a \textquotedblleft prime\textquotedblright). Hence, they
are positive integers; thus, their product $p_{1}p_{2}\cdots p_{k}$ is a
positive integer as well. Thus, $p_{1}p_{2}\cdots p_{k}>0$.

Now, let $n=p_{1}p_{2}\cdots p_{k}+1$. Then, $n=\underbrace{p_{1}p_{2}\cdots
p_{k}}_{>0}+1>1$. Hence, Proposition \ref{prop.ent.prime.ex-pri-div} shows
that there exists at least one prime $p$ such that $p\mid n$. Consider this
$p$.

We claim that $p$ is distinct from each of $p_{1},p_{2},\ldots,p_{k}$.

[\textit{Proof:} Assume the contrary. Thus, $p=p_{i}$ for some $i\in\left\{
1,2,\ldots,k\right\}  $. Consider this $i$.

We have $p_{1}p_{2}\cdots p_{k}=p_{i}\cdot\left(  p_{1}p_{2}\cdots
p_{i-1}p_{i+1}p_{i+2}\cdots p_{k}\right)  $. Thus, $p_{i}\mid p_{1}p_{2}\cdots
p_{k}$ (since $p_{1}p_{2}\cdots p_{i-1}p_{i+1}p_{i+2}\cdots p_{k}$ is an
integer). Hence, $p=p_{i}\mid p_{1}p_{2}\cdots p_{k}$. In other words,
$p_{1}p_{2}\cdots p_{k}\equiv0\operatorname{mod}p$. Now,%
\[
n=\underbrace{p_{1}p_{2}\cdots p_{k}}_{\equiv0\operatorname{mod}p}%
+1\equiv0+1=1\operatorname{mod}p.
\]
Hence, $1\equiv n\operatorname{mod}p$. But $p\mid n$ and thus $n\equiv
0\operatorname{mod}p$. Hence, $1\equiv n\equiv0\operatorname{mod}p$; in other
words, $p\mid1-0=1$. Thus, Proposition \ref{prop.ent.div.1} \textbf{(b)}
(applied to $a=p$ and $b=1$) yields $\left\vert p\right\vert \leq\left\vert
1\right\vert =1$. But $p$ is a prime; thus, $p>1>0$, so that $\left\vert
p\right\vert =p>1$. This contradicts $\left\vert p\right\vert \leq1$. This
contradiction shows that our assumption was wrong, qed.]

Thus, we have proven that $p$ is distinct from each of $p_{1},p_{2}%
,\ldots,p_{k}$. Hence, there exists a prime distinct from each of $p_{1}%
,p_{2},\ldots,p_{k}$ (namely, $p$).

Now, forget that we fixed $p_{1},p_{2},\ldots,p_{k}$. We thus have proven that
if $\left(  p_{1},p_{2},\ldots,p_{k}\right)  $ is any finite list of primes,
then there exists a prime distinct from each of $p_{1},p_{2},\ldots,p_{k}$. In
other words, given any finite list of primes, there exists at least one prime
that is not in this list. In other words, no finite list of primes can cover
all the primes. In other words, there are infinitely many primes. This proves
Theorem \ref{thm.ent.prime.infin}.
\end{proof}

Note that our proof of Theorem \ref{thm.ent.prime.infin} is constructive: It
gives an algorithm to construct arbitrarily many distinct primes. This
algorithm is not very efficient, since $p_{1}p_{2}\cdots p_{k}+1$ can be very
large even if $p_{1},p_{2},\ldots,p_{k}$ are fairly small. In practice, the
sieve of Eratosthenes is much better for generating primes.
\href{https://en.wikipedia.org/wiki/Generating_primes}{Much faster algorithms
are known}.

\begin{exercise}
\label{exe.ent.prime.aa-1}Let $p$ be a prime. Let $a\in\mathbb{Z}$ be such
that $a^{2}\equiv1\operatorname{mod}p$. Prove that $a\equiv1\operatorname{mod}%
p$ or $a\equiv-1\operatorname{mod}p$.
\end{exercise}

\subsection{Euler's totient function ($\phi$-function)}

\subsubsection{Definition and some formulas}

Recall that $\mathbb{P}$ stands for the set of all positive integers.

\begin{definition}
\label{def.ent.phi.phi}We define a function $\phi:\mathbb{P}\rightarrow
\mathbb{N}$ as follows: For each $n\in\mathbb{P}$, we let $\phi\left(
n\right)  $ be the number of all $i\in\left\{  1,2,\ldots,n\right\}  $ that
are coprime to $n$. In other words,%
\begin{equation}
\phi\left(  n\right)  =\left\vert \left\{  i\in\left\{  1,2,\ldots,n\right\}
\ \mid\ i\perp n\right\}  \right\vert . \label{eq.def.ent.phi.phi.1}%
\end{equation}


This function $\phi$ is called \textit{Euler's totient function} or just
$\phi$\textit{-function}.
\end{definition}

\begin{example}
\textbf{(a)} We have $\phi\left(  12\right)  =4$, since the number of all
$i\in\left\{  1,2,\ldots,12\right\}  $ that are coprime to $12$ is $4$
(indeed, these $i$ are $1$, $5$, $7$ and $11$).

\textbf{(b)} We have $\phi\left(  13\right)  =12$, since the number of all
$i\in\left\{  1,2,\ldots,13\right\}  $ that are coprime to $13$ is $12$
(indeed, these $i$ are $1,2,\ldots,12$).

\textbf{(c)} We have $\phi\left(  14\right)  =6$, since the number of all
$i\in\left\{  1,2,\ldots,14\right\}  $ that are coprime to $14$ is $6$
(indeed, these $i$ are $1,3,5,9,11,13$).

\textbf{(d)} We have $\phi\left(  1\right)  =1$, since the number of all
$i\in\left\{  1,2,\ldots,1\right\}  $ that are coprime to $1$ is $1$ (indeed,
the only such $i$ is $1$).
\end{example}

The $\phi$-function $\phi$ is denoted by $\varphi$ by some authors.

\begin{proposition}
\label{prop.ent.phi.p}Let $p$ be a prime. Then, $\phi\left(  p\right)  =p-1$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.phi.p}.]Here is the idea: The definition
of $\phi$ shows that $\phi\left(  p\right)  $ is the number of all
$i\in\left\{  1,2,\ldots,p\right\}  $ that are coprime to $p$. But we know
exactly what these $i$ are: They are just the first $p-1$ positive integers
$1,2,\ldots,p-1$. (In fact, Proposition \ref{prop.ent.prime.each-i-coprime}
shows that each of the integers $1,2,\ldots,p-1$ is coprime to $p$, whereas
$\gcd\left(  p,p\right)  =p>1$ shows that $p$ is \textbf{not} coprime to $p$.)
Thus, $\phi\left(  p\right)  $ is the number of these $p-1$ integers; in other
words, $\phi\left(  p\right)  =p-1$.

\begin{fineprint}
For one last time, here is the proof in detail:

We have $p>1$ (since $p$ is a prime), thus $p\neq1$. Also, $p\mid p$; hence,
Proposition \ref{prop.ent.gcd.props1} \textbf{(i)} (applied to $a=p$ and
$b=p$) yields $\gcd\left(  p,p\right)  =\left\vert p\right\vert =p$ (since
$p>1>0$).

Now, we claim that%
\begin{equation}
\left\{  i\in\left\{  1,2,\ldots,p\right\}  \ \mid\ i\perp p\right\}
\subseteq\left\{  1,2,\ldots,p-1\right\}  . \label{pf.prop.ent.phi.p.1}%
\end{equation}


[\textit{Proof of (\ref{pf.prop.ent.phi.p.1}):} Let $i\in\left\{
1,2,\ldots,p\right\}  $ be such that $i\perp p$. From $i\perp p$, we obtain
$\gcd\left(  i,p\right)  =1$. If we had $i=p$, then we would have $\gcd\left(
\underbrace{i}_{=p},p\right)  =\gcd\left(  p,p\right)  =p\neq1$, which would
contradict $\gcd\left(  i,p\right)  =1$. Thus, we cannot have $i=p$. Hence, we
have $i\neq p$. Combining this with $i\in\left\{  1,2,\ldots,p\right\}  $, we
obtain $i\in\left\{  1,2,\ldots,p\right\}  \setminus\left\{  p\right\}
=\left\{  1,2,\ldots,p-1\right\}  $.

Now, forget that we fixed $i$. We thus have proven that every $i\in\left\{
1,2,\ldots,p\right\}  $ satisfying $i\perp p$ must belong to $\left\{
1,2,\ldots,p-1\right\}  $. In other words, $\left\{  i\in\left\{
1,2,\ldots,p\right\}  \ \mid\ i\perp p\right\}  \subseteq\left\{
1,2,\ldots,p-1\right\}  $. This proves (\ref{pf.prop.ent.phi.p.1}).]

Conversely, we have%
\begin{equation}
\left\{  1,2,\ldots,p-1\right\}  \subseteq\left\{  i\in\left\{  1,2,\ldots
,p\right\}  \ \mid\ i\perp p\right\}  . \label{pf.prop.ent.phi.p.2}%
\end{equation}


[\textit{Proof of (\ref{pf.prop.ent.phi.p.2}):} Let $j\in\left\{
1,2,\ldots,p-1\right\}  $. Thus, $j$ is coprime to $p$ (by Proposition
\ref{prop.ent.prime.each-i-coprime}, applied to $i=j$). In other words,
$j\perp p$. Also, $j\in\left\{  1,2,\ldots,p-1\right\}  \subseteq\left\{
1,2,\ldots,p\right\}  $. Hence, $j$ is an $i\in\left\{  1,2,\ldots,p\right\}
$ satisfying $i\perp p$. In other words, $j\in\left\{  i\in\left\{
1,2,\ldots,p\right\}  \ \mid\ i\perp p\right\}  $.

Now, forget that we fixed $j$. We thus have shown that $j\in\left\{
i\in\left\{  1,2,\ldots,p\right\}  \ \mid\ i\perp p\right\}  $ for each
$j\in\left\{  1,2,\ldots,p-1\right\}  $. In other words, $\left\{
1,2,\ldots,p-1\right\}  \subseteq\left\{  i\in\left\{  1,2,\ldots,p\right\}
\ \mid\ i\perp p\right\}  $. This proves (\ref{pf.prop.ent.phi.p.2}).]

Combining (\ref{pf.prop.ent.phi.p.1}) with (\ref{pf.prop.ent.phi.p.2}), we
obtain%
\[
\left\{  i\in\left\{  1,2,\ldots,p\right\}  \ \mid\ i\perp p\right\}
=\left\{  1,2,\ldots,p-1\right\}  .
\]
Now, (\ref{eq.def.ent.phi.phi.1}) (applied to $n=p$) yields%
\[
\phi\left(  p\right)  =\left\vert \underbrace{\left\{  i\in\left\{
1,2,\ldots,p\right\}  \ \mid\ i\perp p\right\}  }_{=\left\{  1,2,\ldots
,p-1\right\}  }\right\vert =\left\vert \left\{  1,2,\ldots,p-1\right\}
\right\vert =p-1.
\]
This proves Proposition \ref{prop.ent.phi.p}.
\end{fineprint}
\end{proof}

Proposition \ref{prop.ent.phi.p} can be generalized as follows:

\begin{exercise}
\label{exe.ent.phi.pk}Let $p$ be a prime. Let $k$ be a positive integer. Prove
that $\phi\left(  p^{k}\right)  =\left(  p-1\right)  p^{k-1}$.
\end{exercise}

\begin{theorem}
\label{thm.ent.phi.mult}Let $m$ and $n$ be two coprime positive integers.
Then, $\phi\left(  mn\right)  =\phi\left(  m\right)  \cdot\phi\left(
n\right)  $.
\end{theorem}

We will prove Theorem \ref{thm.ent.phi.mult} later (in Section
\ref{sect.ent.phi-fml-proof}).

\begin{theorem}
\label{thm.ent.phi.explicit}Let $n$ be a positive integer. Then,%
\[
\phi\left(  n\right)  =\prod_{\substack{p\text{ prime;}\\p\mid n}}\left(
\left(  p-1\right)  p^{v_{p}\left(  n\right)  -1}\right)  =n\cdot
\prod_{\substack{p\text{ prime;}\\p\mid n}}\left(  1-\dfrac{1}{p}\right)  .
\]

\end{theorem}

Theorem \ref{thm.ent.phi.explicit} will be proven in Section
\ref{sect.ent.phi-fml-proof}.

\begin{exercise}
\label{exe.ent.phi.d-phid}Let $n$ be a positive integer.

\textbf{(a)} Prove that%
\[
n-\phi\left(  n\right)  =\left\vert \left\{  i\in\left\{  1,2,\ldots
,n\right\}  \ \mid\ \text{we don't have }i\perp n\right\}  \right\vert .
\]


\textbf{(b)} We have $n-\phi\left(  n\right)  \geq0$.

\textbf{(c)} Let $d$ be a positive divisor of $n$. Prove that $d-\phi\left(
d\right)  \leq n-\phi\left(  n\right)  $.

\textbf{(d)} Let $d$ be a positive divisor of $n$ such that $d\neq n$. Prove
that $d-\phi\left(  d\right)  <n-\phi\left(  n\right)  $.
\end{exercise}

\subsubsection{The totient sum theorem}

\begin{theorem}
\label{thm.ent.phi.sum-div}Let $n$ be a positive integer. Then,%
\[
\sum_{d\mid n}\phi\left(  d\right)  =n.
\]
Here and in the following, the symbol \textquotedblleft$\sum_{d\mid n}%
$\textquotedblright\ stands for \textquotedblleft sum over all
\textbf{positive} divisors $d$ of $n$\textquotedblright.
\end{theorem}

For example, for $n=12$, Theorem \ref{thm.ent.phi.sum-div} states that%
\[
\phi\left(  1\right)  +\phi\left(  2\right)  +\phi\left(  3\right)
+\phi\left(  4\right)  +\phi\left(  6\right)  +\phi\left(  12\right)  =12.
\]


Before we prove Theorem \ref{thm.ent.phi.sum-div}, let us motivate an argument
via a classical puzzle:

\begin{exercise}
\label{exe.ent.phi.ghosts}You have a corridor with $1000$ lamps, which are
initially all off. Each lamp has a lightswitch controlling its state.

Every night, a ghost glides through the corridor (always in the same
direction) and flips some of the switches:

On the $1$st night, the ghost flips every switch.

On the $2$nd night, the ghost flips switches $2,4,6,8,10,\ldots$.

On the $3$rd night, the ghost flips switches $3,6,9,12,15,\ldots$.

etc.

(That is: For each $k\in\left\{  1,2,\ldots,1000\right\}  $, the ghost spends
the $k$-th night flipping switches $k,2k,3k,\ldots$.)

Which lamps will be on after $1000$ nights?
\end{exercise}

In more rigorous terms, Exercise \ref{exe.ent.phi.ghosts} is simply asking
which of the numbers $1,2,\ldots,1000$ have an odd number of positive
divisors. (Indeed, the situation after $1000$ nights looks as follows: For
each $n\in\left\{  1,2,\ldots,1000\right\}  $, the $n$-th switch has been
flipped exactly once for each positive divisor of $n$; thus, the $n$-th lamp
is on if and only if $n$ has an odd number of positive divisors.)

Experiments reveal that among the first $10$ positive integers, only three
have an odd number of positive divisors: namely, $1$, $4$ and $9$. (For
example, $9$ has the $3$ positive divisors $1$, $3$ and $9$.) This suggests
the following:

\begin{proposition}
\label{prop.ent.phi.ghosts}A positive integer $n$ has an odd number of
positive divisors if and only if $n$ is a perfect square.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ent.phi.ghosts}.]Fix a positive integer $n$.
If $d$ is a positive divisor of $n$, then $n/d$ is a positive divisor of $n$
as well\footnote{\textit{Proof.} Let $d$ be a positive divisor of $n$. Thus,
$d$ is a positive integer satisfying $d\mid n$. But Proposition
\ref{prop.ent.div.1} \textbf{(c)} (applied to $a=d$ and $b=n$) yields that
$d\mid n$ if and only if $\dfrac{n}{d}\in\mathbb{Z}$ (since $d\neq0$). Hence,
$\dfrac{n}{d}\in\mathbb{Z}$ (since $d\mid n$). In other words, $n/d\in
\mathbb{Z}$. Moreover, $n/d$ is positive (since $n$ and $d$ are positive).
\par
So $n/d$ is a positive integer (since $n/d\in\mathbb{Z}$) and is a divisor of
$n$ (since $n=\left(  n/d\right)  \cdot d$). Hence, $n/d$ is a positive
divisor of $n$. Qed.}. This allows us to define a map%
\begin{align*}
F:\left\{  \text{positive divisors of }n\right\}   &  \rightarrow\left\{
\text{positive divisors of }n\right\}  ,\\
d  &  \mapsto n/d.
\end{align*}
This map $F$ has the property that $F\circ F=\operatorname*{id}$, because each
$d\in\left\{  \text{positive divisors of }n\right\}  $ satisfies%
\begin{align*}
\left(  F\circ F\right)  \left(  d\right)   &  =F\left(  \underbrace{F\left(
d\right)  }_{\substack{=n/d\\\text{(by the definition of }F\text{)}}}\right)
=F\left(  n/d\right) \\
&  =n/\left(  n/d\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition
of }F\right) \\
&  =d=\operatorname*{id}\left(  d\right)  .
\end{align*}
Hence, the map $F$ is inverse to itself. Thus, the map $F$ is invertible,
i.e., is a bijection.

For the rest of this proof, the word \textquotedblleft
divisor\textquotedblright\ shall mean \textquotedblleft positive divisor of
$n$\textquotedblright. Thus, $F$ is a map from $\left\{  \text{divisors}%
\right\}  $ to $\left\{  \text{divisors}\right\}  $.

The rough idea from here on is the following:\footnote{We shall give a more
rigorous proof shortly.} The map $F$ \textquotedblleft pairs
up\textquotedblright\ each divisor $d$ with the divisor $F\left(  d\right)
=n/d$. Thus, the divisors are \textquotedblleft grouped into
pairs\textquotedblright, except for those that satisfy $d=n/d$ (because these
would have to be paired up with themselves). When $n$ is not a perfect square,
there are no such \textquotedblleft exceptional\textquotedblright\ divisors,
since $d=n/d$ means $n=d^{2}$. When $n$ is a perfect square, there is exactly
one such \textquotedblleft exceptional\textquotedblright\ divisor, namely
$\sqrt{n}$. So the number of divisors is even if $n$ is not a perfect square,
and odd otherwise (because clearly, all the pairs have no effect on the parity
of the total number of divisors, and thus can be forgotten). In other words,
$n$ has an odd number of positive divisors if and only if $n$ is a perfect square.

\begin{fineprint}
There are several ways to make this argument rigorous; here is the easiest
(though perhaps the least instructive one): A divisor $d$ shall be called

\begin{itemize}
\item \textit{small} if $d<n/d$;

\item \textit{medium} if $d=n/d$;

\item \textit{large} if $d>n/d$.
\end{itemize}

It is easy to see that if $d$ is a small divisor, then $F\left(  d\right)  $
is a large divisor\footnote{\textit{Proof.} Let $d$ be a small divisor. Thus,
$d<n/d$. Hence, $n/d>d=n/\left(  n/d\right)  $. In view of $F\left(  d\right)
=n/d$, this rewrites as $F\left(  d\right)  >n/\left(  F\left(  d\right)
\right)  $. In other words, $F\left(  d\right)  $ is a large divisor (by the
definition of \textquotedblleft large divisor\textquotedblright). Qed.}.
Hence, the map%
\begin{align*}
F^{+}:\left\{  \text{small divisors}\right\}   &  \rightarrow\left\{
\text{large divisors}\right\}  ,\\
d  &  \mapsto F\left(  d\right)
\end{align*}
is well-defined. Similarly, the map%
\begin{align*}
F^{-}:\left\{  \text{large divisors}\right\}   &  \rightarrow\left\{
\text{small divisors}\right\}  ,\\
d  &  \mapsto F\left(  d\right)
\end{align*}
is well-defined. These two maps $F^{+}$ and $F^{-}$ are both restrictions of
the map $F$, and thus are mutually inverse (since the map $F$ is inverse to
itself). Hence, the map $F^{+}$ is invertible, i.e., is a bijection. Thus, we
have found a bijection from $\left\{  \text{small divisors}\right\}  $ to
$\left\{  \text{large divisors}\right\}  $ (namely, $F^{+}$). Therefore,%
\begin{equation}
\left\vert \left\{  \text{small divisors}\right\}  \right\vert =\left\vert
\left\{  \text{large divisors}\right\}  \right\vert .
\label{pf.prop.ent.phi.ghosts.s=l}%
\end{equation}


On the other hand, let us take a look at medium divisors. If $d$ is a medium
divisor, then $d=n/d$ (by the definition of \textquotedblleft
medium\textquotedblright), so that $d^{2}=n$ and thus $n$ must be a perfect
square. Thus, if $n$ is \textbf{not} a perfect square, then there are no
medium divisors. In other words, if $n$ is \textbf{not} a perfect square, then%
\begin{equation}
\left\vert \left\{  \text{medium divisors}\right\}  \right\vert =0.
\label{pf.prop.ent.phi.ghosts.m0}%
\end{equation}


But if $n$ \textbf{is} a perfect square, then $n$ has exactly one medium
divisor\footnote{\textit{Proof.} Assume that $n$ is a perfect square. Thus,
$n=w^{2}$ for some $w\in\mathbb{Z}$. Consider this $w$. Clearly, $w\neq0$
(since $ww=w^{2}=n\neq0$), so that $\left\vert w\right\vert >0$.
\par
Let $u=\left\vert w\right\vert $. Thus, $u\in\mathbb{Z}$ (since $w\in
\mathbb{Z}$). Hence, $u$ is a positive integer (since $u=\left\vert
w\right\vert >0$). Moreover, from $u=\left\vert w\right\vert $, we obtain
$u^{2}=\left\vert w\right\vert ^{2}=w^{2}=n$. Hence, $u=n/u$.
\par
This positive integer $u$ satisfies $uu=u^{2}=n$ and thus $u\mid n$. Hence,
$u$ is a positive divisor of $n$ (that is, a divisor, as we call it). This
divisor $u$ is medium, since it satisfies $u=n/u$.
\par
Moreover, if $d$ is any medium divisor, then $d=n/d$ (by the definition of
\textquotedblleft medium\textquotedblright), thus $d^{2}=n=u^{2}$, thus
$\sqrt{d^{2}}=\sqrt{u^{2}}=\left\vert u\right\vert =u$ (since $u$ is
positive), thus $u=\sqrt{d^{2}}=\left\vert d\right\vert =d$ (since $d$ is
positive) and therefore $d=u$. In other words, any medium divisor must equal
$u$. This shows that $u$ is the \textbf{only} medium divisor (since we already
know that $u$ is a medium divisor). Hence, $n$ has exactly one medium
divisor.}. In other words, if $n$ \textbf{is} a perfect square, then%
\begin{equation}
\left\vert \left\{  \text{medium divisors}\right\}  \right\vert =1.
\label{pf.prop.ent.phi.ghosts.m1}%
\end{equation}


But each divisor is either small or medium or large, and there are no overlaps
between these three classes (i.e., a divisor cannot be small and medium at the
same time, or small and large, or medium and large). Thus, in order to count
the number of all divisors, we can add the number of small divisors, the
number of medium divisors and the number of large divisors. In other words:%
\begin{align*}
\left\vert \left\{  \text{divisors}\right\}  \right\vert  &
=\underbrace{\left\vert \left\{  \text{small divisors}\right\}  \right\vert
}_{\substack{=\left\vert \left\{  \text{large divisors}\right\}  \right\vert
\\\text{(by (\ref{pf.prop.ent.phi.ghosts.s=l}))}}}+\left\vert \left\{
\text{medium divisors}\right\}  \right\vert +\left\vert \left\{  \text{large
divisors}\right\}  \right\vert \\
&  =\left\vert \left\{  \text{large divisors}\right\}  \right\vert +\left\vert
\left\{  \text{medium divisors}\right\}  \right\vert +\left\vert \left\{
\text{large divisors}\right\}  \right\vert \\
&  =\underbrace{2\cdot\left\vert \left\{  \text{large divisors}\right\}
\right\vert }_{\equiv0\operatorname{mod}2}+\left\vert \left\{  \text{medium
divisors}\right\}  \right\vert \\
&  \equiv\left\vert \left\{  \text{medium divisors}\right\}  \right\vert
\operatorname{mod}2.
\end{align*}


Hence, if $n$ is \textbf{not} a perfect square, then%
\[
\left\vert \left\{  \text{divisors}\right\}  \right\vert \equiv\left\vert
\left\{  \text{medium divisors}\right\}  \right\vert =0\operatorname{mod}2
\]
(by (\ref{pf.prop.ent.phi.ghosts.m0})). In other words, if $n$ is \textbf{not}
a perfect square, then the number of divisors is even.

On the other hand, if $n$ \textbf{is} a perfect square, then%
\[
\left\vert \left\{  \text{divisors}\right\}  \right\vert \equiv\left\vert
\left\{  \text{medium divisors}\right\}  \right\vert =1\operatorname{mod}2
\]
(by (\ref{pf.prop.ent.phi.ghosts.m1})). In other words, if $n$ \textbf{is} a
perfect square, then the number of divisors is odd.

Combining the results of the previous two paragraphs, we conclude that the
number of divisors is odd if $n$ is a perfect square, and is even otherwise.
In other words, $n$ has an odd number of positive divisors if and only if $n$
is a perfect square. This proves Proposition \ref{prop.ent.phi.ghosts}.
\end{fineprint}
\end{proof}

Having proven Proposition \ref{prop.ent.phi.ghosts}, we now can answer
Exercise \ref{exe.ent.phi.ghosts}: The $31$ lamps $1^{2},2^{2},\ldots,31^{2}$
(and no others) will be on after the $1000$ nights. (Indeed, these $31$ lamps
correspond to the $31$ perfect squares in the set $\left\{  1,2,\ldots
,1000\right\}  $.)

The bijection $F$ from the proof of Proposition \ref{prop.ent.phi.ghosts} will
serve us well in our proof of Theorem \ref{thm.ent.phi.sum-div}. Beside that,
we need the following lemma:

\begin{lemma}
\label{lem.ent.phi.sum-div.n/d}Let $n$ be a positive integer. Let $d$ be a
positive divisor of $n$. Then,%
\[
\left(  \text{the number of }i\in\left\{  1,2,\ldots,n\right\}  \text{ such
that }\gcd\left(  i,n\right)  =d\right)  =\phi\left(  n/d\right)  .
\]

\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.phi.sum-div.n/d}.]We have $d\mid n$ (since $d$ is
a divisor of $n$) and $d\neq0$ (since $d$ is positive). Thus, Proposition
\ref{prop.ent.div.1} \textbf{(c)} (applied to $d$ and $n$ instead of $a$ and
$b$) yields that $d\mid n$ if and only if $\dfrac{n}{d}\in\mathbb{Z}$. Thus,
$\dfrac{n}{d}\in\mathbb{Z}$ (since $d\mid n$). In other words, $n/d\in
\mathbb{Z}$. Thus, $n/d$ is an integer. This integer $n/d$ is positive (since
$n$ and $d$ are positive). Hence, $\phi\left(  n/d\right)  $ is well-defined.

Define two sets $I$ and $J$ by%
\begin{equation}
I=\left\{  i\in\left\{  1,2,\ldots,n\right\}  \ \mid\ \gcd\left(  i,n\right)
=d\right\}  \label{pf.lem.ent.phi.sum-div.n/d.I=}%
\end{equation}
and%
\begin{equation}
J=\left\{  i\in\left\{  1,2,\ldots,n/d\right\}  \ \mid\ i\perp n/d\right\}  .
\label{pf.lem.ent.phi.sum-div.n/d.J=}%
\end{equation}
But (\ref{eq.def.ent.phi.phi.1}) (applied to $n/d$ instead of $n$) yields%
\begin{equation}
\phi\left(  n/d\right)  =\left\vert \left\{  i\in\left\{  1,2,\ldots
,n/d\right\}  \ \mid\ i\perp n/d\right\}  \right\vert =\left\vert J\right\vert
\label{pf.lem.ent.phi.sum-div.n/d.2}%
\end{equation}
(since $\left\{  i\in\left\{  1,2,\ldots,n/d\right\}  \ \mid\ i\perp
n/d\right\}  =J$).

We shall next construct a bijection from $I$ to $J$ (which will show that
$\left\vert I\right\vert =\left\vert J\right\vert $).

For each $a\in I$, we have $a/d\in J$\ \ \ \ \footnote{\textit{Proof.} Let
$a\in I$. Thus, $a\in I=\left\{  i\in\left\{  1,2,\ldots,n\right\}
\ \mid\ \gcd\left(  i,n\right)  =d\right\}  $. In other words, $a$ is an
element of $\left\{  1,2,\ldots,n\right\}  $ satisfying $\gcd\left(
a,n\right)  =d$.
\par
Thus, $d=\gcd\left(  a,n\right)  \mid a$. But Proposition \ref{prop.ent.div.1}
\textbf{(c)} (applied to $d$ and $a$ instead of $a$ and $b$) yields that
$d\mid a$ if and only if $\dfrac{a}{d}\in\mathbb{Z}$. Thus, $\dfrac{a}{d}%
\in\mathbb{Z}$ (since $d\mid a$). In other words, $a/d\in\mathbb{Z}$. Also,
$a\in\left\{  1,2,\ldots,n\right\}  $, so that $0<a\leq n$. We can divide this
chain of inequalities by $d$ (since $d$ is positive), and thus obtain
$0<a/d\leq n/d$. Hence, $a/d\in\left\{  1,2,\ldots,n/d\right\}  $ (since
$a/d\in\mathbb{Z}$). Furthermore, Corollary \ref{cor.ent.gcd.sa,sb} (applied
to $d$, $a/d$ and $n/d$ instead of $s$, $a$ and $b$) yields%
\[
\gcd\left(  d\left(  a/d\right)  ,d\left(  n/d\right)  \right)
=\underbrace{\left\vert d\right\vert }_{\substack{=d\\\text{(since }d\text{ is
positive)}}}\gcd\left(  a/d,n/d\right)  =d\gcd\left(  a/d,n/d\right)  .
\]
Solving this for $\gcd\left(  a/d,n/d\right)  $, we obtain%
\[
\gcd\left(  a/d,n/d\right)  =\dfrac{1}{d}\gcd\left(  \underbrace{d\left(
a/d\right)  }_{=a},\underbrace{d\left(  n/d\right)  }_{=n}\right)  =\dfrac
{1}{d}\underbrace{\gcd\left(  a,n\right)  }_{=d}=\dfrac{1}{d}d=1.
\]
In other words, $a/d\perp n/d$.
\par
So we know that $a/d$ is an element of $\left\{  1,2,\ldots,n/d\right\}  $
satisfying $a/d\perp n/d$. In other words, $a/d\in\left\{  i\in\left\{
1,2,\ldots,n/d\right\}  \ \mid\ i\perp n/d\right\}  =J$. Qed.}. Hence, we can
define a map%
\begin{align*}
f:I  &  \rightarrow J,\\
a  &  \mapsto a/d.
\end{align*}


For each $b\in J$, we have $bd\in I$\ \ \ \ \footnote{\textit{Proof.} Let
$b\in J$. Thus, $b\in J=\left\{  i\in\left\{  1,2,\ldots,n/d\right\}
\ \mid\ i\perp n/d\right\}  $. In other words, $b$ is an element of $\left\{
1,2,\ldots,n/d\right\}  $ satisfying $b\perp n/d$.
\par
From $b\in\left\{  1,2,\ldots,n/d\right\}  \subseteq\mathbb{Z}$ and
$d\in\mathbb{Z}$, we obtain $bd\in\mathbb{Z}$. From $b\in\left\{
1,2,\ldots,n/d\right\}  $, we obtain $0<b\leq n/d$. We can multiply this chain
of inequalities by $d$ (since $d$ is positive), and thus obtain $0<bd\leq n$.
Thus, $bd\in\left\{  1,2,\ldots,n\right\}  $ (since $bd\in\mathbb{Z}$).
Corollary \ref{cor.ent.gcd.sa,sb} (applied to $d$, $b$ and $n/d$ instead of
$s$, $a$ and $b$) yields%
\[
\gcd\left(  db,d\left(  n/d\right)  \right)  =\underbrace{\left\vert
d\right\vert }_{\substack{=d\\\text{(since }d\text{ is positive)}%
}}\underbrace{\gcd\left(  b,n/d\right)  }_{\substack{=1\\\text{(since }b\perp
n/d\text{)}}}=d.
\]
Thus, $d=\gcd\left(  \underbrace{db}_{=bd},\underbrace{d\left(  n/d\right)
}_{=n}\right)  =\gcd\left(  bd,n\right)  $, so that $\gcd\left(  bd,n\right)
=d$.
\par
So we know that $bd$ is an element of $\left\{  1,2,\ldots,n\right\}  $
satisfying $\gcd\left(  bd,n\right)  =d$. In other words, $bd\in\left\{
i\in\left\{  1,2,\ldots,n\right\}  \ \mid\ \gcd\left(  i,n\right)  =d\right\}
=I$, qed.}. Thus, we can define a map%
\begin{align*}
g:J  &  \rightarrow I,\\
b  &  \mapsto bd.
\end{align*}


The two maps $f$ and $g$ are mutually inverse (since the map $f$ divides its
input by $d$, while the map $g$ multiplies its input by $d$). Hence, $f$ is
invertible, i.e., is a bijection. Thus, there exists a bijection from $I$ to
$J$ (namely, $f$). Hence, $\left\vert I\right\vert =\left\vert J\right\vert
=\phi\left(  n/d\right)  $ (by (\ref{pf.lem.ent.phi.sum-div.n/d.2})). Thus,%
\begin{align*}
\phi\left(  n/d\right)   &  =\left\vert I\right\vert =\left\vert \left\{
i\in\left\{  1,2,\ldots,n\right\}  \ \mid\ \gcd\left(  i,n\right)  =d\right\}
\right\vert \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.lem.ent.phi.sum-div.n/d.I=})}\right) \\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,n\right\}  \text{
such that }\gcd\left(  i,n\right)  =d\right)  .
\end{align*}
This proves Lemma \ref{lem.ent.phi.sum-div.n/d}.
\end{proof}

\begin{proof}
[Proof of Theorem \ref{thm.ent.phi.sum-div}.]Consider the map $F$ we defined
in the proof of Proposition \ref{prop.ent.phi.ghosts}. This map $F$ is a
bijection (as we have seen back in that proof). In other words, the map%
\begin{align*}
\left\{  \text{positive divisors of }n\right\}   &  \rightarrow\left\{
\text{positive divisors of }n\right\}  ,\\
d  &  \mapsto n/d
\end{align*}
is a bijection (since this is precisely the map $F$). Thus, we can substitute
$n/d$ for $d$ in the sum $\sum_{d\mid n}\phi\left(  d\right)  $ (and, more
generally, in any sum that ranges over all positive divisors $d$ of $n$). We
thus obtain%
\begin{equation}
\sum_{d\mid n}\phi\left(  d\right)  =\sum_{d\mid n}\phi\left(  n/d\right)  .
\label{pf.thm.ent.phi.sum-div.subst}%
\end{equation}


But%
\begin{align*}
n  &  =\left\vert \left\{  1,2,\ldots,n\right\}  \right\vert =\left(
\text{the number of }i\in\left\{  1,2,\ldots,n\right\}  \right) \\
&  =\sum_{d\mid n}\underbrace{\left(  \text{the number of }i\in\left\{
1,2,\ldots,n\right\}  \text{ such that }\gcd\left(  i,n\right)  =d\right)
}_{\substack{=\phi\left(  n/d\right)  \\\text{(by Lemma
\ref{lem.ent.phi.sum-div.n/d})}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{because if }i\in\left\{  1,2,\ldots
,n\right\}  \text{, then }\gcd\left(  i,n\right)  \text{ is a positive divisor
of }n\right) \\
&  =\sum_{d\mid n}\phi\left(  n/d\right)  =\sum_{d\mid n}\phi\left(  d\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.thm.ent.phi.sum-div.subst}%
)}\right)  .
\end{align*}
This proves Theorem \ref{thm.ent.phi.sum-div}.
\end{proof}

\begin{exercise}
\label{exe.ent.phi.even}Let $n\in\mathbb{N}$ satisfy $n>2$. Prove that
$\phi\left(  n\right)  $ is even.
\end{exercise}

\begin{exercise}
\label{exe.ent.phi.gauss}Let $n\in\mathbb{N}$ satisfy $n>1$. Prove that
\[
\sum_{\substack{i\in\left\{  1,2,\ldots,n\right\}  ;\\i\perp n}}i=n\phi\left(
n\right)  /2.
\]

\end{exercise}

\begin{center}
\textbf{2019-02-15 lecture}
\end{center}

\subsection{Fermat, Euler, Wilson}

\subsubsection{Fermat and Euler: statements}

The following theorem is known as \textit{Fermat's Little Theorem} (often
abbreviated as \textquotedblleft FLT\textquotedblright):

\begin{theorem}
\label{thm.ent.fermat}Let $p$ be a prime. Let $a\in\mathbb{Z}$.

\textbf{(a)} If $p\nmid a$, then $a^{p-1}\equiv1\operatorname{mod}p$.

\textbf{(b)} We always have $a^{p}\equiv a\operatorname{mod}p$.
\end{theorem}

The word \textquotedblleft little\textquotedblright\ in the name of Theorem
\ref{thm.ent.fermat} is meant to distinguish the theorem from
\textquotedblleft%
\href{https://en.wikipedia.org/wiki/Fermat's_Last_Theorem}{Fermat's Last
Theorem}\textquotedblright, a much more difficult result only proven in the
1990s. (Unfortunately, the latter result is also abbreviated as
\textquotedblleft FLT\textquotedblright.)

We will prove Theorem \ref{thm.ent.fermat} soon, by showing a more general
result (Theorem \ref{thm.ent.euler}). But before we do so, let us convince
ourselves that the parts \textbf{(a)} and \textbf{(b)} of Theorem
\ref{thm.ent.fermat} are equivalent:

\begin{remark}
Theorem \ref{thm.ent.fermat} \textbf{(b)} follows from Theorem
\ref{thm.ent.fermat} \textbf{(a)}, because (using the notations of Theorem
\ref{thm.ent.fermat}):

\begin{itemize}
\item If $p\nmid a$, then Theorem \ref{thm.ent.fermat} \textbf{(a)} yields
$a^{p-1}\equiv1\operatorname{mod}p$, thus $a^{p}=a\underbrace{a^{p-1}}%
_{\equiv1\operatorname{mod}p}\equiv a1=a\operatorname{mod}p$.

\item If $p\mid a$, then both $a^{p}$ and $a$ are $\equiv0\operatorname{mod}p$
(because $p\mid a$ entails $a\equiv0\operatorname{mod}p$ and thus $a^{p}%
\equiv0^{p}=0\operatorname{mod}p$ (since $p>0$)), and therefore $a^{p}%
\equiv0\equiv a\operatorname{mod}p$.
\end{itemize}

Conversely, Theorem \ref{thm.ent.fermat} \textbf{(a)} follows from Theorem
\ref{thm.ent.fermat} \textbf{(b)} by the following argument: Let $p$ and $a$
be as in Theorem \ref{thm.ent.fermat}. Assume that $p\nmid a$. Then, $p\perp
a$ (by Proposition \ref{prop.ent.prime.div-or-coprime}), so that $a\perp p$.
Thus, we can \textquotedblleft cancel\textquotedblright\ $a$ from any
congruence modulo $p$ (by Lemma \ref{lem.ent.coprime.cancel}). Doing this to
the congruence $a^{p}\equiv a\operatorname{mod}p$ (which follows from Theorem
\ref{thm.ent.fermat} \textbf{(b)}), we obtain $a^{p-1}\equiv
1\operatorname{mod}p$.
\end{remark}

The next result is known as \textit{Euler's theorem}:

\begin{theorem}
\label{thm.ent.euler}Let $n$ be a positive integer. Let $a\in\mathbb{Z}$ be
coprime to $n$.

Then, $a^{\phi\left(  n\right)  }\equiv1\operatorname{mod}n$.
\end{theorem}

Theorem \ref{thm.ent.euler} yields Theorem \ref{thm.ent.fermat} \textbf{(a)},
since $\phi\left(  p\right)  =p-1$ when $p$ is prime\footnote{See below for
details of this argument.}. Since we also know that Theorem
\ref{thm.ent.fermat} \textbf{(b)} follows from Theorem \ref{thm.ent.fermat}
\textbf{(a)}, we see that a proof of Theorem \ref{thm.ent.euler} will
immediately yield the whole Theorem \ref{thm.ent.fermat}. Before we give said
proof, let us show an example of how Theorem \ref{thm.ent.euler} can be used:

\begin{exercise}
\label{exe.ent.euler345}What is the last digit of $3^{4^{5}}$?

\textit{Notational remark:} An expression of the form \textquotedblleft%
$a^{b^{c}}$\textquotedblright\ always means $a^{\left(  b^{c}\right)  }$, not
$\left(  a^{b}\right)  ^{c}$. (Actually, there is no need for an extra
notation for $\left(  a^{b}\right)  ^{c}$, because $\left(  a^{b}\right)
^{c}=a^{bc}$.)
\end{exercise}

\begin{proof}
[Solution to Exercise \ref{exe.ent.euler345} (sketched).]The last digit of a
positive integer $n$ is $n\%10$ (that is, the remainder of $n$ upon division
by $10$). So we need to work modulo $10$.

Since $3$ is coprime to $10$, we can apply Theorem \ref{thm.ent.euler} to
$n=10$ and $a=3$. We thus get $3^{\phi\left(  10\right)  }\equiv
1\operatorname{mod}10$. Since $\phi\left(  10\right)  =4$, this rewrites as
$3^{4}\equiv1\operatorname{mod}10$. Now, $4^{5}=4\cdot4^{4}$, so that%
\[
3^{4^{5}}=3^{4\cdot4^{4}}=\left(  \underbrace{3^{4}}_{\equiv
1\operatorname{mod}10}\right)  ^{4^{4}}\equiv1^{4^{4}}=1\operatorname{mod}10.
\]
So the last digit of $3^{4^{5}}$ is $1$.
\end{proof}

Theorem \ref{thm.ent.euler} is also the reason why certain rational numbers
(such as $\dfrac{2}{7}=0.\overline{285714}$\ \ \ \ \footnote{The bar
($\overline{}$) over the \textquotedblleft$285714$\textquotedblright\ means
that we are repeating $285714$ over and over. So $0.\overline{285714}%
=0.285714285714285714\ldots$.}) have purely periodic decimal expansions, while
others (such as $\dfrac{1}{12}=0.08\overline{3}=0.0833333\ldots$ or $\dfrac
{1}{2}=0.5\overline{0}=0.50000\ldots$) have their periods start only after
some initial nonrepeating block. We refer \cite[\S 4]{Conrad-Euler} to the
details of this.\footnote{In brief, the rule is as follows: Any fraction
$\dfrac{a}{b}$ with $a,b\in\mathbb{Z}$ (and $b\neq0$) has such a decimal
representation with a period. (A \textit{period} means a part that gets
repeated over and over.) A fraction $\dfrac{a}{b}$ is called \textit{purely
periodic} if its period (in decimal notation) begins straight after the
decimal point. So $\dfrac{2}{7}$ is purely periodic but $\dfrac{1}{12}$ and
$\dfrac{1}{2}$ are not. Now, the answer is that a fraction $\dfrac{a}{b}$
(with $a\perp b$) is purely periodic if and only if $b\perp10$ (in other
words, $2\nmid b$ and $5\nmid b$). This can be proven using Theorem
\ref{thm.ent.euler}.}

\subsubsection{Proving Euler and Fermat}

Our proof of Theorem \ref{thm.ent.euler} will rely on the following lemma:

\begin{lemma}
\label{lem.ent.euler.phi0}Let $n$ be a positive integer. Then,%
\[
\phi\left(  n\right)  =\left\vert \left\{  i\in\left\{  0,1,\ldots
,n-1\right\}  \ \mid\ i\perp n\right\}  \right\vert .
\]

\end{lemma}

\begin{proof}
[First proof of Lemma \ref{lem.ent.euler.phi0} (sketched).]If $n=1$, then this
lemma can easily be proven by hand. Thus, WLOG assume that $n\neq1$. Hence,
$n>1$ (since $n$ is a positive integer). Thus, neither $0$ nor $n$ is coprime
to $n$ (since $\gcd\left(  0,n\right)  =n>1$ and $\gcd\left(  n,n\right)
=n>1$). Hence,%
\[
\left\{  i\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ i\perp n\right\}
=\left\{  i\in\left\{  1,2,\ldots,n\right\}  \ \mid\ i\perp n\right\}
\]
(because these sets could only differ in the elements $0$ and $n$, but none of
these two elements belongs to any of these two sets\footnote{since neither $0$
nor $n$ is coprime to $n$}), and therefore%
\[
\left\vert \left\{  i\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ i\perp
n\right\}  \right\vert =\left\vert \left\{  i\in\left\{  1,2,\ldots,n\right\}
\ \mid\ i\perp n\right\}  \right\vert =\phi\left(  n\right)
\]
(by \eqref{eq.def.ent.phi.phi.1}). This proves Lemma \ref{lem.ent.euler.phi0}.
\end{proof}

\begin{proof}
[Second proof of Lemma \ref{lem.ent.euler.phi0}.]We have $n \mid n$ and thus
$n \equiv0 \mod n$. Hence, Proposition \ref{prop.ent.gcd.props1} \textbf{(d)}
(applied to $a = n$, $b = n$ and $c = 0$) yields that $\gcd\left(  n, n
\right)  = \gcd\left(  n, 0 \right)  = \gcd\left(  0, n \right)  $ (by
Proposition \ref{prop.ent.gcd.props1} \textbf{(b)}). Hence, $\gcd\left(  0, n
\right)  = 1$ holds if and only if $\gcd\left(  n, n \right)  = 1$. In other
words, the number $0$ is coprime to $n$ if and only if $n$ is coprime to $n$.
Hence, if we remove $n$ from the set $\left\{  1,2,\ldots,n\right\}  $ and add
$0$ instead (so that our set becomes $\left\{  0, 1, \ldots, n-1 \right\}  $),
then the number of elements coprime to $n$ in that set does not change. In
other words,
\begin{align*}
&  \left(  \text{the number of all } i\in\left\{  0,1,\ldots,n-1\right\}
\text{ that are coprime to } n \right) \\
&  = \left(  \text{the number of all } i\in\left\{  1,2,\ldots,n\right\}
\text{ that are coprime to } n \right) \\
&  = \left\vert \left\{  i\in\left\{  1,2,\ldots,n\right\}  \ \mid\ i\perp
n\right\}  \right\vert =\phi\left(  n\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by \eqref{eq.def.ent.phi.phi.1}} \right)  .
\end{align*}
In other words,
\begin{align*}
\phi\left(  n \right)   &  = \left(  \text{the number of all } i\in\left\{
0,1,\ldots,n-1\right\}  \text{ that are coprime to } n \right) \\
&  = \left\vert \left\{  i\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ i\perp
n\right\}  \right\vert .
\end{align*}
This proves Lemma \ref{lem.ent.euler.phi0} again.
\end{proof}

\begin{noncompile}
We will also need a fact about modular inverses, which we state as an
exercise. Namely, recall that Theorem \ref{thm.ent.coprime.modinv}
\textbf{(b)} guarantees the existence of a modular inverse for an integer $a$
modulo an integer $n$ as soon as $a$ and $n$ are coprime. We can slightly
improve this to guarantee a modular inverse that belongs to $\left\{  0, 1,
\ldots, n-1 \right\}  $ as long as $n$ is a positive integer:

\begin{exercise}
\label{exe.ent.coprime.modinv-in-set}Let $a$ be an integer, and $n$ be a
positive integer such that $a \perp n$. Then, there exists an $a^{\prime}%
\in\left\{  0,1,\ldots,n-1 \right\}  $ such that $aa^{\prime}\equiv
1\operatorname{mod}n$.
\end{exercise}

\begin{fineprint}
\begin{proof}
[Solution to Exercise \ref{exe.ent.coprime.modinv-in-set}.]Theorem
\ref{thm.ent.coprime.modinv} \textbf{(b)} shows that there exists an
$a^{\prime}\in\mathbb{Z}$ such that $aa^{\prime}\equiv1\operatorname{mod}n$.
Consider this $a^{\prime}$, and denote it by $u$. Thus, $u$ is an element of
$\mathbb{Z}$ and satisfies $au \equiv1 \mod n$. Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(a)} yields that $u\%n\in\left\{
0,1,\ldots,n-1\right\}  $ and $u\%n\equiv u\operatorname{mod}n$. Multiplying
the congruences $a \equiv a \mod n$ and $u \% n \equiv u \mod n$ together, we
find $a \left(  u\%n \right)  \equiv au \equiv1 \mod n$. Hence, there exists
an $a^{\prime}\in\left\{  0,1,\ldots,n-1 \right\}  $ such that $aa^{\prime
}\equiv1\operatorname{mod}n$ (namely, $a^{\prime} = u \% n$). This solves
Exercise \ref{exe.ent.coprime.modinv-in-set}.
\end{proof}
\end{fineprint}
\end{noncompile}

\begin{proof}
[Proof of Theorem \ref{thm.ent.euler}.]Let
\[
C=\left\{  i\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ i\perp n\right\}  .
\]
Then, Lemma \ref{lem.ent.euler.phi0} says that $\phi\left(  n\right)
=\left\vert C\right\vert $.

Now, set
\begin{equation}
z=\prod_{i\in C}i. \label{pf.thm.ent.euler.z=}%
\end{equation}
Exercise \ref{exe.ent.coprime.ab-to-cI} (applied to $I=C$, $c=n$ and $b_{i}%
=i$) yields $\prod_{i\in C}i\perp n$ (since each $i\in C$ satisfies $i\perp
n$). In other words, $z\perp n$ (since $z=\prod_{i\in C}i$).

We have $\left(  ai\right)  \%n\in C$ for each $i\in C$.

[\textit{Proof:} Let $i\in C$. Corollary \ref{cor.ent.quo-rem.remmod}
\textbf{(a)} (applied to $u=ai$) yields that $\left(  ai\right)
\%n\in\left\{  0,1,\ldots,n-1\right\}  $ and $\left(  ai\right)  \%n\equiv
ai\operatorname{mod}n$. Thus, $ai\equiv\left(  ai\right)
\%n\operatorname{mod}n$.

From $a\perp n$ and $i\perp n$, we obtain $ai\perp n$ (by Theorem
\ref{thm.ent.coprime.ab-to-c}, applied to $i$ and $n$ instead of $b$ and $c$).
Hence, Exercise \ref{exe.ent.coprime.b==c} (applied to $ai$, $\left(
ai\right)  \%n$ and $n$ instead of $a$, $b$ and $c$) yields $\left(
ai\right)  \%n\perp n$ (since $ai\equiv\left(  ai\right)
\%n\operatorname{mod}n$). Combining this with $\left(  ai\right)
\%n\in\left\{  0,1,\ldots,n-1\right\}  $, we obtain $\left(  ai\right)  \%n\in
C$ (by the definition of $C$), qed.]

Thus, we can define a map%
\begin{align*}
f:C  &  \rightarrow C,\\
i  &  \mapsto\left(  ai\right)  \%n.
\end{align*}


The map $f$ is injective.

[\textit{Proof:} Let $i$ and $j$ be two elements of $C$ such that $f\left(
i\right)  =f\left(  j\right)  $. We must prove that $i=j$.

We have $f\left(  i\right)  =f\left(  j\right)  $. In view of $f\left(
i\right)  =\left(  ai\right)  \%n$ (by the definition of $f$) and $f\left(
j\right)  =\left(  aj\right)  \%n$, this rewrites as $\left(  ai\right)
\%n=\left(  aj\right)  \%n$. But Exercise \ref{exe.ent.quo-rem.mod=rem}
(applied to $u=ai$ and $v=aj$) shows that $ai\equiv aj\operatorname{mod}n$ if
and only if $\left(  ai\right)  \%n=\left(  aj\right)  \%n$. Hence, we have
$ai\equiv aj\operatorname{mod}n$ (since $\left(  ai\right)  \%n=\left(
aj\right)  \%n$). By Lemma \ref{lem.ent.coprime.cancel}, we can
\textquotedblleft cancel\textquotedblright\ $a$ from this congruence (since
$a\perp n$), and obtain $i\equiv j\operatorname{mod}n$. But both $i$ and $j$
belong to $C$ and thus belong to $\left\{  0,1,\ldots,n-1\right\}  $ (by the
definition of $C$). Hence, from $i\equiv j\operatorname{mod}n$, we can easily
obtain that $i=j$\ \ \ \ \footnote{\textit{Proof.} Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(c)} (applied to $u=j$ and $c=i$) yields
$i=j\%n$ (since $i\equiv j\operatorname{mod}n$ and $i\in\left\{
0,1,\ldots,n-1\right\}  $). But Corollary \ref{cor.ent.quo-rem.remmod}
\textbf{(c)} (applied to $u=j$ and $c=j$) yields $j=j\%n$ (since $j\equiv
j\operatorname{mod}n$ and $j\in\left\{  0,1,\ldots,n-1\right\}  $). Hence,
$i=j\%n=j$.}.

Now, forget that we fixed $i$ and $j$. We thus have proven that if $i$ and $j$
and two elements of $C$ such that $f\left(  i\right)  =f\left(  j\right)  $,
then $i=j$. In other words, $f$ is injective.]

The map $f$ is surjective.

[\textit{Proof:} Let $i\in C$. We shall prove that $i\in f\left(  C\right)  $.

Indeed, $i\in C$. By the definition of $C$, this means that $i\in\left\{
0,1,\ldots,n-1\right\}  $ and $i\perp n$.

But Proposition \ref{thm.ent.coprime.modinv} \textbf{(b)} shows that there
exists an $a^{\prime}\in\mathbb{Z}$ such that $aa^{\prime}\equiv
1\operatorname{mod}n$ (since $a\perp n$). Consider this $a^{\prime}$, and
denote it by $u$. Thus, $u$ is an element of $\mathbb{Z}$ and satisfies
$au\equiv1\mod n$. From $ua=au\equiv1\mod n$, we conclude that there exists an
$u^{\prime}\in\mathbb{Z}$ such that $uu^{\prime}\equiv1\mod n$ (namely,
$u^{\prime}=a$). Hence, Theorem \ref{thm.ent.coprime.modinv} \textbf{(c)}
(applied to $u$ and $u^{\prime}$ instead of $a$ and $a^{\prime}$) shows that
$u\perp n$.

Now, Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(a)} (applied to $ui$
instead of $u$) shows that $\left(  ui\right)  \%n\in\left\{  0,1,\ldots
,n-1\right\}  $ and $\left(  ui\right)  \%n\equiv ui\operatorname{mod}n$. Set
$j=\left(  ui\right)  \%n$. Thus, $j=\left(  ui\right)  \%n\in\left\{
0,1,\ldots,n-1\right\}  $ and $j=\left(  ui\right)  \%n\equiv
ui\operatorname{mod}n$. Multiplying the congruences $a\equiv
a\operatorname{mod}n$ and $j\equiv ui\operatorname{mod}n$, we obtain%
\[
aj\equiv\underbrace{au}_{\equiv1\operatorname{mod}n}i\equiv
1i=i\operatorname{mod}n.
\]
In other words, $i\equiv aj\operatorname{mod}n$. Therefore, Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(c)} (applied to $aj$ and $i$ instead of
$u$ and $c$) yields $i=\left(  aj\right)  \%n$ (since $i\in\left\{
0,1,\ldots,n-1\right\}  $).

Combining $u\perp n$ with $i\perp n$, we obtain $ui\perp n$ (by Theorem
\ref{thm.ent.coprime.ab-to-c}, applied to $u$, $i$ and $n$ instead of $a$, $b$
and $c$). Also, $ui\equiv j\operatorname{mod}n$ (since $j\equiv
ui\operatorname{mod}n$). Hence, Exercise \ref{exe.ent.coprime.b==c} (applied
to $ui$, $j$ and $n$ instead of $a$, $b$ and $c$) yields $j\perp n$. From
$j\in\left\{  0,1,\ldots,n-1\right\}  $ and $j\perp n$, we obtain $j\in C$ (by
the definition of $C$). Thus, $f\left(  j\right)  $ is well-defined. The
definition of $f$ yields $f\left(  j\right)  =\left(  aj\right)  \%n=i$ (since
$i=\left(  aj\right)  \%n$). Hence, $i=f\left(  \underbrace{j}_{\in C}\right)
\in f\left(  C\right)  $.

Now, forget that we fixed $i$. We thus have proven that $i\in f\left(
C\right)  $ for each $i\in C$. In other words, $C\subseteq f\left(  C\right)
$. In other words, the map $f$ is surjective.]

Now we know that the map $f$ is injective and surjective. Hence, this map $f$
is bijective. In other words, $f$ is a bijection from $C$ to $C$. Thus, we can
substitute $f\left(  s\right)  $ for $i$ in the product $\prod\limits_{i\in
C}i$. So we obtain%
\begin{equation}
\prod_{i\in C}i=\prod_{s\in C}f\left(  s\right)  .
\label{pf.thm.ent.euler.finale.1}%
\end{equation}
But for each $s\in C$, we have%
\begin{align*}
f\left(  s\right)   &  =\left(  as\right)  \%n\ \ \ \ \ \ \ \ \ \ \left(
\text{by the definition of }f\right) \\
&  \equiv as\operatorname{mod}n\ \ \ \ \ \ \ \ \ \ \left(  \text{by Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(a)}, applied to }u=as\right)  .
\end{align*}
Hence, (\ref{eq.exe.ent.mod.k-sum.b}) (applied to $S=C$, $a_{s}=f\left(
s\right)  $ and $b_{s}=as$) yields%
\[
\prod_{s\in C}f\left(  s\right)  \equiv\prod_{s\in C}\left(  as\right)
=a^{\left\vert C\right\vert }\underbrace{\prod_{s\in C}s}_{\substack{=\prod
_{i\in C}i=z\\\text{(by (\ref{pf.thm.ent.euler.z=}))}}}=a^{\left\vert
C\right\vert }z=a^{\phi\left(  n\right)  }z\operatorname{mod}n
\]
(since $\left\vert C\right\vert =\phi\left(  n\right)  $). Now,
(\ref{pf.thm.ent.euler.z=}) becomes%
\begin{align*}
z  &  =\prod_{i\in C}i=\prod_{s\in C}f\left(  s\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.thm.ent.euler.finale.1})}\right)
\\
&  \equiv a^{\phi\left(  n\right)  }z=za^{\phi\left(  n\right)  }%
\operatorname{mod}n.
\end{align*}
Thus, $z\cdot1=z\equiv za^{\phi\left(  n\right)  }\operatorname{mod}n$. Lemma
\ref{lem.ent.coprime.cancel} lets us \textquotedblleft
cancel\textquotedblright\ $z$ from this congruence (since $z\perp n$). We thus
obtain $1\equiv a^{\phi\left(  n\right)  }\operatorname{mod}n$. This proves
Theorem \ref{thm.ent.euler}.
\end{proof}

\begin{proof}
[Proof of Theorem \ref{thm.ent.fermat}.]As we have explained above, Theorem
\ref{thm.ent.fermat} follows from Theorem \ref{thm.ent.euler}.

\begin{fineprint}
Here is the argument in more detail:

\textbf{(a)} Assume that $p\nmid a$. Proposition \ref{prop.ent.phi.p} yields
$\phi\left(  p\right)  =p-1$. But Proposition
\ref{prop.ent.prime.div-or-coprime} yields that either $p\mid a$ or $p\perp
a$. Hence, $p\perp a$ (since $p\nmid a$). In other words, $a\perp p$. In other
words, $a$ is coprime to $p$. Hence, Theorem \ref{thm.ent.euler} (applied to
$n=p$) yields $a^{\phi\left(  p\right)  }\equiv1\operatorname{mod}p$. This
rewrites as $a^{p-1}\equiv1\operatorname{mod}p$ (since $\phi\left(  p\right)
=p-1$). This proves Theorem \ref{thm.ent.fermat} \textbf{(a)}.

\textbf{(b)} We are in one of the following two cases:

\textit{Case 1:} We have $p\nmid a$.

\textit{Case 2:} We have $p\mid a$.

Let us first consider Case 1. In this case, we have $p\nmid a$. Hence, Theorem
\ref{thm.ent.fermat} \textbf{(a)} yields $a^{p-1}\equiv1\operatorname{mod}p$.
Multiplying this congruence with the congruence $a\equiv a\operatorname{mod}%
p$, we obtain $a^{p-1}a\equiv1a=a\operatorname{mod}p$. In view of
$a^{p-1}a=a^{p}$, this rewrites as $a^{p}\equiv a\operatorname{mod}p$. Hence,
Theorem \ref{thm.ent.fermat} \textbf{(b)} is proven in Case 1.

Let us now consider Case 2. In this case, we have $p\mid a$. In other words,
$a\equiv0\operatorname{mod}p$. Taking this congruence to the $p$-th power, we
obtain $a^{p}\equiv0^{p}=0\operatorname{mod}p$ (since $p>0$). Thus,
$a^{p}\equiv0\equiv a\operatorname{mod}p$ (since $a\equiv0\operatorname{mod}%
p$). Hence, Theorem \ref{thm.ent.fermat} \textbf{(b)} is proven in Case 2.

We have now proven Theorem \ref{thm.ent.fermat} \textbf{(b)} in both Cases 1
and 2. Hence, Theorem \ref{thm.ent.fermat} \textbf{(b)} always holds.
\end{fineprint}
\end{proof}

The next exercise shows an amusing (and useful) corollary of Fermat's Little
Theorem: a situation in which congruent exponents lead to congruent powers
(albeit under rather specific conditions, and with the congruent powers being
congruent modulo a different number than the exponents):

\begin{exercise}
\label{exe.ent.fermat.uv}Let $p$ be a prime. Let $a\in\mathbb{Z}$ be such that
$p\nmid a$. Let $u,v\in\mathbb{N}$ satisfy $u\equiv v\operatorname{mod}p-1$.
Then, $a^{u}\equiv a^{v}\operatorname{mod}p$.
\end{exercise}

\subsubsection{The Pigeonhole Principles}

In our above proof of Theorem \ref{thm.ent.euler}, we have proven that the map
$f:C\rightarrow C$ (that we constructed) is injective and surjective. It turns
out that this was, to some extent, wasteful: It would have been enough to
prove one of the two properties only (i.e., injectivity \textbf{or}
surjectivity). The reason for this are the following two basic facts about
finite sets:

\begin{theorem}
[Pigeonhole Principle for Injections]\label{thm.pigeon.inj}Let $A$ and $B$ be
two finite sets such that $\left\vert A\right\vert \geq\left\vert B\right\vert
$. Let $f:A\rightarrow B$ be an injective map. Then, $f$ is bijective.
\end{theorem}

\begin{theorem}
[Pigeonhole Principle for Surjections]\label{thm.pigeon.surj}Let $A$ and $B$
be two finite sets such that $\left\vert A\right\vert \leq\left\vert
B\right\vert $. Let $f:A\rightarrow B$ be an surjective map. Then, $f$ is bijective.
\end{theorem}

Theorem \ref{thm.pigeon.inj} is called the \textit{Pigeonhole Principle for
Injections}, due to the following interpretation: If $a$ pigeons sit in $b$
pigeonholes with $a\geq b$ (that is, there are at least as many pigeons as
there are pigeonholes), and if no two pigeons are sharing the same hole, then
every hole must have at least one pigeon in it. (This corresponds to the
statement of Theorem \ref{thm.pigeon.inj} if you let $A$ be the set of
pigeons, $B$ be the set of holes, and $f$ be the map that sends each pigeon to
the hole it is sitting in. The injectivity of $f$ is then precisely the
statement that no two pigeons are sharing the same hole.)

Likewise, Theorem \ref{thm.pigeon.surj} is called the \textit{Pigeonhole
Principle for Surjections}, due to the following interpretation: If $a$
pigeons sit in $b$ pigeonholes with $a\leq b$ (that is, there are at most as
many pigeons as there are pigeonholes), and if each hole contains at least one
pigeon, then no two pigeons are sharing the same hole.

Theorem \ref{thm.pigeon.inj} and Theorem \ref{thm.pigeon.surj} are both basic
facts of set theory; how to prove them depends on how you define the size of a
finite set in the first place. See \cite[solution to Exercise 1.1]{detnotes}
for one way of proving them (more precisely, Theorem \ref{thm.pigeon.inj} is
the \textquotedblleft$\Longrightarrow$\textquotedblright\ direction of
\cite[Lemma 1.5]{detnotes}, while Theorem \ref{thm.pigeon.surj} is the
\textquotedblleft$\Longrightarrow$\textquotedblright\ direction of \cite[Lemma
1.4]{detnotes}).

Now, Theorem \ref{thm.pigeon.inj} can be used to simplify our above proof of
Theorem \ref{thm.ent.euler}. Indeed, in the latter proof, once we have shown
that $f$ is injective, we can immediately apply Theorem \ref{thm.pigeon.inj}
(to $A=C$ and $B=C$) in order to conclude that $f$ is bijective (since $C$ is
a finite set and satisfies $\left\vert C\right\vert \geq\left\vert
C\right\vert $). The proof of surjectivity of $f$ is thus unnecessary.
Alternatively, we could have omitted the proof of injectivity of $f$, and
instead used the surjectivity of $f$ to apply Theorem \ref{thm.pigeon.surj}
(to $A=C$ and $B=C$) in order to conclude that $f$ is bijective (since $C$ is
a finite set and satisfies $\left\vert C\right\vert \leq\left\vert
C\right\vert $). Either way, we would have obtained a shorter proof.

\subsubsection{Wilson}

The next theorem is known as \textit{Wilson's theorem}:

\begin{theorem}
\label{thm.ent.wilson}Let $p$ be a prime. Then, $\left(  p-1\right)
!\equiv-1\operatorname{mod}p$.
\end{theorem}

We shall prove Theorem \ref{thm.ent.wilson} using modular inverses modulo $p$.
The main idea is that we can \textquotedblleft pair up\textquotedblright\ each
factor in the product $\left(  p-1\right)  !=1\cdot2\cdot\cdots\cdot\left(
p-1\right)  $ with its modular inverse modulo $p$, where of course we take the
unique modular inverse that belongs to the set $\left\{  1,2,\ldots
,p-1\right\}  $. This relies on the following lemma:

\begin{lemma}
\label{lem.ent.wilson.modi}Let $p$ be a prime. Set $A=\left\{  1,2,\ldots
,p-1\right\}  $.

\textbf{(a)} If $a_{1}$ and $a_{2}$ are two elements of $A$ satisfying
$a_{1}\equiv a_{2}\operatorname{mod}p$, then $a_{1}=a_{2}$.

\textbf{(b)} For each $a\in A$, there exists a unique $a^{\prime}\in A$
satisfying $aa^{\prime}\equiv1\operatorname{mod}p$.

\textbf{(c)} Define a map $J:A\rightarrow A$ as follows: For each $a\in A$, we
let $J\left(  a\right)  $ denote the unique $a^{\prime}\in A$ satisfying
$aa^{\prime}\equiv1\operatorname{mod}p$. (This unique $a^{\prime}$ indeed
exists, by Lemma \ref{lem.ent.wilson.modi} \textbf{(b)}.)

Then, this map $J$ is a bijection satisfying $J\circ J=\operatorname*{id}$.
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.ent.wilson.modi}.]\textbf{(a)} Let $a_{1}$ and
$a_{2}$ be two elements of $A$ satisfying $a_{1}\equiv a_{2}\operatorname{mod}%
p$. We must prove that $a_{1}=a_{2}$.

We have $a_{1}\equiv a_{2}\operatorname{mod}p$. Hence, Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(c)} (applied to $p$, $a_{2}$ and $a_{1}$
instead of $n$, $u$ and $c$) yields $a_{1}=a_{2}\%p$ (since $a_{1}\in
A=\left\{  1,2,\ldots,p-1\right\}  \subseteq\left\{  0,1,\ldots,p-1\right\}
$). Also, $a_{2}\equiv a_{2}\operatorname{mod}p$. Thus, Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(c)} (applied to $p$, $a_{2}$ and $a_{2}$
instead of $n$, $u$ and $c$) yields $a_{2}=a_{2}\%p$ (since $a_{2}\in
A=\left\{  1,2,\ldots,p-1\right\}  \subseteq\left\{  0,1,\ldots,p-1\right\}
$). Comparing this with $a_{1}=a_{2}\%p$, we obtain $a_{1}=a_{2}$. This proves
Lemma \ref{lem.ent.wilson.modi} \textbf{(a)}.

\textbf{(b)} Let $a\in A$. Thus, $a\in A=\left\{  1,2,\ldots,p-1\right\}  $.
Hence, Proposition \ref{prop.ent.prime.each-i-coprime} (applied to $i=a$)
shows that $a$ is coprime to $p$. In other words, $a\perp p$. Hence, Theorem
\ref{thm.ent.coprime.modinv} \textbf{(a)} shows that there exists a
$b\in\mathbb{Z}$ such that $ab\equiv\gcd\left(  a,p\right)  \operatorname{mod}%
p$. Consider this $b$.

We have $ab\equiv\gcd\left(  a,p\right)  =1\operatorname{mod}p$ (since $a\perp
p$). Let $c=b\%p$. Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(a)}
(applied to $n=p$ and $u=b$) yields $b\%p\in\left\{  0,1,\ldots,p-1\right\}  $
and $b\%p\equiv b\operatorname{mod}p$. Now, $c=b\%p\in\left\{  0,1,\ldots
,p-1\right\}  $ and $a\underbrace{c}_{=b\%p\equiv b\operatorname{mod}p}\equiv
ab\equiv1\operatorname{mod}p$.

Assume (for the sake of contradiction) that $c=0$. Thus, $a\underbrace{c}%
_{=0}=0$ and thus $0=ac\equiv1\operatorname{mod}p$. Hence, $1\equiv
0\operatorname{mod}p$. In other words, $p\mid1-0=1$. Hence, Exercise
\ref{exe.ent.div.g|1} (applied to $g=p$) yields $p=1$. But $p>1$ (since $p$ is
prime). This contradicts $p=1$. This contradiction shows that our assumption
(that $c=0$) is false.

Hence, $c\neq0$. Combining this with $c\in\left\{  0,1,\ldots,p-1\right\}  $,
we obtain $c\in\left\{  0,1,\ldots,p-1\right\}  \setminus\left\{  0\right\}
=\left\{  1,2,\ldots,p-1\right\}  =A$. Recall that $ac\equiv
1\operatorname{mod}p$.

Thus, there exists \textbf{at least one} $a^{\prime}\in A$ satisfying
$aa^{\prime}\equiv1\operatorname{mod}p$ (namely, $a^{\prime}=c$). It remains
to prove that there is only one such $a^{\prime}$.

Indeed, let $a_{1}^{\prime}$ and $a_{2}^{\prime}$ be two elements $a^{\prime
}\in A$ satisfying $aa^{\prime}\equiv1\operatorname{mod}p$. We shall prove
that $a_{1}^{\prime}=a_{2}^{\prime}$.

We know that $a_{1}^{\prime}$ is an element $a^{\prime}\in A$ satisfying
$aa^{\prime}\equiv1\operatorname{mod}p$. In other words, $a_{1}^{\prime}$ is
an element of $A$ and satisfies $aa_{1}^{\prime}\equiv1\operatorname{mod}p$.
Similarly, $a_{2}^{\prime}$ is an element of $A$ and satisfies $aa_{2}%
^{\prime}\equiv1\operatorname{mod}p$. Hence, $1\equiv aa_{2}^{\prime
}\operatorname{mod}p$, so that $aa_{1}^{\prime}\equiv1\equiv aa_{2}^{\prime
}\operatorname{mod}p$. Thus, Lemma \ref{lem.ent.coprime.cancel} (applied to
$a_{1}^{\prime}$, $a_{2}^{\prime}$ and $p$ instead of $b$, $c$ and $n$) yields
$a_{1}^{\prime}\equiv a_{2}^{\prime}\operatorname{mod}p$ (since $a\perp p$).
Hence, Lemma \ref{lem.ent.wilson.modi} \textbf{(a)} (applied to $a_{1}%
=a_{1}^{\prime}$ and $a_{2}=a_{2}^{\prime}$) yields $a_{1}^{\prime}%
=a_{2}^{\prime}$.

Now, forget that we fixed $a_{1}^{\prime}$ and $a_{2}^{\prime}$. We thus have
shown that if $a_{1}^{\prime}$ and $a_{2}^{\prime}$ are two elements
$a^{\prime}\in A$ satisfying $aa^{\prime}\equiv1\operatorname{mod}p$, then
$a_{1}^{\prime}=a_{2}^{\prime}$. In other words, there exists \textbf{at most
one} $a^{\prime}\in A$ satisfying $aa^{\prime}\equiv1\operatorname{mod}p$.
Thus, there exists \textbf{a unique} such $a^{\prime}$ (because we have
already shown that there exists \textbf{at least one} such $a^{\prime}$). In
other words, there exists a unique $a^{\prime}\in A$ satisfying $aa^{\prime
}\equiv1\operatorname{mod}p$. This proves Lemma \ref{lem.ent.wilson.modi}
\textbf{(b)}.

\textbf{(c)} Let $a\in A$. Then, $J\left(  a\right)  $ is the unique
$a^{\prime}\in A$ satisfying $aa^{\prime}\equiv1\operatorname{mod}p$ (by the
definition of $J$). Hence, $J\left(  a\right)  $ is an $a^{\prime}\in A$
satisfying $aa^{\prime}\equiv1\operatorname{mod}p$. In other words, $J\left(
a\right)  $ is an element of $A$ and satisfies%
\begin{equation}
aJ\left(  a\right)  \equiv1\operatorname{mod}p.
\label{pf.lem.ent.wilson.modi.b.aJa}%
\end{equation}


Now, forget that we fixed $a$. We thus have proven
(\ref{pf.lem.ent.wilson.modi.b.aJa}) for each $a\in A$.

Now, let $a\in A$ be arbitrary. Then, $J\left(  a\right)  \in A$ (since $J$ is
a map from $A$ to $A$). Thus, (\ref{pf.lem.ent.wilson.modi.b.aJa}) (applied to
$J\left(  a\right)  $ instead of $a$) yields $J\left(  a\right)  J\left(
J\left(  a\right)  \right)  \equiv1\operatorname{mod}p$. Also, from $J\left(
a\right)  \in A$, we obtain $J\left(  J\left(  a\right)  \right)  \in A$
(since $J$ is a map from $A$ to $A$). On the other hand,
(\ref{pf.lem.ent.wilson.modi.b.aJa}) yields $aJ\left(  a\right)
\equiv1\operatorname{mod}p$. Thus, $1\equiv aJ\left(  a\right)
\operatorname{mod}p$. Now,%
\[
J\left(  a\right)  J\left(  J\left(  a\right)  \right)  \equiv1\equiv
aJ\left(  a\right)  =J\left(  a\right)  a\operatorname{mod}p.
\]
But $J\left(  a\right)  \in A=\left\{  1,2,\ldots,p-1\right\}  $. Hence,
Proposition \ref{prop.ent.prime.each-i-coprime} (applied to $i=J\left(
a\right)  $) shows that $J\left(  a\right)  $ is coprime to $p$. In other
words, $J\left(  a\right)  \perp p$. Hence, Lemma \ref{lem.ent.coprime.cancel}
(applied to $J\left(  a\right)  $, $J\left(  J\left(  a\right)  \right)  $,
$a$ and $p$ instead of $a$, $b$, $c$ and $n$) yields $J\left(  J\left(
a\right)  \right)  \equiv a\operatorname{mod}p$ (since $J\left(  a\right)
J\left(  J\left(  a\right)  \right)  \equiv J\left(  a\right)
a\operatorname{mod}p$). Therefore, Lemma \ref{lem.ent.wilson.modi}
\textbf{(a)} (applied to $a_{1}=J\left(  J\left(  a\right)  \right)  $ and
$a_{2}=a$) yields $J\left(  J\left(  a\right)  \right)  =a$. Thus, $\left(
J\circ J\right)  \left(  a\right)  =J\left(  J\left(  a\right)  \right)
=a=\operatorname*{id}\left(  a\right)  $.

Now, forget that we fixed $a$. We thus have proven that $\left(  J\circ
J\right)  \left(  a\right)  =\operatorname*{id}\left(  a\right)  $ for each
$a\in A$. In other words, $J\circ J=\operatorname*{id}$. Hence, the maps $J$
and $J$ are mutually inverse. Thus, the map $J$ is invertible, i.e., is a
bijection. Thus, Lemma \ref{lem.ent.wilson.modi} \textbf{(c)} is proven.
\end{proof}

\begin{remark}
Let $S$ be a set. An \textit{involution} on $S$ means a map $f:S\rightarrow S$
satisfying $f\circ f=\operatorname*{id}$. Thus, Lemma
\ref{lem.ent.wilson.modi} \textbf{(c)} says that the map $J:A\rightarrow A$
defined in this lemma is an involution on $A$.
\end{remark}

We are now ready to prove Theorem \ref{thm.ent.wilson}:

\begin{proof}
[First proof of Theorem \ref{thm.ent.wilson}.]We have $\left(  2-1\right)
!=1!=1\equiv-1\operatorname{mod}2$ (since $1-\left(  -1\right)  =2$ is
divisible by $2$). In other words, Theorem \ref{thm.ent.wilson} holds when
$p=2$. Hence, for the rest of this proof, we WLOG assume that we don't have
$p=2$. Hence, $p\neq2$. Thus, $1 \neq p-1$.

But $p$ is a prime; thus, $p>1$, so that $p\geq2$ (since $p$ is an integer).
Combining this with $p\neq2$, we obtain $p>2$, so that $p\geq3$ (since $p$ is
an integer).

Define the set $A$ and the map $J:A\rightarrow A$ as in Lemma
\ref{lem.ent.wilson.modi}. Hence, Lemma \ref{lem.ent.wilson.modi} \textbf{(c)}
shows that this map $J$ is a bijection satisfying $J\circ J=\operatorname*{id}%
$. The equality $J \circ J = \operatorname{id}$ shows that the map $J$ is
inverse to itself. For each $a\in A$, we have
\begin{equation}
aJ\left(  a\right)  \equiv1\operatorname{mod}p. \label{pf.thm.ent.wilson.aJa}%
\end{equation}
(This congruence is proven in the same way as it was proven in our above proof
of Lemma \ref{lem.ent.wilson.modi} \textbf{(c)}.)

Now, the rest of our proof shall follow the following plan (using the same
\textquotedblleft pairing\textquotedblright\ idea that we have seen in our
proof of Proposition \ref{prop.ent.phi.ghosts} and in the solution to Exercise
\ref{exe.ent.phi.even}): We will use the map $J$ to establish a pairing
between the factors of the product $1\cdot2\cdot\cdots\cdot\left(  p-1\right)
$ (pairing up each factor $a$ with the factor $J\left(  a\right)  $), which
will pair up almost all of them -- more precisely, all of them except for the
very first and very last factors (since these two factors would have to pair
up with themselves)\footnote{The reason \textbf{why} it is precisely these two
factors that will not be paired up is not completely trivial. It follows from
Exercise \ref{exe.ent.prime.aa-1}.}. For example, if $p=11$, then we have the
following table of values of $J$:%
\[%
\begin{tabular}
[c]{|c||c|c|c|c|c|c|c|c|c|c||}\hline
$a$ & $1$ & $2$ & $3$ & $4$ & $5$ & $6$ & $7$ & $8$ & $9$ & $10$\\\hline
$J\left(  a\right)  $ & $1$ & $6$ & $4$ & $3$ & $9$ & $2$ & $8$ & $7$ & $5$ &
$10$\\\hline
\end{tabular}
\]
(indeed, for example, $J\left(  2\right)  =6$, since $6$ is the unique
$a^{\prime}\in A$ satisfying $2\cdot a^{\prime}\equiv1\operatorname{mod}11$),
and thus we pair up the factors of the product $1\cdot2\cdot\cdots\cdot\left(
p-1\right)  $ as follows:%
\begin{align*}
1\cdot2\cdot\cdots\cdot\left(  p-1\right)   &  =1\cdot2\cdot3\cdot4\cdot
5\cdot6\cdot7\cdot8\cdot9\cdot10\\
&  =1\cdot\left(  2\cdot6\right)  \cdot\left(  3\cdot4\right)  \cdot\left(
5\cdot9\right)  \cdot\left(  7\cdot8\right)  \cdot10.
\end{align*}
By the definition of the map $J$, each pair has the form $\left(  a,J\left(
a\right)  \right)  $ for some $a\in A$, and thus the product of any two
different factors paired up with each other is $\equiv1\operatorname{mod}p$
(by (\ref{pf.thm.ent.wilson.aJa})). For example, if $p=11$, then we have%
\begin{align*}
1\cdot2\cdot\cdots\cdot\left(  p-1\right)   &  =1\cdot\underbrace{\left(
2\cdot6\right)  }_{\equiv1\operatorname{mod}11}\cdot\underbrace{\left(
3\cdot4\right)  }_{\equiv1\operatorname{mod}11}\cdot\underbrace{\left(
5\cdot9\right)  }_{\equiv1\operatorname{mod}11}\cdot\underbrace{\left(
7\cdot8\right)  }_{\equiv1\operatorname{mod}11}\cdot10\\
&  \equiv1\cdot10\operatorname{mod}11.
\end{align*}
Thus, any two different factors paired up with each other \textquotedblleft
neutralize\textquotedblright\ each other when being multiplied (as long as we
are computing modulo $p$). Hence, the product of all the $p-1$ factors will
reduce (when working modulo $p$) to the product of the two factors that have
not been paired up, which will be $1\cdot\left(  p-1\right)  =p-1\equiv
-1\operatorname{mod}p$.

\begin{fineprint}
Here are the details of this argument:

An element $a$ of $A$ will be called

\begin{itemize}
\item \textit{small} if $a<J\left(  a\right)  $;

\item \textit{medium} if $a=J\left(  a\right)  $;

\item \textit{large} if $a>J\left(  a\right)  $.
\end{itemize}

Now, we claim that the medium elements of $A$ are precisely $1$ and $p-1$.

[\textit{Proof:} We have $1 \leq p-1$ (since $p \geq2$). Thus, $1 \in\left\{
1,2,\ldots,p-1\right\}  = A$ and $p-1 \in\left\{  1,2,\ldots,p-1\right\}  =
A$. The element $1$ of $A$ is medium\footnote{\textit{Proof.} We have $1\in
A$. Hence, $J\left(  1\right)  \in A$ (since $J$ is a map from $A$ to $A$).
Furthermore, (\ref{pf.thm.ent.wilson.aJa}) (applied to $a=1$) yields
$1J\left(  1\right)  \equiv1\operatorname{mod}p$. Thus, $1\equiv1J\left(
1\right)  =J\left(  1\right)  \operatorname{mod}p$. Thus, Lemma
\ref{lem.ent.wilson.modi} \textbf{(a)} (applied to $a_{1}=1$ and
$a_{2}=J\left(  1\right)  $) yields $1=J\left(  1\right)  $. In other words,
the element $1$ of $A$ is medium.}. The element $p-1$ of $A$ is
medium\footnote{\textit{Proof.} We have $p-1 \in A$. Hence, $J\left(
p-1\right)  \in A$ (since $J$ is a map from $A$ to $A$). Furthermore,
(\ref{pf.thm.ent.wilson.aJa}) (applied to $a=p-1$) yields $\left(  p-1\right)
J\left(  p-1\right)  \equiv1\operatorname{mod}p$. Multiplying this congruence
with the obvious congruence $p-1\equiv p-1\operatorname{mod}p$, we obtain%
\[
\left(  p-1\right)  \left(  p-1\right)  J\left(  p-1\right)  \equiv\left(
p-1\right)  1=p-1\operatorname{mod}p.
\]
Hence,%
\begin{align*}
p-1  &  \equiv\left(  p-1\right)  \left(  p-1\right)  J\left(  p-1\right)
=\left(  \underbrace{p-1}_{\equiv-1\operatorname{mod}p}\right)  ^{2}J\left(
p-1\right)  \equiv\underbrace{\left(  -1\right)  ^{2}}_{=1}J\left(  p-1\right)
\\
&  =J\left(  p-1\right)  \operatorname{mod}p.
\end{align*}
Thus, Lemma \ref{lem.ent.wilson.modi} \textbf{(a)} (applied to $a_{1}=p-1$ and
$a_{2}=J\left(  p-1\right)  $) yields $p-1=J\left(  p-1\right)  $. In other
words, the element $p-1$ of $A$ is medium.}. Hence, the two numbers $1$ and
$p-1$ are medium elements of $A$. It remains to prove that these two numbers
are the only medium elements of $A$.

Indeed, let $a$ be a medium element of $A$. We shall show that $a=1$ or
$a=p-1$.

Indeed, assume the contrary. Thus, neither $a=1$ nor $a=p-1$ holds.

If we had $a \equiv1 \mod p$, then Lemma \ref{lem.ent.wilson.modi}
\textbf{(a)} (applied to $a_{1}=a$ and $a_{2}=1$) would yield $a = 1$, which
would contradict the fact that $a=1$ does not hold. Thus, we do not have $a
\equiv1 \mod p$.

If we had $a \equiv p-1 \mod p$, then Lemma \ref{lem.ent.wilson.modi}
\textbf{(a)} (applied to $a_{1}=a$ and $a_{2}=p-1$) would yield $a = p-1$,
which would contradict the fact that $a=p-1$ does not hold. Thus, we do not
have $a \equiv p-1 \mod p$.

We have assumed that $a$ is medium. In other words, $a = J\left(  a\right)  $.
But (\ref{pf.thm.ent.wilson.aJa}) yields $aJ\left(  a \right)  \equiv1
\mod p$. Thus, $a^{2} = a \underbrace{a}_{= J\left(  a \right)  } = aJ\left(
a \right)  \equiv1 \mod p$. Hence, Exercise \ref{exe.ent.prime.aa-1} shows
that $a\equiv1\operatorname{mod}p$ or $a\equiv-1\operatorname{mod}p$. Hence,
we must have $a \equiv-1 \mod p$ (since we do not have $a \equiv1 \mod p$).
Thus, $a \equiv-1 \equiv p-1 \mod p$ (since $p-1 \equiv-1 \mod p$). This
contradicts the fact that we do not have $a \equiv p-1 \mod p$.

This contradiction shows that our assumption was false. Hence, $a = 1$ or $a =
p-1$.

Now, forget that we fixed $a$. We thus have proven that every medium element
$a$ of $A$ satisfies $a=1$ or $a=p-1$. In other words, every medium element of
$A$ is either $1$ or $p-1$. Since we know that $1$ and $p-1$ actually are
medium elements of $A$, we thus conclude that the medium elements of $A$ are
precisely $1$ and $p-1$.]

So we have shown that the medium elements of $A$ are precisely $1$ and $p-1$.
Since these two elements are distinct (because $p-1\neq1$), we thus obtain%
\begin{equation}
\prod_{\substack{a\in A;\\a\text{ is medium}}}a=1\cdot\left(  p-1\right)
=p-1\equiv-1\operatorname{mod}p. \label{pf.thm.ent.wilson.prodmed}%
\end{equation}


It is easy to see that if $a$ is a small element of $A$, then $J\left(
a\right)  $ is a large element of $A$\ \ \ \ \footnote{\textit{Proof.} Let $a$
be a small element of $A$. Thus, $a<J\left(  a\right)  $. Note that $J\left(
a\right)  \in A$ (since $J$ is a map from $A$ to $A$). But $J\circ
J=\operatorname{id}$, so that $\left(  J\circ J\right)  \left(  a\right)
=\operatorname{id}{a}=a<J\left(  a\right)  $. In view of $\left(  J\circ
J\right)  \left(  a\right)  =J\left(  J\left(  a\right)  \right)  $, this
rewrites as $J\left(  J\left(  a\right)  \right)  <J\left(  a\right)  $. In
other words, $J\left(  a\right)  > J\left(  J\left(  a\right)  \right)  $. In
other words, the element $J\left(  a\right)  $ of $A$ is large (by the
definition of \textquotedblleft large\textquotedblright). Qed.}. Hence, the
map%
\begin{align*}
J^{+}:\left\{  \text{small elements of }A\right\}   &  \rightarrow\left\{
\text{large elements of }A\right\}  ,\\
a  &  \mapsto J\left(  a\right)
\end{align*}
is well-defined. Similarly, the map%
\begin{align*}
J^{-}:\left\{  \text{large elements of }A\right\}   &  \rightarrow\left\{
\text{small elements of }A\right\}  ,\\
a  &  \mapsto J\left(  a\right)
\end{align*}
is well-defined. These two maps $J^{+}$ and $J^{-}$ are both restrictions of
the map $J$, and thus are mutually inverse (since the map $J$ is inverse to
itself). Hence, the map $J^{+}$ is invertible, i.e., is a bijection. In other
words, the map%
\begin{align*}
\left\{  \text{small elements of }A\right\}   &  \rightarrow\left\{
\text{large elements of }A\right\}  ,\\
a  &  \mapsto J\left(  a\right)
\end{align*}
is a bijection (since this map is just the map $J^{+}$). Thus, we can
substitute $J\left(  b\right)  $ for $a$ in the product $\prod_{\substack{a\in
A;\\a\text{ is large}}}a$. We thus obtain%
\begin{equation}
\prod_{\substack{a\in A;\\a\text{ is large}}}a=\prod_{\substack{b\in
A;\\b\text{ is small}}}J\left(  b\right)  =\prod_{\substack{a\in A;\\a\text{
is small}}}J\left(  a\right)  \label{pf.thm.ent.wilson.prodlar}%
\end{equation}
(here, we have renamed the index $b$ as $a$ in the product). Now, the
definition of $\left(  p-1\right)  !$ yields%
\begin{align}
\left(  p-1\right)  !  &  =1\cdot2\cdot\cdots\cdot\left(  p-1\right)
=\prod_{a\in A}a\nonumber\\
&  =\left(  \prod_{\substack{a\in A;\\a\text{ is small}}}a\right)
\cdot\underbrace{\left(  \prod_{\substack{a\in A;\\a\text{ is medium}%
}}a\right)  }_{\substack{\equiv-1\operatorname{mod}p\\\text{(by
(\ref{pf.thm.ent.wilson.prodmed}))}}}\cdot\underbrace{\left(  \prod
_{\substack{a\in A;\\a\text{ is large}}}a\right)  }_{\substack{=\prod
_{\substack{a\in A;\\a\text{ is small}}}J\left(  a\right)  \\\text{(by
(\ref{pf.thm.ent.wilson.prodlar}))}}}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since each }a\in A\text{ is either small or medium or large (but
never}\\
\text{has more than one of these three attributes simultaneously)}%
\end{array}
\right) \nonumber\\
&  \equiv\left(  \prod_{\substack{a\in A;\\a\text{ is small}}}a\right)
\cdot\left(  -1\right)  \cdot\left(  \prod_{\substack{a\in A;\\a\text{ is
small}}}J\left(  a\right)  \right)  =-\underbrace{\left(  \prod
_{\substack{a\in A;\\a\text{ is small}}}a\right)  \cdot\left(  \prod
_{\substack{a\in A;\\a\text{ is small}}}J\left(  a\right)  \right)  }%
_{=\prod_{\substack{a\in A;\\a\text{ is small}}}\left(  aJ\left(  a\right)
\right)  }\nonumber\\
&  =-\prod_{\substack{a\in A;\\a\text{ is small}}}\left(  aJ\left(  a\right)
\right)  \operatorname{mod}p. \label{pf.thm.ent.wilson.6}%
\end{align}


But it is clear that $\prod_{\substack{a\in A;\\a\text{ is small}%
}}\underbrace{\left(  aJ\left(  a\right)  \right)  }_{\substack{\equiv
1\operatorname{mod}p\\\text{(by (\ref{pf.thm.ent.wilson.aJa}))}}%
}\equiv1\operatorname{mod}p$\ \ \ \ \footnote{\textit{Proof.} Here is this
argument in more detail:
\par
Every $a\in\left\{  \text{small elements of }A\right\}  $ satisfies $aJ\left(
a\right)  \equiv1\operatorname{mod}p$ (by (\ref{pf.thm.ent.wilson.aJa})).
Renaming the index $a$ as $s$ in this statement, we obtain the following:
Every $s\in\left\{  \text{small elements of }A\right\}  $ satisfies $sJ\left(
s\right)  \equiv1\operatorname{mod}p$. Hence, (\ref{eq.exe.ent.mod.k-sum.b})
(applied to $n=p$, $S=\left\{  \text{small elements of }A\right\}  $,
$a_{s}=sJ\left(  s\right)  $ and $b_{s}=1$) yields
\[
\prod_{s\in\left\{  \text{small elements of }A\right\}  }\left(  sJ\left(
s\right)  \right)  \equiv\prod_{s\in\left\{  \text{small elements of
}A\right\}  }1=1\operatorname{mod}p.
\]
In view of%
\begin{align*}
\prod_{s\in\left\{  \text{small elements of }A\right\}  }\left(  sJ\left(
s\right)  \right)   &  =\prod_{a\in\left\{  \text{small elements of
}A\right\}  }\left(  aJ\left(  a\right)  \right)  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we have renamed the}\\
\text{index }s\text{ as }a\text{ in the product}%
\end{array}
\right) \\
&  =\prod_{\substack{a\in A;\\a\text{ is small}}}\left(  aJ\left(  a\right)
\right)  ,
\end{align*}
this rewrites as $\prod_{\substack{a\in A;\\a\text{ is small}}}\left(
aJ\left(  a\right)  \right)  \equiv1\operatorname{mod}p$.}. Hence,
(\ref{pf.thm.ent.wilson.6}) rewrites as%
\begin{equation}
\left(  p-1\right)  !\equiv-\underbrace{\prod_{\substack{a\in A;\\a\text{ is
small}}}\left(  aJ\left(  a\right)  \right)  }_{\equiv1\operatorname{mod}%
p}\equiv-1\operatorname{mod}p. \label{pf.thm.ent.wilson.8}%
\end{equation}
This proves Theorem \ref{thm.ent.wilson}.
\end{fineprint}
\end{proof}

Later, in Section \ref{sect.equiv.modinv}, we shall give a different version
of this proof.

Theorem \ref{thm.ent.wilson} has a converse:

\begin{exercise}
\label{exe.ent.wilson.converse}If an integer $p>1$ satisfies $\left(
p-1\right)  !\equiv-1\operatorname{mod}p$, then prove that $p$ is a prime.
\end{exercise}

(This is actually easier to prove than Theorem \ref{thm.ent.wilson} itself.)

\begin{exercise}
\label{exe.ent.wilson.gauss}Let $p$ be a prime. Prove that
\[
\left(  p-1\right)  !\equiv p-1\operatorname{mod}1+2+\cdots+\left(
p-1\right)  .
\]

\end{exercise}

\begin{exercise}
\label{exe.ent.wilson.-1qr}Let $p$ be an odd prime. Write $p$ in the form
$p=2k+1$ for some $k\in\mathbb{N}$. Prove that $k!^{2}\equiv-\left(
-1\right)  ^{k}\operatorname{mod}p$.

[\textbf{Hint:} Each $j\in\mathbb{Z}$ satisfies $j\left(  p-j\right)
\equiv-j^{2}\operatorname{mod}p$.]
\end{exercise}

\subsection{The Chinese Remainder Theorem as a bijection}

\subsubsection{The bijection $K_{m,n}$}

Here comes another of the many facts known as the \textquotedblleft Chinese
Remainder Theorem\textquotedblright:

\begin{theorem}
\label{thm.ent.CRT-bij}Let $m$ and $n$ be two coprime positive integers. Then,
the map%
\begin{align*}
K_{m,n}:\left\{  0,1,\ldots,mn-1\right\}   &  \rightarrow\left\{
0,1,\ldots,m-1\right\}  \times\left\{  0,1,\ldots,n-1\right\}  ,\\
a  &  \mapsto\left(  a\%m,a\%n\right)
\end{align*}
is well-defined and is a bijection.
\end{theorem}

\begin{example}
\label{exa.ent.CRT-bij.exa1}\textbf{(a)} Theorem \ref{thm.ent.CRT-bij}
(applied to $m=3$ and $n=2$) says that the map%
\begin{align*}
K_{3,2}:\left\{  0,1,2,3,4,5\right\}   &  \rightarrow\left\{  0,1,2\right\}
\times\left\{  0,1\right\}  ,\\
a  &  \mapsto\left(  a\%3,a\%2\right)
\end{align*}
is a bijection. This map sends%
\[%
\begin{array}
[c]{cccccccc}%
0, & 1, & 2, & 3, & 4, & 5 &  & \text{to}\\
\left(  0,0\right)  , & \left(  1,1\right)  , & \left(  2,0\right)  , &
\left(  0,1\right)  , & \left(  1,0\right)  , & \left(  2,1\right)  , &  &
\end{array}
\]
respectively (since $0\%3=0$ and $0\%2=0$ and $1\%3=1$ and $1\%2=1$ and
$2\%3=2$ and $2\%2=0$ and so on). This list of values shows that this map is
bijective (since it takes on every possible value in $\left\{  0,1,2\right\}
\times\left\{  0,1\right\}  $ exactly once). Theorem \ref{thm.ent.CRT-bij}
says that this holds for arbitrary coprime $m$ and $n$.

\textbf{(b)} Let us see how Theorem \ref{thm.ent.CRT-bij} fails when $m$ and
$n$ are \textbf{not} coprime. For example, take $m=6$ and $n=4$. Then, the map%
\begin{align*}
K_{6,4}:\left\{  0,1,\ldots,23\right\}   &  \rightarrow\left\{
0,1,2,3,4,5\right\}  \times\left\{  0,1,2,3\right\}  ,\\
a  &  \mapsto\left(  a\%6,a\%4\right)
\end{align*}
is \textbf{not} a bijection. Indeed, it is neither injective (for example, it
sends both $0$ and $12$ to the same pair $\left(  0,0\right)  $) nor
surjective (for example, it never takes the value $\left(  1,2\right)  $).
\end{example}

\begin{proof}
[Proof of Theorem \ref{thm.ent.CRT-bij}.]For every $a\in\left\{
0,1,\ldots,mn-1\right\}  $, we have $\left(  a\%m,a\%n\right)  \in\left\{
0,1,\ldots,m-1\right\}  \times\left\{  0,1,\ldots,n-1\right\}  $%
\ \ \ \ \footnote{\textit{Proof.} Let $a\in\left\{  0,1,\ldots,mn-1\right\}
$. We must prove that $\left(  a\%m,a\%n\right)  \in\left\{  0,1,\ldots
,m-1\right\}  \times\left\{  0,1,\ldots,n-1\right\}  $.
\par
Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(a)} (applied to $u=a$) yields
that $a\%n\in\left\{  0,1,\ldots,n-1\right\}  $ and $a\%n\equiv
a\operatorname{mod}n$. Thus, $a\%n\in\left\{  0,1,\ldots,n-1\right\}  $. The
same argument (applied to $m$ instead of $n$) yields $a\%m\in\left\{
0,1,\ldots,m-1\right\}  $. Combining this with $a\%n\in\left\{  0,1,\ldots
,n-1\right\}  $, we obtain $\left(  a\%m,a\%n\right)  \in\left\{
0,1,\ldots,m-1\right\}  \times\left\{  0,1,\ldots,n-1\right\}  $. Qed.}.
Hence, the map $K_{m,n}$ is well-defined. It remains to prove that this map
$K_{m,n}$ is a bijection. To that aim, we shall prove that $K_{m,n}$ is
injective and surjective.

[\textit{Proof that the map }$K_{m,n}$ \textit{is injective:} Let
$a,b\in\left\{  0,1,\ldots,mn-1\right\}  $ be such that $K_{m,n}\left(
a\right)  =K_{m,n}\left(  b\right)  $. We want to prove $a=b$.

The definition of $K_{m,n}$ yields $K_{m,n}\left(  a\right)  =\left(
a\%m,a\%n\right)  $ and $K_{m,n}\left(  b\right)  =\left(  b\%m,b\%n\right)
$. Hence, the equality $K_{m,n}\left(  a\right)  =K_{m,n}\left(  b\right)  $
(which is true by assumption) rewrites as $\left(  a\%m,a\%n\right)  =\left(
b\%m,b\%n\right)  $. In other words, $a\%m=b\%m$ and $a\%n=b\%n$.

Now, Exercise \ref{exe.ent.quo-rem.mod=rem} (applied to $u=a$ and $v=b$)
yields that $a\equiv b\operatorname{mod}n$ if and only if $a\%n=b\%n$. Hence,
$a\equiv b\operatorname{mod}n$ (since $a\%n=b\%n$). In other words, $n\mid
a-b$. The same argument (but applied to $m$ instead of $n$) yields $m\mid a-b$.

Now, we have $m\perp n$ (since $m$ and $n$ are coprime) and $m\mid a-b$ and
$n\mid a-b$. Hence, Theorem \ref{thm.ent.coprime.combine} (applied to $m$, $n$
and $a-b$ instead of $a$, $b$ and $c$) yields $mn\mid a-b$. In other words,
$a\equiv b\operatorname{mod}mn$. Hence, Corollary \ref{cor.ent.quo-rem.remmod}
\textbf{(c)} (applied to $mn$, $b$ and $a$ instead of $n$, $u$ and $c$) yields
$a=b\%\left(  mn\right)  $ (since $a\in\left\{  0,1,\ldots,mn-1\right\}  $).

On the other hand, $b\equiv b\operatorname{mod}mn$. Hence, Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(c)} (applied to $mn$, $b$ and $b$
instead of $n$, $u$ and $c$) yields $b=b\%\left(  mn\right)  $ (since
$b\in\left\{  0,1,\ldots,mn-1\right\}  $). Comparing this with $a=b\%\left(
mn\right)  $, we obtain $a=b$.

Now, forget that we fixed $a$ and $b$. We thus have shown that if
$a,b\in\left\{  0,1,\ldots,mn-1\right\}  $ are such that $K_{m,n}\left(
a\right)  =K_{m,n}\left(  b\right)  $, then $a=b$. In other words, the map
$K_{m,n}$ is injective.]

[\textit{Proof that the map }$K_{m,n}$ \textit{is surjective:} Fix $\left(
a,b\right)  \in\left\{  0,1,\ldots,m-1\right\}  \times\left\{  0,1,\ldots
,n-1\right\}  $. We want to find a $c\in\left\{  0,1,\ldots,mn-1\right\}  $
such that $K_{m,n}\left(  c\right)  =\left(  a,b\right)  $.

We have $\left(  a,b\right)  \in\left\{  0,1,\ldots,m-1\right\}
\times\left\{  0,1,\ldots,n-1\right\}  $. In other words, $a\in\left\{
0,1,\ldots,m-1\right\}  $ and $b\in\left\{  0,1,\ldots,n-1\right\}  $. Theorem
\ref{thm.ent.crt1} \textbf{(a)} shows that there exists an integer
$x\in\mathbb{Z}$ such that%
\[
\left(  x\equiv a\operatorname{mod}m\text{ and }x\equiv b\operatorname{mod}%
n\right)  .
\]
Consider such an $x$. We have $x\equiv a\operatorname{mod}m$, thus $a\equiv
x\operatorname{mod}m$. From $x\equiv b\operatorname{mod}n$, we obtain $b\equiv
x\operatorname{mod}n$.

Let $y=x\%\left(  mn\right)  $. Then, Corollary \ref{cor.ent.quo-rem.remmod}
\textbf{(a)} (applied to $mn$ and $x$ instead of $n$ and $u$) yields
$x\%\left(  mn\right)  \in\left\{  0,1,\ldots,mn-1\right\}  $ and $x\%\left(
mn\right)  \equiv x\operatorname{mod}mn$. Hence, $x\equiv x\%\left(
mn\right)  =y\operatorname{mod}mn$ (since $y=x\%\left(  mn\right)  $).

Since $m\mid mn$, we thus obtain $x\equiv y\operatorname{mod}m$ (by
Proposition \ref{prop.ent.mod.basics} \textbf{(e)}, applied to $mn$, $x$, $y$
and $m$ instead of $n$, $a$, $b$ and $m$). Thus, $a\equiv x\equiv
y\operatorname{mod}m$. Hence, Corollary \ref{cor.ent.quo-rem.remmod}
\textbf{(c)} (applied to $m$, $y$ and $a$ instead of $n$, $u$ and $c$) yields
$a=y\%m$ (since $a\in\left\{  0,1,\ldots,m-1\right\}  $).

Also, from $x\equiv y\operatorname{mod}mn$ and $n\mid mn$, we obtain $x\equiv
y\operatorname{mod}n$ (by Proposition \ref{prop.ent.mod.basics} \textbf{(e)},
applied to $mn$, $x$, $y$ and $n$ instead of $n$, $a$, $b$ and $m$). Thus,
$b\equiv x\equiv y\operatorname{mod}n$. Hence, Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(c)} (applied to $y$ and $b$ instead of
$u$ and $c$) yields $b=y\%n$ (since $b\in\left\{  0,1,\ldots,n-1\right\}  $).

From $a=y\%m$ and $b=y\%n$, we obtain $\left(  a,b\right)  =\left(
y\%m,y\%n\right)  $.

We have $y\in x\%\left(  mn\right)  \in\left\{  0,1,\ldots,mn-1\right\}  $;
thus, the definition of the map $K_{m,n}$ yields $K_{m,n}\left(  y\right)
=\left(  y\%m,y\%n\right)  =\left(  a,b\right)  $ (since $\left(  a,b\right)
=\left(  y\%m,y\%n\right)  $). Thus, there exists a $c\in\left\{
0,1,\ldots,mn-1\right\}  $ such that $K_{m,n}\left(  c\right)  =\left(
a,b\right)  $ (namely, $c=y$).

Now, forget that we fixed $\left(  a,b\right)  $. We thus have shown that for
any $\left(  a,b\right)  \in\left\{  0,1,\ldots,m-1\right\}  \times\left\{
0,1,\ldots,n-1\right\}  $, there exists a $c\in\left\{  0,1,\ldots
,mn-1\right\}  $ such that $K_{m,n}\left(  c\right)  =\left(  a,b\right)  $.
In other words, the map $K_{m,n}$ is surjective.]

We have now proven that the map $K_{m,n}$ is both injective and surjective.
Hence, this map $K_{m,n}$ is bijective, i.e., is a bijection. This proves
Theorem \ref{thm.ent.CRT-bij}.

[\textit{Remark:} We could have saved ourselves some of the work done in this
proof by invoking the Pigeonhole Principle. Indeed, our goal was to show that
the map $K_{m,n}$ is bijective. By the Pigeonhole Principle for Injections
(Theorem \ref{thm.pigeon.inj}), it suffices to prove that it is injective,
because $\left\{  0,1,\ldots,mn-1\right\}  $ and $\left\{  0,1,\ldots
,m-1\right\}  \times\left\{  0,1,\ldots,n-1\right\}  $ are two finite sets of
the same size. Alternatively, by the Pigeonhole Principle for Surjections
(Theorem \ref{thm.pigeon.surj}), it would instead suffice to prove that the
map $K_{m,n}$ is surjective].
\end{proof}

\subsubsection{Coprime remainders}

For the rest of this section, we shall use the following notation:

\begin{definition}
\label{def.ent.CRT-bij.Cn}Let $n$ be a positive integer. Then, let $C_{n}$ be
the subset $\left\{  i\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ i\perp
n\right\}  $ of $\left\{  0,1,\ldots,n-1\right\}  $.
\end{definition}

For instance,%
\[
C_{4}=\left\{  1,3\right\}  ,\ \ \ \ \ \ \ \ \ \ C_{5}=\left\{
1,2,3,4\right\}  ,\ \ \ \ \ \ \ \ \ \ C_{6}=\left\{  1,5\right\}
\ \ \ \ \ \ \ \ \ \ \text{and}\ \ \ \ \ \ \ \ \ \ C_{1}=\left\{  0\right\}  .
\]


Now, we claim the following:

\begin{proposition}
\label{prop.ent.CRT-bij.Cn}Let $m$ and $n$ be two coprime positive integers.
Consider the map $K_{m,n}$ defined in Theorem \ref{thm.ent.CRT-bij}. Then,%
\[
K_{m,n}\left(  C_{mn}\right)  =C_{m}\times C_{n}.
\]
(Here, $K_{m,n}\left(  C_{mn}\right)  $ denotes the image of the subset
$C_{mn}$ of $\left\{  0,1,\ldots,mn-1\right\}  $ under the map $K_{m,n}$; that
is, $K_{m,n}\left(  C_{mn}\right)  =\left\{  K_{m,n}\left(  x\right)
\ \mid\ x\in C_{mn}\right\}  $.)
\end{proposition}

\begin{example}
Theorem \ref{thm.ent.CRT-bij} (applied to $m=3$ and $n=5$) says that the map%
\begin{align*}
K_{3,5}:\left\{  0,1,\ldots,14\right\}   &  \rightarrow\left\{  0,1,2\right\}
\times\left\{  0,1,2,3,4\right\}  ,\\
a  &  \mapsto\left(  a\%3,a\%5\right)
\end{align*}
is a bijection. Proposition \ref{prop.ent.CRT-bij.Cn} (applied to $m=3$ and
$n=5$) says that this map satisfies $K_{3,5}\left(  C_{15}\right)
=C_{3}\times C_{5}$. In view of
\begin{align*}
C_{15}  &  =\left\{  i\in\left\{  0,1,\ldots,14\right\}  \ \mid\ i\perp
15\right\}  =\left\{  1,2,4,7,8,11,13,14\right\}  ,\\
C_{3}  &  =\left\{  i\in\left\{  0,1,2\right\}  \ \mid\ i\perp3\right\}
=\left\{  1,2\right\}  ,\ \ \ \ \ \ \ \ \ \ \text{and}\\
C_{5}  &  =\left\{  i\in\left\{  0,1,2,3,4\right\}  \ \mid\ i\perp5\right\}
=\left\{  1,2,3,4\right\}  ,
\end{align*}
this rewrites as%
\[
K_{3,5}\left(  \left\{  1,2,4,7,8,11,13,14\right\}  \right)  =\left\{
1,2\right\}  \times\left\{  1,2,3,4\right\}  .
\]
And indeed, this can easily be checked: The map $K_{3,5}$ sends%
\[%
\begin{array}
[c]{cccccccccc}%
1, & 2, & 4, & 7, & 8, & 11, & 13, & 14, &  & \text{to}\\
\left(  1,1\right)  , & \left(  2,2\right)  , & \left(  1,4\right)  , &
\left(  1,2\right)  , & \left(  2,3\right)  , & \left(  2,1\right)  , &
\left(  1,3\right)  & \left(  2,4\right)  , &  &
\end{array}
\]
respectively, which entails%
\begin{align*}
&  K_{3,5}\left(  \left\{  1,2,4,7,8,11,13,14\right\}  \right) \\
&  =\left\{  \left(  1,1\right)  ,\left(  2,2\right)  ,\left(  1,4\right)
,\left(  1,2\right)  ,\left(  2,3\right)  ,\left(  2,1\right)  ,\left(
1,3\right)  ,\left(  2,4\right)  \right\}  =\left\{  1,2\right\}
\times\left\{  1,2,3,4\right\}  .
\end{align*}

\end{example}

\begin{proof}
[Proof of Proposition \ref{prop.ent.CRT-bij.Cn}.]Theorem \ref{thm.ent.CRT-bij}
yields that the map $K_{m,n}$ is well-defined and is a bijection.

The definition of $C_{n}$ yields%
\[
C_{n}=\left\{  i\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ i\perp n\right\}
\subseteq\left\{  0,1,\ldots,n-1\right\}  .
\]
The definition of $C_{m}$ yields%
\[
C_{m}=\left\{  i\in\left\{  0,1,\ldots,m-1\right\}  \ \mid\ i\perp m\right\}
\subseteq\left\{  0,1,\ldots,m-1\right\}  .
\]
The definition of $C_{mn}$ yields
\[
C_{mn}=\left\{  i\in\left\{  0,1,\ldots,mn-1\right\}  \ \mid\ i\perp
mn\right\}  \subseteq\left\{  0,1,\ldots,mn-1\right\}  .
\]
Hence, $K_{m,n}\left(  C_{mn}\right)  $ is well-defined. Also, from
$C_{m}\subseteq\left\{  0,1,\ldots,m-1\right\}  $ and $C_{n}\subseteq\left\{
0,1,\ldots,n-1\right\}  $, we obtain
\[
C_{m}\times C_{n}\subseteq\left\{  0,1,\ldots,m-1\right\}  \times\left\{
0,1,\ldots,n-1\right\}  .
\]


Now, we claim that%
\begin{equation}
K_{m,n}\left(  C_{mn}\right)  \subseteq C_{m}\times C_{n}\text{.}
\label{pf.prop.ent.CRT-bij.Cn.1}%
\end{equation}


[\textit{Proof of (\ref{pf.prop.ent.CRT-bij.Cn.1}):} Let $z\in K_{m,n}\left(
C_{mn}\right)  $. Thus, $z=K_{m,n}\left(  x\right)  $ for some $x\in C_{mn}$.
Consider this $x$.

We have $x\in C_{mn}=\left\{  i\in\left\{  0,1,\ldots,mn-1\right\}
\ \mid\ i\perp mn\right\}  $. In other words, $x$ is an $i\in\left\{
0,1,\ldots,mn-1\right\}  $ satisfying $i\perp mn$. In other words, $x$ is an
element of $\left\{  0,1,\ldots,mn-1\right\}  $ and satisfies $x\perp mn$. In
other words, $x\perp nm$ (since $mn=nm$).

We have $x\mid x$ and $m\mid mn$. Hence, Exercise \ref{exe.ent.gcd.div}
(applied to $a_{1}=x$, $a_{2}=m$, $b_{1}=x$ and $b_{2}=mn$) yields
$\gcd\left(  x,m\right)  \mid\gcd\left(  x,mn\right)  =1$ (since $x\perp mn$).
Since $\gcd\left(  x,m\right)  $ is a nonnegative integer\footnote{because any
gcd is a nonnegative integer}, this entails $\gcd\left(  x,m\right)  =1$ (by
Exercise \ref{exe.ent.div.g|1}, applied to $g=\gcd\left(  x,m\right)  $). In
other words, $x\perp m$. But Corollary \ref{cor.ent.quo-rem.remmod}
\textbf{(a)} (applied to $m$ and $x$ instead of $n$ and $u$) yields
$x\%m\in\left\{  0,1,\ldots,m-1\right\}  $ and $x\%m\equiv x\operatorname{mod}%
m$. From $x\%m\equiv x\operatorname{mod}m$, we obtain $x\equiv
x\%m\operatorname{mod}m$. Hence, Exercise \ref{exe.ent.coprime.b==c} (applied
to $x$, $x\%m$ and $m$ instead of $a$, $b$ and $c$) yields $x\%m\perp m$
(since $x\perp m$). Hence, $x\%m$ is an $i\in\left\{  0,1,\ldots,m-1\right\}
$ satisfying $i\perp m$ (since $x\%m\in\left\{  0,1,\ldots,m-1\right\}  $). In
other words, $x\%m\in\left\{  i\in\left\{  0,1,\ldots,m-1\right\}
\ \mid\ i\perp m\right\}  $. In other words, $x\%m\in C_{m}$ (since
$C_{m}=\left\{  i\in\left\{  0,1,\ldots,m-1\right\}  \ \mid\ i\perp m\right\}
$).

The same argument (with the roles of $m$ and $n$ swapped) yields $x\%n\in
C_{n}$ (since $x\perp nm$). Now,
\begin{align*}
z  &  =K_{m,n}\left(  x\right)  =\left(  x\%m,x\%n\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }K_{m,n}\right) \\
&  \in C_{m}\times C_{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }x\%m\in
C_{m}\text{ and }x\%n\in C_{n}\right)  .
\end{align*}


Now, forget that we fixed $z$. We thus have proven that $z\in C_{m}\times
C_{n}$ for each $z\in K_{m,n}\left(  C_{mn}\right)  $. In other words,
$K_{m,n}\left(  C_{mn}\right)  \subseteq C_{m}\times C_{n}$. This proves
(\ref{pf.prop.ent.CRT-bij.Cn.1}).]

Next, we claim that%
\begin{equation}
C_{m}\times C_{n}\subseteq K_{m,n}\left(  C_{mn}\right)  .
\label{pf.prop.ent.CRT-bij.Cn.2}%
\end{equation}


[\textit{Proof of (\ref{pf.prop.ent.CRT-bij.Cn.2}):} Let $y\in C_{m}\times
C_{n}$. We shall prove that $y\in K_{m,n}\left(  C_{mn}\right)  $.

We have $y\in C_{m}\times C_{n}\subseteq\left\{  0,1,\ldots,m-1\right\}
\times\left\{  0,1,\ldots,n-1\right\}  =K_{m,n}\left(  \left\{  0,1,\ldots
,mn-1\right\}  \right)  $ (since the map $K_{m,n}$ is a bijection). In other
words, there exists some $x\in\left\{  0,1,\ldots,mn-1\right\}  $ such that
$y=K_{m,n}\left(  x\right)  $. Consider this $x$. The definition of $K_{m,n}$
yields $K_{m,n}\left(  x\right)  =\left(  x\%m,x\%n\right)  $. Hence,%
\[
\left(  x\%m,x\%n\right)  =K_{m,n}\left(  x\right)  =y\in C_{m}\times C_{n}.
\]
In other words, $x\%m\in C_{m}$ and $x\%n\in C_{n}$.

We have $x\%m\in C_{m}=\left\{  i\in\left\{  0,1,\ldots,m-1\right\}
\ \mid\ i\perp m\right\}  $. In other words, $x\%m$ is an $i\in\left\{
0,1,\ldots,m-1\right\}  $ satisfying $i\perp m$. In other words, $x\%m$ is an
element of $\left\{  0,1,\ldots,m-1\right\}  $ and satisfies $x\%m\perp m$.

But Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(a)} (applied to $m$ and
$x$ instead of $n$ and $u$) yields $x\%m\in\left\{  0,1,\ldots,m-1\right\}  $
and $x\%m\equiv x\operatorname{mod}m$. Hence, Exercise
\ref{exe.ent.coprime.b==c} (applied to $x\%m$, $x$ and $m$ instead of $a$, $b$
and $c$) yields $x\perp m$ (since $x\%m\perp m$). This yields $m\perp x$ (by
Proposition \ref{prop.ent.coprime.perp-symm}). The same argument (applied to
$n$ instead of $m$) yields $n\perp x$ (since $x\%n\in C_{n}$). Hence, Theorem
\ref{thm.ent.coprime.ab-to-c} (applied to $m$, $n$ and $x$ instead of $a$, $b$
and $c$) yields $mn\perp x$. This yields $x\perp mn$ (by Proposition
\ref{prop.ent.coprime.perp-symm}). Thus, $x$ is an $i\in\left\{
0,1,\ldots,mn-1\right\}  $ satisfying $i\perp mn$ (since $x\in\left\{
0,1,\ldots,mn-1\right\}  $). In other words, $x\in\left\{  i\in\left\{
0,1,\ldots,mn-1\right\}  \ \mid\ i\perp mn\right\}  $. In other words, $x\in
C_{mn}$ (since $C_{mn}=\left\{  i\in\left\{  0,1,\ldots,mn-1\right\}
\ \mid\ i\perp mn\right\}  $). Hence, $y=K_{m,n}\left(  \underbrace{x}_{\in
C_{mn}}\right)  \in K_{m,n}\left(  C_{mn}\right)  $.

Now, forget that we fixed $y$. We thus have shown that $y\in K_{m,n}\left(
C_{mn}\right)  $ for each $y\in C_{m}\times C_{n}$. In other words,
$C_{m}\times C_{n}\subseteq K_{m,n}\left(  C_{mn}\right)  $. This proves
(\ref{pf.prop.ent.CRT-bij.Cn.2}).]

Combining (\ref{pf.prop.ent.CRT-bij.Cn.1}) with
(\ref{pf.prop.ent.CRT-bij.Cn.2}), we obtain $K_{m,n}\left(  C_{mn}\right)
=C_{m}\times C_{n}$. This proves Proposition \ref{prop.ent.CRT-bij.Cn}.
\end{proof}

\subsubsection{\label{sect.ent.phi-fml-proof}Proving the formula for $\phi$}

We now can prove Theorem \ref{thm.ent.phi.mult}:

\begin{proof}
[First proof of Theorem \ref{thm.ent.phi.mult}.]The definition of $C_{n}$
yields
\begin{equation}
C_{n}=\left\{  i\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ i\perp n\right\}
. \label{pf.thm.ent.phi.mult.Cn=}%
\end{equation}
Lemma \ref{lem.ent.euler.phi0} yields%
\[
\phi\left(  n\right)  =\left\vert \underbrace{\left\{  i\in\left\{
0,1,\ldots,n-1\right\}  \ \mid\ i\perp n\right\}  }_{\substack{=C_{n}%
\\\text{(by (\ref{pf.thm.ent.phi.mult.Cn=}))}}}\right\vert =\left\vert
C_{n}\right\vert .
\]
The same argument (applied to $mn$ instead of $n$) yields $\phi\left(
mn\right)  =\left\vert C_{mn}\right\vert $.

We have shown that $\phi\left(  n\right)  =\left\vert C_{n}\right\vert $, so
that $\left\vert C_{n}\right\vert =\phi\left(  n\right)  $. The same argument
(applied to $m$ instead of $n$) yields $\left\vert C_{m}\right\vert
=\phi\left(  m\right)  $.

It is well-known that any two finite sets $A$ and $B$ satisfy $\left\vert
A\times B\right\vert =\left\vert A\right\vert \cdot\left\vert B\right\vert
$\ \ \ \ \footnote{This is the so-called \textit{product rule} in its simplest
form (see, e.g., \cite[1.5]{Loehr-BC} or \cite[\S 15.2.1]{LeLeMe}).}. Applying
this to $A=C_{m}$ and $B=C_{n}$, we obtain%
\[
\left\vert C_{m}\times C_{n}\right\vert =\underbrace{\left\vert C_{m}%
\right\vert }_{=\phi\left(  m\right)  }\cdot\underbrace{\left\vert
C_{n}\right\vert }_{=\phi\left(  n\right)  }=\phi\left(  m\right)  \cdot
\phi\left(  n\right)  .
\]


Note that $C_{mn}$ is a subset of $\left\{  0,1,\ldots,mn-1\right\}  $ (since
the definition of $C_{mn}$ yields $C_{mn}=\left\{  i\in\left\{  0,1,\ldots
,mn-1\right\}  \ \mid\ i\perp mn\right\}  \subseteq\left\{  0,1,\ldots
,mn-1\right\}  $).

Now, consider the map $K_{m,n}$ defined in Theorem \ref{thm.ent.CRT-bij}.
Then, Theorem \ref{thm.ent.CRT-bij} shows that this map $K_{m,n}$ is a
bijection. Thus, in particular, $K_{m,n}$ is injective. Hence, $\left\vert
K_{m,n}\left(  S\right)  \right\vert =\left\vert S\right\vert $ for each
subset $S$ of $\left\{  0,1,\ldots,mn-1\right\}  $\ \ \ \ \footnote{This
follows from the following general principle: If $f:X\rightarrow Y$ is an
injective map between two finite sets $X$ and $Y$, then $\left\vert f\left(
S\right)  \right\vert =\left\vert S\right\vert $ for each subset $S$ of $X$.}.
Applying this to $S=C_{mn}$, we obtain $\left\vert K_{m,n}\left(
C_{mn}\right)  \right\vert =\left\vert C_{mn}\right\vert $. Thus,%
\[
\left\vert C_{mn}\right\vert =\left\vert \underbrace{K_{m,n}\left(
C_{mn}\right)  }_{\substack{=C_{m}\times C_{n}\\\text{(by Proposition
\ref{prop.ent.CRT-bij.Cn})}}}\right\vert =\left\vert C_{m}\times
C_{n}\right\vert =\phi\left(  m\right)  \cdot\phi\left(  n\right)  .
\]
Hence, $\phi\left(  mn\right)  =\left\vert C_{mn}\right\vert =\phi\left(
m\right)  \cdot\phi\left(  n\right)  $. This proves Theorem
\ref{thm.ent.phi.mult}.
\end{proof}

We now take aim at proving Theorem \ref{thm.ent.phi.explicit}. First, let us
extend Theorem \ref{thm.ent.phi.mult} to products of $k$ mutually coprime integers:

\begin{exercise}
\label{exe.ent.phi.multk.1}Let $n_{1},n_{2},\ldots,n_{k}$ be mutually coprime
positive integers. Prove that $\phi\left(  n_{1}n_{2}\cdots n_{k}\right)
=\phi\left(  n_{1}\right)  \cdot\phi\left(  n_{2}\right)  \cdot\cdots\cdot
\phi\left(  n_{k}\right)  $.
\end{exercise}

\begin{exercise}
\label{exe.ent.phi.multk.2}Let $I$ be a finite set. For each $i\in I$, let
$n_{i}$ be an integer. Assume that%
\begin{equation}
\text{every two distinct elements }i\text{ and }j\text{ of }I\text{ satisfy
}n_{i}\perp n_{j}. \label{eq.exe.ent.phi.multk.2.ass}%
\end{equation}
Prove that
\[
\phi\left(  \prod_{i\in I}n_{i}\right)  =\prod_{i\in I}\phi\left(
n_{i}\right)  .
\]

\end{exercise}

We are finally ready to prove Theorem \ref{thm.ent.phi.explicit}:

\begin{proof}
[Proof of Theorem \ref{thm.ent.phi.explicit}.]If $p$ is a prime satisfying
$p\nmid n$, then $v_{p}\left(  n\right)  =0$ (by Corollary
\ref{cor.ent.prime.vp-0}) and therefore
\begin{equation}
p^{v_{p}\left(  n\right)  }=p^{0}=1. \label{pf.thm.ent.phi.explicit.=1}%
\end{equation}


If $p$ is a prime satisfying $p\mid n$, then $v_{p}\left(  n\right)  $ is a
positive integer\footnote{\textit{Proof.} Let $p$ be a prime satisfying $p\mid
n$. If we had $v_{p}\left(  n\right)  =0$, then we would have $p\nmid n$ (by
Corollary \ref{cor.ent.prime.vp-0}), and this would contradict $p\mid n$.
Hence, we cannot have $v_{p}\left(  n\right)  =0$. Thus, $v_{p}\left(
n\right)  \neq0$. But $v_{p}\left(  n\right)  \in\mathbb{N}$ (since $n$ is
nonzero). Thus, from $v_{p}\left(  n\right)  \neq0$, we conclude that
$v_{p}\left(  n\right)  $ is a positive integer. Qed.} and therefore we have%
\begin{equation}
\phi\left(  p^{v_{p}\left(  n\right)  }\right)  =\left(  p-1\right)
p^{v_{p}\left(  n\right)  -1} \label{pf.thm.ent.phi.explicit.=p-1}%
\end{equation}
(by Exercise \ref{exe.ent.phi.pk}, applied to $k=v_{p}\left(  n\right)  $).

Corollary \ref{cor.ent.prime.can-fac} yields%
\begin{align}
n  &  =\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }=\left(
\prod_{\substack{p\text{ prime;}\\p\mid n}}p^{v_{p}\left(  n\right)  }\right)
\cdot\left(  \prod_{\substack{p\text{ prime;}\\p\nmid n}}\underbrace{p^{v_{p}%
\left(  n\right)  }}_{\substack{=1\\\text{(by
(\ref{pf.thm.ent.phi.explicit.=1}))}}}\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since each prime }p\text{ satisfies either }p\mid n\text{ or }p\nmid n\\
\text{(but not both at the same time)}%
\end{array}
\right) \nonumber\\
&  =\left(  \prod_{\substack{p\text{ prime;}\\p\mid n}}p^{v_{p}\left(
n\right)  }\right)  \cdot\underbrace{\left(  \prod_{\substack{p\text{
prime;}\\p\nmid n}}1\right)  }_{=1}=\prod_{\substack{p\text{ prime;}\\p\mid
n}}p^{v_{p}\left(  n\right)  }. \label{pf.thm.ent.phi.explicit.2}%
\end{align}


Let $P$ be the set of all primes $p$ satisfying $p\mid n$. This set $P$ is
finite\footnote{\textit{Proof.} We shall show that $P\subseteq\left\{
1,2,\ldots,n\right\}  $.
\par
Indeed, let $p\in P$. Thus, $p$ is a prime satisfying $p\mid n$ (by the
definition of $P$). Hence, $p$ is positive (since $p$ is prime); thus,
$p\neq0$. Thus, from $p\mid n$, we obtain $\left\vert p\right\vert
\leq\left\vert n\right\vert $ (by Proposition \ref{prop.ent.div.1}
\textbf{(b)}, applied to $a=p$ and $b=n$). In view of $\left\vert p\right\vert
=p$ (since $p$ is positive) and $\left\vert n\right\vert =n$ (since $n$ is
positive), this rewrites as $p\leq n$. Hence, $p\in\left\{  1,2,\ldots
,n\right\}  $ (since $p$ is a positive integer).
\par
Now, forget that we fixed $p$. We thus have shown that $p\in\left\{
1,2,\ldots,n\right\}  $ for each $p\in P$. In other words, $P\subseteq\left\{
1,2,\ldots,n\right\}  $. Hence, the set $P$ is finite (since the set $\left\{
1,2,\ldots,n\right\}  $ is finite).}. For each $i\in P$, the number
$i^{v_{i}\left(  n\right)  }$ is an integer (since $v_{i}\left(  n\right)
\in\mathbb{N}$ (since $n$ is nonzero)). Moreover, every two distinct elements
$i$ and $j$ of $P$ satisfy $i^{v_{i}\left(  n\right)  }\perp j^{v_{j}\left(
n\right)  }$\ \ \ \ \footnote{\textit{Proof.} Let $i$ and $j$ be two distinct
elements of $P$. All elements of $P$ are primes (by the definition of $P$);
thus, $i$ and $j$ are primes (since $i$ and $j$ are elements of $P$). Also,
$i\neq j$ (since $i$ and $j$ are distinct). Hence, Exercise
\ref{exe.ent.prime.dist=cop} (applied to $p=i$ and $q=j$) yields $i\perp j$.
But $v_{i}\left(  n\right)  \in\mathbb{N}$ (since $n$ is nonzero) and
$v_{j}\left(  n\right)  \in\mathbb{N}$ (for the same reason). Hence, Exercise
\ref{exe.ent.coprime.powers} (applied to $i$, $j$, $v_{i}\left(  n\right)  $
and $v_{j}\left(  n\right)  $ instead of $a$, $b$, $n$ and $m$) yields
$i^{v_{i}\left(  n\right)  }\perp j^{v_{j}\left(  n\right)  }$. Qed.}. Hence,
Exercise \ref{exe.ent.phi.multk.2} (applied to $I=P$ and $n_{i}=i^{v_{i}%
\left(  n\right)  }$) yields
\[
\phi\left(  \prod_{i\in P}i^{v_{i}\left(  n\right)  }\right)  =\prod_{i\in
P}\phi\left(  i^{v_{i}\left(  n\right)  }\right)  .
\]
Renaming the index $i$ as $p$ in both products, we can rewrite this equality
as
\begin{equation}
\phi\left(  \prod_{p\in P}p^{v_{p}\left(  n\right)  }\right)  =\prod_{p\in
P}\phi\left(  p^{v_{p}\left(  n\right)  }\right)  .
\label{pf.thm.ent.phi.explicit.4}%
\end{equation}
But the product signs \textquotedblleft$\prod_{p\in P}$\textquotedblright\ in
this equality can be replaced by \textquotedblleft$\prod_{\substack{p\text{
prime;}\\p\mid n}}$\textquotedblright\ without changing their meaning (since
$P$ is the set of all primes $p$ satisfying $p\mid n$). Hence, the equality
(\ref{pf.thm.ent.phi.explicit.4}) rewrites as%
\begin{equation}
\phi\left(  \prod_{\substack{p\text{ prime;}\\p\mid n}}p^{v_{p}\left(
n\right)  }\right)  =\prod_{\substack{p\text{ prime;}\\p\mid n}}\phi\left(
p^{v_{p}\left(  n\right)  }\right)  . \label{pf.thm.ent.phi.explicit.5}%
\end{equation}
Now, applying the map $\phi$ to both sides of the equality
(\ref{pf.thm.ent.phi.explicit.2}), we find%
\begin{align*}
\phi\left(  n\right)   &  =\phi\left(  \prod_{\substack{p\text{ prime;}\\p\mid
n}}p^{v_{p}\left(  n\right)  }\right)  =\prod_{\substack{p\text{
prime;}\\p\mid n}}\underbrace{\phi\left(  p^{v_{p}\left(  n\right)  }\right)
}_{\substack{=\left(  p-1\right)  p^{v_{p}\left(  n\right)  -1}\\\text{(by
(\ref{pf.thm.ent.phi.explicit.=p-1}))}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.thm.ent.phi.explicit.5})}\right) \\
&  =\prod_{\substack{p\text{ prime;}\\p\mid n}}\underbrace{\left(  \left(
p-1\right)  p^{v_{p}\left(  n\right)  -1}\right)  }_{\substack{=pp^{v_{p}%
\left(  n\right)  -1}-p^{v_{p}\left(  n\right)  -1}\\=p^{v_{p}\left(
n\right)  }-p^{v_{p}\left(  n\right)  -1}\\=p^{v_{p}\left(  n\right)
}-p^{v_{p}\left(  n\right)  }/p\\=p^{v_{p}\left(  n\right)  }\left(
1-\dfrac{1}{p}\right)  }}=\prod_{\substack{p\text{ prime;}\\p\mid n}}\left(
p^{v_{p}\left(  n\right)  }\left(  1-\dfrac{1}{p}\right)  \right) \\
&  =\underbrace{\left(  \prod_{\substack{p\text{ prime;}\\p\mid n}%
}p^{v_{p}\left(  n\right)  }\right)  }_{\substack{=n\\\text{(by
(\ref{pf.thm.ent.phi.explicit.2}))}}}\cdot\prod_{\substack{p\text{
prime;}\\p\mid n}}\left(  1-\dfrac{1}{p}\right)  =n\cdot\prod
_{\substack{p\text{ prime;}\\p\mid n}}\left(  1-\dfrac{1}{p}\right)  .
\end{align*}
This proves Theorem \ref{thm.ent.phi.explicit}.
\end{proof}

Theorem \ref{thm.ent.euler} generalizes Theorem \ref{thm.ent.fermat}
\textbf{(a)}. Likewise, the following exercise generalizes Theorem
\ref{thm.ent.fermat} \textbf{(b)}:

\begin{exercise}
\label{exe.ent.euler.non-coprime}Let $a$ be an integer, and let $n$ be a
positive integer. Prove that $a^{n}\equiv a^{n-\phi\left(  n\right)
}\operatorname{mod}n$.

[\textbf{Hint:} Use Exercises \ref{exe.ent.prime.modpvp} and
\ref{exe.ent.phi.d-phid} and Theorems \ref{thm.ent.euler} and
\ref{thm.ent.phi.mult}.]
\end{exercise}

\begin{center}
\textbf{2019-02-18 lecture}
\end{center}

\subsection{Binomial coefficients}

\subsubsection{Definitions and basics}

Next, we shall introduce and briefly study binomial coefficients. While
binomial coefficients belong more to (enumerative) combinatorics than to
algebra, they are used significantly in algebra, so we have to derive some of
their properties.

Here is the definition of binomial coefficients (at least the one I am going
to follow in these notes):

\begin{definition}
\label{def.binom.binom}Let $n\in\mathbb{Q}$ and $k\in\mathbb{N}$. Then, we
define the \textit{binomial coefficient} $\dbinom{n}{k}$ as follows:

\textbf{(a)} If $k\in\mathbb{N}$, then we set
\[
\dbinom{n}{k}=\dfrac{n\left(  n-1\right)  \left(  n-2\right)  \cdots\left(
n-k+1\right)  }{k!}=\dfrac{\prod_{i=0}^{k-1}\left(  n-i\right)  }{k!}.
\]


\textbf{(b)} If $k\notin\mathbb{N}$, then we set $\dbinom{n}{k}=0$.
\end{definition}

This definition is exactly the definition of $\dbinom{n}{k}$ that we used in
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw0s.pdf}{homework set \#0}.
It is also almost exactly the definition given in \cite[(5.1)]{GKP} (except
that we are allowing $k$ to be non-integer, while the authors of \cite{GKP} do
not). Definition \ref{def.binom.binom} \textbf{(a)} is also identical with the
definition of binomial coefficients in \cite{detnotes}. Our choice to require
$n\in\mathbb{Q}$ is more or less arbitrary -- we could have as well made the
same definition for $n\in\mathbb{R}$ or $n\in\mathbb{C}$ (but I am not aware
of this generality being of much use).

Generally, when you read literature on binomial coefficients, be aware that
some authors use somewhat different definitions of $\dbinom{n}{k}$. All known
definitions give the same results when $n$ and $k$ are nonnegative integers,
but in the other cases there may be discrepancies.

Here are some examples of binomial coefficients:

\begin{example}
\textbf{(a)} Definition \ref{def.binom.binom} \textbf{(a)} yields $\dbinom
{n}{2}=\dfrac{n\left(  n-1\right)  }{2!}=\dfrac{n\left(  n-1\right)  }{2}$ for
all $n\in\mathbb{Q}$. Thus, for example,%
\[
\dbinom{5}{2}=\dfrac{5\cdot4}{2}=10.
\]


\textbf{(b)} Definition \ref{def.binom.binom} \textbf{(a)} yields $\dbinom
{n}{3}=\dfrac{n\left(  n-1\right)  \left(  n-2\right)  }{3!}=\dfrac{n\left(
n-1\right)  \left(  n-2\right)  }{6}$ for all $n\in\mathbb{Q}$. Thus, for
example,%
\begin{align*}
\dbinom{5}{3}  &  =\dfrac{5\cdot4\cdot3}{6}=\dfrac{60}{6}=10;\\
\dbinom{1}{3}  &  =\dfrac{1\cdot0\cdot\left(  -1\right)  }{6}=\dfrac{0}%
{6}=0;\\
\dbinom{-2}{3}  &  =\dfrac{\left(  -2\right)  \cdot\left(  -3\right)
\cdot\left(  -4\right)  }{6}=\dfrac{-24}{6}=-4;\\
\dbinom{1/2}{3}  &  =\dfrac{\left(  1/2\right)  \cdot\left(  -1/2\right)
\cdot\left(  -3/2\right)  }{6}=\dfrac{3/8}{6}=\dfrac{1}{16}.
\end{align*}


\textbf{(c)} Definition \ref{def.binom.binom} \textbf{(a)} yields $\dbinom
{n}{1}=\dfrac{n}{1!}=\dfrac{n}{1}=n$ for all $n\in\mathbb{Q}$.

\textbf{(d)} Definition \ref{def.binom.binom} \textbf{(b)} yields $\dbinom
{4}{1/2}=0$ (since $1/2\notin\mathbb{N}$).
\end{example}

The binomial coefficients $\dbinom{n}{k}$ for $n\in\mathbb{N}$ and
$k\in\left\{  0,1,\ldots,n\right\}  $ are particularly important. They are
usually tabulated in a triangle-shaped table known as
\textit{\href{https://en.wikipedia.org/wiki/Pascal's_triangle}{\textit{Pascal's
triangle}}}, which starts as follows:%
\[%
\begin{array}
[c]{ccccccccccccc}%
\phantom{15} & \phantom{15} & \phantom{15} & \phantom{15} & \phantom{15} &
\phantom{15} & 1 & \phantom{15} & \phantom{15} & \phantom{15} & \phantom{15} &
\phantom{15} & \phantom{15}\\
&  &  &  &  & 1 &  & 1 &  &  &  &  & \\
&  &  &  & 1 &  & 2 &  & 1 &  &  &  & \\
&  &  & 1 &  & 3 &  & 3 &  & 1 &  &  & \\
&  & 1 &  & 4 &  & 6 &  & 4 &  & 1 &  & \\
& 1 &  & 5 &  & 10 &  & 10 &  & 5 &  & 1 & \\
1 &  & 6 &  & 15 &  & 20 &  & 15 &  & 6 &  & 1
\end{array}
\ .
\]
In this table, the binomial coefficient $\dbinom{n}{k}$ appears as the $k$-th
entry (from the left) of the $n$-th row (but we count the rows from $0$; that
is, the topmost row, consisting just of a single \textquotedblleft%
$1$\textquotedblright, is actually the $0$-th row). We advise the reader to
peruse \href{https://en.wikipedia.org/wiki/Pascal's_triangle}{the Wikipedia
article} for the history and the multiple illustrious properties of Pascal's triangle.

The expression $\dbinom{n}{k}$ is pronounced as \textquotedblleft$n$ choose
$k$\textquotedblright. The reason for the word \textquotedblleft
choose\textquotedblright\ will become clearer once we have seen Theorem
\ref{thm.binom.comb-int} further below.

Some of these properties are so fundamental that we are going to list them
right now:

\begin{theorem}
\label{thm.binom.n!k!}Let $n\in\mathbb{N}$ and $k\in\mathbb{N}$ be such that
$n\geq k$. Then,%
\[
\dbinom{n}{k}=\dfrac{n!}{k!\left(  n-k\right)  !}.
\]

\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.binom.n!k!}.]This was Exercise 3 \textbf{(a)} on
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw0s.pdf}{homework set \#0}.
\end{proof}

Several authors use the formula $\dbinom{n}{k}=\dfrac{n!}{k!\left(
n-k\right)  !}$ as a definition of the binomial coefficients. However, this
definition has the massive disadvantage of being less general than Definition
\ref{def.binom.binom} (since it only covers the case when $n,k\in\mathbb{N}$
and $n\geq k$). To us, this formula is not a definition, but a result that can
be proven.

\begin{theorem}
\label{thm.binom.k>n0}Let $n\in\mathbb{N}$ and $k\in\mathbb{Q}$ be such that
$k>n$. Then,
\[
\dbinom{n}{k}=0.
\]

\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.binom.k>n0}.]This was Exercise 3 \textbf{(b)} on
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw0s.pdf}{homework set \#0}.
\end{proof}

\begin{theorem}
\label{thm.binom.n0}Let $n\in\mathbb{Q}$. Then,%
\[
\dbinom{n}{0}=1.
\]

\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.binom.n0}.]Definition \ref{def.binom.binom}
\textbf{(a)} (applied to $k=0$) yields%
\[
\dbinom{n}{0}=\dfrac{\prod_{i=0}^{0-1}\left(  n-i\right)  }{0!}=\dfrac{1}{1}%
\]
(since $\prod_{i=0}^{0-1}\left(  n-i\right)  =\left(  \text{empty
product}\right)  =1$ and $0!=1$). Thus, $\dbinom{n}{0}=\dfrac{1}{1}=1$. This
proves Theorem \ref{thm.binom.n0}.
\end{proof}

\begin{theorem}
\label{thm.binom.symmetry}Let $n\in\mathbb{N}$ and $k\in\mathbb{Q}$. Then,%
\[
\dbinom{n}{k}=\dbinom{n}{n-k}.
\]

\end{theorem}

Theorem \ref{thm.binom.symmetry} is known as the \textit{symmetry of binomial
coefficients}. Note that it fails if $n\notin\mathbb{N}$; thus, be careful
when applying it!

\begin{proof}
[Proof of Theorem \ref{thm.binom.symmetry}.]This was Exercise 3 \textbf{(c)}
on \href{http://www-users.math.umn.edu/~dgrinber/19s/hw0s.pdf}{homework set
\#0}.
\end{proof}

\begin{theorem}
\label{thm.binom.upneg-n}Let $n\in\mathbb{Q}$ and $k\in\mathbb{Q}$. Then,%
\[
\dbinom{-n}{k}=\left(  -1\right)  ^{k}\dbinom{k+n-1}{k}.
\]

\end{theorem}

Theorem \ref{thm.binom.upneg-n} is one of the versions of the \textit{upper
negation formula}.

\begin{proof}
[Proof of Theorem \ref{thm.binom.upneg-n}.]This was Exercise 3 \textbf{(d)} on
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw0s.pdf}{homework set \#0}.
\end{proof}

\begin{theorem}
\label{thm.binom.rec}Any $n\in\mathbb{Q}$ and $k\in\mathbb{Q}$ satisfy
\[
\dbinom{n}{k}=\dbinom{n-1}{k}+\dbinom{n-1}{k-1}.
\]

\end{theorem}

Theorem \ref{thm.binom.rec} is known as the \textit{recurrence of the binomial
coefficients}, and is the reason why each entry of
\href{https://en.wikipedia.org/wiki/Pascal%27s_triangle}{Pascal's triangle} is
the sum of the two entries above it\footnote{Of course, this does not apply to
the \textquotedblleft$1$\textquotedblright\ at the apex of Pascal's triangle
(unless we extend the triangle further to the top by a $\left(  -1\right)
$-st row).}.

\begin{proof}
[Proof of Theorem \ref{thm.binom.rec}.]This was Exercise 3 \textbf{(e)} on
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw0s.pdf}{homework set \#0}.
\end{proof}

\begin{theorem}
\label{thm.binom.abs}Any $n\in\mathbb{Q}$ and $k\in\mathbb{Q}$ satisfy
\[
k\dbinom{n}{k}=n\dbinom{n-1}{k-1}.
\]

\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.binom.abs}.]This was Exercise 3 \textbf{(f)} on
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw0s.pdf}{homework set \#0}.
\end{proof}

\subsubsection{Combinatorial interpretation}

The next property of binomial coefficients is one of the major motivations for
defining them:

\begin{theorem}
\label{thm.binom.comb-int}Let $n\in\mathbb{N}$ and $k\in\mathbb{Q}$. Let $N$
be an $n$-element set. Then, $\dbinom{n}{k}$ is the number of $k$-element
subsets of $N$.
\end{theorem}

We shall refer to Theorem \ref{thm.binom.comb-int} as the
\textit{Combinatorial interpretation of binomial coefficients}. Theorem
\ref{thm.binom.comb-int} can be restated as \textquotedblleft$\dbinom{n}{k}$
is the number of ways to choose $k$ elements (with no repetitions and with no
regard for the order) from a given $n$-element set (when $n\in\mathbb{N}%
$)\textquotedblright. This is the reason why $\dbinom{n}{k}$ is called
\textquotedblleft$n$ choose $k$\textquotedblright. Note, however, that Theorem
\ref{thm.binom.comb-int} does not directly help us compute $\dbinom{n}{k}$
when $n\notin\mathbb{N}$.

\begin{proof}
[Proof of Theorem \ref{thm.binom.comb-int}.]What follows is an outline of the
proof. For a detailed proof, see \cite[Exercise 3.4]{detnotes}, where I
thoroughly prove Theorem \ref{thm.binom.comb-int} in the case $k\in\mathbb{N}%
$. (The remaining case $k\notin\mathbb{N}$ is obvious, because in that case
the theorem simply says $0=0$.)

We proceed by induction on $n$:

\textit{Induction base:} Let $n$, $k$ and $N$ be as in Theorem
\ref{thm.binom.comb-int}, and let us assume that $n=0$. From $n=0$, we obtain
$\dbinom{n}{k}=\dbinom{0}{k}=%
\begin{cases}
1, & \text{if }k=0;\\
0, & \text{if }k\neq0
\end{cases}
$ (this is easy to derive from Definition \ref{def.binom.binom}\footnote{To
wit:
\par
\begin{itemize}
\item If $k=0$, then $\dbinom{0}{k}=\dbinom{0}{0}=1$ (by Theorem
\ref{thm.binom.n0}).
\par
\item If $k>0$, then Theorem \ref{thm.binom.k>n0} (applied to $0$ instead of
$n$) yields $\dbinom{0}{k}=0$.
\par
\item If $k<0$, then $k\notin\mathbb{N}$ and thus $\dbinom{0}{k}=0$ (by
Definition \ref{def.binom.binom} \textbf{(b)}).
\end{itemize}
\par
Thus, in all three cases ($k=0$, $k>0$ and $k<0$), we conclude that
$\dbinom{0}{k}=%
\begin{cases}
1, & \text{if }k=0;\\
0, & \text{if }k\neq0
\end{cases}
$.}). On the other hand, the set $N$ is empty (since $\left\vert N\right\vert
=n=0$). Thus, its only subset is $\varnothing$, which is a $0$-element subset.
Hence, $N$ has exactly one $0$-element subset, and no subsets of any other
size. Hence, the number of $k$-element subsets of $N$ is $%
\begin{cases}
1, & \text{if }k=0;\\
0, & \text{if }k\neq0
\end{cases}
$. Comparing this with $\dbinom{n}{k}=%
\begin{cases}
1, & \text{if }k=0;\\
0, & \text{if }k\neq0
\end{cases}
$, we conclude that $\dbinom{n}{k}$ is the number of $k$-element subsets of
$N$. Thus, we have proven Theorem \ref{thm.binom.comb-int} under the
assumption that $n=0$. This completes the induction base.

\textit{Induction step:} Let $m$ be a positive integer. Assume (as the
induction hypothesis) that Theorem \ref{thm.binom.comb-int} holds for $n=m-1$.
We must now prove that Theorem \ref{thm.binom.comb-int} holds for $n=m$.

Let $k\in\mathbb{Q}$. Let $N$ be an $m$-element set. Thus, $\left\vert
N\right\vert =m>0$. Hence, the set $N$ is nonempty; in other words, there
exists some $a\in N$. Pick such an $a$. (It does not matter which one we
choose, but we need to leave it fixed from now on.) Clearly, $\left\vert
N\setminus\left\{  a\right\}  \right\vert =m-1$ (since $\left\vert
N\right\vert =m$). In other words, $N\setminus\left\{  a\right\}  $ is an
$\left(  m-1\right)  $-element set.

Now, the $k$-element subsets of $N$ can be classified into two types:

\begin{itemize}
\item We say that a $k$-element subset is \textit{type-1} if it doesn't
contain $a$.

\item We say that a $k$-element subset is \textit{type-2} if it does contain
$a$.
\end{itemize}

(We shall use the adjectives \textquotedblleft type-1\textquotedblright\ and
\textquotedblleft type-2\textquotedblright\ for $k$-element subsets of $N$
only. Thus, whenever we say \textquotedblleft type-1 subset\textquotedblright%
\ in the following, we will always mean \textquotedblleft type-1 $k$-element
subset of $N$\textquotedblright, and similarly for \textquotedblleft type-2
subset\textquotedblright.)

Clearly, any $k$-element subset of $N$ is either type-1 or type-2 (but never
both at the same time).

The type-1 subsets are precisely the $k$-element subsets of the $\left(
m-1\right)  $-element set $N\setminus\left\{  a\right\}  $. By our induction
hypothesis, we know that Theorem \ref{thm.binom.comb-int} holds for $n=m-1$.
Hence, we can apply Theorem \ref{thm.binom.comb-int} to $m-1$ and
$N\setminus\left\{  a\right\}  $ instead of $n$ and $N$. We thus conclude that
$\dbinom{m-1}{k}$ is the number of $k$-element subsets of $N\setminus\left\{
a\right\}  $. In other words, $\dbinom{m-1}{k}$ is the number of type-1
subsets (since the type-1 subsets are precisely the $k$-element subsets of
$N\setminus\left\{  a\right\}  $). In other words,%
\begin{equation}
\dbinom{m-1}{k}=\left(  \text{the number of type-1 subsets}\right)  .
\label{pf.thm.binom.comb-int.IS.1}%
\end{equation}


Now, let us count the type-2 subsets\footnote{Keep in mind that
\textquotedblleft type-2 subset\textquotedblright\ means \textquotedblleft
type-2 $k$-element subset of $N$\textquotedblright.}. This is a bit harder,
since they are not subsets of $N\setminus\left\{  a\right\}  $ anymore.
However, they are in 1-to-1 correspondence (aka bijection) with some such
subsets. Namely, there is a bijection%
\begin{align*}
\left\{  \left(  k-1\right)  \text{-element subsets of }N\setminus\left\{
a\right\}  \right\}   &  \rightarrow\left\{  \text{type-2 subsets}\right\}
,\\
S  &  \mapsto S\cup\left\{  a\right\}  .
\end{align*}
(The inverse of this bijection sends each type-2 subset $T$ to $T\setminus
\left\{  a\right\}  $. You can easily show that these two maps are actually
well-defined and mutually inverse, so that they really are bijections.) This
bijection shows that%
\begin{equation}
\left\vert \left\{  \text{type-2 subsets}\right\}  \right\vert =\left\vert
\left\{  \left(  k-1\right)  \text{-element subsets of }N\setminus\left\{
a\right\}  \right\}  \right\vert . \label{pf.thm.binom.comb-int.IS.2}%
\end{equation}
But recall that Theorem \ref{thm.binom.comb-int} holds for $n=m-1$. Hence, we
can apply Theorem \ref{thm.binom.comb-int} to $m-1$, $k-1$ and $N\setminus
\left\{  a\right\}  $ instead of $n$, $k$ and $N$. We thus conclude that
$\dbinom{m-1}{k-1}$ is the number of $\left(  k-1\right)  $-element subsets of
$N\setminus\left\{  a\right\}  $. In other words,
\[
\dbinom{m-1}{k-1}=\left\vert \left\{  \left(  k-1\right)  \text{-element
subsets of }N\setminus\left\{  a\right\}  \right\}  \right\vert .
\]
Comparing this equality with (\ref{pf.thm.binom.comb-int.IS.2}), we obtain%
\begin{align}
\dbinom{m-1}{k-1}  &  =\left\vert \left\{  \text{type-2 subsets}\right\}
\right\vert \nonumber\\
&  =\left(  \text{the number of type-2 subsets}\right)  .
\label{pf.thm.binom.comb-int.IS.3}%
\end{align}


Now, recall that any $k$-element subset of $N$ is either type-1 or type-2 (but
never both at the same time). Hence, we can count all $k$-element subsets of
$N$ by first counting the type-1 subsets, then counting the type-2 subsets,
and then adding these two results. We thus find\footnote{The combinatorial
principle we are using in the following computation is the so-called
\textit{sum rule} in its simplest form (see, e.g., \cite[1.1]{Loehr-BC} or
\cite[\S 15.2.3]{LeLeMe}).}%
\begin{align*}
&  \left(  \text{the number of }k\text{-element subsets of }N\right) \\
&  =\underbrace{\left(  \text{the number of type-1 subsets}\right)
}_{\substack{=\dbinom{m-1}{k}\\\text{(by (\ref{pf.thm.binom.comb-int.IS.1}))}%
}}+\underbrace{\left(  \text{the number of type-2 subsets}\right)
}_{\substack{=\dbinom{m-1}{k-1}\\\text{(by (\ref{pf.thm.binom.comb-int.IS.3}%
))}}}\\
&  =\dbinom{m-1}{k}+\dbinom{m-1}{k-1}=\dbinom{m}{k}%
\end{align*}
(since Theorem \ref{thm.binom.rec} (applied to $n=m$) yields $\dbinom{m}%
{k}=\dbinom{m-1}{k}+\dbinom{m-1}{k-1}$). In other words, $\dbinom{m}{k}$ is
the number of $k$-element subsets of $N$.

Now, forget that we fixed $N$ and $k$. We thus have shown that if
$k\in\mathbb{Q}$ and if $N$ is an $m$-element set, then $\dbinom{m}{k}$ is the
number of $k$-element subsets of $N$. In other words, Theorem
\ref{thm.binom.comb-int} holds for $n=m$. This completes the induction step.
Hence, Theorem \ref{thm.binom.comb-int} is proven.
\end{proof}

\begin{corollary}
\label{cor.binom.N->N}Let $n\in\mathbb{N}$ and $k\in\mathbb{Q}$. Then,
$\dbinom{n}{k}$ is a nonnegative integer.
\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.binom.N->N}.]Let $N=\left\{  1,2,\ldots
,n\right\}  $; thus, $N$ is an $n$-element set. Hence, Theorem
\ref{thm.binom.comb-int} shows that $\dbinom{n}{k}$ is the number of
$k$-element subsets of $N$. But the latter number is clearly a nonnegative
integer (since it counts something). Thus, $\dbinom{n}{k}$ is a nonnegative
integer. This proves Corollary \ref{cor.binom.N->N}.
\end{proof}

\begin{proposition}
\label{prop.binom.Z->Z}Let $n\in\mathbb{Z}$ and $k\in\mathbb{Q}$. Then,
$\dbinom{n}{k}$ is a integer.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.binom.Z->Z}.]If $n\geq0$, then this follows
from Corollary \ref{cor.binom.N->N} (because $n\geq0$ implies $n\in\mathbb{N}%
$, and thus we can apply Corollary \ref{cor.binom.N->N}). Thus, for the rest
of this proof, we WLOG assume that $n<0$. Hence, $n\leq-1$ (since $n$ is an
integer), so that $n+1\leq0$ and thus $-\left(  n+1\right)  \geq0$. Therefore,
$-\left(  n+1\right)  \in\mathbb{N}$ (since $-\left(  n+1\right)  $ is an integer).

If $k\notin\mathbb{N}$, then $\dbinom{n}{k}$ is a integer (since Definition
\ref{def.binom.binom} \textbf{(b)} yields $\dbinom{n}{k}=0$ in this case).
Thus, for the rest of this proof, we WLOG assume that $k\in\mathbb{N}$. Thus,
$k+\left(  -n\right)  -1=\underbrace{k}_{\in\mathbb{N}}+\underbrace{\left(
-\left(  n+1\right)  \right)  }_{\in\mathbb{N}}\in\mathbb{N}$. Hence,
Corollary \ref{cor.binom.N->N} (applied to $k+\left(  -n\right)  -1$ instead
of $n$) yields that $\dbinom{k+\left(  -n\right)  -1}{k}$ is a nonnegative
integer. Thus, $\dbinom{k+\left(  -n\right)  -1}{k}\in\mathbb{Z}$.

Theorem \ref{thm.binom.upneg-n} (applied to $-n$ instead of $n$) yields%
\[
\dbinom{-\left(  -n\right)  }{k}=\underbrace{\left(  -1\right)  ^{k}}%
_{\in\mathbb{Z}}\underbrace{\dbinom{k+\left(  -n\right)  -1}{k}}%
_{\in\mathbb{Z}}\in\mathbb{Z}.
\]
In other words, $\dbinom{n}{k}\in\mathbb{Z}$. In other words, $\dbinom{n}{k}$
is an integer. Thus, Proposition \ref{prop.binom.Z->Z} is proven.
\end{proof}

\begin{exercise}
\label{exe.binom.k!divprod}Let $k\in\mathbb{N}$. Prove that the product of any
$k$ consecutive integers is divisible by $k!$.
\end{exercise}

\begin{exercise}
\label{exe.binom.legendre}In this exercise, we shall use
\href{https://en.wikipedia.org/wiki/Iverson_bracket}{the \textit{Iverson
bracket notation}}: If $\mathcal{A}$ is any statement, then $\left[
\mathcal{A}\right]  $ stands for the integer $%
\begin{cases}
1, & \text{if $\mathcal{A}$ is true;}\\
0, & \text{if $\mathcal{A}$ is false}%
\end{cases}
$ (which is also known as the \textit{truth value} of $\mathcal{A}$). For
instance, $\left[  1+1=2\right]  =1$ and $\left[  1+1=1\right]  =0$.

\textbf{(a)} Prove that $n//k=\sum_{i=1}^{n}\left[  k\mid i\right]  $ for any
$n\in\mathbb{N}$ and any positive integer $k$.

\textbf{(b)} Prove that $v_{p}\left(  n\right)  =\sum_{i\geq1}\left[
p^{i}\mid n\right]  $ for any prime $p$ and any nonzero integer $n$. Here, the
sum $\sum_{i\geq1}\left[  p^{i}\mid n\right]  $ is a sum over all positive
integers; but it is well-defined, since it has only finitely many nonzero addends.

\textbf{(c)} Prove that $v_{p}\left(  n!\right)  =\sum_{i\geq1}n//p^{i}$ for
any prime $p$ and any $n\in\mathbb{N}$. (Here, the expression
\textquotedblleft$\sum_{i\geq1}n//p^{i}$\textquotedblright\ should be
understood as $\sum_{i\geq1}\left(  n//p^{i}\right)  $. Again, this sum
$\sum_{i\geq1}\left(  n//p^{i}\right)  $ is well-defined, since it has only
finitely many nonzero addends.)

\textbf{(d)} Use part \textbf{(c)} to prove Corollary \ref{cor.binom.N->N} again.
\end{exercise}

The claim of Exercise \ref{exe.binom.legendre} \textbf{(c)} is usually
rewritten in the form $v_{p}\left(  n!\right)  =\sum_{i\geq1}\left\lfloor
\dfrac{n}{p^{i}}\right\rfloor $ (which is equivalent, because of Proposition
\ref{prop.ent.floor.quorem}); in this form, it is
\href{https://en.wikipedia.org/wiki/Legendre's_formula}{known as Legendre's
formula or as de Polignac's formula} (see, e.g., \cite[Theorem 1.3.3]{floor}).
It is often a helpful tool in proving divisibility properties of factorials
and binomial coefficients. One application, for example, is to quickly compute
how many zeroes the decimal expansion of $n!$ ends with. (Note that Exercise
\ref{exe.binom.legendre} \textbf{(b)} can be rewritten as $v_{p}\left(
n\right)  =\sum_{\substack{i\geq1;\\p^{i}\mid n}}1$; in this form it appears
in \cite[Lemma 1.3.4]{floor}.)

\subsubsection{\label{subsect.ent.vandermonde}Binomial formula and Vandermonde
convolution}

One of the staples of enumerative combinatorics are identities that involve
binomial coefficients. Hundreds of such identities have been found (see, e.g.,
\href{http://www.math.wvu.edu/~gould/}{Henry W. Gould's website} for a list of
some of them; see also \cite[Chapter 5]{GKP} and \cite[Chapter 3]{detnotes}
for introductions). At this point, let us only show two of the most important
ones (not counting the ones we have already shown above). Probably the most
famous one is the \textit{binomial formula}:

\begin{theorem}
\label{thm.binom.binf}Let $x,y$ be any numbers (e.g., rational or real or
complex numbers). Let $n\in\mathbb{N}$. Then,%
\[
\left(  x+y\right)  ^{n}=\sum_{k=0}^{n}\dbinom{n}{k}x^{k}y^{n-k}.
\]

\end{theorem}

Theorem \ref{thm.binom.binf} is known as the \textit{binomial formula} or the
\textit{binomial theorem}. It generalizes the well-known and beloved
identities%
\begin{align*}
\left(  x+y\right)  ^{2}  &  =x^{2}+2xy+y^{2};\\
\left(  x+y\right)  ^{3}  &  =x^{3}+3x^{2}y+3xy^{2}+y^{3};\\
\left(  x+y\right)  ^{4}  &  =x^{4}+4x^{3}y+6x^{2}y^{2}+4xy^{3}+y^{4}%
\end{align*}
(as well as $\left(  x+y\right)  ^{1}=x^{1}+y^{1}$ and $\left(  x+y\right)
^{0}=1$, of course).

\begin{proof}
[Proof of Theorem \ref{thm.binom.binf} (sketched).]This can be proven by a
straightforward induction on $n$ (using Theorem \ref{thm.binom.rec} in the
induction step). See \cite[Exercise 3.6]{detnotes} for details of this proof.
Alternatively, see \cite[Identity 11.4]{Galvin} for combinatorial proofs
(which rely on Theorem \ref{thm.binom.comb-int}).
\end{proof}

The next identity we want to show is the \textit{Vandermonde convolution
identity}:

\begin{theorem}
\label{thm.binom.vandermonde}Let $x,y\in\mathbb{Q}$ and $n\in\mathbb{N}$.
Then,%
\[
\dbinom{x+y}{n}=\sum_{k=0}^{n}\dbinom{x}{k}\dbinom{y}{n-k}.
\]

\end{theorem}

For example, for $n=2$, Theorem \ref{thm.binom.vandermonde} says that
\[
\dbinom{x+y}{2}=\underbrace{\dbinom{x}{0}}_{=1}\dbinom{y}{2}%
+\underbrace{\dbinom{x}{1}}_{=x}\underbrace{\dbinom{y}{1}}_{=y}+\dbinom{x}%
{2}\underbrace{\dbinom{y}{0}}_{=1}=\dbinom{y}{2}+xy+\dbinom{x}{2}.
\]


The proof of Theorem \ref{thm.binom.vandermonde} that we are soon going to
sketch is similar to the one given in \cite[\S 3.3.3]{detnotes} (but, unlike
the latter proof, we will use polynomials in $1$ variable only). It will not
be a complete proof, since it will rely on some properties of polynomials, and
not only have we not proven these properties -- we have actually not
rigorously defined polynomials yet! (We will do so later, after we have
introduced rings.) See \cite[\S 3.3.2]{detnotes} for another (more boring and
tedious, but conceptually simpler) proof of Theorem
\ref{thm.binom.vandermonde}.

Our proof of Theorem \ref{thm.binom.vandermonde} proceeds via several
intermediate steps. The first one is to prove Theorem
\ref{thm.binom.vandermonde} in the particular case when $x,y\in\mathbb{N}$:

\begin{lemma}
\label{lem.binom.vandermonde.NN}Let $a,b\in\mathbb{N}$ and $n\in\mathbb{N}$.
Then,%
\[
\dbinom{a+b}{n}=\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{b}{n-k}.
\]

\end{lemma}

(We have renamed the variables $x$ and $y$ from Theorem
\ref{thm.binom.vandermonde} as $a$ and $b$ here, since we will soon use the
letter \textquotedblleft$x$\textquotedblright\ for something completely different.)

\begin{proof}
[Proof of Lemma \ref{lem.binom.vandermonde.NN} (sketched).]Let%
\[
C=\left\{  1,2,\ldots,a\right\}  \cup\left\{  -1,-2,\ldots,-b\right\}  .
\]
Thus, $C$ is an $\left(  a+b\right)  $-element set, containing only positive
and negative integers. How many $n$-element subsets does $C$ have?

\begin{itemize}
\item On the one hand: The set $C$ is an $\left(  a+b\right)  $-element set.
Hence, Theorem \ref{thm.binom.comb-int} (applied to $a+b$, $n$ and $C$ instead
of $n$, $k$ and $N$) shows that the number of $n$-element subsets of $C$ is
$\dbinom{a+b}{n}$.

\item On the other hand: Let us classify the $n$-element subsets of $C$
according to how many positive elements they have. We claim the following:

\begin{statement}
\textit{Claim 1:} For each $k\in\left\{  0,1,\ldots,n\right\}  $, the number
of $n$-element subsets of $C$ having \textbf{exactly }$k$ \textbf{positive
elements} is $\dbinom{a}{k}\dbinom{b}{n-k}$.
\end{statement}

[\textit{Proof of Claim 1:} Let $k\in\left\{  0,1,\ldots,n\right\}  $. In
order to choose an $n$-element subset of $C$ having exactly $k$ positive
elements, we need to choose

\begin{itemize}
\item its $k$ positive elements from the set of all positive elements of $C$
(that is, from the set $\left\{  1,2,\ldots,a\right\}  $), and

\item its remaining $n-k$ (negative) elements from the set of all negative
elements of $C$ (that is, from the set $\left\{  -1,-2,\ldots,-b\right\}  $).
\end{itemize}

In other words, we need to choose

\begin{itemize}
\item a $k$-element subset of the set $\left\{  1,2,\ldots,a\right\}  $, and

\item an $\left(  n-k\right)  $-element subset of the set $\left\{
-1,-2,\ldots,-b\right\}  $.
\end{itemize}

Theorem \ref{thm.binom.comb-int} (applied to $a$, $k$ and $\left\{
1,2,\ldots,a\right\}  $ instead of $n$, $k$ and $N$) shows that the number of
$k$-element subsets of the set $\left\{  1,2,\ldots,a\right\}  $ is
$\dbinom{a}{k}$ (since $\left\{  1,2,\ldots,a\right\}  $ is an $a$-element
set). Similarly, the number of $\left(  n-k\right)  $-element subsets of the
set $\left\{  -1,-2,\ldots,-b\right\}  $ is $\dbinom{b}{n-k}$. Since we need
to choose one of the former subsets and one of the latter subsets (and our
choices are independent -- i.e., any of the former subsets can be combined
with any of the latter), we thus conclude that the total number of options we
have is $\dbinom{a}{k}\dbinom{b}{n-k}$\ \ \ \ \footnote{The combinatorial
principle we are using here is the so-called \textit{product rule} (see, e.g.,
\cite[1.8]{Loehr-BC} or \cite[\S 15.2.1]{LeLeMe}).}. In other words, the
number of $n$-element subsets of $C$ having \textbf{exactly }$k$
\textbf{positive elements} is $\dbinom{a}{k}\dbinom{b}{n-k}$. This proves
Claim 1.]

Now, the total number of $n$-element subsets of $C$ is\footnote{The
combinatorial principle we are using in the following computation is the
so-called \textit{sum rule} (see, e.g., \cite[1.2]{Loehr-BC} or
\cite[\S 15.2.3]{LeLeMe}).}%
\begin{align*}
&  \left(  \text{the number of }n\text{-element subsets of }C\right) \\
&  =\sum_{k=0}^{n}\underbrace{\left(  \text{the number of }n\text{-element
subsets of }C\text{ having exactly }k\text{ positive elements}\right)
}_{\substack{=\dbinom{a}{k}\dbinom{b}{n-k}\\\text{(by Claim 1)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the number of positive elements of an }n\text{-element}\\
\text{subset of }C\text{ must always be an integer between }0\text{ and }n
\end{array}
\right) \\
&  =\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{b}{n-k}.
\end{align*}

\end{itemize}

Now, we have computed the number of $n$-element subsets of $C$ in two ways.
The first way yielded the result $\dbinom{a+b}{n}$, while the second way
yielded $\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{b}{n-k}$. But these two results
clearly have to be equal. In other words, we have%
\[
\dbinom{a+b}{n}=\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{b}{n-k}.
\]
Thus, Lemma \ref{lem.binom.vandermonde.NN} holds.

(This was an example of a proof by \textit{double counting}, also known as a
\textit{combinatorial proof}. See \cite[\S 15.10]{LeLeMe} for some more
examples of such proofs, and see most textbooks on combinatorics for more.)
\end{proof}

This shows that Theorem \ref{thm.binom.vandermonde} holds for all
$x\in\mathbb{N}$ and $y\in\mathbb{N}$. In order to extend its reach to
arbitrary rational $a$ and $b$, we shall use the \textquotedblleft polynomial
identity trick\textquotedblright. First, let us briefly explain what
polynomials are, without giving a formal definition.

Informally, a \textit{polynomial} (in $1$ variable $x$, with rational
coefficients) is an \textquotedblleft expression\textquotedblright\ of the
form $a_{k}x^{k}+a_{k-1}x^{k-1}+\cdots+a_{0}$, where $a_{k},a_{k-1}%
,\ldots,a_{0}$ are (fixed) rational numbers and where $x$ is a (so far
meaningless) symbol\ (called \textit{indeterminate} or \textit{variable}). For
example, $4x^{3}+2x^{2}-\dfrac{1}{3}x+\dfrac{2}{7}$ is a polynomial, and so is
$0x^{3}+x^{2}-0x+\dfrac{1}{3}$. We can omit terms of the form
\textquotedblleft$0x^{i}$\textquotedblright\ when writing down a polynomial
and treat the result as being the same polynomial; thus, $0x^{3}%
+x^{2}-0x+\dfrac{1}{3}$ can also be written as $x^{2}-0x+\dfrac{1}{3}$ and as
$x^{2}+\dfrac{1}{3}$. Likewise, we can treat the \textquotedblleft%
$+$\textquotedblright\ signs as signifying addition and behaving like it, so,
e.g., commutativity holds: $2x^{3}+5x$ and $5x+2x^{3}$ are the same polynomial
(but $2x+5x^{3}$ is different). We also pretend that distributivity holds, so
\textquotedblleft like terms\textquotedblright\ can be combined: e.g., we have
$4x^{3}+9x^{3}=\left(  4+9\right)  x^{3}=13x^{3}$ or $4x^{3}-12x^{3}=\left(
4-12\right)  x^{3}=-8x^{3}$. Thus, we can add two polynomials: e.g.,%
\[
\left(  3x^{2}-1x+\dfrac{1}{2}\right)  +\left(  6x-7\right)  =3x^{2}%
+\underbrace{\left(  -1+6\right)  }_{=5}x+\underbrace{\left(  \dfrac{1}%
{2}-7\right)  }_{=\dfrac{-13}{2}}=3x^{2}+5x+\dfrac{-13}{2}.
\]
By pretending that the $x^{i}$ (with $i\in\mathbb{N}$) are actual powers of
the symbol $x$, and that multiplication obeys the associativity law (so that
$\left(  \lambda x^{i}\right)  x^{j}=\lambda\left(  x^{i}x^{j}\right)
=\lambda x^{i+j}$ for rational $\lambda$ and $i,j\in\mathbb{N}$), we can
multiply polynomials as well (first use distributivity to expand the product):%
\begin{align*}
\left(  3x-5\right)  \left(  x^{2}+3x+2\right)   &  =3x\left(  x^{2}%
+3x+2\right)  -5\left(  x^{2}+3x+2\right) \\
&  =\left(  3x^{3}+9x^{2}+6x\right)  -\left(  5x^{2}+15x+10\right) \\
&  =3x^{3}+4x^{2}-9x-10.
\end{align*}


Most importantly, it is possible to \textit{substitute} a number into a
polynomial: If $u\in\mathbb{Q}$ and if $P=a_{k}x^{k}+a_{k-1}x^{k-1}%
+\cdots+a_{0}$ is a polynomial, then we define $P\left(  u\right)  $ (called
the \textit{evaluation} of $P$ \textit{at} $u$, or the \textit{result of
substituting }$u$ \textit{for }$x$ \textit{in} $P$) to be the number
$a_{k}u^{k}+a_{k-1}u^{k-1}+\cdots+a_{0}$. More generally, if the polynomial
$P$ is given in any of its forms (e.g., as a product of other polynomials),
then we can compute $P\left(  u\right)  $ by replacing each $x$ appearing in
this form by an $u$. For example, if $P=\left(  2x+1\right)  \left(
3x+1\right)  -\left(  4x+1\right)  \left(  5x+1\right)  $, then $P\left(
u\right)  =\left(  2u+1\right)  \left(  3u+1\right)  -\left(  4u+1\right)
\left(  5u+1\right)  $; thus, we do not need to expand $P$ before substituting
$u$ into it.

Even more generally, $u$ does not have to be a rational number in order to be
substituted in a polynomial $P$ -- it can be (roughly speaking!) anything that
can be taken to the $i$-th power for $i\in\mathbb{N}$ and that can be added
and multiplied by a rational number. For example, $u$ can be a real number or
a square matrix or another polynomial. (We will later learn the precise
meaning of \textquotedblleft anything\textquotedblright\ here.)

We have been vague in our definition of polynomials, since making it rigorous
would take us a fair way afield. But we \textbf{will} eventually (in April?)
define polynomials rigorously and prove that all of the above claims (e.g.,
about associativity and distributivity) actually hold. For now, we need a
basic property of polynomials:

\begin{proposition}
\label{prop.poly.informal.f=g}Let $P$ and $Q$ be two polynomials in $1$
variable $x$ with rational coefficients. Assume that infinitely many
$u\in\mathbb{Q}$ satisfy $P\left(  u\right)  =Q\left(  u\right)  $. Then,
$P=Q$ (as polynomials).
\end{proposition}

We will prove Proposition \ref{prop.poly.informal.f=g} later.

Note that polynomials are not functions -- despite the fact that we can
substitute numbers into them and obtain other numbers. However, in many
regards, they behave like functions. For what we are going to do in this
section, the difference does not matter; we can treat polynomials as functions here.

With Lemma \ref{lem.binom.vandermonde.NN}, we have proven Theorem
\ref{thm.binom.vandermonde} in the case when $x$ and $y$ belong to
$\mathbb{N}$. Our goal, however, is to prove it for arbitrary $x,y\in
\mathbb{Q}$. Let us first go to the intermediate level of generality --
allowing $x$ to be arbitrary, but still requiring $y\in\mathbb{N}$. Thus, we
want to prove the following lemma:

\begin{lemma}
\label{lem.binom.vandermonde.QN}Let $a\in\mathbb{Q}$, $b\in\mathbb{N}$ and
$n\in\mathbb{N}$. Then,%
\[
\dbinom{a+b}{n}=\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{b}{n-k}.
\]

\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.binom.vandermonde.NN} (sketched).]Let us define a
polynomial $P$ in $1$ variable $x$ with rational coefficients as follows:%
\begin{equation}
P=\dbinom{x+b}{n}. \label{pf.lem.binom.vandermonde.NN.P=}%
\end{equation}
The \textquotedblleft binomial coefficient\textquotedblright\ $\dbinom{x+b}%
{n}$ here is to be understood by extending Definition \ref{def.binom.binom}
\textbf{(a)} in the obvious fashion to the case when $n$ is a polynomial (in
our case, $x+b$) rather than a rational number. Thus,%
\[
\dbinom{x+b}{n}=\dfrac{\left(  x+b\right)  \left(  x+b-1\right)  \left(
x+b-2\right)  \cdots\left(  x+b-n+1\right)  }{n!}.
\]


Let us also define a polynomial $Q$ in $1$ variable $x$ with rational
coefficients as follows:%
\begin{equation}
Q=\sum_{k=0}^{n}\dbinom{x}{k}\dbinom{b}{n-k}.
\label{pf.lem.binom.vandermonde.NN.Q=}%
\end{equation}
(Again, the \textquotedblleft binomial coefficients\textquotedblright%
\ $\dbinom{x}{k}$ are defined via our extension of Definition
\ref{def.binom.binom} \textbf{(a)}, and can be explicitly written as
$\dbinom{x}{k}=\dfrac{x\left(  x-1\right)  \left(  x-2\right)  \cdots\left(
x-k+1\right)  }{k!}$. Meanwhile, the $\dbinom{b}{n-k}$ are just constant integers.)

Now, for each $u\in\mathbb{N}$, we have%
\begin{align*}
P\left(  u\right)   &  =\dbinom{u+b}{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{by
substituting }u\text{ for }x\text{ in the equality
(\ref{pf.lem.binom.vandermonde.NN.P=})}\right) \\
&  =\sum_{k=0}^{n}\dbinom{u}{k}\dbinom{b}{n-k}%
\end{align*}
(by Lemma \ref{lem.binom.vandermonde.NN}, applied to $u$ instead of $a$) and%
\[
Q\left(  u\right)  =\sum_{k=0}^{n}\dbinom{u}{k}\dbinom{b}{n-k}%
\]
(by substituting $u$ for $x$ in the equality
(\ref{pf.lem.binom.vandermonde.NN.Q=})). Comparing these two equalities, we
obtain $P\left(  u\right)  =Q\left(  u\right)  $ for all $u\in\mathbb{N}$.
Hence, infinitely many $u\in\mathbb{Q}$ satisfy $P\left(  u\right)  =Q\left(
u\right)  $ (since infinitely many $u\in\mathbb{Q}$ satisfy $u\in\mathbb{N}$).
Thus, Proposition \ref{prop.poly.informal.f=g} yields $P=Q$. In view of
(\ref{pf.lem.binom.vandermonde.NN.P=}) and
(\ref{pf.lem.binom.vandermonde.NN.Q=}), this rewrites as%
\begin{equation}
\dbinom{x+b}{n}=\sum_{k=0}^{n}\dbinom{x}{k}\dbinom{b}{n-k}.
\label{pf.lem.binom.vandermonde.NN.final}%
\end{equation}
Now, substituting $a$ for $x$ in this equality of polynomials, we obtain
$\dbinom{a+b}{n}=\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{b}{n-k}$. This proves
Lemma \ref{lem.binom.vandermonde.QN}.
\end{proof}

Let us summarize the main idea of this proof: We replaced the rational number
$a$ by the indeterminate $x$, thus transforming the identity we were proving
into an equality between two polynomials (namely, $P=Q$). But in order to
prove an equality between polynomials, it suffices to prove that it holds at
infinitely many numbers (by Proposition \ref{prop.poly.informal.f=g}); thus,
in particular, it suffices to check it at all nonnegative integers. But this
is precisely what we did in Lemma \ref{lem.binom.vandermonde.NN} above. This
kind of argument (with its use of Proposition \ref{prop.poly.informal.f=g}) is
known as the \textquotedblleft polynomial identity trick\textquotedblright.

Now, let us extend the reach of Lemma \ref{lem.binom.vandermonde.QN} further,
allowing both $a$ and $b$ to be arbitrary (and thus obtaining the whole
Theorem \ref{thm.binom.vandermonde}):

\begin{lemma}
\label{lem.binom.vandermonde.QQ}Let $a,b\in\mathbb{Q}$ and $n\in\mathbb{N}$.
Then,%
\[
\dbinom{a+b}{n}=\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{b}{n-k}.
\]

\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.binom.vandermonde.QQ} (sketched).]Deriving Lemma
\ref{lem.binom.vandermonde.QQ} from Lemma \ref{lem.binom.vandermonde.QN} is
very similar to deriving Lemma \ref{lem.binom.vandermonde.QN} from Lemma
\ref{lem.binom.vandermonde.NN}. The main difference is that we replace $b$
(rather than $a$) by the indeterminate $x$ now.

\begin{fineprint}
Here are the details: Let us define a polynomial $P$ in $1$ variable $x$ with
rational coefficients as follows:%
\begin{equation}
P=\dbinom{a+x}{n}. \label{pf.lem.binom.vandermonde.QQ.P=}%
\end{equation}


Let us also define a polynomial $Q$ in $1$ variable $x$ with rational
coefficients as follows:%
\begin{equation}
Q=\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{x}{n-k}.
\label{pf.lem.binom.vandermonde.QQ.Q=}%
\end{equation}


Now, for each $u\in\mathbb{N}$, we have%
\begin{align*}
P\left(  u\right)   &  =\dbinom{a+u}{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{by
substituting }u\text{ for }x\text{ in the equality
(\ref{pf.lem.binom.vandermonde.QQ.P=})}\right) \\
&  =\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{u}{n-k}%
\end{align*}
(by Lemma \ref{lem.binom.vandermonde.QN}, applied to $u$ instead of $b$) and%
\[
Q\left(  u\right)  =\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{u}{n-k}%
\]
(by substituting $u$ for $x$ in the equality
(\ref{pf.lem.binom.vandermonde.QQ.Q=})). Comparing these two equalities, we
obtain $P\left(  u\right)  =Q\left(  u\right)  $ for all $u\in\mathbb{N}$.
Hence, infinitely many $u\in\mathbb{Q}$ satisfy $P\left(  u\right)  =Q\left(
u\right)  $ (since infinitely many $u\in\mathbb{Q}$ satisfy $u\in\mathbb{N}$).
Thus, Proposition \ref{prop.poly.informal.f=g} yields $P=Q$. In view of
(\ref{pf.lem.binom.vandermonde.QQ.P=}) and
(\ref{pf.lem.binom.vandermonde.QQ.Q=}), this rewrites as%
\[
\dbinom{a+x}{n}=\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{x}{n-k}.
\]
Now, substituting $b$ for $x$ in this equality of polynomials, we obtain
$\dbinom{a+b}{n}=\sum_{k=0}^{n}\dbinom{a}{k}\dbinom{b}{n-k}$. This proves
Lemma \ref{lem.binom.vandermonde.QQ}.
\end{fineprint}
\end{proof}

\begin{proof}
[Proof of Theorem \ref{thm.binom.vandermonde} (sketched).]Theorem
\ref{thm.binom.vandermonde} is just Lemma \ref{lem.binom.vandermonde.QQ}, with
$a$ and $b$ renamed as $x$ and $y$.
\end{proof}

\begin{noncompile}
See \cite{GKP} and \cite{detnotes} for further identities involving binomial coefficients.
\end{noncompile}

\subsubsection{Some divisibilities and congruences}

So far we have been proving identities between binomial coefficients. Let us
now step to divisibilities and congruences.

Proposition \ref{prop.binom.Z->Z} shows that binomial coefficients $\dbinom
{n}{k}$ are integers whenever $n$ is an integer. This allows us to study
divisibilities and congruences between binomial coefficients (and you have
seen a few of them on
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw1s.pdf}{homework set
\#1}). One of the most important such divisibilities is the following fact:

\begin{theorem}
\label{thm.binom.p|bin}Let $p$ be a prime. Let $k\in\left\{  1,2,\ldots
,p-1\right\}  $. Then, $p\mid\dbinom{p}{k}$.
\end{theorem}

\begin{proof}
[First proof of Theorem \ref{thm.binom.p|bin}.]Applying Theorem
\ref{thm.binom.abs} to $n=p$, we obtain%
\[
k\dbinom{p}{k}=p\dbinom{p-1}{k-1}.
\]
Thus, $p\mid k\dbinom{p}{k}$ (since $\dbinom{p-1}{k-1}$ is an
integer\footnote{by an application of Proposition \ref{prop.binom.Z->Z}}). But
Proposition \ref{prop.ent.prime.each-i-coprime} (applied to $i=k$) yields that
$k$ is coprime to $p$. In other words, $k\perp p$, and thus $p\perp k$. Hence,
Theorem \ref{thm.ent.coprime.cancel} (applied to $a=p$, $b=k$ and
$c=\dbinom{p}{k}$) yields $p\mid\dbinom{p}{k}$ (since $p\mid k\dbinom{p}{k}$).
This proves Theorem \ref{thm.binom.p|bin}.
\end{proof}

We shall see a second, combinatorial proof of Theorem \ref{thm.binom.p|bin}
further below; it will rely on the concept of group actions.

\begin{noncompile}
\begin{proof}
[Second proof of Theorem \ref{thm.binom.p|bin} (outline).]The following is not
rigorous and probably not readable; we will make sense of this later.

We know that $\dbinom{p}{k}$ counts $k$-element subsets of $\left\{
1,2,\ldots,p\right\}  $. We can restate this using $p$\textit{-bitstrings}.

A $p$\textit{-bitstring} is a $p$-tuple $\left(  i_{1},i_{2},\ldots
,i_{p}\right)  \in\left\{  0,1\right\}  ^{p}$. For example, the $2$-bitstrings
are $\left(  0,0\right)  ,\ \left(  0,1\right)  ,\ \left(  1,0\right)
,\ \left(  1,1\right)  $.

I claim that there is a bijection%
\begin{align*}
\left\{  k\text{-element subsets of }\left\{  1,2,\ldots,p\right\}  \right\}
&  \rightarrow\left\{  p\text{-bitstrings with }k\text{ 1's}\right\}  ,\\
S  &  \mapsto\left\{  \left(  i_{1},i_{2},\ldots,i_{p}\right)  \right\}  ,
\end{align*}
where $i_{x}=%
\begin{cases}
1, & \text{if }x\in S;\\
0, & \text{if }x\notin S
\end{cases}
$.

(Example: If $p=3$ and $k=2$, then

\begin{itemize}
\item the $k$-element subsets of $\left\{  1,2,\ldots,p\right\}  $ are
$\left\{  1,2\right\}  ,\ \left\{  1,3\right\}  ,\ \left\{  2,3\right\}  $;

\item the $p$-bitstrings with $k$ 1's are $\left(  1,1,0\right)  ,\ \left(
1,0,1\right)  ,\ \left(  0,1,1\right)  $.
\end{itemize}

These are listed in a way that the bijection sends them to each other in order.)

Thus,%
\begin{align*}
&  \left(  \text{the number of }p\text{-bitstrings with }k\text{ 1's}\right)
\\
&  =\left(  \text{the number of }k\text{-element subsets of }\left\{
1,2,\ldots,p\right\}  \right) \\
&  =\dbinom{p}{k}.
\end{align*}


\textit{Cyclic rotation} is the map $\mathbf{c}$ sending a $p$-bitstring
$\left(  i_{1},i_{2},\ldots,i_{p}\right)  $ to $\left(  i_{2},i_{3}%
,\ldots,i_{p},i_{1}\right)  $.

A \textit{necklace} is (essentially) a bitstring up to cyclic rotation.

If $\left(  i_{1},i_{2},\ldots,i_{p}\right)  $ is any $p$-bitstring, then
\begin{align*}
&  \left(  i_{1},i_{2},\ldots,i_{p}\right)  ,\ \ \ \ \ \ \ \ \ \ \mathbf{c}%
\left(  i_{1},i_{2},\ldots,i_{p}\right)  ,\ \ \ \ \ \ \ \ \ \ \mathbf{c}%
^{2}\left(  i_{1},i_{2},\ldots,i_{p}\right)  ,\\
&  \ldots,\ \ \ \ \ \ \ \ \ \ \mathbf{c}^{p-1}\left(  i_{1},i_{2},\ldots
,i_{p}\right)
\end{align*}
are all distinct \textbf{unless} it is either $\left(  0,0,\ldots,0\right)  $
or $\left(  1,1,\ldots,1\right)  $.

(Example: $\left(  1,1,0\right)  ,\ \left(  1,0,1\right)  ,\ \left(
0,1,1\right)  $ are distinct.

$\left(  1,0,1,0\right)  ,\ \left(  0,1,0,1\right)  ,\ \left(  1,0,1,0\right)
,\ \left(  0,1,0,1\right)  $ are \textbf{not} distinct, but $4$ is not prime.)

We don't claim that this is mathematically obvious! It will be a consequence
of things we do later (group actions on sets).

Thus, the $p$-bitstrings with $k$ 1's can be grouped into \textquotedblleft
necklaces\textquotedblright: A necklace is always a group formed by a
$p$-bitstring $\left(  i_{1},i_{2},\ldots,i_{p}\right)  $ and all its images
$\mathbf{c}^{\ell}\left(  i_{1},i_{2},\ldots,i_{p}\right)  $ under cyclic
rotation (applied several times). Each necklace contains exactly $p$ many
$p$-bitstrings. So the number of $p$-bitstrings with $k$ 1's equals $p$ times
the number of necklaces.
\end{proof}
\end{noncompile}

Let us state two congruences for binomial coefficients, which we will show
later using tools from abstract algebra:

\begin{theorem}
[Lucas's congruence]\label{thm.binom.lucas}Let $p$ be a prime. Let
$a,b\in\mathbb{Z}$. Let $c,d\in\left\{  0,1,\ldots,p-1\right\}  $. Then,%
\[
\dbinom{pa+c}{pb+d}\equiv\dbinom{a}{b}\dbinom{c}{d}\operatorname{mod}p.
\]

\end{theorem}

\begin{theorem}
[Babbage's congruence]\label{thm.binom.babbage}Let $p$ be a prime. Let
$a,b\in\mathbb{Z}$. Then,%
\[
\dbinom{pa}{pb}\equiv\dbinom{a}{b}\operatorname{mod}p^{2}.
\]

\end{theorem}

For the impatient: Elementary proofs of Theorem \ref{thm.binom.lucas} and
Theorem \ref{thm.binom.babbage} can be found in \cite{lucas}.

\begin{remark}
Lucas's congruence has the following consequence: Let $p$ be a prime. Let
$a,b\in\mathbb{N}$. Write $a$ and $b$ in base $p$ as follows:%
\begin{align*}
a  &  =a_{k}p^{k}+a_{k-1}p^{k-1}+\cdots+a_{0}p^{0}%
\ \ \ \ \ \ \ \ \ \ \text{and}\\
b  &  =b_{k}p^{k}+b_{k-1}p^{k-1}+\cdots+b_{0}p^{0}%
\end{align*}
with $k\in\mathbb{N}$ and $a_{k},a_{k-1},\ldots,a_{0},b_{k},b_{k-1}%
,\ldots,b_{0}\in\left\{  0,1,\ldots,p-1\right\}  $. (Note that we allow
\textquotedblleft leading zeroes\textquotedblright\ -- i.e., any of $a_{k}$
and $b_{k}$ can be $0$.) Then,%
\[
\dbinom{a}{b}\equiv\dbinom{a_{k}}{b_{k}}\dbinom{a_{k-1}}{b_{k-1}}\cdots
\dbinom{a_{0}}{b_{0}}\operatorname{mod}p.
\]
(This can be easily proven by induction on $k$, using Theorem
\ref{thm.binom.lucas} in the induction step.) This allows for quick
computation of remainders of $\dbinom{a}{b}$ modulo prime numbers, and also
explains (when applied to $p=2$) why
\href{https://en.wikipedia.org/wiki/Sierpinski_triangle#Pascal's_triangle}{we
can obtain (an approximation of) Sierpinski's triangle from Pascal's triangle
by coloring all even numbers white and all odd numbers black}.
\end{remark}

See \cite{Mestro14} and \cite{Granvi05} for overviews of more complicated
divisibilities and congruences for binomial coefficients.

\begin{center}
\textbf{2019-02-20 lecture}
\end{center}

\subsubsection{Integer-valued polynomials}

Now that we have introduced polynomials (albeit informally and on somewhat
shaky foundations) and binomial coefficients (albeit briefly), it would be a
shame to leave unmentioned a subject that connects the two particularly
closely: the \textit{integer-valued polynomials}. We are going to state a few
basic facts, but we will not prove them.

If $f=a_{k}x^{k}+a_{k-1}x^{k-1}+\cdots+a_{0}$ is a polynomial (in $1$ variable
$x$, with rational coefficients), then the rational numbers $a_{k}%
,a_{k-1},\ldots,a_{0}$ are called the \textit{coefficients} of $f$. The
coefficients of a polynomial $f$ are uniquely determined by $f$ (except for
the fact that we can always add terms of the form $0x^{\ell}$ and thus obtain
extra coefficients that are equal to $0$). (This fact is not obvious, given
our \textquotedblleft definition\textquotedblright\ of polynomials
above\footnote{For example, why cannot we start with (say) $6x^{2}+5x+4$, then
rewrite it as $\left(  2x+1\right)  \left(  3x+1\right)  +3$, then do some
other transformations (using commutativity, associativity and other laws), and
finally end up with a polynomial that has different coefficients (say,
$3x^{2}+9x+4$) ? We cannot, but it is not easy to prove with what we have.}.
We will later define polynomials more formally as sequences of coefficients;
then this will become clear.)

If $f=a_{k}x^{k}+a_{k-1}x^{k-1}+\cdots+a_{0}$ is a polynomial (in $1$ variable
$x$, with rational coefficients) such that $a_{k}\neq0$ (each polynomial that
is not just $0$ can be uniquely written in such a form), then the integer $k$
is called the \textit{degree} of $f$.

\begin{definition}
\label{def.ivp.ivp}A polynomial $P$ with rational coefficients is said to be
\textit{integer-valued} if $\left(  P\left(  n\right)  \in\mathbb{Z}\text{ for
all }n\in\mathbb{Z}\right)  $.
\end{definition}

Of course, a polynomial with integer coefficients is always integer-valued.
But there are other integer-valued polynomials, too:

\begin{example}
\label{exa.ivp.ivps1}\textbf{(a)} The polynomial $\dbinom{x}{2}=\dfrac
{x\left(  x-1\right)  }{2}=\dfrac{1}{2}x^{2}-\dfrac{1}{2}x$ is integer-valued
(since $\dbinom{n}{2}\in\mathbb{Z}$ for each $n\in\mathbb{Z}$), but its
coefficients are $\dfrac{1}{2},-\dfrac{1}{2},0$.

\textbf{(b)} More generally: If $k\in\mathbb{N}$ is arbitrary, then the
polynomial $\dbinom{x}{k}=\dfrac{x\left(  x-1\right)  \left(  x-2\right)
\cdots\left(  x-k+1\right)  }{k!}$ is integer-valued (since $\dbinom{n}{k}%
\in\mathbb{Z}$ for each $n\in\mathbb{Z}$).

\textbf{(c)} If $p$ is any prime, then the polynomial $\dfrac{x^{p}-x}{p}$ is
integer-valued (since Theorem \ref{thm.ent.fermat} \textbf{(b)} yields
$a^{p}\equiv a\operatorname{mod}p$ for each $a\in\mathbb{Z}$, which means that
$\dfrac{a^{p}-a}{p}\in\mathbb{Z}$ for each $a\in\mathbb{Z}$). Its coefficients
are not integers.
\end{example}

This suggests the following question\textbf{:} How can we describe the
integer-valued polynomials? The following result of P\'{o}lya \cite{Polya19}
gives an answer:

\begin{theorem}
\label{thm.ivp.binomial}Let $k\in\mathbb{N}$.

\textbf{(a)} Any polynomial $P$ (in $1$ variable $x$, with rational
coefficients) of degree $k$ can be uniquely written in the form%
\[
P\left(  x\right)  =a_{k}\dbinom{x}{k}+a_{k-1}\dbinom{x}{k-1}+\cdots
+a_{0}\dbinom{x}{0}%
\]
with \textbf{rational} $a_{k},a_{k-1},\ldots,a_{0}$.

\textbf{(b)} The polynomial $P$ is integer-valued if and only if these
$a_{k},a_{k-1},\ldots,a_{0}$ are integers.
\end{theorem}

For example, the integer-valued polynomial $\dfrac{x^{3}-x}{3}$ can be written
as%
\[
\dfrac{x^{3}-x}{3}=a_{3}\dbinom{x}{3}+a_{2}\dbinom{x}{2}+a_{1}\dbinom{x}%
{1}+a_{0}\dbinom{x}{0}%
\]
for
\[
a_{3}=2,\ \ \ \ \ \ \ \ \ \ a_{2}=2,\ \ \ \ \ \ \ \ \ \ a_{1}%
=0,\ \ \ \ \ \ \ \ \ \ a_{0}=0.
\]
These $a_{3},a_{2},a_{1},a_{0}$ are integers -- exactly as Theorem
\ref{thm.ivp.binomial} \textbf{(b)} says.

I sketched a proof of Theorem \ref{thm.ivp.binomial} \textbf{(b)} in a talk in
2013 ( \url{http://www.cip.ifi.lmu.de/~grinberg/storrs2013.pdf} )\footnote{In
this talk, I refer to integer-valued polynomials as \textquotedblleft
integral-valued polynomials\textquotedblright.}. See also \cite{daSilv12} for
a self-contained proof.

\subsection{Counting divisors}

Now that we have seen some combinatorial reasoning (e.g., in the proof of
Theorem \ref{thm.binom.vandermonde}), let us solve a rather natural counting
problem: Let us count the divisors of a nonzero integer $n$.

\begin{proposition}
\label{prop.ent.count-divs}Let $n\in\mathbb{Z}$ be nonzero. Then:

\textbf{(a)} The product $\prod_{p\text{ prime}}\left(  v_{p}\left(  n\right)
+1\right)  $ is well-defined, since all but finitely many of its factors are
$1$.

\textbf{(b)} We have
\[
\left(  \text{the number of positive divisors of }n\right)  =\prod_{p\text{
prime}}\left(  v_{p}\left(  n\right)  +1\right)  .
\]


\textbf{(c)} We have%
\[
\left(  \text{the number of divisors of }n\right)  =2\prod_{p\text{ prime}%
}\left(  v_{p}\left(  n\right)  +1\right)  .
\]

\end{proposition}

\begin{example}
If $n=12$, then
\[
\left(  \text{the number of positive divisors of }n\right)  =6
\]
(since the positive divisors of $n=12$ are $1,2,3,4,6,12$) and%
\begin{align*}
\prod_{p\text{ prime}}\left(  v_{p}\left(  n\right)  +1\right)   &  =\left(
\underbrace{v_{2}\left(  n\right)  }_{=2}+1\right)  \left(  \underbrace{v_{3}%
\left(  n\right)  }_{=1}+1\right)  \prod_{\substack{p\text{ prime;}%
\\p\notin\left\{  2,3\right\}  }}\left(  \underbrace{v_{p}\left(  n\right)
}_{=0}+1\right) \\
&  =\left(  2+1\right)  \left(  1+1\right)  \underbrace{\prod
_{\substack{p\text{ prime;}\\p\notin\left\{  2,3\right\}  }}1}_{=1}=\left(
2+1\right)  \left(  1+1\right)  =6.
\end{align*}
This confirms Proposition \ref{prop.ent.count-divs} \textbf{(b)} for $n=12$.
In order to confirm Proposition \ref{prop.ent.count-divs} \textbf{(c)} for
$n=12$ as well, we observe that $\left(  \text{the number of divisors of
}n\right)  =12$ (since the divisors of $n=12$ are
$-12,-6,-4,-3,-2,-1,1,2,3,4,6,12$).
\end{example}

The function
\begin{align*}
\left\{  1,2,3,\ldots\right\}   &  \rightarrow\mathbb{N},\\
n  &  \mapsto\left(  \text{the number of positive divisors of }n\right)
\end{align*}
is known as \href{https://en.wikipedia.org/wiki/Divisor_function}{the
\textit{divisor function}} and is commonly denoted by $\tau$. So Proposition
\ref{prop.ent.count-divs} \textbf{(b)} gives a formula for $\tau\left(
n\right)  $. See \cite[Theorem 2.1.7 (proof sketched in \S 2.7)]{floor} for a
different proof of this formula.

\begin{noncompile}
Sketch of an old proof of Proposition \ref{prop.ent.count-divs} \textbf{(b)}:

Consider the set $\prod_{p\text{ prime}}\left\{  0,1,\ldots,v_{p}\left(
n\right)  \right\}  $. This is the set of all families $\left(  a_{p}\right)
_{p\text{ prime}}$ indexed by all the primes such that $a_{p}\in\left\{
0,1,\ldots,v_{p}\left(  n\right)  \right\}  $ for each prime $p$. (You can
regard these families as sequences $\left(  a_{2},a_{3},a_{5},a_{7}%
,a_{11},\ldots\right)  $ of nonnegative integers.)

Consider the bijection%
\begin{align*}
M:\prod_{p\text{ prime}}\left\{  0,1,\ldots,v_{p}\left(  n\right)  \right\}
&  \rightarrow\left\{  \text{positive divisors of }n\right\}  ,\\
\left(  a_{p}\right)  _{p\text{ prime}}  &  \mapsto\prod_{p\text{ prime}%
}p^{a_{p}}%
\end{align*}
with inverse map%
\begin{align*}
\left\{  \text{positive divisors of }n\right\}   &  \rightarrow\prod_{p\text{
prime}}\left\{  0,1,\ldots,v_{p}\left(  n\right)  \right\}  ,\\
d  &  \mapsto\left(  v_{p}\left(  d\right)  \right)  _{p\text{ prime}}.
\end{align*}

\end{noncompile}

Our proof of Proposition \ref{prop.ent.count-divs} will rely on the following
lemma, which classifies all divisors of a positive integer in terms of its
prime factorization:

\begin{lemma}
\label{lem.ent.divs-bijs}Let $p_{1},p_{2},\ldots,p_{u}$ be finitely many
distinct primes. For each $i\in\left\{  1,2,\ldots,u\right\}  $, let $a_{i}$
be a nonnegative integer. Let $n=p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots p_{u}%
^{a_{u}}$.

Define a set $T$ by%
\begin{align*}
T  &  =\left\{  0,1,\ldots,a_{1}\right\}  \times\left\{  0,1,\ldots
,a_{2}\right\}  \times\cdots\times\left\{  0,1,\ldots,a_{u}\right\} \\
&  =\left\{  \left(  b_{1},b_{2},\ldots,b_{u}\right)  \ \mid\text{ }b_{i}%
\in\left\{  0,1,\ldots,a_{i}\right\}  \text{ for each }i\in\left\{
1,2,\ldots,u\right\}  \right\} \\
&  =\left\{  \left(  b_{1},b_{2},\ldots,b_{u}\right)  \in\mathbb{N}^{u}%
\ \mid\ b_{i}\leq a_{i}\text{ for each }i\in\left\{  1,2,\ldots,u\right\}
\right\}  .
\end{align*}
Then, the map%
\begin{align*}
\Lambda:T  &  \rightarrow\left\{  \text{positive divisors of }n\right\}  ,\\
\left(  b_{1},b_{2},\ldots,b_{u}\right)   &  \mapsto p_{1}^{b_{1}}p_{2}%
^{b_{2}}\cdots p_{u}^{b_{u}}%
\end{align*}
is well-defined and bijective.
\end{lemma}

\begin{example}
For this example, let $u=2$, $p_{1}=2$, $p_{2}=3$, $a_{1}=2$ and $a_{2}=1$.
Define the integer $n$ and the set $T$ as in Lemma \ref{lem.ent.divs-bijs};
then,%
\[
n=p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots p_{u}^{a_{u}}=2^{2}\cdot3^{1}=12
\]
and%
\begin{align*}
T  &  =\left\{  0,1,\ldots,a_{1}\right\}  \times\left\{  0,1,\ldots
,a_{2}\right\}  \times\cdots\times\left\{  0,1,\ldots,a_{u}\right\}  =\left\{
0,1,2\right\}  \times\left\{  0,1\right\} \\
&  =\left\{  \left(  0,0\right)  ,\left(  0,1\right)  ,\left(  1,0\right)
,\left(  1,1\right)  ,\left(  2,0\right)  ,\left(  2,1\right)  \right\}  .
\end{align*}
Now, Lemma \ref{lem.ent.divs-bijs} says that the map
\begin{align*}
\Lambda:T  &  \rightarrow\left\{  \text{positive divisors of }n\right\}  ,\\
\left(  b_{1},b_{2},\ldots,b_{u}\right)   &  \mapsto p_{1}^{b_{1}}p_{2}%
^{b_{2}}\cdots p_{u}^{b_{u}}%
\end{align*}
is well-defined and bijective. Here is a table of values of this map $\Lambda
$:%
\[%
\begin{tabular}
[c]{|c||c|c|c|c|c|c||}\hline
$\mathbf{b}$ & $\left(  0,0\right)  $ & $\left(  0,1\right)  $ & $\left(
1,0\right)  $ & $\left(  1,1\right)  $ & $\left(  2,0\right)  $ & $\left(
2,1\right)  $\\\hline
$\Lambda\left(  \mathbf{b}\right)  $ & $1$ & $3$ & $2$ & $6$ & $4$ &
$12$\\\hline
\end{tabular}
\ .\
\]

\end{example}

\begin{proof}
[Proof of Lemma \ref{lem.ent.divs-bijs}.]The numbers $p_{1},p_{2},\ldots
,p_{u}$ are primes, and thus positive integers. Hence, the product
$p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots p_{u}^{a_{u}}$ is a positive integer as well
(since $a_{1},a_{2},\ldots,a_{u}$ are nonnegative integers). In other words,
$n$ is a positive integer (since $n=p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots
p_{u}^{a_{u}}$). Note that%
\[
n=p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots p_{u}^{a_{u}}=\prod_{i=1}^{u}p_{i}^{a_{i}%
}.
\]
Each $i\in\left\{  1,2,\ldots,u\right\}  $ satisfies%
\begin{equation}
v_{p_{i}}\left(  \underbrace{n}_{=p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots
p_{u}^{a_{u}}}\right)  =v_{p_{i}}\left(  p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots
p_{u}^{a_{u}}\right)  =a_{i} \label{pf.lem.ent.divs-bijs.vpi}%
\end{equation}
(by Exercise \ref{exe.ent.prime.p1a1puau} \textbf{(a)}). Furthermore, if $p$
is a prime satisfying $p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  $,
then%
\begin{equation}
v_{p}\left(  \underbrace{n}_{=p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots p_{u}^{a_{u}}%
}\right)  =v_{p}\left(  p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots p_{u}^{a_{u}}\right)
=0 \label{pf.lem.ent.divs-bijs.vp}%
\end{equation}
(by Exercise \ref{exe.ent.prime.p1a1puau} \textbf{(b)}).

For each $\left(  b_{1},b_{2},\ldots,b_{u}\right)  \in T$, we have%
\begin{equation}
p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}\in\left\{  \text{positive
divisors of }n\right\}  . \label{pf.lem.ent.divs-bijs.wd}%
\end{equation}


\begin{fineprint}
[\textit{Proof of (\ref{pf.lem.ent.divs-bijs.wd}):} Let $\left(  b_{1}%
,b_{2},\ldots,b_{u}\right)  \in T$. We must prove
(\ref{pf.lem.ent.divs-bijs.wd}).

We have $\left(  b_{1},b_{2},\ldots,b_{u}\right)  \in T=\left\{
0,1,\ldots,a_{1}\right\}  \times\left\{  0,1,\ldots,a_{2}\right\}
\times\cdots\times\left\{  0,1,\ldots,a_{u}\right\}  $. In other words,
$b_{i}\in\left\{  0,1,\ldots,a_{i}\right\}  $ for each $i\in\left\{
1,2,\ldots,u\right\}  $. Hence, for each $i\in\left\{  1,2,\ldots,u\right\}
$, we have%
\begin{align*}
a_{i}-b_{i}  &  \in\left\{  0,1,\ldots,a_{i}\right\}
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }b_{i}\in\left\{  0,1,\ldots
,a_{i}\right\}  \right) \\
&  \subseteq\mathbb{N},
\end{align*}
and thus $p_{i}^{a_{i}-b_{i}}$ is an integer. Hence, $\prod_{i=1}^{u}%
p_{i}^{a_{i}-b_{i}}$ is a product of integers, and thus is an integer as well.
Now,%
\begin{align*}
n  &  =\prod_{i=1}^{u}\underbrace{p_{i}^{a_{i}}}_{\substack{=p_{i}%
^{b_{i}+\left(  a_{i}-b_{i}\right)  }\\=p_{i}^{b_{i}}p_{i}^{a_{i}-b_{i}}%
}}=\prod_{i=1}^{u}\left(  p_{i}^{b_{i}}p_{i}^{a_{i}-b_{i}}\right)
=\underbrace{\left(  \prod_{i=1}^{u}p_{i}^{b_{i}}\right)  }_{=p_{1}^{b_{1}%
}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}}\left(  \prod_{i=1}^{u}p_{i}^{a_{i}-b_{i}%
}\right) \\
&  =\left(  p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}\right)  \left(
\prod_{i=1}^{u}p_{i}^{a_{i}-b_{i}}\right)  .
\end{align*}
Thus, $p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}\mid n$ (since
$\prod_{i=1}^{u}p_{i}^{a_{i}-b_{i}}$ is an integer). In other words,
$p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}$ is a divisor of $n$. Hence,
$p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}$ is a positive divisor of $n$
(since $p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}$ is clearly positive).
In other words, $p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}\in\left\{
\text{positive divisors of }n\right\}  $. This proves
(\ref{pf.lem.ent.divs-bijs.wd}).]
\end{fineprint}

The equality (\ref{pf.lem.ent.divs-bijs.wd}) shows that the map $\Lambda$ in
Lemma \ref{lem.ent.divs-bijs} is well-defined. It remains to prove that it is bijective.

We shall achieve this by constructing an inverse to $\Lambda$.

Indeed, for each $d\in\left\{  \text{positive divisors of }n\right\}  $, we
have%
\begin{equation}
\left(  v_{p_{1}}\left(  d\right)  ,v_{p_{2}}\left(  d\right)  ,\ldots
,v_{p_{u}}\left(  d\right)  \right)  \in T. \label{pf.lem.ent.divs-bijs.Vwd}%
\end{equation}


\begin{fineprint}
[\textit{Proof of (\ref{pf.lem.ent.divs-bijs.Vwd}):} Let $d\in\left\{
\text{positive divisors of }n\right\}  $. Thus, $d$ is a positive divisor of
$n$. In other words, $d$ is a positive integer satisfying $d\mid n$.

Fix $i\in\left\{  1,2,\ldots,u\right\}  $. We shall show that $v_{p_{i}%
}\left(  d\right)  \in\left\{  0,1,\ldots,a_{i}\right\}  $.

The integer $d$ is positive and thus nonzero. Hence, $v_{p_{i}}\left(
d\right)  \in\mathbb{N}$. But Proposition \ref{prop.ent.prime.n|m} (applied to
$d$ and $n$ instead of $n$ and $m$) shows that $d\mid n$ if and only if each
prime $p$ satisfies $v_{p}\left(  d\right)  \leq v_{p}\left(  n\right)  $.
Thus, each prime $p$ satisfies $v_{p}\left(  d\right)  \leq v_{p}\left(
n\right)  $ (since $d\mid n$). Applying this to $p=p_{i}$, we obtain
$v_{p_{i}}\left(  d\right)  \leq v_{p_{i}}\left(  n\right)  =a_{i}$ (by
(\ref{pf.lem.ent.divs-bijs.vpi})). Hence, $v_{p_{i}}\left(  d\right)
\in\left\{  0,1,\ldots,a_{i}\right\}  $ (since $v_{p_{i}}\left(  d\right)
\in\mathbb{N}$).

Now, forget that we fixed $i$. We thus have shown that $v_{p_{i}}\left(
d\right)  \in\left\{  0,1,\ldots,a_{i}\right\}  $ for each $i\in\left\{
1,2,\ldots,u\right\}  $. In other words,%
\[
\left(  v_{p_{1}}\left(  d\right)  ,v_{p_{2}}\left(  d\right)  ,\ldots
,v_{p_{u}}\left(  d\right)  \right)  \in\left\{  0,1,\ldots,a_{1}\right\}
\times\left\{  0,1,\ldots,a_{2}\right\}  \times\cdots\times\left\{
0,1,\ldots,a_{u}\right\}  .
\]
This rewrites as $\left(  v_{p_{1}}\left(  d\right)  ,v_{p_{2}}\left(
d\right)  ,\ldots,v_{p_{u}}\left(  d\right)  \right)  \in T$ (since
$T=\left\{  0,1,\ldots,a_{1}\right\}  \times\left\{  0,1,\ldots,a_{2}\right\}
\times\cdots\times\left\{  0,1,\ldots,a_{u}\right\}  $). Thus,
(\ref{pf.lem.ent.divs-bijs.Vwd}) is proven.]
\end{fineprint}

We now define a map%
\begin{align*}
V:\left\{  \text{positive divisors of }n\right\}   &  \rightarrow T,\\
d  &  \mapsto\left(  v_{p_{1}}\left(  d\right)  ,v_{p_{2}}\left(  d\right)
,\ldots,v_{p_{u}}\left(  d\right)  \right)  .
\end{align*}
This map is well-defined, because of (\ref{pf.lem.ent.divs-bijs.Vwd}).

Now, we claim that $\Lambda\circ V=\operatorname*{id}$.

\begin{fineprint}
[\textit{Proof:} Let $d\in\left\{  \text{positive divisors of }n\right\}  $.
We shall show that $\left(  \Lambda\circ V\right)  \left(  d\right)
=\operatorname*{id}\left(  d\right)  $.

Indeed, $d$ is a positive divisor of $n$ (since $d\in\left\{  \text{positive
divisors of }n\right\}  $). Hence, $d$ is a positive integer and satisfies
$d\mid n$. But Proposition \ref{prop.ent.prime.n|m} (applied to $d$ and $n$
instead of $n$ and $m$) shows that $d\mid n$ if and only if each prime $p$
satisfies $v_{p}\left(  d\right)  \leq v_{p}\left(  n\right)  $. Thus, each
prime $p$ satisfies $v_{p}\left(  d\right)  \leq v_{p}\left(  n\right)  $
(since $d\mid n$). Hence, if $p$ is a prime satisfying $p\notin\left\{
p_{1},p_{2},\ldots,p_{u}\right\}  $, then we have%
\[
v_{p}\left(  d\right)  \leq v_{p}\left(  n\right)
=0\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.lem.ent.divs-bijs.vp}%
)}\right)
\]
and therefore
\[
v_{p}\left(  d\right)  =0\ \ \ \ \ \ \ \ \ \ \left(  \text{since }v_{p}\left(
d\right)  \in\mathbb{N}\cup\left\{  \infty\right\}  \text{ and }v_{p}\left(
d\right)  \leq0\right)
\]
and therefore%
\begin{equation}
p^{v_{p}\left(  d\right)  }=p^{0}=1. \label{pf.lem.ent.divs-bijs.LVid.pf.2}%
\end{equation}


The elements $p_{1},p_{2},\ldots,p_{u}$ are distinct. Thus, the map $\left\{
1,2,\ldots,u\right\}  \rightarrow\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
,\ i\mapsto p_{i}$ is a bijection\footnote{Indeed, this map is injective,
since the elements $p_{1},p_{2},\ldots,p_{u}$ are distinct; and it is
surjective, since its image is clearly $\left\{  p_{1},p_{2},\ldots
,p_{u}\right\}  $.}.

But $d$ is a positive integer. Thus, Corollary \ref{cor.ent.prime.can-fac}
(applied to $d$ instead of $n$) yields
\begin{align*}
d  &  =\prod_{p\text{ prime}}p^{v_{p}\left(  d\right)  }=\left(
\prod_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2},\ldots
,p_{u}\right\}  }}p^{v_{p}\left(  d\right)  }\right)  \left(  \prod
_{\substack{p\text{ prime;}\\p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
}}\underbrace{p^{v_{p}\left(  d\right)  }}_{\substack{=1\\\text{(by
(\ref{pf.lem.ent.divs-bijs.LVid.pf.2}))}}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since each prime }p\text{ satisfies either }p\in\left\{  p_{1}%
,p_{2},\ldots,p_{u}\right\} \\
\text{or }p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  \text{ (but not
both simultaneously)}%
\end{array}
\right) \\
&  =\left(  \prod_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2}%
,\ldots,p_{u}\right\}  }}p^{v_{p}\left(  d\right)  }\right)
\underbrace{\left(  \prod_{\substack{p\text{ prime;}\\p\notin\left\{
p_{1},p_{2},\ldots,p_{u}\right\}  }}1\right)  }_{=1}=\underbrace{\prod
_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
}}}_{\substack{=\prod_{p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
}\\\text{(since each }p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
\\\text{is a prime)}}}p^{v_{p}\left(  d\right)  }\\
&  =\prod_{p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  }p^{v_{p}\left(
d\right)  }=\prod_{i=1}^{u}p_{i}^{v_{p_{i}}\left(  d\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we have substituted }p_{i}\text{ for }p\text{ in the product,}\\
\text{since the map }\left\{  1,2,\ldots,u\right\}  \rightarrow\left\{
p_{1},p_{2},\ldots,p_{u}\right\}  ,\ i\mapsto p_{i}\text{ is a bijection}%
\end{array}
\right)  .
\end{align*}
Comparing this with%
\begin{align*}
\left(  \Lambda\circ V\right)  \left(  d\right)   &  =\Lambda\left(
\underbrace{V\left(  d\right)  }_{\substack{=\left(  v_{p_{1}}\left(
d\right)  ,v_{p_{2}}\left(  d\right)  ,\ldots,v_{p_{u}}\left(  d\right)
\right)  \\\text{(by the definition of }V\text{)}}}\right)  =\Lambda\left(
\left(  v_{p_{1}}\left(  d\right)  ,v_{p_{2}}\left(  d\right)  ,\ldots
,v_{p_{u}}\left(  d\right)  \right)  \right) \\
&  =p_{1}^{v_{p_{1}}\left(  d\right)  }p_{2}^{v_{p_{2}}\left(  d\right)
}\cdots p_{u}^{v_{p_{u}}\left(  d\right)  }=\prod_{i=1}^{u}p_{i}^{v_{p_{i}%
}\left(  d\right)  },
\end{align*}
we obtain $\left(  \Lambda\circ V\right)  \left(  d\right)
=d=\operatorname*{id}\left(  d\right)  $.

Now, forget that we fixed $d$. We thus have shown that $\left(  \Lambda\circ
V\right)  \left(  d\right)  =\operatorname*{id}\left(  d\right)  $ for each
$d\in\left\{  \text{positive divisors of }n\right\}  $. In other words,
$\Lambda\circ V=\operatorname*{id}$.]
\end{fineprint}

Next, we claim that $V\circ\Lambda=\operatorname*{id}$.

\begin{fineprint}
[\textit{Proof:} Let $\mathbf{b}\in T$. We shall show that $\left(
V\circ\Lambda\right)  \left(  \mathbf{b}\right)  =\operatorname*{id}\left(
\mathbf{b}\right)  $.

Indeed, we have $\mathbf{b}\in T=\left\{  0,1,\ldots,a_{1}\right\}
\times\left\{  0,1,\ldots,a_{2}\right\}  \times\cdots\times\left\{
0,1,\ldots,a_{u}\right\}  $. Thus, $\mathbf{b}$ is a $u$-tuple of nonnegative
integers. Hence, write $\mathbf{b}$ in the form $\mathbf{b}=\left(
b_{1},b_{2},\ldots,b_{u}\right)  $ for some $u$ nonnegative integers
$b_{1},b_{2},\ldots,b_{u}$. Then, the definition of $\Lambda$ yields
$\Lambda\left(  \mathbf{b}\right)  =p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots
p_{u}^{b_{u}}$. Hence, for each $i\in\left\{  1,2,\ldots,u\right\}  $, we have%
\[
v_{p_{i}}\left(  \underbrace{\Lambda\left(  \mathbf{b}\right)  }%
_{=p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}}\right)  =v_{p_{i}}\left(
p_{1}^{b_{1}}p_{2}^{b_{2}}\cdots p_{u}^{b_{u}}\right)  =b_{i}%
\]
(by Exercise \ref{exe.ent.prime.p1a1puau} \textbf{(a)}, applied to $b_{i}$
instead of $a_{i}$). In other words,%
\[
\left(  v_{p_{1}}\left(  \Lambda\left(  \mathbf{b}\right)  \right)  ,v_{p_{2}%
}\left(  \Lambda\left(  \mathbf{b}\right)  \right)  ,\ldots,v_{p_{u}}\left(
\Lambda\left(  \mathbf{b}\right)  \right)  \right)  =\left(  b_{1}%
,b_{2},\ldots,b_{u}\right)  .
\]
Now,%
\begin{align*}
\left(  V\circ\Lambda\right)  \left(  \mathbf{b}\right)   &  =V\left(
\Lambda\left(  \mathbf{b}\right)  \right) \\
&  =\left(  v_{p_{1}}\left(  \Lambda\left(  \mathbf{b}\right)  \right)
,v_{p_{2}}\left(  \Lambda\left(  \mathbf{b}\right)  \right)  ,\ldots,v_{p_{u}%
}\left(  \Lambda\left(  \mathbf{b}\right)  \right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }V\right) \\
&  =\left(  b_{1},b_{2},\ldots,b_{u}\right)  =\mathbf{b}=\operatorname*{id}%
\left(  \mathbf{b}\right)  .
\end{align*}


Now, forget that we fixed $\mathbf{b}$. We have thus proven that $\left(
V\circ\Lambda\right)  \left(  \mathbf{b}\right)  =\operatorname*{id}\left(
\mathbf{b}\right)  $ for each $\mathbf{b}\in T$. In other words,
$V\circ\Lambda=\operatorname*{id}$.]
\end{fineprint}

We have now proven the equalities $\Lambda\circ V=\operatorname*{id}$ and
$V\circ\Lambda=\operatorname*{id}$. These equalities show that the maps
$\Lambda$ and $V$ are mutually inverse. Hence, the map $\Lambda$ is
invertible, i.e., bijective. This completes the proof of Lemma
\ref{lem.ent.divs-bijs}.
\end{proof}

\begin{proof}
[Proof of Proposition \ref{prop.ent.count-divs}.]The integer $\left\vert
n\right\vert $ is positive (since $n$ is nonzero) and thus nonzero. We observe
that%
\begin{equation}
\left\{  \text{positive divisors of }\left\vert n\right\vert \right\}
=\left\{  \text{positive divisors of }n\right\}
\label{pf.prop.ent.count-divs.abs-1}%
\end{equation}
\footnote{\textit{Proof of (\ref{pf.prop.ent.count-divs.abs-1}):} Let
$d\in\left\{  \text{positive divisors of }\left\vert n\right\vert \right\}  $.
Thus, $d$ is a positive divisor of $\left\vert n\right\vert $. In other words,
$d$ is a positive integer and satisfies $d\mid\left\vert n\right\vert $. But
$\left\vert n\right\vert \mid n$ (by Exercise \ref{exe.ent.div.aabs}
\textbf{(b)}, applied to $a=n$). Hence, Proposition \ref{prop.ent.div.2}
\textbf{(b)} (applied to $a=d$, $b=\left\vert n\right\vert $ and $c=n$) shows
that $d\mid n$. Thus, $d$ is a positive integer and satisfies $d\mid n$. In
other words, $d$ is a positive divisor of $n$. In other words, $d\in\left\{
\text{positive divisors of }n\right\}  $.
\par
Now, forget that we fixed $d$. We thus have proven that $d\in\left\{
\text{positive divisors of }n\right\}  $ for each $d\in\left\{  \text{positive
divisors of }\left\vert n\right\vert \right\}  $. In other words,%
\begin{equation}
\left\{  \text{positive divisors of }\left\vert n\right\vert \right\}
\subseteq\left\{  \text{positive divisors of }n\right\}  .
\label{pf.prop.ent.count-divs.abs-1.pf.1}%
\end{equation}
\par
Let $e\in\left\{  \text{positive divisors of }n\right\}  $. Thus, $e$ is a
positive divisor of $n$. In other words, $e$ is a positive integer and
satisfies $e\mid n$. But $n\mid\left\vert n\right\vert $ (by Exercise
\ref{exe.ent.div.aabs} \textbf{(a)}, applied to $a=n$). Hence, Proposition
\ref{prop.ent.div.2} \textbf{(b)} (applied to $a=e$, $b=n$ and $c=\left\vert
n\right\vert $) shows that $e\mid\left\vert n\right\vert $. Thus, $e$ is a
positive integer and satisfies $e\mid\left\vert n\right\vert $. In other
words, $e$ is a positive divisor of $\left\vert n\right\vert $. In other
words, $e\in\left\{  \text{positive divisors of }\left\vert n\right\vert
\right\}  $.
\par
Now, forget that we fixed $e$. We thus have proven that $e\in\left\{
\text{positive divisors of }\left\vert n\right\vert \right\}  $ for each
$e\in\left\{  \text{positive divisors of }n\right\}  $. In other words,%
\[
\left\{  \text{positive divisors of }n\right\}  \subseteq\left\{
\text{positive divisors of }\left\vert n\right\vert \right\}  .
\]
Combining this with (\ref{pf.prop.ent.count-divs.abs-1.pf.1}), we obtain
$\left\{  \text{positive divisors of }\left\vert n\right\vert \right\}
=\left\{  \text{positive divisors of }n\right\}  $. Thus,
(\ref{pf.prop.ent.count-divs.abs-1}) is proven.}. Hence,%
\begin{align}
&  \left(  \text{the number of positive divisors of }\left\vert n\right\vert
\right) \nonumber\\
&  =\left(  \text{the number of positive divisors of }n\right)  .
\label{pf.prop.ent.count-divs.abs-2}%
\end{align}
The same argument (but with the word \textquotedblleft
positive\textquotedblright\ removed) yields%
\begin{equation}
\left(  \text{the number of divisors of }\left\vert n\right\vert \right)
=\left(  \text{the number of divisors of }n\right)  .
\label{pf.prop.ent.count-divs.abs-3}%
\end{equation}
Finally, Exercise \ref{exe.ent.prime.vp-abs} yields that
\begin{equation}
v_{p}\left(  \left\vert n\right\vert \right)  =v_{p}\left(  n\right)
\ \ \ \ \ \ \ \ \ \ \text{for each prime }p.
\label{pf.prop.ent.count-divs.abs-4}%
\end{equation}


The claim of Proposition \ref{prop.ent.count-divs} does not change if we
replace $n$ by $\left\vert n\right\vert $ (because of
(\ref{pf.prop.ent.count-divs.abs-2}), (\ref{pf.prop.ent.count-divs.abs-3}) and
(\ref{pf.prop.ent.count-divs.abs-4})). Thus, we can WLOG assume that $n\geq0$
(since otherwise, we can just replace $n$ by $\left\vert n\right\vert $).
Assume this. Combining $n\neq0$ (since $n$ is nonzero) with $n\geq0$, we find
$n>0$. Hence, $n$ is a positive integer.

\textbf{(a)} For every prime $p>\left\vert n\right\vert $, we have
$v_{p}\left(  n\right)  =0$ (by Lemma \ref{lem.ent.prime.vpn=0} \textbf{(a)})
and thus $\underbrace{v_{p}\left(  n\right)  }_{=0}+1=1$. Thus, all but
finitely many primes $p$ satisfy $v_{p}\left(  n\right)  +1=1$ (since all but
finitely many primes $p$ satisfy $p>\left\vert n\right\vert $). Therefore, all
but finitely many factors of the product $\prod_{p\text{ prime}}\left(
v_{p}\left(  n\right)  +1\right)  $ are $1$. In other words, the product
$\prod_{p\text{ prime}}\left(  v_{p}\left(  n\right)  +1\right)  $ has only
finitely many factors different from $1$. Hence, this product is well-defined.
This proves Proposition \ref{prop.ent.count-divs} \textbf{(a)}.

\textbf{(b)} For every prime $p>\left\vert n\right\vert $, we have
$v_{p}\left(  n\right)  =0$ (by Lemma \ref{lem.ent.prime.vpn=0} \textbf{(a)}).
Thus, all but finitely many primes $p$ satisfy $v_{p}\left(  n\right)  =0$
(since all but finitely many primes $p$ satisfy $p>\left\vert n\right\vert $).
In other words, the set of all primes $p$ satisfying $v_{p}\left(  n\right)
\neq0$ is finite. Let $P$ be this set. Thus, $P$ is finite.

Let $\left(  p_{1},p_{2},\ldots,p_{u}\right)  $ be a list of elements of $P$,
with no repetitions.\footnote{Such a list exists, since $P$ is finite.} Thus,
\[
\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  =P.
\]
The elements $p_{1},p_{2},\ldots,p_{u}$ are distinct (since $\left(
p_{1},p_{2},\ldots,p_{u}\right)  $ is a list with no repetitions). Thus, the
map $\left\{  1,2,\ldots,u\right\}  \rightarrow\left\{  p_{1},p_{2}%
,\ldots,p_{u}\right\}  ,\ i\mapsto p_{i}$ is a bijection\footnote{Indeed, this
map is injective, since the elements $p_{1},p_{2},\ldots,p_{u}$ are distinct;
and it is surjective, since its image is clearly $\left\{  p_{1},p_{2}%
,\ldots,p_{u}\right\}  $.}. Moreover, the elements $p_{1},p_{2},\ldots,p_{u}$
belong to $\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  =P$, and thus are primes
(since $P$ is a set of primes).

If $p$ is a prime such that $p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
$, then
\begin{equation}
v_{p}\left(  n\right)  =0. \label{pf.prop.ent.count-divs.vpn=0}%
\end{equation}


\begin{fineprint}
[\textit{Proof of (\ref{pf.prop.ent.count-divs.vpn=0}):} Recall that $P$ is
the set of all primes $p$ satisfying $v_{p}\left(  n\right)  \neq0$ (by the
definition of $P$). Hence, every prime $p$ satisfying $v_{p}\left(  n\right)
\neq0$ must belong to $P$. Thus, if $p$ is a prime that does not belong to
$P$, then $p$ cannot satisfy $v_{p}\left(  n\right)  \neq0$. In other words,
if $p$ is a prime that does not belong to $P$, then $p$ must satisfy
$v_{p}\left(  n\right)  =0$. In other words, if $p$ is a prime such that
$p\notin P$, then $v_{p}\left(  n\right)  =0$. Since $\left\{  p_{1}%
,p_{2},\ldots,p_{u}\right\}  =P$, this rewrites as follows: If $p$ is a prime
such that $p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  $, then
$v_{p}\left(  n\right)  =0$. This proves (\ref{pf.prop.ent.count-divs.vpn=0}).]
\end{fineprint}

If $p$ is a prime such that $p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
$, then%
\begin{align}
p^{v_{p}\left(  n\right)  }  &  =p^{0}\ \ \ \ \ \ \ \ \ \ \left(  \text{since
(\ref{pf.prop.ent.count-divs.vpn=0}) yields }v_{p}\left(  n\right)  =0\right)
\nonumber\\
&  =1 \label{pf.prop.ent.count-divs.pvpn=1}%
\end{align}
and%
\begin{equation}
\underbrace{v_{p}\left(  n\right)  }_{\substack{=0\\\text{(by
(\ref{pf.prop.ent.count-divs.vpn=0}))}}}+1=1.
\label{pf.prop.ent.count-divs.vpn+1=1}%
\end{equation}


For each $i\in\left\{  1,2,\ldots,u\right\}  $, define a nonnegative integer
$a_{i}$ by%
\begin{equation}
a_{i}=v_{p_{i}}\left(  n\right)  . \label{pf.prop.ent.count-divs.ai=}%
\end{equation}
This is well-defined, since $p_{i}$ is a prime (because $p_{1},p_{2}%
,\ldots,p_{u}$ are primes) and since $n$ is nonzero.

Define a set $T$ as in Lemma \ref{lem.ent.divs-bijs}.

Recall that $n$ is a positive integer. Thus, Corollary
\ref{cor.ent.prime.can-fac} yields%
\begin{align*}
n  &  =\prod_{p\text{ prime}}p^{v_{p}\left(  n\right)  }=\left(
\prod_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2},\ldots
,p_{u}\right\}  }}p^{v_{p}\left(  n\right)  }\right)  \left(  \prod
_{\substack{p\text{ prime;}\\p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
}}\underbrace{p^{v_{p}\left(  n\right)  }}_{\substack{=1\\\text{(by
(\ref{pf.prop.ent.count-divs.pvpn=1}))}}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since each prime }p\text{ satisfies either }p\in\left\{  p_{1}%
,p_{2},\ldots,p_{u}\right\} \\
\text{or }p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  \text{ (but not
both simultaneously)}%
\end{array}
\right) \\
&  =\left(  \prod_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2}%
,\ldots,p_{u}\right\}  }}p^{v_{p}\left(  n\right)  }\right)
\underbrace{\left(  \prod_{\substack{p\text{ prime;}\\p\notin\left\{
p_{1},p_{2},\ldots,p_{u}\right\}  }}1\right)  }_{=1}=\underbrace{\prod
_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
}}}_{\substack{=\prod_{p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
}\\\text{(since each }p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
\\\text{is a prime)}}}p^{v_{p}\left(  n\right)  }\\
&  =\prod_{p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  }p^{v_{p}\left(
n\right)  }=\prod_{i=1}^{u}\underbrace{p_{i}^{v_{p_{i}}\left(  n\right)  }%
}_{\substack{=p_{i}^{a_{i}}\\\text{(since (\ref{pf.prop.ent.count-divs.ai=}%
)}\\\text{yields }v_{p_{i}}\left(  n\right)  =a_{i}\text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we have substituted }p_{i}\text{ for }p\text{ in the product,}\\
\text{since the map }\left\{  1,2,\ldots,u\right\}  \rightarrow\left\{
p_{1},p_{2},\ldots,p_{u}\right\}  ,\ i\mapsto p_{i}\text{ is a bijection}%
\end{array}
\right) \\
&  =\prod_{i=1}^{u}p_{i}^{a_{i}}=p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots p_{u}%
^{a_{u}}.
\end{align*}
Hence, Lemma \ref{lem.ent.divs-bijs} shows that the map
\begin{align*}
\Lambda:T  &  \rightarrow\left\{  \text{positive divisors of }n\right\}  ,\\
\left(  b_{1},b_{2},\ldots,b_{u}\right)   &  \mapsto p_{1}^{b_{1}}p_{2}%
^{b_{2}}\cdots p_{u}^{b_{u}}%
\end{align*}
is well-defined and bijective.

Thus, there is a bijective map from $T$ to $\left\{  \text{positive divisors
of }n\right\}  $ (namely, $\Lambda$). Hence,
\begin{align*}
&  \left\vert \left\{  \text{positive divisors of }n\right\}  \right\vert \\
&  =\left\vert T\right\vert =\left\vert \left\{  0,1,\ldots,a_{1}\right\}
\times\left\{  0,1,\ldots,a_{2}\right\}  \times\cdots\times\left\{
0,1,\ldots,a_{u}\right\}  \right\vert \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }T=\left\{  0,1,\ldots
,a_{1}\right\}  \times\left\{  0,1,\ldots,a_{2}\right\}  \times\cdots
\times\left\{  0,1,\ldots,a_{u}\right\}  \right) \\
&  =\left\vert \left\{  0,1,\ldots,a_{1}\right\}  \right\vert \cdot\left\vert
\left\{  0,1,\ldots,a_{2}\right\}  \right\vert \cdot\cdots\cdot\left\vert
\left\{  0,1,\ldots,a_{u}\right\}  \right\vert \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the product rule }\left\vert A_{1}\times A_{2}\times\cdots\times
A_{u}\right\vert =\left\vert A_{1}\right\vert \cdot\left\vert A_{2}\right\vert
\cdot\cdots\cdot\left\vert A_{u}\right\vert \\
\text{holds whenever }A_{1},A_{2},\ldots,A_{u}\text{ are any }u\text{ finite
sets}%
\end{array}
\right) \\
&  =\prod_{i=1}^{u}\underbrace{\left\vert \left\{  0,1,\ldots,a_{i}\right\}
\right\vert }_{=a_{i}+1}=\prod_{i=1}^{u}\left(  a_{i}+1\right)  .
\end{align*}
Comparing this with%
\begin{align*}
&  \prod_{p\text{ prime}}\left(  v_{p}\left(  n\right)  +1\right) \\
&  =\left(  \prod_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2}%
,\ldots,p_{u}\right\}  }}\left(  v_{p}\left(  n\right)  +1\right)  \right)
\left(  \prod_{\substack{p\text{ prime;}\\p\notin\left\{  p_{1},p_{2}%
,\ldots,p_{u}\right\}  }}\underbrace{\left(  v_{p}\left(  n\right)  +1\right)
}_{\substack{=1\\\text{(by (\ref{pf.prop.ent.count-divs.vpn+1=1}))}}}\right)
\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since each prime }p\text{ satisfies either }p\in\left\{  p_{1}%
,p_{2},\ldots,p_{u}\right\} \\
\text{or }p\notin\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  \text{ (but not
both simultaneously)}%
\end{array}
\right) \\
&  =\left(  \prod_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2}%
,\ldots,p_{u}\right\}  }}\left(  v_{p}\left(  n\right)  +1\right)  \right)
\underbrace{\left(  \prod_{\substack{p\text{ prime;}\\p\notin\left\{
p_{1},p_{2},\ldots,p_{u}\right\}  }}1\right)  }_{=1}=\underbrace{\prod
_{\substack{p\text{ prime;}\\p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
}}}_{\substack{=\prod_{p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
}\\\text{(since each }p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}
\\\text{is a prime)}}}\left(  v_{p}\left(  n\right)  +1\right) \\
&  =\prod_{p\in\left\{  p_{1},p_{2},\ldots,p_{u}\right\}  }\left(
v_{p}\left(  n\right)  +1\right)  =\prod_{i=1}^{u}\left(  \underbrace{v_{p_{i}%
}\left(  n\right)  }_{\substack{=a_{i}\\\text{(by
(\ref{pf.prop.ent.count-divs.ai=}))}}}+1\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{here, we have substituted }p_{i}\text{ for }p\text{ in the product,}\\
\text{since the map }\left\{  1,2,\ldots,u\right\}  \rightarrow\left\{
p_{1},p_{2},\ldots,p_{u}\right\}  ,\ i\mapsto p_{i}\text{ is a bijection}%
\end{array}
\right) \\
&  =\prod_{i=1}^{u}\left(  a_{i}+1\right)  ,
\end{align*}
we obtain%
\[
\left\vert \left\{  \text{positive divisors of }n\right\}  \right\vert
=\prod_{p\text{ prime}}\left(  v_{p}\left(  n\right)  +1\right)  .
\]
Hence,%
\begin{align*}
\left(  \text{the number of positive divisors of }n\right)   &  =\left\vert
\left\{  \text{positive divisors of }n\right\}  \right\vert \\
&  =\prod_{p\text{ prime}}\left(  v_{p}\left(  n\right)  +1\right)  .
\end{align*}
This proves Proposition \ref{prop.ent.count-divs} \textbf{(b)}.

\textbf{(c)} Every divisor of $n$ is either positive or
negative\footnote{\textit{Proof.} Let $d$ be a divisor of $n$. We must prove
that $d$ is either positive or negative.
\par
We have $d\mid n$ (since $d$ is a divisor of $n$). Thus, there is an integer
$e$ such that $n=de$. Consider this $e$. If we had $d=0$, then we would have
$n=\underbrace{d}_{=0}e=0$, which would contradict the fact that $n$ is
nonzero. Hence, we cannot have $d=0$. In other words, we have $d\neq0$. Thus,
$d$ is a nonzero integer. Hence, $d$ is either positive or negative. Qed.}
(but clearly cannot be both at the same time). Hence,%
\begin{align*}
&  \left(  \text{the number of divisors of }n\right) \\
&  =\left(  \text{the number of positive divisors of }n\right)  +\left(
\text{the number of negative divisors of }n\right)  .
\end{align*}


If $d$ is a positive divisor of $n$, then $-d$ is a negative divisor of
$n$\ \ \ \ \footnote{\textit{Proof.} Let $d$ be a positive divisor of $n$. We
must prove that $-d$ is a negative divisor of $n$. Clearly, $-d$ is negative
(since $d$ is positive).
\par
We have assumed that $d$ is a positive divisor of $n$. In other words, $d$ is
a positive integer and satisfies $d\mid n$. But $d=\left(  -d\right)  \left(
-1\right)  $; thus, $-d\mid d$ (since $-1$ is an integer). Hence, $-d\mid
d\mid n$. Hence, $-d$ is a divisor of $n$. Thus, $-d$ is a negative divisor of
$n$ (since $-d$ is negative). Qed.}. Hence, we can define a map%
\begin{align*}
A:\left\{  \text{positive divisors of }n\right\}   &  \rightarrow\left\{
\text{negative divisors of }n\right\}  ,\\
d  &  \mapsto-d.
\end{align*}
For similar reasons, we can define a map%
\begin{align*}
B:\left\{  \text{negative divisors of }n\right\}   &  \rightarrow\left\{
\text{positive divisors of }n\right\}  ,\\
d  &  \mapsto-d.
\end{align*}
Consider these two maps $A$ and $B$. Clearly, $A\circ B=\operatorname*{id}$
(since each negative divisor $d$ of $n$ satisfies $\left(  A\circ B\right)
\left(  d\right)  =A\left(  \underbrace{B\left(  d\right)  }_{=-d}\right)
=A\left(  -d\right)  =-\left(  -d\right)  =d=\operatorname*{id}\left(
d\right)  $) and $B\circ A=\operatorname*{id}$ (similarly). Thus, these maps
$A$ and $B$ are mutually inverse. Hence, the map $A$ is invertible, i.e., a bijection.

Hence, there is a bijection between $\left\{  \text{positive divisors of
}n\right\}  $ and $\left\{  \text{negative divisors of }n\right\}  $ (namely,
$A$). Thus,%
\[
\left\vert \left\{  \text{negative divisors of }n\right\}  \right\vert
=\left\vert \left\{  \text{positive divisors of }n\right\}  \right\vert ,
\]
so that%
\begin{align*}
&  \left(  \text{the number of negative divisors of }n\right) \\
&  =\left\vert \left\{  \text{negative divisors of }n\right\}  \right\vert
=\left\vert \left\{  \text{positive divisors of }n\right\}  \right\vert \\
&  =\left(  \text{the number of positive divisors of }n\right)  .
\end{align*}
Therefore,%
\begin{align*}
&  \left(  \text{the number of divisors of }n\right) \\
&  =\left(  \text{the number of positive divisors of }n\right)
+\underbrace{\left(  \text{the number of negative divisors of }n\right)
}_{=\left(  \text{the number of positive divisors of }n\right)  }\\
&  =\left(  \text{the number of positive divisors of }n\right)  +\left(
\text{the number of positive divisors of }n\right) \\
&  =2\cdot\underbrace{\left(  \text{the number of positive divisors of
}n\right)  }_{\substack{=\prod_{p\text{ prime}}\left(  v_{p}\left(  n\right)
+1\right)  \\\text{(by Proposition \ref{prop.ent.count-divs} \textbf{(b)})}%
}}=2\prod_{p\text{ prime}}\left(  v_{p}\left(  n\right)  +1\right)  .
\end{align*}
Hence, Proposition \ref{prop.ent.count-divs} \textbf{(c)} follows.
\end{proof}

\begin{remark}
Proposition \ref{prop.ent.count-divs} can be used to re-prove Proposition
\ref{prop.ent.phi.ghosts}. We leave the details of this argument to the reader.
\end{remark}

The method by which we proved Proposition \ref{prop.ent.count-divs} can be
used (with a minor modification) to not just count the positive divisors of a
positive integer $n$, but also (for example) to compute their sum or the sum
of their squares. This relies on the following basic property of $\sum$ and
$\prod$ signs:

\begin{lemma}
\label{lem.prodrule.nums}Let $n\in\mathbb{N}$. For every $i\in\left\{
1,2,\ldots,n\right\}  $, let $Z_{i}$ be a finite set. For every $i\in\left\{
1,2,\ldots,n\right\}  $ and every $k\in Z_{i}$, let $p_{i,k}$ be a number.
Then,%
\[
\prod_{i=1}^{n}\sum_{k\in Z_{i}}p_{i,k}=\sum_{\left(  k_{1},k_{2},\ldots
,k_{n}\right)  \in Z_{1}\times Z_{2}\times\cdots\times Z_{n}}\prod_{i=1}%
^{n}p_{i,k_{i}}.
\]
(Note that if $n=0$, then the Cartesian product $Z_{1}\times Z_{2}\times
\cdots\times Z_{n}$ has no factors; it is what is called an \textit{empty
Cartesian product}. It is understood to be a $1$-element set, and its single
element is the $0$-tuple $\left(  {}\right)  $ (also known as the empty list).)
\end{lemma}

Lemma \ref{lem.prodrule.nums} is essentially a version of the distributivity
law (or the \href{https://en.wikipedia.org/wiki/FOIL_method}{FOIL method}) for
expanding a product of several sums, each of which has several factors. For
example, if we take $n=3$ and $Z_{i}=\left\{  1,2\right\}  $ for each
$i\in\left\{  1,2,3\right\}  $, then Lemma \ref{lem.prodrule.nums} says that%
\begin{align*}
&  \left(  p_{1,1}+p_{1,2}\right)  \left(  p_{2,1}+p_{2,2}\right)  \left(
p_{3,1}+p_{3,2}\right) \\
&  =p_{1,1}p_{2,1}p_{3,1}+p_{1,1}p_{2,1}p_{3,2}+p_{1,1}p_{2,2}p_{3,1}%
+p_{1,1}p_{2,2}p_{3,2}\\
&  \ \ \ \ \ \ \ \ \ \ +p_{1,2}p_{2,1}p_{3,1}+p_{1,2}p_{2,1}p_{3,2}%
+p_{1,2}p_{2,2}p_{3,1}+p_{1,2}p_{2,2}p_{3,2}%
\end{align*}
(which is precisely what you get if you expand the product \newline$\left(
p_{1,1}+p_{1,2}\right)  \left(  p_{2,1}+p_{2,2}\right)  \left(  p_{3,1}%
+p_{3,2}\right)  $ using the distributivity law). For another example, if we
take $n=2$ and $Z_{i}=\left\{  1,2,3\right\}  $ for each $i\in\left\{
1,2\right\}  $, then Lemma \ref{lem.prodrule.nums} says that%
\begin{align*}
\left(  p_{1,1}+p_{1,2}+p_{1,3}\right)  \left(  p_{2,1}+p_{2,2}+p_{2,3}%
\right)   &  =p_{1,1}p_{2,1}+p_{1,1}p_{2,2}+p_{1,1}p_{2,3}\\
&  \ \ \ \ \ \ \ \ \ \ +p_{1,2}p_{2,1}+p_{1,2}p_{2,2}+p_{1,2}p_{2,3}\\
&  \ \ \ \ \ \ \ \ \ \ +p_{1,3}p_{2,1}+p_{1,3}p_{2,2}+p_{1,3}p_{2,3}%
\end{align*}
(which is, again, simply the result of expanding the left hand side). In the
general case, the idea behind Lemma \ref{lem.prodrule.nums} is that if you
expand the product\footnote{We are here assuming (for the sake of simplicity)
that each set $Z_{i}$ is $\left\{  1,2,\ldots,m_{i}\right\}  $ for some
$m_{i}\in\mathbb{N}$. This does not weaken the reach of Lemma
\ref{lem.prodrule.nums}, since each finite set $Z_{i}$ can be relabelled as
$\left\{  1,2,\ldots,m_{i}\right\}  $ for $m_{i}=\left\vert Z_{i}\right\vert
$.}%
\begin{align*}
&  \prod_{i=1}^{n}\sum_{k=1}^{m_{i}}p_{i,k}\\
&  =\prod_{i=1}^{n}\left(  p_{i,1}+p_{i,2}+\cdots+p_{i,m_{i}}\right) \\
&  =\left(  p_{1,1}+p_{1,2}+\cdots+p_{1,m_{1}}\right)  \left(  p_{2,1}%
+p_{2,2}+\cdots+p_{2,m_{2}}\right)  \cdots\left(  p_{n,1}+p_{n,2}%
+\cdots+p_{n,m_{n}}\right)  ,
\end{align*}
then you get a sum of $m_{1}m_{2}\cdots m_{n}$ terms, each of which has the
form
\[
p_{1,k_{1}}p_{2,k_{2}}\cdots p_{n,k_{n}}=\prod_{i=1}^{n}p_{i,k_{i}}%
\]
for some $\left(  k_{1},k_{2},\ldots,k_{n}\right)  \in\left\{  1,2,\ldots
,m_{1}\right\}  \times\left\{  1,2,\ldots,m_{2}\right\}  \times\cdots
\times\left\{  1,2,\ldots,m_{n}\right\}  $. See \cite[proof of Lemma
7.160]{detnotes} for a rigorous proof of Lemma \ref{lem.prodrule.nums} (which
uses induction and the distributivity law).

Now, we can state a formula for the sum of all positive divisors of a positive
integer $n$, and more generally for the sum of the $k$-th powers of these
positive divisors, where $k$ is a fixed integer:

\begin{exercise}
\label{exe.ent.count-divs-k}Let $n$ be a positive integer. Let $k\in
\mathbb{Z}$. Prove that:

\textbf{(a)} The product $\prod_{p\text{ prime}}\left(  p^{0k}+p^{1k}%
+\cdots+p^{v_{p}\left(  n\right)  \cdot k}\right)  $ is well-defined, since
all but finitely many of its factors are $1$.

\textbf{(b)} We have
\[
\sum_{d\mid n}d^{k}=\prod_{p\text{ prime}}\left(  p^{0k}+p^{1k}+\cdots
+p^{v_{p}\left(  n\right)  \cdot k}\right)  .
\]

\end{exercise}

(Recall that the summation sign \textquotedblleft$\sum_{d\mid n}%
$\textquotedblright\ means a sum over all \textbf{positive} divisors $d$ of
$n$.)

\begin{example}
If $n=6$, then the positive divisors of $n$ are $1,2,3,6$. Thus, in this case,
the claim of Exercise \ref{exe.ent.count-divs-k} \textbf{(b)} becomes%
\[
1^{k}+2^{k}+3^{k}+6^{k}=\prod_{p\text{ prime}}\left(  p^{0k}+p^{1k}%
+\cdots+p^{v_{p}\left(  6\right)  \cdot k}\right)  .
\]
This equality can easily be verified, since the right hand side is%
\begin{align*}
&  \prod_{p\text{ prime}}\left(  p^{0k}+p^{1k}+\cdots+p^{v_{p}\left(
6\right)  \cdot k}\right) \\
&  =\underbrace{\left(  2^{0k}+2^{1k}+\cdots+2^{v_{2}\left(  6\right)  \cdot
k}\right)  }_{\substack{=2^{0k}+2^{1k}\\\text{(since }v_{2}\left(  6\right)
=1\text{)}}}\cdot\underbrace{\left(  3^{0k}+3^{1k}+\cdots+3^{v_{3}\left(
6\right)  \cdot k}\right)  }_{\substack{=3^{0k}+3^{1k}\\\text{(since }%
v_{3}\left(  6\right)  =1\text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \cdot\prod_{\substack{p\text{ prime;}\\p\notin\left\{
2,3\right\}  }}\underbrace{\left(  p^{0k}+p^{1k}+\cdots+p^{v_{p}\left(
6\right)  \cdot k}\right)  }_{\substack{=p^{0k}\\\text{(since }v_{p}\left(
6\right)  =0\text{ (because }p\notin\left\{  2,3\right\}  \text{))}}}\\
&  =\left(  \underbrace{2^{0k}}_{=1}+\underbrace{2^{1k}}_{=2^{k}}\right)
\cdot\left(  \underbrace{3^{0k}}_{=1}+\underbrace{3^{1k}}_{=3^{k}}\right)
\cdot\prod_{\substack{p\text{ prime;}\\p\notin\left\{  2,3\right\}
}}\underbrace{p^{0k}}_{=1}\\
&  =\left(  1+2^{k}\right)  \cdot\left(  1+3^{k}\right)  =\underbrace{1}%
_{=1^{k}}+2^{k}+3^{k}+\underbrace{2^{k}\cdot3^{k}}_{=\left(  2\cdot3\right)
^{k}=6^{k}}=1^{k}+2^{k}+3^{k}+6^{k}.
\end{align*}

\end{example}

Note that Proposition \ref{prop.ent.count-divs} \textbf{(b)} is the particular
case of Exercise \ref{exe.ent.count-divs-k} \textbf{(b)} obtained when setting
$k=0$ (because each integer $z$ satisfies $z^{0}=1$, and thus $\sum_{d\mid
n}d^{0}$ is the number of positive divisors of $n$).

\begin{exercise}
\label{exe.ent.count-divs-134}Let $n$ be a positive integer. Let%
\begin{align*}
z  &  =\left(  \text{the number of positive divisors $d$ of $n$ such that
$d\equiv1\mod 4$}\right) \\
&  \ \ \ \ \ \ \ \ \ \ -\left(  \text{the number of positive divisors $d$ of
$n$ such that $d\equiv3\mod 4$}\right)  .
\end{align*}


Prove the following:

\textbf{(a)} If there exists a prime $p$ satisfying $p\equiv
3\operatorname{mod}4$ and $v_{p}\left(  n\right)  \equiv1\operatorname{mod}2$,
then $z=0$.

\textbf{(b)} If there exists no prime $p$ satisfying $p\equiv
3\operatorname{mod}4$ and $v_{p}\left(  n\right)  \equiv1\operatorname{mod}2$,
then
\[
z=\prod_{\substack{p\text{ prime;}\\p\equiv1\operatorname{mod}4}}\left(
v_{p}\left(  n\right)  +1\right)  .
\]


[\textbf{Hint:} For every $u\in\mathbb{Z}$, set $L\left(  u\right)  =%
\begin{cases}
1, & \text{if }u\%4=1;\\
-1, & \text{if }u\%4=3;\\
0, & \text{otherwise.}%
\end{cases}
$ Prove that $L\left(  uv\right)  =L\left(  u\right)  \cdot L\left(  v\right)
$ for any integers $u$ and $v$. Then, show that $z=\sum_{d\mid n}L\left(
d\right)  $. Exploit the similarity between the sum $\sum_{d\mid n}L\left(
d\right)  $ and the sum in Exercise \ref{exe.ent.count-divs-k} \textbf{(b)}.]
\end{exercise}

\section{Equivalence relations and residue classes}

\subsection{Relations}

Loosely speaking, a \textit{relation} on a set $S$ is a property that two
elements $a$ and $b$ of $S$ (or, more formally, a pair $\left(  a,b\right)
\in S\times S$ of two elements of $S$) can either have or not have. For
example, equality (denoted $=$) is a relation, since two elements $a$ and $b$
of $S$ are either equal (i.e., satisfy $a=b$) or not equal. Likewise, the
divisibility relation (denoted $\mid$) is a relation on $\mathbb{Z}$, since
two elements $a$ and $b$ of $\mathbb{Z}$ either satisfy $a\mid b$ or do not.

A formal definition of relations proceeds as follows:

\begin{definition}
\label{def.eqrel.rel.rel}Fix a set $S$. A \textit{binary relation} on $S$ is a
subset of $S\times S$ (that is, a set of pairs of elements of $S$).

If $R$ is a binary relation (on $S$), and if $a,b\in S$, then we write $aRb$
for $\left(  a,b\right)  \in R$.

The word \textquotedblleft\textit{relation}\textquotedblright\ shall always
mean \textquotedblleft binary relation\textquotedblright\ unless we say otherwise.
\end{definition}

So a relation on a set $S$ is, formally speaking, a subset of $S\times S$ --
but in practice, we think of it as a property that holds for some pairs
$\left(  a,b\right)  \in S\times S$ (namely, for the ones that belong to this
subset) and does not hold for some others (namely, for the ones that do not
belong to this subset).\footnote{Here, the word \textquotedblleft
some\textquotedblright\ can mean \textquotedblleft none\textquotedblright\ or
\textquotedblleft all\textquotedblright\ or anything inbetween.} In order to
define a relation $R$ on a given set $S$, it suffices to tell which pairs
$\left(  a,b\right)  \in S\times S$ satisfy $aRb$ (because then, $R$ will
simply be the set of all these pairs $\left(  a,b\right)  $). Let us define
several relations on the set $\mathbb{Z}$ by this strategy:

\begin{example}
\label{exa.eqrel.rel.rels1}Let $S=\mathbb{Z}$.

\textbf{(a)} The relation $=$ is a binary relation on $S$. As a subset of
$S\times S$, this relation is%
\begin{align*}
&  \left\{  \left(  a,b\right)  \in S\times S\ \mid\ a=b\right\} \\
&  =\left\{  \left(  c,c\right)  \ \mid\ c\in S\right\}  =\left\{
\ldots,\left(  -1,-1\right)  ,\left(  0,0\right)  ,\left(  1,1\right)
,\ldots\right\}  .
\end{align*}


\textbf{(b)} The relation $<$ is a binary relation on $S$. As a subset of
$S\times S$, this relation is%
\[
\left\{  \left(  a,b\right)  \in S\times S\ \mid\ a<b\right\}  .
\]


\textbf{(c)} The relation $\leq$ is a binary relation on $S$. As a subset of
$S\times S$, this relation is%
\[
\left\{  \left(  a,b\right)  \in S\times S\ \mid\ a\leq b\right\}  .
\]


\textbf{(d)} The relation $\neq$ is also a binary relation on $S$.

\textbf{(e)} Fix $n\in\mathbb{Z}$. Define a relation $\underset{n}{\equiv}$ on
$S=\mathbb{Z}$ by
\[
\left(  a\underset{n}{\equiv}b\right)  \Longleftrightarrow\left(  a\equiv
b\operatorname{mod}n\right)  .
\]
As a subset of $S\times S=\mathbb{Z}\times\mathbb{Z}$, this relation
$\underset{n}{\equiv}$ is%
\begin{align*}
&  \left\{  \left(  a,b\right)  \in\mathbb{Z}\times\mathbb{Z}\ \mid\ a\equiv
b\operatorname{mod}n\right\} \\
&  =\left\{  \left(  a,b\right)  \in\mathbb{Z}\times\mathbb{Z}\ \mid
\ \text{there exists an integer }d\text{ such that }b=a+nd\right\} \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Exercise \ref{exe.ent.mod.a+nd}%
}\right) \\
&  =\left\{  \left(  a,a+nd\right)  \ \mid\ a,d\in\mathbb{Z}\right\}  .
\end{align*}


Note that the relation $\underset{0}{\equiv}$ is exactly the relation $=$ (by
Example \ref{exa.ent.cong.triv} \textbf{(c)}).

\textbf{(f)} Define a binary relation \fbox{$N$} on $S$ by%
\[
\left(  a\fbox{$N$}b\right)  \Longleftrightarrow\left(  \text{false}\right)
\]
(that is, $a\fbox{$N$}b$ never holds, no matter what $a$ and $b$ are). As a
subset of $S\times S$, this relation \fbox{$N$} is just the empty subset of
$S\times S$.

\textbf{(g)} On the other extreme: Define a binary relation \fbox{$A$} on $S$
by%
\[
\left(  a\fbox{$A$}b\right)  \Longleftrightarrow\left(  \text{true}\right)
\]
(that is, $a\fbox{$A$}b$ holds for all $a$ and $b$). As a subset of $S\times
S$, this relation \fbox{$A$} is the whole set $S\times S$. Note that the
relation \fbox{$A$} is exactly the relation $\underset{1}{\equiv}$ (by Example
\ref{exa.ent.cong.triv} \textbf{(d)}).

\textbf{(h)} The relation $\mid$ (divisibility) is also a relation on
$S=\mathbb{Z}$.

\textbf{(i)} The relation $\perp$ (coprimality) is also a relation on
$S=\mathbb{Z}$.

\textbf{(j)} We have defined several relations on the set $S=\mathbb{Z}$ now.
The relations $=$, $\neq$, \fbox{$N$} and \fbox{$A$} (or, rather, relations
analogous to them) can be defined on \textbf{any} set.
\end{example}

\subsection{Equivalence relations}

Relations occur frequently in mathematics, and there is a bunch of properties
that a relation can have or not have. (See
\href{https://en.wikipedia.org/wiki/Binary_relation}{the Wikipedia article on
binary relations} for a long list of such properties.) We shall need only the
following three:

\begin{definition}
\label{def.eqrel.rel.rst}Let $R$ be a binary relation on a set $S$.

\textbf{(a)} We say that $R$ is \textit{reflexive} if every $a\in S$ satisfies
$aRa$.

\textbf{(b)} We say that $R$ is \textit{symmetric} if every $a,b\in S$
satisfying $aRb$ satisfy $bRa$.

\textbf{(c)} We say that $R$ is \textit{transitive} if every $a,b,c\in S$
satisfying $aRb$ and $bRc$ satisfy $aRc$.
\end{definition}

(Here are mnemonics for the three words we just defined:

\begin{itemize}
\item \textquotedblleft Reflexive\textquotedblright\ should make you think of
$R$ as a mirror through which $a$ can see itself (that is, satisfy $aRa$).

\item \textquotedblleft Symmetric\textquotedblright\ means that the roles of
$a$ and $b$ in $aRb$ are interchangeable -- a symmetry.

\item \textquotedblleft Transitive\textquotedblright\ means that you can
\textquotedblleft transit\textquotedblright\ an element $b$ on your way from
$a$ to $c$ (that is, if you treat $aRb$ as the existence of a
\textquotedblleft path\textquotedblright\ from $a$ to $b$, and $bRc$ as the
existence of a \textquotedblleft path\textquotedblright\ from $b$ to $c$, then
you can combine a \textquotedblleft path\textquotedblright\ from $a$ to $b$
with a \textquotedblleft path\textquotedblright\ from $b$ to $c$ to get a
\textquotedblleft path\textquotedblright\ from $a$ to $c$).)
\end{itemize}

Let us see some examples of these properties of relations\footnote{See further
below for the proofs of the claims made in this example.}:

\begin{example}
\label{exa.eqrel.rel.rst1}Let $S$ be the set $\mathbb{Z}$. Consider the
relations on $\mathbb{Z}$ defined in Example \ref{exa.eqrel.rel.rels1}.

\textbf{(a)} The relation $=$ is reflexive, symmetric and transitive.

\textbf{(b)} The relation $<$ is transitive, but neither reflexive nor symmetric.

\textbf{(c)} The relation $\leq$ is transitive and reflexive, but not symmetric.

\textbf{(d)} The relation $\neq$ is symmetric, but neither reflexive nor transitive.

\textbf{(e)} For each $n\in\mathbb{Z}$, the relation $\underset{n}{\equiv}$ is
reflexive, symmetric and transitive.

\textbf{(f)} The relation \fbox{$N$} is symmetric and transitive, but not reflexive.

\textbf{(g)} The relation \fbox{$A$} is reflexive, symmetric and transitive.

\textbf{(h)} The divisibility relation $\mid$ is reflexive and transitive, but
not symmetric.

\textbf{(i)} The coprimality relation $\perp$ is symmetric, but neither
reflexive nor transitive.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.eqrel.rel.rst1}.]\textbf{(a)} Indeed:

\begin{itemize}
\item The relation $=$ is reflexive, because every $a\in S$ satisfies $a=a$.

\item The relation $=$ is symmetric, because every $a,b\in S$ satisfying $a=b$
satisfy $b=a$.

\item The relation $=$ is transitive, because every $a,b,c\in S$ satisfying
$a=b$ and $b=c$ satisfy $a=c$.
\end{itemize}

\textbf{(b)} Indeed:

\begin{itemize}
\item The relation $<$ is transitive (because every $a,b,c\in S$ satisfying
$a<b$ and $b<c$ satisfy $a<c$).

\item Not every $a\in S$ satisfies $a<a$ (in fact, no $a\in S$ satisfies
$a<a$); thus, $<$ is not reflexive.

\item Similarly, $<$ is not symmetric, since $a<b$ does not imply $b<a$ (quite
the opposite).
\end{itemize}

\textbf{(c)} Indeed:

\begin{itemize}
\item The relation $\leq$ is transitive (because every $a,b,c\in S$ satisfying
$a\leq b$ and $b\leq c$ satisfy $a\leq c$).

\item The relation $\leq$ is reflexive (since every $a\in S$ satisfies $a\leq
a$).

\item The relation $\leq$ is not symmetric (since $a\leq b$ does not imply
$b\leq a$; for example, $1\leq2$ holds but $2\leq1$ does not).
\end{itemize}

\textbf{(d)} Indeed:

\begin{itemize}
\item The relation $\neq$ is symmetric (because every $a,b\in S$ satisfying
$a\neq b$ satisfy $b\neq a$).

\item The relation $\neq$ is not reflexive (since we don't have $2\neq2$).

\item The relation $\neq$ is not transitive (since $2\neq3$ and $3\neq2$ do
not lead to $2\neq2$).
\end{itemize}

\textbf{(e)} Let $n\in\mathbb{Z}$.

\begin{itemize}
\item Proposition \ref{prop.ent.mod.basics} \textbf{(b)} shows that every
$a,b,c\in\mathbb{Z}$ satisfying $a\equiv b\operatorname{mod}n$ and $b\equiv
c\operatorname{mod}n$ satisfy $a\equiv c\operatorname{mod}n$. In other words,
every $a,b,c\in S$ satisfying $a\underset{n}{\equiv}b$ and
$b\underset{n}{\equiv}c$ satisfy $a\underset{n}{\equiv}c$ (since the
definition of $\underset{n}{\equiv}$ shows that the three statements
\[
\left(  a\underset{n}{\equiv}b\right)  ,\ \ \ \ \ \ \ \ \ \ \left(
b\underset{n}{\equiv}c\right)  ,\ \ \ \ \ \ \ \ \ \ \left(
a\underset{n}{\equiv}c\right)
\]
are equivalent to%
\[
\left(  a\equiv b\operatorname{mod}n\right)  ,\ \ \ \ \ \ \ \ \ \ \left(
b\equiv c\operatorname{mod}n\right)  ,\ \ \ \ \ \ \ \ \ \ \left(  a\equiv
c\operatorname{mod}n\right)  ,
\]
respectively). But this means precisely that the relation $\underset{n}{\equiv
}$ is transitive.

\item Similarly, the relation $\underset{n}{\equiv}$ is reflexive (by
Proposition \ref{prop.ent.mod.basics} \textbf{(a)}).

\item Similarly, the relation $\underset{n}{\equiv}$ is symmetric (by
Proposition \ref{prop.ent.mod.basics} \textbf{(c)}).
\end{itemize}

\textbf{(f)} This may appear strange, but is a completely straightforward
consequence of the concept of \textquotedblleft%
\href{https://en.wikipedia.org/wiki/Vacuous_truth}{vacuous truth}%
\textquotedblright:

\begin{itemize}
\item Every $a,b\in S$ satisfying $a\fbox{$N$}b$ satisfy $b\fbox{$N$}a$
(because there are no such $a,b$ to begin with -- since $a$\fbox{$N$}$b$ never
holds). Thus, \fbox{$N$} is symmetric.

\item Similarly, \fbox{$N$} is transitive.

\item But \fbox{$N$} is not reflexive, since (for example) $1\fbox{$N$}1$ does
not hold.
\end{itemize}

\textbf{(g)} All of this is trivial, because $a$\fbox{$A$}$b$ holds for all
$a,b\in S$.

\textbf{(h)} The divisibility relation $\mid$ is reflexive (by Proposition
\ref{prop.ent.div.2} \textbf{(a)}) and transitive (by Proposition
\ref{prop.ent.div.2} \textbf{(b)}), but not symmetric (since $1\mid2$ does not
lead to $2\mid1$).

\textbf{(i)} The coprimality relation is symmetric (by Proposition
\ref{prop.ent.coprime.perp-symm}), but neither reflexive (since we don't have
$2\perp2$) nor transitive (since $2\perp3$ and $3\perp2$ do not lead to
$2\perp2$).
\end{proof}

\begin{definition}
\label{def.eqrel.rel.eqrel}An \textit{equivalence relation} on a set $S$ means
a relation on $S$ that is reflexive, symmetric and transitive.
\end{definition}

\begin{example}
\label{exa.eqrel.eqrel.eqrel=}Let $S$ be any set. The relation $=$ on the set
$S$ is an equivalence relation, because it is reflexive, symmetric and transitive.
\end{example}

\begin{example}
\label{exa.eqrel.eqrel.eqrelmodn}Let $n\in\mathbb{Z}$. The relation relation
$\underset{n}{\equiv}$ on $\mathbb{Z}$ (defined in Example
\ref{exa.eqrel.rel.rels1} \textbf{(e)}) is an equivalence relation, because
(as we saw in Example \ref{exa.eqrel.rel.rst1} \textbf{(e)}) it is reflexive,
symmetric and transitive.
\end{example}

\begin{example}
Here are some examples from elementary plane geometry: Congruence (e.g., of
triangles) is an equivalence relation. Similarity is also an equivalence
relation. The same holds for direct similarity (i.e., orientation-preserving
similarity). The same holds for parallelism of lines.
\end{example}

\begin{example}
\label{exa.eqrel.eqrel.eqrelf}Let $S$ and $T$ be two sets, and let
$f:S\rightarrow T$ be a map. Define a relation $\underset{f}{\equiv}$ on $S$
by%
\[
\left(  a\underset{f}{\equiv}b\right)  \Longleftrightarrow\left(  f\left(
a\right)  =f\left(  b\right)  \right)  .
\]
This relation $\underset{f}{\equiv}$ is an equivalence relation.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.eqrel.eqrel.eqrelf}.]Indeed:

\begin{itemize}
\item The relation $\underset{f}{\equiv}$ is reflexive, because every $a\in S$
satisfies $a\underset{f}{\equiv}a$ (since $f\left(  a\right)  =f\left(
a\right)  $).

\item The relation $\underset{f}{\equiv}$ is symmetric, because every $a,b\in
S$ satisfying $a\underset{f}{\equiv}b$ satisfy $b\underset{f}{\equiv}a$.
(Indeed, $a\underset{f}{\equiv}b$ means $f\left(  a\right)  =f\left(
b\right)  $, which entails $f\left(  b\right)  =f\left(  a\right)  $, which in
turn rewrites as $b\underset{f}{\equiv}a$.)

\item The relation $\underset{f}{\equiv}$ is transitive, because every
$a,b,c\in S$ satisfying $a\underset{f}{\equiv}b$ and $b\underset{f}{\equiv}c$
satisfy $a\underset{f}{\equiv}c$. (Indeed, the assumptions
$a\underset{f}{\equiv}b$ and $b\underset{f}{\equiv}c$ rewrite as $f\left(
a\right)  =f\left(  b\right)  $ and $f\left(  b\right)  =f\left(  c\right)  $;
therefore, $f\left(  a\right)  =f\left(  b\right)  =f\left(  c\right)  $,
which rewrites as $a\underset{f}{\equiv}c$.)
\end{itemize}

\noindent Thus, $\underset{f}{\equiv}$ is an equivalence relation.
\end{proof}

We will soon learn that \textbf{every} equivalence relation on a set $S$ is
actually of the form $\underset{f}{\equiv}$ for some set $T$ and some map
$f:S\rightarrow T$. (Namely, this is proven in Exercise
\ref{exe.eqrel.eqrel.=f} below.)

\begin{example}
\label{exa.eqrel.eqrel.eqrel-continents}Let $S$ be the set of all points on
the landmass of the Earth, and let $\sim$ be the relation on $S$ defined by%
\[
\left(  a\sim b\right)  \Longleftrightarrow\left(  \text{there is a land route
from }a\text{ to }b\right)  .
\]
This $\sim$ is an equivalence relation (with the caveat that $S$ is not a
mathematical object and thus not really well-defined).
\end{example}

\begin{example}
\label{exa.eqrel.eqrel.eqrelQ}Let
\[
S=\mathbb{Z}\times\left(  \mathbb{Z}\setminus\left\{  0\right\}  \right)
=\left\{  \left(  a_{1},a_{2}\right)  \ \mid\ a_{1}\in\mathbb{Z}\text{ and
}a_{2}\in\mathbb{Z}\setminus\left\{  0\right\}  \right\}  .
\]
This is the set of all pairs whose first entry is an integer and whose second
entry is a nonzero integer. We define a relation $\underset{\ast}{\sim}$ on
$S$ by%
\[
\left(  \left(  a_{1},a_{2}\right)  \underset{\ast}{\sim}\left(  b_{1}%
,b_{2}\right)  \right)  \ \Longleftrightarrow\ \left(  a_{1}b_{2}=a_{2}%
b_{1}\right)  .
\]
This relation $\underset{\ast}{\sim}$ is an equivalence relation.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.eqrel.eqrel.eqrelQ}.]Indeed:

\begin{itemize}
\item The relation $\underset{\ast}{\sim}$ is reflexive.

\begin{fineprint}
[\textit{Proof:} Let $a\in S$. Thus, $a\in S=\mathbb{Z}\times\left(
\mathbb{Z}\setminus\left\{  0\right\}  \right)  $; in other words, we can
write $a$ as $a=\left(  a_{1},a_{2}\right)  $ for some $a_{1}\in\mathbb{Z}$
and $a_{2}\in\mathbb{Z}\setminus\left\{  0\right\}  $. Consider these $a_{1}$
and $a_{2}$.

Clearly, $a_{1}a_{2}=a_{2}a_{1}$. In other words, $\left(  a_{1},a_{2}\right)
\underset{\ast}{\sim}\left(  a_{1},a_{2}\right)  $ (because the definition of
the relation $\underset{\ast}{\sim}$ yields that $\left(  a_{1},a_{2}\right)
\underset{\ast}{\sim}\left(  a_{1},a_{2}\right)  $ means $a_{1}a_{2}%
=a_{2}a_{1}$). In other words, $a\underset{\ast}{\sim}a$ (since $a=\left(
a_{1},a_{2}\right)  $).

Now, forget that we fixed $a$. We thus have shown that every $a\in S$
satisfies $a\underset{\ast}{\sim}a$. In other words, the relation
$\underset{\ast}{\sim}$ is reflexive.]
\end{fineprint}

\item The relation $\underset{\ast}{\sim}$ is symmetric.

\begin{fineprint}
[\textit{Proof:} Let $a,b\in S$ be such that $a\underset{\ast}{\sim}b$. We
shall prove that $b\underset{\ast}{\sim}a$.

We have $a\in S=\mathbb{Z}\times\left(  \mathbb{Z}\setminus\left\{  0\right\}
\right)  $; in other words, we can write $a$ as $a=\left(  a_{1},a_{2}\right)
$ for some $a_{1}\in\mathbb{Z}$ and $a_{2}\in\mathbb{Z}\setminus\left\{
0\right\}  $. Similarly, we can write $b$ as $b=\left(  b_{1},b_{2}\right)  $
for some $b_{1}\in\mathbb{Z}$ and $b_{2}\in\mathbb{Z}\setminus\left\{
0\right\}  $. Consider these $a_{1}$, $a_{2}$, $b_{1}$ and $b_{2}$.

We have assumed that $a\underset{\ast}{\sim}b$. In other words, $\left(
a_{1},a_{2}\right)  \underset{\ast}{\sim}\left(  b_{1},b_{2}\right)  $ (since
$a=\left(  a_{1},a_{2}\right)  $ and $b=\left(  b_{1},b_{2}\right)  $). In
other words, $a_{1}b_{2}=a_{2}b_{1}$ (because this is what $\left(
a_{1},a_{2}\right)  \underset{\ast}{\sim}\left(  b_{1},b_{2}\right)  $ means,
by the definition of the relation $\underset{\ast}{\sim}$). Thus, $b_{2}%
a_{1}=a_{1}b_{2}=a_{2}b_{1}=b_{1}a_{2}$; in other words, $b_{1}a_{2}%
=b_{2}a_{1}$. In other words, $\left(  b_{1},b_{2}\right)  \underset{\ast
}{\sim}\left(  a_{1},a_{2}\right)  $ (by the definition of the relation
$\underset{\ast}{\sim}$). In other words, $b\underset{\ast}{\sim}a$ (since
$a=\left(  a_{1},a_{2}\right)  $ and $b=\left(  b_{1},b_{2}\right)  $).

Now, forget that we fixed $a$ and $b$. We thus have shown that every $a,b\in
S$ satisfying $a\underset{\ast}{\sim}b$ satisfy $b\underset{\ast}{\sim}a$. In
other words, the relation $\underset{\ast}{\sim}$ is symmetric.]
\end{fineprint}

\item The relation $\underset{\ast}{\sim}$ is transitive.

\begin{fineprint}
[\textit{Proof:} Let $a,b,c\in S$ be such that $a\underset{\ast}{\sim}b$ and
$b\underset{\ast}{\sim}c$. We shall prove that $a\underset{\ast}{\sim}c$.

We have $a\in S=\mathbb{Z}\times\left(  \mathbb{Z}\setminus\left\{  0\right\}
\right)  $; in other words, we can write $a$ as $a=\left(  a_{1},a_{2}\right)
$ for some $a_{1}\in\mathbb{Z}$ and $a_{2}\in\mathbb{Z}\setminus\left\{
0\right\}  $. Similarly, we can write $b$ as $b=\left(  b_{1},b_{2}\right)  $
for some $b_{1}\in\mathbb{Z}$ and $b_{2}\in\mathbb{Z}\setminus\left\{
0\right\}  $. Similarly, we can write $c$ as $c=\left(  c_{1},c_{2}\right)  $
for some $c_{1}\in\mathbb{Z}$ and $c_{2}\in\mathbb{Z}\setminus\left\{
0\right\}  $. Consider these $a_{1}$, $a_{2}$, $b_{1}$, $b_{2}$, $c_{1}$ and
$c_{2}$. Note that $b_{2}\in\mathbb{Z}\setminus\left\{  0\right\}  $, so that
$b_{2}\neq0$.

We have assumed that $a\underset{\ast}{\sim}b$. In other words, $\left(
a_{1},a_{2}\right)  \underset{\ast}{\sim}\left(  b_{1},b_{2}\right)  $ (since
$a=\left(  a_{1},a_{2}\right)  $ and $b=\left(  b_{1},b_{2}\right)  $). In
other words, $a_{1}b_{2}=a_{2}b_{1}$ (by the definition of the relation
$\underset{\ast}{\sim}$). Similarly (by exploiting the assumption
$b\underset{\ast}{\sim}c$ instead of $a\underset{\ast}{\sim}b$), we can obtain
$b_{1}c_{2}=b_{2}c_{1}$. Hence,%
\[
\underbrace{a_{1}b_{2}}_{=a_{2}b_{1}}c_{2}=a_{2}\underbrace{b_{1}c_{2}%
}_{=b_{2}c_{1}}=a_{2}b_{2}c_{1}.
\]
We can cancel $b_{2}$ from this equality (since $b_{2}\neq0$), and thus obtain
$a_{1}c_{2}=a_{2}c_{1}$. In other words, $\left(  a_{1},a_{2}\right)
\underset{\ast}{\sim}\left(  c_{1},c_{2}\right)  $ (by the definition of the
relation $\underset{\ast}{\sim}$). In other words, $a\underset{\ast}{\sim}c$
(since $a=\left(  a_{1},a_{2}\right)  $ and $c=\left(  c_{1},c_{2}\right)  $).

Now, forget that we fixed $a,b,c$. We thus have shown that every $a,b,c\in S$
satisfying $a\underset{\ast}{\sim}b$ and $b\underset{\ast}{\sim}c$ satisfy
$a\underset{\ast}{\sim}c$. In other words, the relation $\underset{\ast}{\sim
}$ is transitive.]
\end{fineprint}
\end{itemize}

\noindent We have now proven that the relation $\underset{\ast}{\sim}$ is
reflexive, symmetric and transitive. In other words, $\underset{\ast}{\sim}$
is an equivalence relation (by the definition of \textquotedblleft equivalence
relation\textquotedblright). This proves Example \ref{exa.eqrel.eqrel.eqrelQ}.
\end{proof}

The relation $\underset{\ast}{\sim}$ from Example \ref{exa.eqrel.eqrel.eqrelQ}
may appear familiar to you. In fact, its definition can be restated as
follows:%
\[
\left(  \left(  a_{1},a_{2}\right)  \underset{\ast}{\sim}\left(  b_{1}%
,b_{2}\right)  \right)  \ \Longleftrightarrow\ \left(  \dfrac{a_{1}}{a_{2}%
}=\dfrac{b_{1}}{b_{2}}\right)  ,
\]
and this makes the claims of Example \ref{exa.eqrel.eqrel.eqrelQ} a lot more
obvious. However, this is (in a sense) circular reasoning: The statement
\textquotedblleft$\dfrac{a_{1}}{a_{2}}=\dfrac{b_{1}}{b_{2}}$\textquotedblright%
\ only makes sense if the rational numbers have been defined\footnote{since
$\dfrac{a_{1}}{a_{2}}$ and $\dfrac{b_{1}}{b_{2}}$ are (in general) not
integers but rational numbers}, but the definition of rational numbers (at
least the usual definition, given in \cite[\S 3.6]{Swanso18} and in many other
places) already relies on the claims of Example \ref{exa.eqrel.eqrel.eqrelQ}.
(Namely, the rational numbers are defined as the equivalence classes of the
relation $\underset{\ast}{\sim}$; this is explained in Example
\ref{exa.eqrel.eqcl.rat} below.) Thus, our above proof of Example
\ref{exa.eqrel.eqrel.eqrelQ} was not a waste of time, but rather an important
prerequisite for the construction of rational numbers (one of the cornerstones
of mathematics).

If you are familiar with basic linear algebra, you may notice that the
relation $\underset{\ast}{\sim}$ from Example \ref{exa.eqrel.eqrel.eqrelQ} can
also be regarded as linear dependence. Namely, two pairs $\left(  a_{1}%
,a_{2}\right)  $ and $\left(  b_{1},b_{2}\right)  $ in $\mathbb{Z}%
\times\left(  \mathbb{Z}\setminus\left\{  0\right\}  \right)  $ satisfy
$\left(  a_{1},a_{2}\right)  \underset{\ast}{\sim}\left(  b_{1},b_{2}\right)
$ if and only if the vectors $\left(  a_{1},a_{2}\right)  $ and $\left(
b_{1},b_{2}\right)  $ in $\mathbb{Q}^{2}$ are linearly
dependent.\footnote{Note, however, that linear dependence is no longer an
equivalence relation if we allow the vector $\left(  0,0\right)  $ in our set
$S$, because then, it is no longer transitive (for example, $\left(
1,1\right)  $ and $\left(  0,0\right)  $ are linearly dependent, and $\left(
0,0\right)  $ and $\left(  1,2\right)  $ are linearly dependent, but $\left(
1,1\right)  $ and $\left(  1,2\right)  $ are not).}

One simple property of symmetric relations will come useful:

\begin{proposition}
\label{prop.eqrel.rel.symm-ba}Let $\sim$ be a symmetric relation on a set $S$.
Let $a,b\in S$. Then, $a\sim b$ if and only if $b\sim a$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.rel.symm-ba}.]The relation $\sim$ is
symmetric. Thus, if $a$ and $b$ satisfy $a\sim b$, then they also satisfy
$b\sim a$ (by the definition of \textquotedblleft symmetric\textquotedblright%
). In other words, we have the logical implication $\left(  a\sim b\right)
\Longrightarrow\left(  b\sim a\right)  $. But the same argument (with the
roles of $a$ and $b$ interchanged) yields the implication $\left(  b\sim
a\right)  \Longrightarrow\left(  a\sim b\right)  $. Combining these two
implications, we obtain the equivalence $\left(  a\sim b\right)
\Longleftrightarrow\left(  b\sim a\right)  $. This proves Proposition
\ref{prop.eqrel.rel.symm-ba}.
\end{proof}

\subsection{Equivalence classes}

\subsubsection{Definition of equivalence classes}

We can now state one of the most important definitions in mathematics:

\begin{definition}
\label{def.eqrel.eqcl.eqcl}Let $\sim$ be an equivalence relation on a set $S$.

\textbf{(a)} For each $a\in S$, we define a subset $\left[  a\right]  _{\sim}$
of $S$ by%
\begin{equation}
\left[  a\right]  _{\sim}=\left\{  b\in S\ \mid\ b\sim a\right\}  .
\label{eq.def.eqrel.eqcl.eqcl.a.eq}%
\end{equation}
This subset $\left[  a\right]  _{\sim}$ is called the \textit{equivalence
class} of $a$, or the $\sim$\textit{-equivalence class} of $a$.

\textbf{(b)} The \textit{equivalence classes} of $\sim$ are defined to be the
sets $\left[  a\right]  _{\sim}$ for $a\in S$. They are also known as the
$\sim$\textit{-equivalence classes}.
\end{definition}

\begin{example}
\label{exa.eqrel.eqcl.mod3}Consider the relation $\underset{3}{\equiv}$ on
$\mathbb{Z}$ (defined in Example \ref{exa.eqrel.rel.rels1} \textbf{(e)}). We
have%
\begin{align*}
\left[  5\right]  _{\underset{3}{\equiv}}  &  =\left\{  b\in\mathbb{Z}%
\ \mid\ b\underset{3}{\equiv}5\right\}  =\left\{  b\in\mathbb{Z}%
\ \mid\ b\equiv5\operatorname{mod}3\right\} \\
&  =\left\{  \ldots,-4,-1,2,5,8,11,14,\ldots\right\}
\end{align*}
and%
\begin{align*}
\left[  3\right]  _{\underset{3}{\equiv}}  &  =\left\{  b\in\mathbb{Z}%
\ \mid\ b\underset{3}{\equiv}3\right\}  =\left\{  b\in\mathbb{Z}%
\ \mid\ b\equiv3\operatorname{mod}3\right\} \\
&  =\left\{  \ldots,-6,-3,0,3,6,9,12,\ldots\right\}
\end{align*}
and%
\begin{align*}
\left[  2\right]  _{\underset{3}{\equiv}}  &  =\left\{  b\in\mathbb{Z}%
\ \mid\ b\underset{3}{\equiv}2\right\}  =\left\{  b\in\mathbb{Z}%
\ \mid\ b\equiv2\operatorname{mod}3\right\} \\
&  =\left\{  \ldots,-4,-1,2,5,8,11,14,\ldots\right\}  .
\end{align*}
Note that $\left[  5\right]  _{\underset{3}{\equiv}}=\left[  2\right]
_{\underset{3}{\equiv}}$, as you can easily see.
\end{example}

\begin{teachingnote}
Add a simple example here: e.g., the set $\left\{  -3,\ldots,5\right\}  $ with
the \textquotedblleft$\left\vert a\right\vert =\left\vert b\right\vert
$\textquotedblright\ equivalence. Visualize with a \textquotedblleft blob
picture\textquotedblright\ (can probably repurpose the one I gave on a
combinatorics homework set).
\end{teachingnote}

\subsubsection{Basic properties}

\begin{proposition}
\label{prop.eqrel.eqcl.ab}Let $\sim$ be an equivalence relation on a set $S$.
Let $a\in S$. Then,%
\[
\left[  a\right]  _{\sim}=\left\{  b\in S\ \mid\ a\sim b\right\}  .
\]

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.eqcl.ab}.]The relation $\sim$ is
symmetric (since it is an equivalence relation). Thus, for any $b\in S$, we
have $\left(  a\sim b\text{ if and only if }b\sim a\right)  $ (by Proposition
\ref{prop.eqrel.rel.symm-ba}). Hence, $\left\{  b\in S\ \mid\ a\sim b\right\}
=\left\{  b\in S\ \mid\ b\sim a\right\}  $. Comparing this with
(\ref{eq.def.eqrel.eqcl.eqcl.a.eq}), we obtain $\left[  a\right]  _{\sim
}=\left\{  b\in S\ \mid\ a\sim b\right\}  $. This proves Proposition
\ref{prop.eqrel.eqcl.ab}.
\end{proof}

Proposition \ref{prop.eqrel.eqcl.ab} shows that we can replace the condition
\textquotedblleft$b\sim a$\textquotedblright\ by \textquotedblleft$a\sim
b$\textquotedblright\ in Definition \ref{def.eqrel.eqcl.eqcl} \textbf{(a)}
without changing the meaning of the definition. (Some authors, such as Swanson
in \cite[Definition 2.3.6]{Swanso18}, do exactly that.)

\begin{proposition}
\label{prop.eqrel.eqcl.aina}Let $\sim$ be an equivalence relation on a set
$S$. Let $a\in S$. Then, $a\in\left[  a\right]  _{\sim}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.eqcl.aina}.]The relation $\sim$ is
reflexive (since it is an equivalence relation). Thus, $a\sim a$. In other
words, $a$ is a $b\in S$ satisfying $b\sim a$. In other words, $a\in\left\{
b\in S\ \mid\ b\sim a\right\}  $. But $\left[  a\right]  _{\sim}=\left\{  b\in
S\ \mid\ b\sim a\right\}  $ (by the definition of $\left[  a\right]  _{\sim}%
$). Hence, $a\in\left\{  b\in S\ \mid\ b\sim a\right\}  =\left[  a\right]
_{\sim}$. This proves Proposition \ref{prop.eqrel.eqcl.aina}.
\end{proof}

Proposition \ref{prop.eqrel.eqcl.aina} shows that all equivalence classes of
an equivalence relation are nonempty sets (because each equivalence class
$\left[  a\right]  _{\sim}$ contains at least the element $a$).

\begin{theorem}
\label{thm.eqrel.eqcl.disj}Let $\sim$ be an equivalence relation on a set $S$.
Let $x,y\in S$.

\textbf{(a)} If $x\sim y$, then $\left[  x\right]  _{\sim}=\left[  y\right]
_{\sim}$.

\textbf{(b)} If not $x\sim y$, then the sets $\left[  x\right]  _{\sim}$ and
$\left[  y\right]  _{\sim}$ are disjoint.

\textbf{(c)} We have $x\sim y$ if and only if $x\in\left[  y\right]  _{\sim}$.

\textbf{(d)} We have $x\sim y$ if and only if $y\in\left[  x\right]  _{\sim}$.

\textbf{(e)} We have $x\sim y$ if and only if $\left[  x\right]  _{\sim
}=\left[  y\right]  _{\sim}$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.eqrel.eqcl.disj}.]The relation $\sim$ is transitive
(since it is an equivalence relation) and symmetric (for the same reason).

The definition of $\left[  x\right]  _{\sim}$ yields $\left[  x\right]
_{\sim}=\left\{  b\in S\ \mid\ b\sim x\right\}  $. Similarly, $\left[
y\right]  _{\sim}=\left\{  b\in S\ \mid\ b\sim y\right\}  $.

\textbf{(a)} Assume that $x\sim y$. Thus, $y\sim x$ (since the relation $\sim$
is symmetric).

Let $c\in\left[  x\right]  _{\sim}$. Thus, $c\in\left[  x\right]  _{\sim
}=\left\{  b\in S\ \mid\ b\sim x\right\}  $. Thus, $c\sim x$. From $c\sim x$
and $x\sim y$, we obtain $c\sim y$ (since the relation $\sim$ is transitive).
Hence, $c\in\left\{  b\in S\ \mid\ b\sim y\right\}  $. In other words,
$c\in\left[  y\right]  _{\sim}$ (since $\left[  y\right]  _{\sim}=\left\{
b\in S\ \mid\ b\sim y\right\}  $).

Forget that we fixed $c$. We thus have proven that $c\in\left[  y\right]
_{\sim}$ for each $c\in\left[  x\right]  _{\sim}$. Thus, $\left[  x\right]
_{\sim}\subseteq\left[  y\right]  _{\sim}$. The same argument (with $x$ and
$y$ switched) yields $\left[  y\right]  _{\sim}\subseteq\left[  x\right]
_{\sim}$ (since $y\sim x$). Combining $\left[  x\right]  _{\sim}%
\subseteq\left[  y\right]  _{\sim}$ with $\left[  y\right]  _{\sim}%
\subseteq\left[  x\right]  _{\sim}$, we obtain $\left[  x\right]  _{\sim
}=\left[  y\right]  _{\sim}$. This proves Theorem \ref{thm.eqrel.eqcl.disj}
\textbf{(a)}.

\textbf{(b)} Assume that we don't have $x\sim y$. Let $c\in\left[  x\right]
_{\sim}\cap\left[  y\right]  _{\sim}$. We aim for a contradiction.

We have $c\in\left[  x\right]  _{\sim}\cap\left[  y\right]  _{\sim}%
\subseteq\left[  x\right]  _{\sim}=\left\{  b\in S\ \mid\ b\sim x\right\}  $,
so that $c\sim x$. Likewise, $c\sim y$. From $c\sim x$, we obtain $x\sim c$
(since the relation $\sim$ is symmetric). Combining this with $c\sim y$, we
obtain $x\sim y$ (since $\sim$ is transitive). This contradicts our assumption
that we don't have $x\sim y$.

Now, forget that we fixed $c$. So we have found a contradiction for each
$c\in\left[  x\right]  _{\sim}\cap\left[  y\right]  _{\sim}$. Thus, there is
no such $c$. In other words, $\left[  x\right]  _{\sim}\cap\left[  y\right]
_{\sim}=\varnothing$. In other words, the sets $\left[  x\right]  _{\sim}$ and
$\left[  y\right]  _{\sim}$ are disjoint. This proves Theorem
\ref{thm.eqrel.eqcl.disj} \textbf{(b)}.

\textbf{(c)} Recall that $\left[  y\right]  _{\sim}=\left\{  b\in
S\ \mid\ b\sim y\right\}  $. Thus, we have $x\in\left[  y\right]  _{\sim}$ if
and only if $x\sim y$. In other words, we have $x\sim y$ if and only if
$x\in\left[  y\right]  _{\sim}$. This proves Theorem \ref{thm.eqrel.eqcl.disj}
\textbf{(c)}.

\textbf{(d)} Theorem \ref{thm.eqrel.eqcl.disj} \textbf{(c)} (applied to $y$
and $x$ instead of $x$ and $y$) shows that we have $y\sim x$ if and only if
$y\in\left[  x\right]  _{\sim}$. In other words, we have the logical
equivalence $\left(  y\sim x\right)  \Longleftrightarrow\left(  y\in\left[
x\right]  _{\sim}\right)  $.

Proposition \ref{prop.eqrel.rel.symm-ba} (applied to $a=x$ and $b=y$) shows
that we have $x\sim y$ if and only if $y\sim x$. Thus, we have the following
chain of logical equivalences:
\[
\left(  x\sim y\right)  \Longleftrightarrow\left(  y\sim x\right)
\Longleftrightarrow\left(  y\in\left[  x\right]  _{\sim}\right)  .
\]
In other words, we have $x\sim y$ if and only if $y\in\left[  x\right]
_{\sim}$. This proves Theorem \ref{thm.eqrel.eqcl.disj} \textbf{(d)}.

\textbf{(e)} $\Longrightarrow:$ Assume that $x\sim y$. Then, Theorem
\ref{thm.eqrel.eqcl.disj} \textbf{(a)} yields $\left[  x\right]  _{\sim
}=\left[  y\right]  _{\sim}$. Thus, the \textquotedblleft$\Longrightarrow
$\textquotedblright\ direction of Theorem \ref{thm.eqrel.eqcl.disj}
\textbf{(e)} is proven.

$\Longleftarrow:$ Assume that $\left[  x\right]  _{\sim}=\left[  y\right]
_{\sim}$. Then, Proposition \ref{prop.eqrel.eqcl.aina} (applied to $a=x$)
yields $x\in\left[  x\right]  _{\sim}=\left[  y\right]  _{\sim}=\left\{  b\in
S\ \mid\ b\sim y\right\}  $. In other words, $x\sim y$. This proves the
\textquotedblleft$\Longleftarrow$\textquotedblright\ direction of Theorem
\ref{thm.eqrel.eqcl.disj} \textbf{(e)}.
\end{proof}

Theorem \ref{thm.eqrel.eqcl.disj} yields an important property of equivalence classes:

\begin{exercise}
\label{exe.eqrel.eqcl.dj}Let $\sim$ be an equivalence relation on a set $S$.
Prove that any two equivalence classes of $\sim$ are either identical or disjoint.
\end{exercise}

In the following, we will try to use Greek letters for equivalence classes and
Roman letters for their representatives (as we did in the solution to Exercise
\ref{exe.eqrel.eqcl.dj} above).

\begin{center}
\textbf{2019-02-22 lecture}
\end{center}

\subsubsection{More examples}

\begin{example}
\label{exa.eqrel.eqcl.rat}Consider the relation $\underset{\ast}{\sim}$ on
$S=\mathbb{Z}\times\left(  \mathbb{Z}\setminus\left\{  0\right\}  \right)  $
defined in Example \ref{exa.eqrel.eqrel.eqrelQ}. Its equivalence classes are
the rational numbers. Indeed, the equivalence class $\left[  \left(
a_{1},a_{2}\right)  \right]  _{\underset{\ast}{\sim}}$ of a pair $\left(
a_{1},a_{2}\right)  \in S$ is commonly denoted by $\dfrac{a_{1}}{a_{2}}$ (or
by $a_{1}/a_{2}$). This is how rational numbers are defined!
\end{example}

Equivalence classes appear in real life too, at least in the modern world.
When you say that the sun rises approximately at 7 AM in\ February\footnote{in
Minneapolis}, what do \textquotedblleft7 AM\textquotedblright\ and
\textquotedblleft February\textquotedblright\ mean? Clearly, \textquotedblleft
February\textquotedblright\ is not a specific month in history, since each
year has its own February. Rather, it stands for an equivalence class of
months, with respect to the relation of \textquotedblleft being an integer
number of years apart\textquotedblright. Similarly, \textquotedblleft7
AM\textquotedblright\ means an equivalence class of moments with respect to
the relation of \textquotedblleft being an integer number of days
apart\textquotedblright. Likewise, \textquotedblleft the
horse\textquotedblright\ in \textquotedblleft the horse has a lifespan of 25
years\textquotedblright\ refers not to a specific horse, but to the whole
species, which is an equivalence class of creatures with respect to a certain
relation\footnote{According to Darwin, the relation is \textquotedblleft being
able to procreate\textquotedblright\ -- although this is not per se an
equivalence relation, so some tweaks need to be made (\textquotedblleft
reflexive-and-transitive closure\textquotedblright) to turn it into one.}.
Finally, the equivalence classes of the relation $\sim$ in Example
\ref{exa.eqrel.eqrel.eqrel-continents} are commonly referred to as
\textquotedblleft continents\textquotedblright\footnote{at least if one
considers Eurasia to be a single continent} or \textquotedblleft
islands\textquotedblright. Equivalence classes provide a way to refer to
multiple objects (usually similar in some way) as if they were one.

\subsubsection{The \textquotedblleft is a permutation of\textquotedblright%
\ relation on tuples}

Let us give a few more mathematical examples for equivalences and equivalence classes:

\begin{definition}
\label{def.eqrel.eqcl.perm}Let $A$ be a set, and let $k\in\mathbb{N}$. As we
know, $A^{k}$ denotes the set of all $k$-tuples of elements of $A$.

The relation $\underset{\operatorname*{perm}}{\sim}$ on $A^{k}$ is defined as
follows:%
\[
\left(  \mathbf{p}\underset{\operatorname*{perm}}{\sim}\mathbf{q}\right)
\Longleftrightarrow\left(  \mathbf{p}\text{ is a permutation of }%
\mathbf{q}\right)  .
\]
(We are using Definition \ref{def.comb.tuples.perm-tup} here.) For example,
$\left(  3,8,8,2\right)  \underset{\operatorname*{perm}}{\sim}\left(
8,3,2,8\right)  $.
\end{definition}

\begin{exercise}
\label{exe.eqrel.eqcl.perm.eq}Prove that the relation
$\underset{\operatorname*{perm}}{\sim}$ is an equivalence relation.
\end{exercise}

\begin{definition}
\label{def.eqrel.eqcl.perm.unord-tup}Let $A$ be a set, and let $k\in
\mathbb{N}$. The relation $\underset{\operatorname*{perm}}{\sim}$ on $A^{k}$
is an equivalence relation (by Exercise \ref{exe.eqrel.eqcl.perm.eq}). Its
equivalence classes are called the \textit{unordered }$k$\textit{-tuples} of
elements of $A$. For example, for $k=2$ and $A=\mathbb{Z}$, the two $2$-tuples
$\left(  6,8\right)  $ and $\left(  8,6\right)  $ are permutations of each
other, so $\left(  6,8\right)  \underset{\operatorname*{perm}}{\sim}\left(
8,6\right)  $ and thus $\left[  \left(  6,8\right)  \right]
_{\underset{\operatorname*{perm}}{\sim}}=\left[  \left(  8,6\right)  \right]
_{\underset{\operatorname*{perm}}{\sim}}$.
\end{definition}

\subsubsection{The \textquotedblleft is a cyclic rotation of\textquotedblright%
\ relation on tuples}

Another example of an equivalence relation is the following:

\begin{definition}
\label{def.eqrel.eqcl.cyc}Again, let $A$ be a set and $k\in\mathbb{N}$. If
$\mathbf{a}=\left(  a_{1},a_{2},\ldots,a_{k}\right)  \in A^{k}$, then a
\textit{cyclic rotation} of $\mathbf{a}$ means a $k$-tuple of the form%
\[
\left(  a_{i+1},a_{i+2},\ldots,a_{k},a_{1},a_{2},\ldots,a_{i}\right)  \in
A^{k}%
\]
for some $i\in\left\{  0,1,\ldots,k\right\}  $.

For example, the cyclic rotations of the $3$-tuple $\left(  1,4,5\right)  $
are $\left(  1,4,5\right)  $, $\left(  4,5,1\right)  $ and $\left(
5,1,4\right)  $.

(Here is an equivalent description of cyclic rotations: Let $C$ be the map
$A^{k}\rightarrow A^{k}$ that sends each $k$-tuple $\left(  a_{1},a_{2}%
,\ldots,a_{k}\right)  $ to $\left(  a_{2},a_{3},\ldots,a_{k},a_{1}\right)  $.
Then, it is easy to see that a cyclic rotation of $\mathbf{a}$ is the same as
a $k$-tuple of the form $C^{i}\left(  \mathbf{a}\right)  $ for some
$i\in\left\{  0,1,\ldots,k\right\}  $. But it is also easy to see that
$C^{k}=\operatorname*{id}$. Thus, the $C^{i}\left(  \mathbf{a}\right)  $ for
$i\in\left\{  0,1,\ldots,k\right\}  $ are exactly the $C^{i}\left(
\mathbf{a}\right)  $ for $i\in\mathbb{N}$.)

The relation $\underset{\operatorname*{cyc}}{\sim}$ on $A^{k}$ is defined as
follows:%
\begin{align*}
\left(  \mathbf{p}\underset{\operatorname*{cyc}}{\sim}\mathbf{q}\right)   &
\Longleftrightarrow\ \left(  \mathbf{p}\text{ is a cyclic rotation of
}\mathbf{q}\right) \\
&  \Longleftrightarrow\ \left(  \mathbf{p}=C^{i}\left(  \mathbf{q}\right)
\text{ for some }i\in\mathbb{N}\right)  .
\end{align*}


This relation $\underset{\operatorname*{cyc}}{\sim}$ is an equivalence
relation. Its equivalence classes are called \textit{necklaces} of length $k$
over $A$.
\end{definition}

We shall not prove the statements claimed in this definition, since they are
particular cases of more general results that will be proven below (about
groups acting on sets).

For example, the necklaces of length $3$ over the set $A=\left\{  1,2\right\}
$ are%
\begin{align*}
\left[  \left(  1,1,1\right)  \right]  _{\underset{\operatorname*{cyc}}{\sim
}}  &  =\left\{  \left(  1,1,1\right)  \right\}  ,\\
\left[  \left(  1,1,2\right)  \right]  _{\underset{\operatorname*{cyc}}{\sim
}}  &  =\left\{  \left(  1,1,2\right)  ,\left(  1,2,1\right)  ,\left(
2,1,1\right)  \right\}  ,\\
\left[  \left(  1,2,2\right)  \right]  _{\underset{\operatorname*{cyc}}{\sim
}}  &  =\left\{  \left(  1,2,2\right)  ,\left(  2,2,1\right)  ,\left(
2,1,2\right)  \right\}  ,\\
\left[  \left(  2,2,2\right)  \right]  _{\underset{\operatorname*{cyc}}{\sim
}}  &  =\left\{  \left(  2,2,2\right)  \right\}  .
\end{align*}
This may suggest that a necklace $\left[  \left(  a_{1},a_{2},\ldots
,a_{k}\right)  \right]  _{\underset{\operatorname*{cyc}}{\sim}}$ is uniquely
determined by how often each element appears in the tuple $\left(  a_{1}%
,a_{2},\ldots,a_{k}\right)  $. But this is not true in general; for example,
if $A=\left\{  1,2,3\right\}  $, then%
\begin{align*}
\left[  \left(  1,2,3\right)  \right]  _{\underset{\operatorname*{cyc}}{\sim
}}  &  =\left\{  \left(  1,2,3\right)  ,\left(  2,3,1\right)  ,\left(
3,1,2\right)  \right\}  \ \ \ \ \ \ \ \ \ \ \text{and}\\
\left[  \left(  1,3,2\right)  \right]  _{\underset{\operatorname*{cyc}}{\sim
}}  &  =\left\{  \left(  1,3,2\right)  ,\left(  3,2,1\right)  ,\left(
2,1,3\right)  \right\}
\end{align*}
are two different necklaces of length $3$ over the set $A=\left\{
1,2,3\right\}  $.

How many necklaces of length $k$ over a $q$-element set $A$ exist? It turns
out that there is a nice formula for this, involving Euler's totient function
$\phi$:

\begin{theorem}
\label{thm.eqrel.eqcl.necklace-count}Let $k$ be a positive integer. Let $A$ be
a $q$-element set (where $q\in\mathbb{N}$). Then, the number of necklaces of
length $k$ over the set $A$ is%
\[
\dfrac{1}{k}\sum_{d\mid k}\phi\left(  d\right)  q^{k/d}.
\]

\end{theorem}

Note that it is not (a priori) clear that $\dfrac{1}{k}\sum_{d\mid k}%
\phi\left(  d\right)  q^{k/d}$ is an integer! Actually, this holds even when
$q$ is a negative integer, even though there exist no $q$-element sets in that
case. Thus, $\dfrac{1}{k}\sum_{d\mid k}\phi\left(  d\right)  x^{k/d}$ is
another integer-valued polynomial for each positive integer $k$.

We will prove Theorem \ref{thm.eqrel.eqcl.necklace-count} using the concept of
group actions further below.

\subsubsection{Definition of the quotient set and the projection map}

\begin{definition}
\label{def.eqrel.eqcl.proj}Let $S$ be a set, and let $\sim$ be an equivalence
relation on $S$.

\textbf{(a)} The set of equivalence classes of $\sim$ is denoted by $S/\sim$.
It is called the \textit{quotient} (or \textit{quotient set}) of $S$ by $\sim$.

\textbf{(b)} The map%
\begin{align*}
S  &  \rightarrow\left.  S/\sim\right.  ,\\
s  &  \mapsto\left[  s\right]  _{\sim}%
\end{align*}
(which sends each element $s\in S$ to its equivalence class) is called the
\textit{canonical projection (onto the quotient)}, and we will denote it by
$\pi_{\sim}$.

\textbf{(c)} An element of an equivalence class of $\sim$ is also called a
\textit{representative} of this class.
\end{definition}

\begin{exercise}
\label{exe.eqrel.eqrel.=f}Let $S$ be a set.

Recall that if $T$ is a further set, and if $f:S\rightarrow T$ is a map, then
an equivalence relation $\underset{f}{\equiv}$ is defined on the set $S$. (See
Example \ref{exa.eqrel.eqrel.eqrelf} for its definition.)

Now, let $\sim$ be \textbf{any} equivalence relation on $S$. Prove that $\sim$
has the form $\underset{f}{\equiv}$ for a properly chosen set $T$ and a
properly chosen $f:S\rightarrow T$.

More precisely, prove that $\sim$ equals $\underset{f}{\equiv}$, where $T$ is
the quotient set $S/\sim$ and where $f:S\rightarrow T$ is the canonical
projection $\pi_{\sim}:S\rightarrow S/\sim$.

[\textbf{Hint:} To prove that two relations $R_{1}$ and $R_{2}$ on $S$ are
equal, you need to check that every pair $\left(  a,b\right)  $ of elements of
$S$ satisfies the equivalence $\left(  aR_{1}b\right)  \iff\left(
aR_{2}b\right)  $.]
\end{exercise}

\subsection{\label{sect.eqrel.Z/n}$\mathbb{Z}/n$ (\textquotedblleft integers
modulo $n$\textquotedblright)}

We now come to one of the most important example of equivalence classes: the
residue classes of integers modulo a given positive integer $n$.

\begin{convention}
For the whole Section \ref{sect.eqrel.Z/n}, we fix an integer $n$.
\end{convention}

\subsubsection{Definition of $\mathbb{Z}/n$}

\begin{definition}
\label{def.eqrel.Z/n.res-class}\textbf{(a)} Define a relation
$\underset{n}{\equiv}$ on the set $\mathbb{Z}$ by
\[
\left(  a\underset{n}{\equiv}b\right)  \Longleftrightarrow\left(  a\equiv
b\operatorname{mod}n\right)  .
\]
(This is precisely the relation $\underset{n}{\equiv}$ from Example
\ref{exa.eqrel.rel.rels1} \textbf{(e)}.)

Recall that $\underset{n}{\equiv}$ is an equivalence relation (by Example
\ref{exa.eqrel.eqrel.eqrelmodn}).

\textbf{(b)} A \textit{residue class modulo}\textbf{ }$n$ means an equivalence
class of the relation $\underset{n}{\equiv}$.
\end{definition}

For example,%
\begin{align*}
\left[  0\right]  _{\underset{5}{\equiv}}  &  =\left\{  \ldots
,-15,-10,-5,0,5,10,15,20,\ldots\right\}  ,\\
\left[  1\right]  _{\underset{5}{\equiv}}  &  =\left\{  \ldots
,-14,-9,-4,1,6,11,16,21,\ldots\right\}  ,\\
\left[  2\right]  _{\underset{5}{\equiv}}  &  =\left\{  \ldots
,-13,-8,-3,2,7,12,17,22,\ldots\right\}  ,\\
\left[  3\right]  _{\underset{5}{\equiv}}  &  =\left\{  \ldots
,-12,-7,-2,3,8,13,18,23,\ldots\right\}  ,\\
\left[  4\right]  _{\underset{5}{\equiv}}  &  =\left\{  \ldots
,-11,-6,-1,4,9,14,19,24,\ldots\right\}
\end{align*}
are all the residue classes modulo $5$. As you see, these classes are in
1-to-1 correspondence with the $5$ possible remainders $0,1,2,3,4$ modulo $5$.
This generalizes (see Theorem \ref{thm.eqrel.Z/n.explicit} below). First, let
us introduce a few notations:

\begin{definition}
\label{def.eqrel.Z/n.Z/n}\textbf{(a)} If $i$ is an integer, then we denote the
residue class $\left[  i\right]  _{\underset{n}{\equiv}}$ by $\left[
i\right]  _{n}$. (Some authors denote this residue class by $\overline{i}_{n}$
or $i\operatorname{mod}n$. Be careful with the notation $i\operatorname{mod}%
n$, since other authors use it for the integer $i\%n$ when $n$ is positive.)

\textbf{(b)} The set $\mathbb{Z}/\underset{n}{\equiv}$ of residue classes
modulo $n$ is called $\mathbb{Z}/n$. (Some authors call it $\mathbb{Z}/\left(
n\right)  $ or $\mathbb{Z}/n\mathbb{Z}$ or $\mathbb{Z}_{n}$. Be careful with
the notation $\mathbb{Z}_{n}$, since it has a different meaning, too.)
\end{definition}

\subsubsection{What $\mathbb{Z}/n$ looks like}

Let us now state and rigorously prove what we have just observed on the
example of $n=5$:

\begin{theorem}
\label{thm.eqrel.Z/n.explicit}Assume that the integer $n$ is positive.

The set $\mathbb{Z}/n$ has exactly $n$ elements, namely $\left[  0\right]
_{n},\left[  1\right]  _{n},\ldots,\left[  n-1\right]  _{n}$. (In particular,
these elements $\left[  0\right]  _{n},\left[  1\right]  _{n},\ldots,\left[
n-1\right]  _{n}$ are distinct.)
\end{theorem}

Before we prove this, let us make a simple observation:

\begin{proposition}
\label{prop.eqrel.Z/n.ab}\textbf{(a)} Each element of $\mathbb{Z}/n$ can be
written in the form $\left[  s\right]  _{n}$ for some integer $s$.

\textbf{(b)} Let $a$ and $b$ be integers. Then, we have $\left[  a\right]
_{n}=\left[  b\right]  _{n}$ if and only if $a\equiv b\operatorname{mod}n$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.Z/n.ab}.]\textbf{(a)} If $\sigma
\in\mathbb{Z}/n$, then $\sigma$ is a residue class modulo $n$ (by the
definition of $\mathbb{Z}/n$), and thus is an equivalence class of the
relation $\underset{n}{\equiv}$ (by the definition of a residue class). Hence,
this $\sigma$ can be written in the form $\left[  s\right]
_{\underset{n}{\equiv}}$ for some integer $s$. In other words, this $\sigma$
can be written in the form $\left[  s\right]  _{n}$ for some integer $s$
(since we have defined $\left[  s\right]  _{n}$ to be a shorthand for $\left[
s\right]  _{\underset{n}{\equiv}}$). In other words, each element of
$\mathbb{Z}/n$ can be written in the form $\left[  s\right]  _{n}$ for some
integer $s$. This proves Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(a)}.

\textbf{(b)} Theorem \ref{thm.eqrel.eqcl.disj} \textbf{(e)} (applied to
$\mathbb{Z}$, $\underset{n}{\equiv}$, $a$ and $b$ instead of $S$, $\sim$, $x$
and $y$) shows that we have $a\underset{n}{\equiv}b$ if and only if $\left[
a\right]  _{\underset{n}{\equiv}}=\left[  b\right]  _{\underset{n}{\equiv}}$.
Thus, we have the logical equivalence
\begin{equation}
\left(  a\underset{n}{\equiv}b\right)  \ \Longleftrightarrow\ \left(  \left[
a\right]  _{\underset{n}{\equiv}}=\left[  b\right]  _{\underset{n}{\equiv}%
}\right)  . \label{pf.prop.eqrel.Z/n.ab.1}%
\end{equation}


Definition \ref{def.eqrel.Z/n.Z/n} \textbf{(a)} shows that $\left[  a\right]
_{n}=\left[  a\right]  _{\underset{n}{\equiv}}$ and $\left[  b\right]
_{n}=\left[  b\right]  _{\underset{n}{\equiv}}$. Hence, we have the following
chain of logical equivalences:
\begin{align*}
\left(  \left[  a\right]  _{n}=\left[  b\right]  _{n}\right)  \  &
\Longleftrightarrow\ \left(  \left[  a\right]  _{\underset{n}{\equiv}}=\left[
b\right]  _{\underset{n}{\equiv}}\right)  \ \Longleftrightarrow\ \left(
a\underset{n}{\equiv}b\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.prop.eqrel.Z/n.ab.1})}\right) \\
&  \Longleftrightarrow\ \left(  a\equiv b\operatorname{mod}n\right)
\end{align*}
(by the definition of the relation $\underset{n}{\equiv}$). In other words, we
have $\left[  a\right]  _{n}=\left[  b\right]  _{n}$ if and only if $a\equiv
b\operatorname{mod}n$. This proves Proposition \ref{prop.eqrel.Z/n.ab}
\textbf{(b)}.
\end{proof}

\begin{proof}
[Proof of Theorem \ref{thm.eqrel.Z/n.explicit}.]We have a map%
\begin{align*}
\pi_{\underset{n}{\equiv}}:\mathbb{Z}  &  \rightarrow\mathbb{Z}/n,\\
s  &  \mapsto\left[  s\right]  _{n}.
\end{align*}
(This is simply the map $\pi_{\sim}$ defined in Definition
\ref{def.eqrel.eqcl.proj} \textbf{(b)}, applied to the case when
$S=\mathbb{Z}$ and when $\sim$ is the equivalence relation
$\underset{n}{\equiv}$.)

We restrict this map $\underset{n}{\equiv}$ to the set $\left\{
0,1,\ldots,n-1\right\}  $; we thus obtain a map%
\begin{align*}
P:\left\{  0,1,\ldots,n-1\right\}   &  \rightarrow\mathbb{Z}/n,\\
s  &  \mapsto\left[  s\right]  _{n}.
\end{align*}
Our goal is to prove that this map $P$ is bijective.

In general, there are two ways in which one usually proves that a map is
bijective: One way is to prove that it is surjective and injective; the other
way is by constructing an inverse to this map. Both ways can be used here; let
us follow the second way, since it demonstrates an important point about
equivalence classes.

So we want to construct an inverse to the map $P$. To do so, we try to define
a map%
\begin{align*}
R:\mathbb{Z}/n  &  \rightarrow\left\{  0,1,\ldots,n-1\right\}  ,\\
\left[  s\right]  _{n}  &  \mapsto s\%n
\end{align*}
(that is, a map $R:\mathbb{Z}/n\rightarrow\left\{  0,1,\ldots,n-1\right\}  $
that sends each residue class $\left[  s\right]  _{n}$ to the remainder
$s\%n$). Can we do this? Would this map $R$ be actually well-defined?

First of all, our definition of $R$ does indeed specify a value of $R\left(
\sigma\right)  $ for each $\sigma\in\mathbb{Z}/n$. This is because each
element of $\mathbb{Z}/n$ can be written in the form $\left[  s\right]  _{n}$
for some integer $s$ (because of Proposition \ref{prop.eqrel.Z/n.ab}
\textbf{(a)}), and therefore our definition tells us where this element should
go under $R$.

Furthermore, if $s$ is an integer, then $s\%n\in\left\{  0,1,\ldots
,n-1\right\}  $ (by Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(a)},
applied to $u=s$). Hence, our definition of $R$ does not require the map $R$
to take values lying outside of its target\footnote{This is one way in which
maps can fail to be well-defined. For example, the map
\[
\mathbb{N}\rightarrow\mathbb{N},\ \ \ \ \ \ \ \ \ \ i\mapsto i-1
\]
is not well-defined for this reason (because $i-1\notin\mathbb{N}$ for
$i=0$).}.

However, there is one more thing that could go wrong with our definition of
$R$: One element $\sigma$ of $\mathbb{Z}/n$ can be written as $\left[
s\right]  _{n}$ for several different integers $s$. For instance, $\left[
2\right]  _{5}=\left[  7\right]  _{5}=\left[  12\right]  _{5}=\left[
17\right]  _{5}=\cdots$. If the remainders $s\%n$ of these integers $s$ were
different, then the map $R$ would have to send the class $\sigma$ to several
different numbers, and this is not something a map can do. To see an example
where this does go wrong, let us try to define a map%
\begin{align*}
R_{\operatorname*{wrong}}:\mathbb{Z}/n  &  \rightarrow\left\{  0,1,\ldots
,n-1\right\}  ,\\
\left[  s\right]  _{n}  &  \mapsto s\%\left(  n+1\right)  .
\end{align*}
So this definition of $R_{\operatorname*{wrong}}$ is identical to our
definition of $R$ above, except that we are sending $\left[  s\right]  _{n}$
to $s\%\left(  n+1\right)  $ rather than to $s\%n$. However,
$R_{\operatorname*{wrong}}$ does not actually exist. In fact, if this
ostensible map $R_{\operatorname*{wrong}}$ would exist, then it would have to
send $\left[  0\right]  _{n}$ to $0\%\left(  n+1\right)  =0$ and send $\left[
-n\right]  _{n}$ to $\left(  -n\right)  \%\left(  n+1\right)  =1$%
\ \ \ \ \footnote{The equality $\left(  -n\right)  \%\left(  n+1\right)  =1$
follows from writing $-n$ in the form $-n=\left(  -1\right)  \cdot\left(
n+1\right)  +1$.}; however, $\left[  0\right]  _{n}$ and $\left[  -n\right]
_{n}$ are the same residue class (since $0\equiv-n\operatorname{mod}n$),
whereas $0$ and $1$ are not the same number, and thus this map
$R_{\operatorname*{wrong}}$ would send the same class to two different
numbers. Thus, the map $R_{\operatorname*{wrong}}$ does not exist.

We shall now check that our above definition of $R$ does \textbf{not} suffer
from this problem. In other words, we shall check that in the definition of
\begin{align*}
R:\mathbb{Z}/n  &  \rightarrow\left\{  0,1,\ldots,n-1\right\}  ,\\
\left[  s\right]  _{n}  &  \mapsto s\%n,
\end{align*}
any two possible integers $s$ leading to the same class $\left[  s\right]
_{n}$ also lead to the same remainder $s\%n$. In other words, we shall prove
the following claim:

\begin{statement}
\textit{Claim 1:} If $s_{1}$ and $s_{2}$ are two integers such that $\left[
s_{1}\right]  _{n}=\left[  s_{2}\right]  _{n}$, then $s_{1}\%n=s_{2}\%n$.
\end{statement}

[\textit{Proof of Claim 1:} Let $s_{1}$ and $s_{2}$ be two integers such that
$\left[  s_{1}\right]  _{n}=\left[  s_{2}\right]  _{n}$.

Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $s_{1}$ and
$s_{2}$ instead of $a$ and $b$) shows that we have $\left[  s_{1}\right]
_{n}=\left[  s_{2}\right]  _{n}$ if and only if $s_{1}\equiv s_{2}%
\operatorname{mod}n$. Thus, we have $s_{1}\equiv s_{2}\operatorname{mod}n$
(since $\left[  s_{1}\right]  _{n}=\left[  s_{2}\right]  _{n}$). But Exercise
\ref{exe.ent.quo-rem.mod=rem} (applied to $u=s_{1}$ and $v=s_{2}$) shows that
$s_{1}\equiv s_{2}\operatorname{mod}n$ if and only if $s_{1}\%n=s_{2}\%n$.
Hence, we have $s_{1}\%n=s_{2}\%n$. This proves Claim 1.]

Claim 1 shows that if $s$ is an integer, then $s\%n$ depends only on the
\textbf{residue class} $\left[  s\right]  _{n}$, but not on the actual integer
$s$. Thus, if we have a residue class $\sigma\in\mathbb{Z}/n$, then we can
write $\sigma$ in the form $\sigma=\left[  s\right]  _{n}$ for some integer
$s$ (since every residue class in $\mathbb{Z}/n$ can be written in this form),
and then the integer $s\%n$ will depend only on the class $\sigma$ and not on
the specific choice of this integer $s$. Hence, the map $R$ is well-defined.

Now we have two maps%
\begin{align*}
P:\left\{  0,1,\ldots,n-1\right\}   &  \rightarrow\mathbb{Z}/n,\\
s  &  \mapsto\left[  s\right]  _{n}%
\end{align*}
and%
\begin{align*}
R:\mathbb{Z}/n  &  \rightarrow\left\{  0,1,\ldots,n-1\right\}  ,\\
\left[  s\right]  _{n}  &  \mapsto s\%n.
\end{align*}
We claim that they are mutually inverse. Indeed:

\begin{itemize}
\item We have $P\circ R=\operatorname*{id}$.

[\textit{Proof:} Let $\sigma\in\mathbb{Z}/n$. We shall prove that $\left(
P\circ R\right)  \left(  \sigma\right)  =\operatorname*{id}\left(
\sigma\right)  $.

Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(a)} says that each element of
$\mathbb{Z}/n$ can be written in the form $\left[  s\right]  _{n}$ for some
integer $s$. Hence, $\sigma$ can be written in this form. In other words,
$\sigma=\left[  s\right]  _{n}$ for some integer $s$. Consider this $s$. The
definition of $R$ yields $R\left(  \left[  s\right]  _{n}\right)  =s\%n$.
Corollary \ref{cor.ent.quo-rem.remmod} \textbf{(a)} (applied to $u=s$) yields
$s\%n\equiv s\operatorname{mod}n$. Now, from $\sigma=\left[  s\right]  _{n}$,
we obtain%
\begin{align*}
\left(  P\circ R\right)  \left(  \sigma\right)   &  =\left(  P\circ R\right)
\left(  \left[  s\right]  _{n}\right)  =P\left(  \underbrace{R\left(  \left[
s\right]  _{n}\right)  }_{=s\%n}\right)  =P\left(  s\%n\right) \\
&  =\left[  s\%n\right]  _{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the
definition of }P\right) \\
&  =\left[  s\right]  _{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }s\%n\equiv
s\operatorname{mod}n\right) \\
&  =\sigma=\operatorname*{id}\left(  \sigma\right)  .
\end{align*}


Now, forget that we fixed $\sigma$. We thus have proven that $\left(  P\circ
R\right)  \left(  \sigma\right)  =\operatorname*{id}\left(  \sigma\right)  $
for each $\sigma\in\mathbb{Z}/n$. In other words, $P\circ R=\operatorname*{id}%
$.]

\item We have $R\circ P=\operatorname*{id}$.

[\textit{Proof:} Let $s\in\left\{  0,1,\ldots,n-1\right\}  $. Thus, Corollary
\ref{cor.ent.quo-rem.remmod} \textbf{(c)} (applied to $u=s$ and $c=s$) yields
$s=s\%n$ (since $s\equiv s\operatorname{mod}n$). But the definition of $P$
yields $P\left(  s\right)  =\left[  s\right]  _{n}$. Hence,%
\begin{align*}
\left(  R\circ P\right)  \left(  s\right)   &  =R\left(  \underbrace{P\left(
s\right)  }_{=\left[  s\right]  _{n}}\right)  =R\left(  \left[  s\right]
_{n}\right)  =s\%n\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of
}R\right) \\
&  =s=\operatorname*{id}\left(  s\right)  .
\end{align*}


Now, forget that we fixed $s$. We thus have proven that $\left(  R\circ
P\right)  \left(  s\right)  =\operatorname*{id}\left(  s\right)  $ for each
$s\in\left\{  0,1,\ldots,n-1\right\}  $. In other words, $R\circ
P=\operatorname*{id}$.]
\end{itemize}

Combining $P\circ R=\operatorname*{id}$ and $R\circ P=\operatorname*{id}$, we
conclude that the maps $P$ and $R$ are mutually inverse. Thus, the map $P$ is
invertible, i.e., bijective. Hence, $P$ is surjective and injective. Since $P$
is injective, we see that $P$ must send the distinct elements $0,1,\ldots,n-1$
of its domain to distinct elements. In other words, the $n$ elements $P\left(
0\right)  ,P\left(  1\right)  ,\ldots,P\left(  n-1\right)  $ of $\mathbb{Z}/n$
must be distinct.

But recall that $P\left(  s\right)  =\left[  s\right]  _{n}$ for each
$s\in\left\{  0,1,\ldots,n-1\right\}  $ (by the definition of $P$). Thus, the
$n$ elements $P\left(  0\right)  ,P\left(  1\right)  ,\ldots,P\left(
n-1\right)  $ can be rewritten as $\left[  0\right]  _{n},\left[  1\right]
_{n},\ldots,\left[  n-1\right]  _{n}$. Hence, the $n$ elements $\left[
0\right]  _{n},\left[  1\right]  _{n},\ldots,\left[  n-1\right]  _{n}$ are
distinct (since the $n$ elements $P\left(  0\right)  ,P\left(  1\right)
,\ldots,P\left(  n-1\right)  $ are distinct).

Moreover, $P$ is surjective. Thus,%
\begin{align*}
\mathbb{Z}/n  &  =P\left(  \left\{  0,1,\ldots,n-1\right\}  \right) \\
&  =\left\{  P\left(  0\right)  ,P\left(  1\right)  ,\ldots,P\left(
n-1\right)  \right\} \\
&  =\left\{  \left[  0\right]  _{n},\left[  1\right]  _{n},\ldots,\left[
n-1\right]  _{n}\right\}
\end{align*}
(since $P\left(  s\right)  =\left[  s\right]  _{n}$ for each $s\in\left\{
0,1,\ldots,n-1\right\}  $). In other words, the elements of $\mathbb{Z}/n$ are
exactly the $n$ elements $\left[  0\right]  _{n},\left[  1\right]  _{n}%
,\ldots,\left[  n-1\right]  _{n}$. These $n$ elements are distinct (as we have
previously shown). Hence, the set $\mathbb{Z}/n$ has exactly $n$ elements,
namely $\left[  0\right]  _{n},\left[  1\right]  _{n},\ldots,\left[
n-1\right]  _{n}$. This proves Theorem \ref{thm.eqrel.Z/n.explicit}.
\end{proof}

Let us summarize some of the facts we have shown in the above proof as a
separate proposition:

\begin{proposition}
\label{prop.eqrel.Z/n.PR}Let $n$ be a positive integer.

\textbf{(a)} The two maps%
\begin{align*}
P:\left\{  0,1,\ldots,n-1\right\}   &  \rightarrow\mathbb{Z}/n,\\
s  &  \mapsto\left[  s\right]  _{n}%
\end{align*}
and%
\begin{align*}
R:\mathbb{Z}/n  &  \rightarrow\left\{  0,1,\ldots,n-1\right\}  ,\\
\left[  s\right]  _{n}  &  \mapsto s\%n
\end{align*}
are well-defined and mutually inverse, and thus are bijections.

\textbf{(b)} Let $\alpha\in\mathbb{Z}/n$. Then, there exists a unique
$a\in\left\{  0,1,\ldots,n-1\right\}  $ satisfying $\alpha=\left[  a\right]
_{n}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.Z/n.PR}.]\textbf{(a)} During the proof
of Theorem \ref{thm.eqrel.Z/n.explicit} above, we have shown that the maps $P$
and $R$ are well-defined and mutually inverse. Hence, these maps $P$ and $R$
are invertible, i.e., are bijective. In other words, the maps $P$ and $R$ are
bijections. Thus, Proposition \ref{prop.eqrel.Z/n.PR} \textbf{(a)} is proven.

\textbf{(b)} Consider the maps $P$ and $R$ from Proposition
\ref{prop.eqrel.Z/n.PR} \textbf{(a)}. Then, Proposition
\ref{prop.eqrel.Z/n.PR} \textbf{(a)} shows that these two maps $P$ and $R$ are
well-defined and mutually inverse, and thus are bijections.

We have $P\circ R=\operatorname*{id}$ (since $P$ and $R$ are mutually
inverse). Hence, $\left(  P\circ R\right)  \left(  \alpha\right)
=\operatorname*{id}\left(  \alpha\right)  =\alpha$. Hence, $\alpha=\left(
P\circ R\right)  \left(  \alpha\right)  =P\left(  R\left(  \alpha\right)
\right)  =\left[  R\left(  \alpha\right)  \right]  _{n}$ (by the definition of
$P$). Thus, there exists \textbf{at least one} $a\in\left\{  0,1,\ldots
,n-1\right\}  $ satisfying $\alpha=\left[  a\right]  _{n}$ (namely,
$a=R\left(  \alpha\right)  $). (Indeed, $R\left(  \alpha\right)  \in\left\{
0,1,\ldots,n-1\right\}  $ follows from the fact that $R$ is a map from
$\mathbb{Z}/n$ to $\left\{  0,1,\ldots,n-1\right\}  $.)

On the other hand, let $a\in\left\{  0,1,\ldots,n-1\right\}  $ be such that
$\alpha=\left[  a\right]  _{n}$. We shall prove that $a=R\left(
\alpha\right)  $. Indeed, the definition of $P$ yields $P\left(  a\right)
=\left[  a\right]  _{n}=\alpha$; hence, $a=P^{-1}\left(  \alpha\right)  $
(since the map $P$ is invertible). But $P^{-1}=R$ (since $P$ and $R$ are
mutually inverse). Thus, $a=\underbrace{P^{-1}}_{=R}\left(  \alpha\right)
=R\left(  \alpha\right)  $.

Now, forget that we fixed $a$. We thus have shown that every $a\in\left\{
0,1,\ldots,n-1\right\}  $ satisfying $\alpha=\left[  a\right]  _{n}$ must
satisfy $a=R\left(  \alpha\right)  $. In other words, every $a\in\left\{
0,1,\ldots,n-1\right\}  $ satisfying $\alpha=\left[  a\right]  _{n}$ must be
equal to $R\left(  \alpha\right)  $. Hence, there exists \textbf{at most one}
such $a$.

Now, we conclude that there exists \textbf{a unique }$a\in\left\{
0,1,\ldots,n-1\right\}  $ satisfying $\alpha=\left[  a\right]  _{n}$ (because
we have shown that there exists \textbf{at least one} such $a$, and we have
shown that there exists \textbf{at most one} such $a$). This proves
Proposition \ref{prop.eqrel.Z/n.PR} \textbf{(b)}.
\end{proof}

Proposition \ref{prop.eqrel.Z/n.PR} \textbf{(b)} can be restated as follows:
Each residue class $\alpha\in\mathbb{Z}/n$ has a unique representative in the
set $\left\{  0,1,\ldots,n-1\right\}  $.

\subsubsection{Making choices that don't matter: The universal property of
quotient sets}

\begin{teachingnote}
I haven't taught this subsection in class.
\end{teachingnote}

In the above proof of Theorem \ref{thm.eqrel.Z/n.explicit}, we have witnessed
an important issue in dealing with quotient sets: If you want to define a map
$f$ going \textbf{out} of a quotient set $S/\sim$\ \ \ \ \footnote{In our
case, the quotient set was $\mathbb{Z}/\underset{n}{\equiv}$ (also known as
$\mathbb{Z}/n$), and the map we wanted to define was $R$.}, then the easiest
way to do so is often to specify $f\left(  \left[  s\right]  _{\sim}\right)  $
for each $s\in S$; but in order to ensure that this definition is well-defined
(i.e., that our map $f$ actually exists), we need to verify that the value of
$f\left(  \left[  s\right]  _{\sim}\right)  $ we are specifying depends
\textbf{only on the equivalence class }$\left[  s\right]  _{\sim}$ but not on
the representative $s$. In other words, we need to verify that if $s_{1}$ and
$s_{2}$ are two elements of $S$ such that $\left[  s_{1}\right]  _{\sim
}=\left[  s_{2}\right]  _{\sim}$, then our definition of $f$ assigns the same
value to $f\left(  \left[  s_{1}\right]  _{\sim}\right)  $ as it does to
$f\left(  \left[  s_{2}\right]  _{\sim}\right)  $. This verification (which we
did in our above proof by proving Claim 1) is often quite easy, but it is necessary.

Let us restate this strategy for defining maps out of a quotient set more rigorously:

\begin{remark}
\label{rmk.eqrel.quot.uniprop-as-method}Let $S$ and $T$ be two sets, and let
$\sim$ be an equivalence relation on $S$. Assume that we want to define a map%
\begin{align*}
f:\left.  S/\sim\right.   &  \rightarrow T,\\
\left[  s\right]  _{\sim}  &  \mapsto F\left(  s\right)  ,
\end{align*}
where $F\left(  s\right)  $ is some element of $T$ for each $s\in S$. (That
is, we want to define a map $f:S\rightarrow T$ such that every $s\in S$
satisfies $f\left(  \left[  s\right]  _{\sim}\right)  =F\left(  s\right)  $.)

In order to ensure that this $f$ is well-defined, we need to verify that if
$s_{1}$ and $s_{2}$ are two elements of $S$ such that $\left[  s_{1}\right]
_{\sim}=\left[  s_{2}\right]  _{\sim}$, then $F\left(  s_{1}\right)  =F\left(
s_{2}\right)  $. If this verification has been done, the map $f$ is well-defined.
\end{remark}

Further examples of maps out of quotient sets defined in this way can be found
in \cite{Conrad-Well}\footnote{When reading \cite[Example 1.1]{Conrad-Well},
keep in mind that rational numbers are defined as equivalence classes of
elements of $\mathbb{Z}\times\left(  \mathbb{Z}\setminus\left\{  0\right\}
\right)  $, as we have seen in Example \ref{exa.eqrel.eqcl.rat}. Thus,
$\mathbb{Q}$ is actually a quotient set: namely, $\mathbb{Q}=S/\underset{\ast
}{\sim}$ using the notations of Example \ref{exa.eqrel.eqcl.rat}.}.

\begin{fineprint}
Let us illustrate this method of defining maps on a few more examples:

\begin{example}
Let $A$ be a set, and let $k\in\mathbb{N}$. Fix some $c\in A$. We can then
define a map%
\begin{align*}
\operatorname*{mult}\nolimits_{c}:A^{k}  &  \rightarrow\mathbb{N},\\
\left(  a_{1},a_{2},\ldots,a_{k}\right)   &  \mapsto\left(  \text{the number
of }i\in\left\{  1,2,\ldots,k\right\}  \text{ such that }a_{i}=c\right)  .
\end{align*}
This map $\operatorname*{mult}\nolimits_{c}$ simply sends each $k$-tuple to
the number of times that $c$ appears in this $k$-tuple. For example,
$\operatorname*{mult}\nolimits_{5}\left(  1,5,2,4,7,5,5,6\right)  =3$, since
$5$ appears exactly $3$ times in the $8$-tuple $\left(
1,5,2,4,7,5,5,6\right)  $ (assuming that $k=8$ and $A=\mathbb{Z}$). It is
clear that this map $\operatorname*{mult}\nolimits_{c}$ is well-defined. (The
number $\operatorname*{mult}\nolimits_{c}\mathbf{a}$ for a $k$-tuple
$\mathbf{a}$ is called the \textit{multiplicity of }$c$ \textit{in
}$\mathbf{a}$. Therefore the notation \textquotedblleft$\operatorname*{mult}%
\nolimits_{c}$\textquotedblright.)

Now, it stands to reason that the same can be done with \textbf{unordered}
$k$-tuples: After all, the number of times that $c$ appears in a $k$-tuple
should not depend on the order of the entries of the tuple. To formalize this,
however, we need to deal with quotient sets. Indeed, recall that the
\textquotedblleft unordered $k$-tuples of elements of $A$\textquotedblright%
\ were defined (in Definition \ref{def.eqrel.eqcl.perm.unord-tup}) as
equivalence classes of the relation $\underset{\operatorname*{perm}}{\sim}$ on
the set $A^{k}$. So $A^{k}/\underset{\operatorname*{perm}}{\sim}$ is the set
of all unordered $k$-tuples of elements of $A$. The map that counts how often
$c$ appears in an unordered $k$-tuple should thus have the form%
\begin{align*}
\operatorname*{mult}\nolimits_{c}^{\prime}:\left.  A^{k}%
/\underset{\operatorname*{perm}}{\sim}\right.   &  \rightarrow\mathbb{N},\\
\left[  \left(  a_{1},a_{2},\ldots,a_{k}\right)  \right]
_{\underset{\operatorname*{perm}}{\sim}}  &  \mapsto\left(  \text{the number
of }i\in\left\{  1,2,\ldots,k\right\}  \text{ such that }a_{i}=c\right)  .
\end{align*}
Or, to put it more compactly (making use of the map $\operatorname*{mult}%
\nolimits_{c}$ for \textbf{ordered} $k$-tuples defined above), it should have
the form%
\begin{align*}
\operatorname*{mult}\nolimits_{c}^{\prime}:\left.  A^{k}%
/\underset{\operatorname*{perm}}{\sim}\right.   &  \rightarrow\mathbb{N},\\
\left[  \mathbf{a}\right]  _{\underset{\operatorname*{perm}}{\sim}}  &
\mapsto\operatorname*{mult}\nolimits_{c}\mathbf{a}.
\end{align*}
The question is: Why is this map $\operatorname*{mult}\nolimits_{c}^{\prime}$ well-defined?

Remark \ref{rmk.eqrel.quot.uniprop-as-method} (applied to $A^{k}$,
$\mathbb{N}$ and $\underset{\operatorname*{perm}}{\sim}$ instead of $S$, $T$
and $\sim$) shows that in order to ensure that this map $\operatorname*{mult}%
\nolimits_{c}^{\prime}$ is well-defined, we need to verify that if
$\mathbf{a}_{1}$ and $\mathbf{a}_{2}$ are two elements of $A^{k}$ (that is,
two ordered $k$-tuples) such that $\left[  \mathbf{a}_{1}\right]
_{\underset{\operatorname*{perm}}{\sim}}=\left[  \mathbf{a}_{2}\right]
_{\underset{\operatorname*{perm}}{\sim}}$, then $\operatorname*{mult}%
\nolimits_{c}\left(  \mathbf{a}_{1}\right)  =\operatorname*{mult}%
\nolimits_{c}\left(  \mathbf{a}_{2}\right)  $. Let us do this: Let
$\mathbf{a}_{1}$ and $\mathbf{a}_{2}$ be two elements of $A^{k}$ (that is, two
ordered $k$-tuples) such that $\left[  \mathbf{a}_{1}\right]
_{\underset{\operatorname*{perm}}{\sim}}=\left[  \mathbf{a}_{2}\right]
_{\underset{\operatorname*{perm}}{\sim}}$. Now, $\left[  \mathbf{a}%
_{1}\right]  _{\underset{\operatorname*{perm}}{\sim}}=\left[  \mathbf{a}%
_{2}\right]  _{\underset{\operatorname*{perm}}{\sim}}$ entails $\mathbf{a}%
_{1}\underset{\operatorname*{perm}}{\sim}\mathbf{a}_{2}$ (indeed, Theorem
\ref{thm.eqrel.eqcl.disj} \textbf{(e)} shows that we have $\mathbf{a}%
_{1}\underset{\operatorname*{perm}}{\sim}\mathbf{a}_{2}$ if and only if
$\left[  \mathbf{a}_{1}\right]  _{\underset{\operatorname*{perm}}{\sim}%
}=\left[  \mathbf{a}_{2}\right]  _{\underset{\operatorname*{perm}}{\sim}}$).
In other words, $\mathbf{a}_{1}$ is a permutation of $\mathbf{a}_{2}$ (by the
definition of $\underset{\operatorname*{perm}}{\sim}$). In other words, the
tuples $\mathbf{a}_{1}$ and $\mathbf{a}_{2}$ differ only in the order of their
entries. Hence, Lemma \ref{lem.comb.tuples.mult=perm.conv} (applied to $A$,
$\mathbf{a}_{1}$, $\mathbf{a}_{2}$ and $c$ instead of $P$, $\left(
a_{1},a_{2},\ldots,a_{k}\right)  $, $\left(  b_{1},b_{2},\ldots,b_{\ell
}\right)  $ and $p$) yields that%
\[
\left(  \text{the number of times }c\text{ appears in }\mathbf{a}_{1}\right)
=\left(  \text{the number of times }c\text{ appears in }\mathbf{a}_{2}\right)
.
\]
This rewrites as $\operatorname*{mult}\nolimits_{c}\left(  \mathbf{a}%
_{1}\right)  =\operatorname*{mult}\nolimits_{c}\left(  \mathbf{a}_{2}\right)
$ (since $\left(  \text{the number of times }c\text{ appears in }%
\mathbf{a}_{1}\right)  =\operatorname*{mult}\nolimits_{c}\left(
\mathbf{a}_{1}\right)  $ and $\left(  \text{the number of times }c\text{
appears in }\mathbf{a}_{2}\right)  =\operatorname*{mult}\nolimits_{c}\left(
\mathbf{a}_{2}\right)  $). This is what we needed to prove. Thus, we have
shown that $\operatorname*{mult}\nolimits_{c}^{\prime}$ is well-defined.

On the other hand, if we tried to define a map%
\begin{align*}
\operatorname*{first}:\left.  A^{k}/\underset{\operatorname*{perm}}{\sim
}\right.   &  \rightarrow\mathbb{N},\\
\left[  \mathbf{a}\right]  _{\underset{\operatorname*{perm}}{\sim}}  &
\mapsto\left(  \text{the first entry of }\mathbf{a}\right)
\end{align*}
(assuming that $k>0$, so that an ordered $k$-tuple does indeed have a first
entry), then we would run into troubles, because it is \textbf{not} true that
if $\mathbf{a}_{1}$ and $\mathbf{a}_{2}$ are two elements of $A^{k}$ such that
$\left[  \mathbf{a}_{1}\right]  _{\underset{\operatorname*{perm}}{\sim}%
}=\left[  \mathbf{a}_{2}\right]  _{\underset{\operatorname*{perm}}{\sim}}$,
then $\left(  \text{the first entry of }\mathbf{a}_{1}\right)  =\left(
\text{the first entry of }\mathbf{a}_{2}\right)  $. And this is no surprise:
There is no such thing as \textquotedblleft the first entry\textquotedblright%
\ of an unordered $k$-tuple. The first entry of a $k$-tuple is sensitive to
reordering of its entries.
\end{example}
\end{fineprint}

We can restate this method of defining maps as a rigorous theorem:

\begin{theorem}
\label{thm.eqrel.quot.uniprop.1}Let $S$ and $T$ be two sets, and let $\sim$ be
an equivalence relation on $S$. For each $s\in S$, let $F\left(  s\right)  $
be an element of $T$. (In other words, let $F$ be a map from $S$ to $T$.)
Assume that the following assumption holds:

\begin{statement}
\textit{Assumption 1:} If $s_{1}$ and $s_{2}$ are two elements of $S$
satisfying $s_{1}\sim s_{2}$, then $F\left(  s_{1}\right)  =F\left(
s_{2}\right)  $.
\end{statement}

Then, there exists a unique map $f:\left.  S/\sim\right.  \rightarrow T$ such
that every $s\in S$ satisfies $f\left(  \left[  s\right]  _{\sim}\right)
=F\left(  s\right)  $.
\end{theorem}

Theorem \ref{thm.eqrel.quot.uniprop.1} says that (under the assumption that
Assumption 1 holds) we can define a map%
\begin{align*}
f:\left.  S/\sim\right.   &  \rightarrow T,\\
\left[  s\right]  _{\sim}  &  \mapsto F\left(  s\right)  .
\end{align*}
For example, the map $R$ defined in our proof of Theorem
\ref{thm.eqrel.Z/n.explicit} was defined in this way (with $\mathbb{Z}$,
$\mathbb{Z}$, $\underset{n}{\equiv}$ and $s\%n$ playing the roles of $S$, $T$,
$\sim$ and $F\left(  s\right)  $), and our proof of Claim 1 was essentially us
verifying that Assumption 1 of Theorem \ref{thm.eqrel.quot.uniprop.1} is satisfied.

\begin{fineprint}
For the sake of completeness, let us give a formal proof for Theorem
\ref{thm.eqrel.quot.uniprop.1} as well:

\begin{proof}
[Proof of Theorem \ref{thm.eqrel.quot.uniprop.1}.]We need to prove the
following two statements:

\begin{statement}
\textit{Statement 1:} There exists \textbf{at least one} map $f:\left.
S/\sim\right.  \rightarrow T$ such that every $s\in S$ satisfies $f\left(
\left[  s\right]  _{\sim}\right)  =F\left(  s\right)  $.
\end{statement}

\begin{statement}
\textit{Statement 2:} There exists \textbf{at most one} map $f:\left.
S/\sim\right.  \rightarrow T$ such that every $s\in S$ satisfies $f\left(
\left[  s\right]  _{\sim}\right)  =F\left(  s\right)  $.
\end{statement}

[\textit{Proof of Statement 1:} We define a map $\varphi$ as follows:

Let $\sigma\in\left.  S/\sim\right.  $. Thus, $\sigma$ is an equivalence class
of $\sim$ (by the definition of $S/\sim$). In other words, $\sigma=\left[
s\right]  _{\sim}$ for some element $s\in S$. In other words, there exists
some element $s\in S$ such that $\sigma=\left[  s\right]  _{\sim}$. If $s_{1}$
and $s_{2}$ are two such elements $s$, then $F\left(  s_{1}\right)  =F\left(
s_{2}\right)  $\ \ \ \ \footnote{\textit{Proof.} Let $s_{1}$ and $s_{2}$ be
two such elements $s$. Then, $\sigma=\left[  s_{1}\right]  _{\sim}$ (since
$s_{1}$ is an element $s\in S$ such that $\sigma=\left[  s\right]  _{\sim}$)
and $\sigma=\left[  s_{2}\right]  _{\sim}$ (for similar reasons). Hence,
$\left[  s_{1}\right]  _{\sim}=\sigma=\left[  s_{2}\right]  _{\sim}$. But
Theorem \ref{thm.eqrel.eqcl.disj} \textbf{(e)} (applied to $x=s_{1}$ and
$y=s_{2}$) yields that we have $s_{1}\sim s_{2}$ if and only if $\left[
s_{1}\right]  _{\sim}=\left[  s_{2}\right]  _{\sim}$. Hence, we have
$s_{1}\sim s_{2}$ (since $\left[  s_{1}\right]  _{\sim}=\left[  s_{2}\right]
_{\sim}$). Thus, Assumption 1 shows that $F\left(  s_{1}\right)  =F\left(
s_{2}\right)  $, qed.}. Thus, the element $F\left(  s\right)  \in T$ obtained
from such an element $s$ does not depend on the choice of $s$ (as long as
$\sigma$ is fixed). Hence, we can define $\varphi\left(  \sigma\right)  $ by
setting
\begin{equation}
\varphi\left(  \sigma\right)  =F\left(  s\right)  ,
\label{pf.thm.eqrel.quot.uniprop.1.s1.pf.3}%
\end{equation}
where $s$ is any element of $S$ satisfying $\sigma=\left[  s\right]  _{\sim}$.

Define $\varphi\left(  \sigma\right)  $ this way. Thus, we have defined an
element $\varphi\left(  \sigma\right)  $ of $T$ for each $\sigma\in\left.
S/\sim\right.  $. Hence, we have defined a map $\varphi:\left.  S/\sim\right.
\rightarrow T$. Moreover, this map has the property that every $s\in S$
satisfies $\varphi\left(  \left[  s\right]  _{\sim}\right)  =F\left(
s\right)  $. (Indeed, this follows from
(\ref{pf.thm.eqrel.quot.uniprop.1.s1.pf.3}) (applied to $\sigma=\left[
s\right]  _{\sim}$), since obviously $\left[  s\right]  _{\sim}=\left[
s\right]  _{\sim}$.)

Hence, there exists \textbf{at least one} map $f:\left.  S/\sim\right.
\rightarrow T$ such that every $s\in S$ satisfies $f\left(  \left[  s\right]
_{\sim}\right)  =F\left(  s\right)  $ (namely, the map $\varphi$). This proves
Statement 1.]

[\textit{Proof of Statement 2:} Let $f_{1}$ and $f_{2}$ be two maps $f:\left.
S/\sim\right.  \rightarrow T$ such that every $s\in S$ satisfies $f\left(
\left[  s\right]  _{\sim}\right)  =F\left(  s\right)  $. We shall show that
$f_{1}=f_{2}$.

We know that $f_{1}$ is a map $f:\left.  S/\sim\right.  \rightarrow T$ such
that every $s\in S$ satisfies $f\left(  \left[  s\right]  _{\sim}\right)
=F\left(  s\right)  $. In other words, $f_{1}$ is a map from $\left.
S/\sim\right.  $ to $T$ and has the property that
\begin{equation}
\text{every }s\in S\text{ satisfies }f_{1}\left(  \left[  s\right]  _{\sim
}\right)  =F\left(  s\right)  . \label{pf.thm.eqrel.quot.uniprop.1.s2.pf.1}%
\end{equation}
Likewise, $f_{2}$ is a map from $\left.  S/\sim\right.  $ to $T$ and has the
property that
\begin{equation}
\text{every }s\in S\text{ satisfies }f_{2}\left(  \left[  s\right]  _{\sim
}\right)  =F\left(  s\right)  . \label{pf.thm.eqrel.quot.uniprop.1.s2.pf.2}%
\end{equation}


Now, let $\sigma\in\left.  S/\sim\right.  $ be arbitrary. Thus, $\sigma$ is an
equivalence class of $\sim$ (by the definition of $S/\sim$). In other words,
$\sigma=\left[  s\right]  _{\sim}$ for some element $s\in S$. Consider this
$s$. Then, from $\sigma=\left[  s\right]  _{\sim}$, we obtain $f_{1}\left(
\sigma\right)  =f_{1}\left(  \left[  s\right]  _{\sim}\right)  =F\left(
s\right)  $ (by (\ref{pf.thm.eqrel.quot.uniprop.1.s2.pf.1})). Similarly,
$f_{2}\left(  \sigma\right)  =F\left(  s\right)  $. Comparing these two
equalities, we find $f_{1}\left(  \sigma\right)  =f_{2}\left(  \sigma\right)
$.

Forget that we fixed $\sigma$. We thus have proven that $f_{1}\left(
\sigma\right)  =f_{2}\left(  \sigma\right)  $ for each $\sigma\in\left.
S/\sim\right.  $. In other words, $f_{1}=f_{2}$.

Forget that we fixed $f_{1}$ and $f_{2}$. We thus have proven that if $f_{1}$
and $f_{2}$ are two maps $f:\left.  S/\sim\right.  \rightarrow T$ such that
every $s\in S$ satisfies $f\left(  \left[  s\right]  _{\sim}\right)  =F\left(
s\right)  $, then $f_{1}=f_{2}$. In other words, there exists \textbf{at most
one} such map $f$. This proves Statement 2.]

Now, we conclude that there exists a unique map $f:\left.  S/\sim\right.
\rightarrow T$ such that every $s\in S$ satisfies $f\left(  \left[  s\right]
_{\sim}\right)  =F\left(  s\right)  $ (because Statement 1 shows that there
exists \textbf{at least one} such map, while Statement 2 shows that there
exists \textbf{at most one} such map). This proves Theorem
\ref{thm.eqrel.quot.uniprop.1}.
\end{proof}
\end{fineprint}

Theorem \ref{thm.eqrel.quot.uniprop.1} is known as the \textit{universal
property of the quotient set}.

\subsubsection{Projecting from $\mathbb{Z}/n$ to $\mathbb{Z}/d$}

As another example of a map from a quotient set, let us define certain maps
from $\mathbb{Z}/n$ to $\mathbb{Z}/d$ that exist whenever two integers $n$ and
$d$ satisfy $d\mid n$:

\begin{proposition}
\label{prop.eqrel.Z/n.pind.wd}Let $n$ be an integer. Let $d$ be a divisor of
$n$. Then, there is a map%
\begin{align*}
\pi_{n,d}:\mathbb{Z}/n  &  \rightarrow\mathbb{Z}/d,\\
\left[  s\right]  _{n}  &  \mapsto\left[  s\right]  _{d}.
\end{align*}

\end{proposition}

\begin{example}
\label{exa.eqrel.Z/n.pind.wd}\textbf{(a)} For example, for $n=6$ and $d=2$,
Proposition \ref{prop.eqrel.Z/n.pind.wd} says that there is a map
\begin{align*}
\pi_{6,2}:\mathbb{Z}/6  &  \rightarrow\mathbb{Z}/2,\\
\left[  s\right]  _{6}  &  \mapsto\left[  s\right]  _{2}.
\end{align*}
This map sends the residue classes
\begin{align*}
&  \left[  0\right]  _{6},\left[  1\right]  _{6},\left[  2\right]
_{6},\left[  3\right]  _{6},\left[  4\right]  _{6},\left[  5\right]  _{6}\\
\text{to }  &  \left[  0\right]  _{2},\left[  1\right]  _{2},\left[  2\right]
_{2},\left[  3\right]  _{2},\left[  4\right]  _{2},\left[  5\right]
_{2}\text{, respectively.}%
\end{align*}
In other words, it sends the residue classes%
\begin{align*}
&  \left[  0\right]  _{6},\left[  1\right]  _{6},\left[  2\right]
_{6},\left[  3\right]  _{6},\left[  4\right]  _{6},\left[  5\right]  _{6}\\
\text{to }  &  \left[  0\right]  _{2},\left[  1\right]  _{2},\left[  0\right]
_{2},\left[  1\right]  _{2},\left[  0\right]  _{2},\left[  1\right]
_{2}\text{, respectively}%
\end{align*}
(since $\left[  2\right]  _{2}=\left[  0\right]  _{2}$ and $\left[  3\right]
_{2}=\left[  1\right]  _{2}$ and $\left[  4\right]  _{2}=\left[  0\right]
_{2}$ and $\left[  5\right]  _{2}=\left[  1\right]  _{2}$). More generally,
for arbitrary positive integers $n$ and $d$ satisfying $d\mid n$, the map
$\pi_{n,d}$ sends the $n$ residue classes $\left[  0\right]  _{n},\left[
1\right]  _{n},\ldots,\left[  n-1\right]  _{n}$ to
\[
\left[  0\right]  _{d},\left[  1\right]  _{d},\ldots,\left[  d-1\right]
_{d},\left[  0\right]  _{d},\left[  1\right]  _{d},\ldots,\left[  d-1\right]
_{d},\ldots,\left[  0\right]  _{d},\left[  1\right]  _{d},\ldots,\left[
d-1\right]  _{d}%
\]
(that is, $\left[  0\right]  _{d},\left[  1\right]  _{d},\ldots,\left[
d-1\right]  _{d}$ in this order, repeated $\dfrac{n}{d}$ many times), respectively.

\textbf{(b)} For a non-example, set $n=3$ and $d=2$. Then, Proposition
\ref{prop.eqrel.Z/n.pind.wd} does not apply, since $2$ is not a divisor of
$3$. And for good reason: There is no map%
\begin{align*}
\pi_{3,2}:\mathbb{Z}/3  &  \rightarrow\mathbb{Z}/2,\\
\left[  s\right]  _{3}  &  \mapsto\left[  s\right]  _{2}.
\end{align*}
Indeed, this map would have to send $\left[  0\right]  _{3}$ and $\left[
3\right]  _{3}$ to $\left[  0\right]  _{2}$ and $\left[  3\right]  _{2}$,
respectively; but this means sending two equal inputs to different outputs
(since $\left[  0\right]  _{3}=\left[  3\right]  _{3}$ but $\left[  0\right]
_{2}\neq\left[  3\right]  _{2}$), which is impossible. More generally, if a
positive integer $d$ is \textbf{not} a divisor of a positive integer $n$, then
there is no map%
\begin{align*}
\pi_{n,d}:\mathbb{Z}/n  &  \rightarrow\mathbb{Z}/d,\\
\left[  s\right]  _{n}  &  \mapsto\left[  s\right]  _{d}.
\end{align*}

\end{example}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.Z/n.pind.wd}.]We must prove that, for an
integer $s\in\mathbb{Z}$, the class $\left[  s\right]  _{d}\in\mathbb{Z}/d$
depends only on the residue class $\left[  s\right]  _{n}$ but not on the
integer $s$ itself. In other words, we need to prove the following claim:

\begin{statement}
\textit{Claim 1:} If $s_{1}$ and $s_{2}$ are two integers such that $\left[
s_{1}\right]  _{n}=\left[  s_{2}\right]  _{n}$, then $\left[  s_{1}\right]
_{d}=\left[  s_{2}\right]  _{d}$.
\end{statement}

[\textit{Proof of Claim 1:} Let $s_{1}$ and $s_{2}$ be two integers such that
$\left[  s_{1}\right]  _{n}=\left[  s_{2}\right]  _{n}$.

Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $a=s_{1}$ and
$b=s_{2}$) shows that we have $\left[  s_{1}\right]  _{n}=\left[
s_{2}\right]  _{n}$ if and only if $s_{1}\equiv s_{2}\operatorname{mod}n$.
Thus, we have $s_{1}\equiv s_{2}\operatorname{mod}n$ (since $\left[
s_{1}\right]  _{n}=\left[  s_{2}\right]  _{n}$). Hence, Proposition
\ref{prop.ent.mod.basics} \textbf{(e)} (applied to $s_{1}$, $s_{2}$ and $d$
instead of $a$, $b$ and $m$) yields $s_{1}\equiv s_{2}\operatorname{mod}d$
(since $d\mid n$).

But Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $d$, $s_{1}$
and $s_{2}$ instead of $n$, $a$ and $b$) shows that we have $\left[
s_{1}\right]  _{d}=\left[  s_{2}\right]  _{d}$ if and only if $s_{1}\equiv
s_{2}\operatorname{mod}d$. Thus, we have $\left[  s_{1}\right]  _{d}=\left[
s_{2}\right]  _{d}$ (since $s_{1}\equiv s_{2}\operatorname{mod}d$). This
proves Claim 1.]

Having proven Claim 1, we can now conclude that the map%
\begin{align*}
\pi_{n,d}:\mathbb{Z}/n  &  \rightarrow\mathbb{Z}/d,\\
\left[  s\right]  _{n}  &  \mapsto\left[  s\right]  _{d}%
\end{align*}
is well-defined. (This can be regarded as a consequence of applying Theorem
\ref{thm.eqrel.quot.uniprop.1} to $\mathbb{Z}$, $\mathbb{Z}/d$,
$\underset{n}{\equiv}$ and $\left[  s\right]  _{d}$ instead of $S$, $T$,
$\sim$ and $F\left(  s\right)  $. The Claim 1 that we proved above guarantees
that Assumption 1 of Theorem \ref{thm.eqrel.quot.uniprop.1} is satisfied.)
Hence, Proposition \ref{prop.eqrel.Z/n.pind.wd} is proven.
\end{proof}

The next exercise is unrelated to $\mathbb{Z}/n$, but has been placed in this
section because it relies on the same sort of \textquotedblleft
well-definedness\textquotedblright\ argument that we have seen in our proofs above:

\begin{exercise}
\label{exe.eqrel.quot.wp}Fix a prime $p$. For each nonzero rational number
$r$, define an integer $w_{p}\left(  r\right)  $ (called the \textit{extended
$p$-adic valuation} of $r$) as follows: We write $r$ in the form $r=a/b$ for
two nonzero integers $a$ and $b$, and we set $w_{p}\left(  r\right)
=v_{p}\left(  a\right)  -v_{p}\left(  b\right)  $. (It also makes sense to set
$w_{p}\left(  0\right)  =\infty$, but we shall not concern ourselves with this
border case in this exercise.)

\textbf{(a)} Prove that this is well-defined -- i.e., that $w_{p}\left(
r\right)  $ does not depend on the precise choice of $a$ and $b$ satisfying
$r=a/b$.

\textbf{(b)} Prove that $w_{p}\left(  n\right)  =v_{p}\left(  n\right)  $ for
each nonzero integer $n$.

\textbf{(c)} Prove that $w_{p}\left(  ab\right)  =w_{p}\left(  a\right)
+w_{p}\left(  b\right)  $ for any two nonzero rational numbers $a$ and $b$.

\textbf{(d)} Prove that $w_{p}\left(  a+b\right)  \geq\min\left\{
w_{p}\left(  a\right)  ,w_{p}\left(  b\right)  \right\}  $ for any two nonzero
rational numbers $a$ and $b$ if $a+b\neq0$.
\end{exercise}

\begin{exercise}
\label{exe.eqrel.quot.wp-glob}Let $r$ be a nonzero rational number. In
Exercise \ref{exe.eqrel.quot.wp}, we have defined an integer $w_{p}\left(
r\right)  $ for each prime $p$. Prove the following:

\textbf{(a)} All but finitely many primes $p$ satisfy $w_{p}\left(  r\right)
=0$.

\textbf{(b)} We have $\left\vert r\right\vert =\prod_{p\text{ prime}}%
p^{w_{p}\left(  r\right)  }$ (and in particular, the product $\prod_{p\text{
prime}}p^{w_{p}\left(  r\right)  }$ is well-defined, i.e., has only finitely
many factors different from $1$).

\textbf{(c)} We have $r\in\mathbb{Z}$ if and only if each prime $p$ satisfies
$w_{p}\left(  r\right)  \geq0$.

\textbf{(d)} We have the logical equivalence%
\begin{align*}
&  \ \left(  \text{there exists a }k\in\mathbb{N}\text{ satisfying }m^{k}%
r\in\mathbb{Z}\right) \\
&  \Longleftrightarrow\ \left(  \text{every prime }p\text{ satisfying }%
w_{p}\left(  r\right)  <0\text{ satisfies }p\mid m\right)  .
\end{align*}

\end{exercise}

Note that Exercise \ref{exe.eqrel.quot.wp-glob} \textbf{(b)} can be regarded
as a canonical factorization for rational numbers. (Unlike the canonical
factorization for integers, it allows negative exponents on the primes.)

\subsubsection{Addition, subtraction and multiplication in $\mathbb{Z}/n$}

Let us recall the concept of a binary operation (defined in Definition
\ref{def.intro.binop}). We shall now define several such operations on the set
$\mathbb{Z}/n$\ \ \ \ \footnote{We will check afterwards that these operations
are indeed well-defined.}:

\begin{definition}
\label{def.eqrel.Z/n.op}\textbf{(a)} We define a binary operation $+$ on
$\mathbb{Z}/n$ (called \textit{addition}) by setting%
\[
\left[  a\right]  _{n}+\left[  b\right]  _{n}=\left[  a+b\right]
_{n}\ \ \ \ \ \ \ \ \ \ \text{for any integers }a\text{ and }b.
\]
(In other words, we define a binary operation $+$ on $\mathbb{Z}/n$ as
follows: For any $\alpha,\beta\in\mathbb{Z}/n$, we let $\alpha+\beta=\left[
a+b\right]  _{n}$, where $a$ and $b$ are two integers satisfying
$\alpha=\left[  a\right]  _{n}$ and $\beta=\left[  b\right]  _{n}$.)

\textbf{(b)} We define a binary operation $-$ on $\mathbb{Z}/n$ (called
\textit{subtraction}) by setting%
\[
\left[  a\right]  _{n}-\left[  b\right]  _{n}=\left[  a-b\right]
_{n}\ \ \ \ \ \ \ \ \ \ \text{for any integers }a\text{ and }b.
\]


\textbf{(c)} We define a binary operation $\cdot$ on $\mathbb{Z}/n$ (called
\textit{multiplication}) by setting%
\[
\left[  a\right]  _{n}\cdot\left[  b\right]  _{n}=\left[  a\cdot b\right]
_{n}\ \ \ \ \ \ \ \ \ \ \text{for any integers }a\text{ and }b.
\]
We also write $\left[  a\right]  _{n}\left[  b\right]  _{n}$ for $\left[
a\right]  _{n}\cdot\left[  b\right]  _{n}$.
\end{definition}

\begin{theorem}
\label{thm.eqrel.Z/n.op.wd}Everything defined in Definition
\ref{def.eqrel.Z/n.op} is well-defined.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.eqrel.Z/n.op.wd}.]\textbf{(a)} Let us first prove
that the binary operation $+$ in Definition \ref{def.eqrel.Z/n.op}
\textbf{(a)} is well-defined.

Indeed, here we are in the same situation in which we were when defining the
map $R$ in the proof of Theorem \ref{thm.eqrel.Z/n.explicit}: We are trying to
define a map (in the current case, the binary operation $+$, which should be a
map from $\left(  \mathbb{Z}/n\right)  \times\left(  \mathbb{Z}/n\right)  $ to
$\mathbb{Z}/n$) by specifying how it acts on inputs of the form $\left[
a\right]  _{n}$, but our definition refers to the integer $a$. (Actually, it
is a little bit more complicated: We have two inputs $\left[  a\right]  _{n}$
and $\left[  b\right]  _{n}$ and thus two integers $a$ and $b$. But the
problem we are facing is the same.) We want to prove that this map is
well-defined. This requires checking that the output (that is, $\left[
a+b\right]  _{n}$) depends only on the two classes $\left[  a\right]  _{n}$
and $\left[  b\right]  _{n}$, but not on the integers $a$ and $b$.

So we have to prove the following:

\begin{statement}
\textit{Claim 1:} Let $a_{1}$ and $a_{2}$ be two integers such that $\left[
a_{1}\right]  _{n}=\left[  a_{2}\right]  _{n}$. Let $b_{1}$ and $b_{2}$ be two
integers such that $\left[  b_{1}\right]  _{n}=\left[  b_{2}\right]  _{n}$.
Then,%
\[
\left[  a_{1}+b_{1}\right]  _{n}=\left[  a_{2}+b_{2}\right]  _{n}.
\]

\end{statement}

[\textit{Proof of Claim 1:} Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)}
(applied to $a_{1}$ and $a_{2}$ instead of $a$ and $b$) shows that we have
$\left[  a_{1}\right]  _{n}=\left[  a_{2}\right]  _{n}$ if and only if
$a_{1}\equiv a_{2}\operatorname{mod}n$. Thus, we have $a_{1}\equiv
a_{2}\operatorname{mod}n$ (since $\left[  a_{1}\right]  _{n}=\left[
a_{2}\right]  _{n}$). Similarly, $b_{1}\equiv b_{2}\operatorname{mod}n$ (since
$\left[  b_{1}\right]  _{n}=\left[  b_{2}\right]  _{n}$). Adding these two
congruences together, we obtain $a_{1}+b_{1}\equiv a_{2}+b_{2}%
\operatorname{mod}n$.

But Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $a_{1}+b_{1}$
and $a_{2}+b_{2}$ instead of $a$ and $b$) shows that we have $\left[
a_{1}+b_{1}\right]  _{n}=\left[  a_{2}+b_{2}\right]  _{n}$ if and only if
$a_{1}+b_{1}\equiv a_{2}+b_{2}\operatorname{mod}n$. Thus, we have $\left[
a_{1}+b_{1}\right]  _{n}=\left[  a_{2}+b_{2}\right]  _{n}$ (since $a_{1}%
+b_{1}\equiv a_{2}+b_{2}\operatorname{mod}n$). This proves Claim 1.]

Claim 1 shows that in Definition \ref{def.eqrel.Z/n.op} \textbf{(a)}, the
residue class $\left[  a+b\right]  _{n}$ depends only on the two classes
$\left[  a\right]  _{n}$ and $\left[  b\right]  _{n}$, but not on the integers
$a$ and $b$. Thus, the binary operation $+$ in Definition
\ref{def.eqrel.Z/n.op} \textbf{(a)} is indeed well-defined.

\textbf{(b)} The binary operation $-$ in Definition \ref{def.eqrel.Z/n.op}
\textbf{(b)} is well-defined. This can be proven in the same way as we just
proved that the binary operation $+$ in Definition \ref{def.eqrel.Z/n.op}
\textbf{(a)} is well-defined; the only difference is that we now have to
subtract the congruences $a_{1}\equiv a_{2}\operatorname{mod}n$ and
$b_{1}\equiv b_{2}\operatorname{mod}n$ instead of adding them together.

\textbf{(c)} The binary operation $\cdot$ in Definition \ref{def.eqrel.Z/n.op}
\textbf{(c)} is well-defined. This can be proven in the same way as we just
proved that the binary operation $+$ in Definition \ref{def.eqrel.Z/n.op}
\textbf{(a)} is well-defined; the only difference is that we now have to
multiply the congruences $a_{1}\equiv a_{2}\operatorname{mod}n$ and
$b_{1}\equiv b_{2}\operatorname{mod}n$ instead of adding them together.

Thus, we have proven that all three operations $+$, $-$ and $\cdot$ in
Definition \ref{def.eqrel.Z/n.op} are well-defined. This proves Theorem
\ref{thm.eqrel.Z/n.op.wd}.
\end{proof}

Recall that $\mathbb{Z}/n$ is a finite set (of size $n$) whenever $n$ is a
positive integer. Hence, for each given positive integer $n$, we can tabulate
all the values of the operations $+$, $-$ and $\cdot$; the resulting tables
are called \textit{addition tables}, \textit{subtraction tables} and
\textit{multiplication tables} (like in high school, except that we are
working with residue classes now).

\begin{example}
\textbf{(a)} If $n=3$, then the addition, subtraction and multiplication
tables for $\mathbb{Z}/n=\mathbb{Z}/3$ are
\[%
\begin{tabular}
[c]{|c|ccc|}\hline
$+$ & $\left[  0\right]  _{3}$ & $\left[  1\right]  _{3}$ & $\left[  2\right]
_{3}$\\\hline
$\left[  0\right]  _{3}$ & $\left[  0\right]  _{3}$ & $\left[  1\right]  _{3}$
& $\left[  2\right]  _{3}$\\
$\left[  1\right]  _{3}$ & $\left[  1\right]  _{3}$ & $\left[  2\right]  _{3}$
& $\left[  0\right]  _{3}$\\
$\left[  2\right]  _{3}$ & $\left[  2\right]  _{3}$ & $\left[  0\right]  _{3}$
& $\left[  1\right]  _{3}$\\\hline
\end{tabular}
\ \ \ ,\ \ \ \ \ \ \ \
\begin{tabular}
[c]{|c|ccc|}\hline
$-$ & $\left[  0\right]  _{3}$ & $\left[  1\right]  _{3}$ & $\left[  2\right]
_{3}$\\\hline
$\left[  0\right]  _{3}$ & $\left[  0\right]  _{3}$ & $\left[  2\right]  _{3}$
& $\left[  1\right]  _{3}$\\
$\left[  1\right]  _{3}$ & $\left[  1\right]  _{3}$ & $\left[  0\right]  _{3}$
& $\left[  2\right]  _{3}$\\
$\left[  2\right]  _{3}$ & $\left[  2\right]  _{3}$ & $\left[  1\right]  _{3}$
& $\left[  0\right]  _{3}$\\\hline
\end{tabular}
\ \ \ ,\ \ \ \ \ \ \ \
\begin{tabular}
[c]{|c|ccc|}\hline
$\cdot$ & $\left[  0\right]  _{3}$ & $\left[  1\right]  _{3}$ & $\left[
2\right]  _{3}$\\\hline
$\left[  0\right]  _{3}$ & $\left[  0\right]  _{3}$ & $\left[  0\right]  _{3}$
& $\left[  0\right]  _{3}$\\
$\left[  1\right]  _{3}$ & $\left[  0\right]  _{3}$ & $\left[  1\right]  _{3}$
& $\left[  2\right]  _{3}$\\
$\left[  2\right]  _{3}$ & $\left[  0\right]  _{3}$ & $\left[  2\right]  _{3}$
& $\left[  1\right]  _{3}$\\\hline
\end{tabular}
\ .
\]
(Here, the entry in the row corresponding to $\alpha$ and the column
corresponding to $\beta$ is $\alpha+\beta$, $\alpha-\beta$ and $\alpha
\cdot\beta$, respectively.)

\textbf{(b)} If $n=2$, then the addition, subtraction and multiplication
tables for $\mathbb{Z}/n=\mathbb{Z}/2$ are
\[%
\begin{tabular}
[c]{|c|cc|}\hline
$+$ & $\left[  0\right]  _{2}$ & $\left[  1\right]  _{2}$\\\hline
$\left[  0\right]  _{2}$ & $\left[  0\right]  _{2}$ & $\left[  1\right]  _{2}%
$\\
$\left[  1\right]  _{2}$ & $\left[  1\right]  _{2}$ & $\left[  0\right]  _{2}%
$\\\hline
\end{tabular}
\ \ \ ,\ \ \ \ \ \ \ \ \ \
\begin{tabular}
[c]{|c|cc|}\hline
$-$ & $\left[  0\right]  _{2}$ & $\left[  1\right]  _{2}$\\\hline
$\left[  0\right]  _{2}$ & $\left[  0\right]  _{2}$ & $\left[  1\right]  _{2}%
$\\
$\left[  1\right]  _{2}$ & $\left[  1\right]  _{2}$ & $\left[  0\right]  _{2}%
$\\\hline
\end{tabular}
\ \ \ ,\ \ \ \ \ \ \ \ \ \
\begin{tabular}
[c]{|c|cc|}\hline
$\cdot$ & $\left[  0\right]  _{2}$ & $\left[  1\right]  _{2}$\\\hline
$\left[  0\right]  _{2}$ & $\left[  0\right]  _{2}$ & $\left[  0\right]  _{2}%
$\\
$\left[  1\right]  _{2}$ & $\left[  0\right]  _{2}$ & $\left[  1\right]  _{2}%
$\\\hline
\end{tabular}
\ .
\]
(In particular, the addition table is the same as the subtraction table,
because any $\alpha,\beta\in\mathbb{Z}/2$ satisfy $\alpha+\beta=\alpha-\beta$.
This follows from Exercise \ref{exe.ent.mod.a+b=a-b}.)
\end{example}

\begin{remark}
We \textbf{cannot} define a division operation on $\mathbb{Z}/n$ by setting%
\[
\left[  a\right]  _{n}/\left[  b\right]  _{n}:=\left[  a/b\right]
_{n}\ \ \ \ \ \ \ \ \ \ \text{for any integers }a\text{ and }b.
\]
Indeed, leaving aside the issues that $b$ could be $0$ or $a/b$ could be
non-integer, this would still not be well-defined, because the class $\left[
a/b\right]  _{n}$ depends not just on $\left[  a\right]  _{n}$ and $\left[
b\right]  _{n}$ but also on the concrete choices of $a$ and $b$. For example,
for $n=4$, this ostensible \textquotedblleft division
operation\textquotedblright\ would have to satisfy
\[
\text{\textquotedblleft}\left[  6\right]  _{4}/\left[  2\right]
_{4}\text{\textquotedblright}=\left[  6/2\right]  _{4}=\left[  3\right]  _{4}%
\]
and%
\[
\text{\textquotedblleft}\left[  2\right]  _{4}/\left[  2\right]
_{4}\text{\textquotedblright}=\left[  2/2\right]  _{4}=\left[  1\right]
_{4},
\]
but this is impossible (since $\left[  6\right]  _{4}=\left[  2\right]  _{4}$
but $\left[  3\right]  _{4}\neq\left[  1\right]  _{4}$).

For similar reasons, we cannot define $\left(  \left[  a\right]  _{n}\right)
^{\left[  b\right]  _{n}}$.
\end{remark}

For the outputs of our binary operations $+$, $-$ and $\cdot$ on
$\mathbb{Z}/n$, we shall use the same terminology as with integers:

\begin{definition}
\label{def.eqrel.Z/n.sum-diff-prod}\textbf{(a)} If $\alpha$ and $\beta$ are
two elements of $\mathbb{Z}/n$, then we shall refer to $\alpha+\beta$ as the
\textit{sum} of $\alpha$ and $\beta$.

\textbf{(b)} If $\alpha$ and $\beta$ are two elements of $\mathbb{Z}/n$, then
we shall refer to $\alpha-\beta$ as the \textit{difference} of $\alpha$ and
$\beta$.

\textbf{(c)} If $\alpha$ and $\beta$ are two elements of $\mathbb{Z}/n$, then
we shall refer to $\alpha\cdot\beta$ (also known as $\alpha\beta$) as the
\textit{product} of $\alpha$ and $\beta$.

\textbf{(d)} If $\alpha$ is an element of $\mathbb{Z}/n$, then the difference
$\left[  0\right]  _{n}-\alpha$ shall be denoted by $-\alpha$.
\end{definition}

Caution: While the remainder $i\%n$ and the residue class $\left[  i\right]
_{n}$ encode the same information about an integer $i$ (for a fixed positive
integer $n$), they are not the same thing! For example, any two integers $u$
and $v$ satisfy $\left[  u\right]  _{n}+\left[  v\right]  _{n}=\left[
u+v\right]  _{n}$ but don't always satisfy $u\%n+v\%n=\left(  u+v\right)
\%n$\ \ \ \ \footnote{Here is a specific example:%
\begin{align*}
\left[  2\right]  _{5}+\left[  3\right]  _{5}  &  =\left[  2+3\right]
_{5}=\left[  5\right]  _{5}=\left[  0\right]  _{5}%
,\ \ \ \ \ \ \ \ \ \ \text{but}\\
2\%5+3\%5  &  =2+3=5\neq0\%5;
\end{align*}
\par
Exercise \ref{exe.ent.quo-rem.u+v} \textbf{(a)} addresses how $u\%n+v\%n$
differs from $\left(  u+v\right)  \%n$.}. Thus, it is important to distinguish
between $i\%n$ and $\left[  i\right]  _{n}$.

\begin{remark}
We can view the residue classes modulo $24$ (that is, the elements of
$\mathbb{Z}/24$) as the hours of the day. For example, the time
\textquotedblleft2 AM\textquotedblright\ can be viewed as the residue class
$\left[  2\right]  _{24}$, whereas the time \textquotedblleft3
PM\textquotedblright\ can be viewed as the residue class $\left[  15\right]
_{24}$. From this point of view, addition of residue classes is a rather
familiar operation: For example, the statement that \textquotedblleft10 hours
from 3 PM is 1 AM\textquotedblright\ is saying $\left[  15\right]
_{24}+\left[  10\right]  _{24}=\left[  1\right]  _{24}$.
\end{remark}

\subsubsection{Scaling by $r\in\mathbb{Z}$}

Let us define another operation -- not binary this time -- on $\mathbb{Z}/n$:

\begin{definition}
\label{def.eqrel.Z/n.scaling}Fix $r\in\mathbb{Z}$.

For any $\alpha\in\mathbb{Z}/n$, we define a residue class $r\alpha
\in\mathbb{Z}/n$ by setting
\[
\left(  r\left[  a\right]  _{n}=\left[  ra\right]  _{n}%
\ \ \ \ \ \ \ \ \ \ \text{for any }a\in\mathbb{Z}\right)  .
\]
(In other words, for any $\alpha\in\mathbb{Z}/n$, we let $r\alpha=\left[
ra\right]  _{n}$, where $a$ is an integer satisfying $\alpha=\left[  a\right]
_{n}$.) This is well-defined, because of Proposition
\ref{prop.eqrel.Z/n.scaling.wd} \textbf{(a)} below.

We also write $r\cdot\left[  a\right]  _{n}$ for $r\left[  a\right]  _{n}$.
\end{definition}

\begin{proposition}
\label{prop.eqrel.Z/n.scaling.wd}Fix $r\in\mathbb{Z}$.

\textbf{(a)} For any $\alpha\in\mathbb{Z}/n$, the residue class $r\alpha
\in\mathbb{Z}/n$ in Definition \ref{def.eqrel.Z/n.scaling} is well-defined.

\textbf{(b)} For any $\alpha\in\mathbb{Z}/n$, we have $r\alpha=\left[
r\right]  _{n}\cdot\alpha$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.Z/n.scaling.wd}.]\textbf{(a)} We are
again in the same situation in which we were when defining the map $R$ in the
proof of Theorem \ref{thm.eqrel.Z/n.explicit}: We are trying to define a map
(in this case, the map%
\begin{align*}
\mathbb{Z}/n  &  \rightarrow\mathbb{Z}/n,\\
\alpha &  \mapsto r\alpha
\end{align*}
) by specifying how it acts on inputs of the form $\left[  a\right]  _{n}$,
but our definition refers to the integer $a$. We want to prove that this map
is well-defined. This requires checking that the output (that is, $\left[
ra\right]  _{n}$) depends only on the class $\left[  a\right]  _{n}$, but not
on the integer $a$. So we have to prove the following:

\begin{statement}
\textit{Claim 1:} Let $a_{1}$ and $a_{2}$ be two integers such that $\left[
a_{1}\right]  _{n}=\left[  a_{2}\right]  _{n}$. Then, $\left[  ra_{1}\right]
_{n}=\left[  ra_{2}\right]  _{n}$.
\end{statement}

[\textit{Proof of Claim 1:} Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)}
(applied to $a_{1}$ and $a_{2}$ instead of $a$ and $b$) shows that we have
$\left[  a_{1}\right]  _{n}=\left[  a_{2}\right]  _{n}$ if and only if
$a_{1}\equiv a_{2}\operatorname{mod}n$. Thus, we have $a_{1}\equiv
a_{2}\operatorname{mod}n$ (since $\left[  a_{1}\right]  _{n}=\left[
a_{2}\right]  _{n}$). On the other hand, we have the (obvious) congruence
$r\equiv r\operatorname{mod}n$. Multiplying this congruence by the congruence
$a_{1}\equiv a_{2}\operatorname{mod}n$, we obtain $ra_{1}\equiv ra_{2}%
\operatorname{mod}n$.

But Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $ra_{1}$ and
$ra_{2}$ instead of $a$ and $b$) shows that we have $\left[  ra_{1}\right]
_{n}=\left[  ra_{2}\right]  _{n}$ if and only if $ra_{1}\equiv ra_{2}%
\operatorname{mod}n$. Thus, we have $\left[  ra_{1}\right]  _{n}=\left[
ra_{2}\right]  _{n}$ (since $ra_{1}\equiv ra_{2}\operatorname{mod}n$). This
proves Claim 1.]

Claim 1 shows that in Definition \ref{def.eqrel.Z/n.scaling}, the residue
class $\left[  ra\right]  _{n}$ depends only on the class $\left[  a\right]
_{n}$, but not on the integer $a$. Thus, the residue class $r\alpha$ is indeed
well-defined for each $\alpha\in\mathbb{Z}/n$. This proves Proposition
\ref{prop.eqrel.Z/n.scaling.wd} \textbf{(a)}.

\textbf{(b)} Let $\alpha\in\mathbb{Z}/n$. Proposition \ref{prop.eqrel.Z/n.ab}
\textbf{(a)} shows that each element of $\mathbb{Z}/n$ can be written in the
form $\left[  s\right]  _{n}$ for some integer $s$. Thus, $\alpha\in
\mathbb{Z}/n$ can be written in this form. In other words, $\alpha=\left[
a\right]  _{n}$ for some integer $a$. Consider this $a$. Comparing%
\[
r\underbrace{\alpha}_{=\left[  a\right]  _{n}}=r\left[  a\right]  _{n}=\left[
ra\right]  _{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{by Definition
\ref{def.eqrel.Z/n.scaling}}\right)
\]
with%
\begin{align*}
\left[  r\right]  _{n}\cdot\underbrace{\alpha}_{=\left[  a\right]  _{n}}  &
=\left[  r\right]  _{n}\cdot\left[  a\right]  _{n}=\left[  r\cdot a\right]
_{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{by Definition \ref{def.eqrel.Z/n.op}
\textbf{(c)}}\right) \\
&  =\left[  ra\right]  _{n},
\end{align*}
we obtain $r\alpha=\left[  r\right]  _{n}\cdot\alpha$. This proves Proposition
\ref{prop.eqrel.Z/n.scaling.wd} \textbf{(b)}.
\end{proof}

For a fixed $r\in\mathbb{Z}$, we shall refer to the map
\begin{align*}
\mathbb{Z}/n  &  \rightarrow\mathbb{Z}/n,\\
\alpha &  \mapsto r\alpha
\end{align*}
as \textit{scaling by }$r$. This map is actually the same as multiplication by
the residue class $\left[  r\right]  _{n}$ (by Proposition
\ref{prop.eqrel.Z/n.scaling.wd} \textbf{(b)}). So why did we define it
\textquotedblleft from scratch\textquotedblright\ rather than piggybacking on
the already established definition of multiplication in $\mathbb{Z}/n$
(Definition \ref{def.eqrel.Z/n.op} \textbf{(c)})? The reason is that scaling
operations appear much more frequently in algebra than multiplication
operations. (For example, every vector space has a scaling operation, but
usually there is no way of multiplying two vectors.) Thus, it is useful to
have seen a scaling operation constructed independently.

\subsubsection{$k$-th powers for $k\in\mathbb{N}$}

Similarly to Definition \ref{def.eqrel.Z/n.scaling}, we can define what it
means to take the $k$-th power of a residue class in $\mathbb{Z}/n$, when $k$
is a nonnegative integer.

\begin{definition}
\label{def.eqrel.Z/n.kpower}Fix $k\in\mathbb{N}$.

For any $\alpha\in\mathbb{Z}/n$, we define a residue class $\alpha^{k}%
\in\mathbb{Z}/n$ by setting
\[
\left(  \left(  \left[  a\right]  _{n}\right)  ^{k}=\left[  a^{k}\right]
_{n}\ \ \ \ \ \ \ \ \ \ \text{for any }a\in\mathbb{Z}\right)  .
\]
(In other words, for any $\alpha\in\mathbb{Z}/n$, we let $\alpha^{k}=\left[
a^{k}\right]  _{n}$, where $a$ is an integer satisfying $\alpha=\left[
a\right]  _{n}$.) This is well-defined, because of Proposition
\ref{prop.eqrel.Z/n.kpower.wd} below.

If $\alpha\in\mathbb{Z}/n$, then we shall refer to $\alpha^{k}$ as the
$k$\textit{-th power} of $\alpha$.
\end{definition}

\begin{proposition}
\label{prop.eqrel.Z/n.kpower.wd}Fix $k\in\mathbb{N}$. For any $\alpha
\in\mathbb{Z}/n$, the residue class $\alpha^{k}\in\mathbb{Z}/n$ in Definition
\ref{def.eqrel.Z/n.kpower} is well-defined.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.Z/n.kpower.wd}.]This proof is analogous
to the above proof of Proposition \ref{prop.eqrel.Z/n.scaling.wd}
\textbf{(a)}; but instead of multiplying the two congruences $r\equiv
r\operatorname{mod}n$ and $a_{1}\equiv a_{2}\operatorname{mod}n$, we now need
to take the $k$-th power of the congruence $a_{1}\equiv a_{2}%
\operatorname{mod}n$. (Exercise \ref{exe.ent.mod.basics.k-power} allows us to
do that.)
\end{proof}

\begin{center}
\textbf{2019-02-25 lecture}
\end{center}

\subsubsection{Rules and properties for the operations}

\begin{convention}
We shall follow \href{https://en.wikipedia.org/wiki/Order_of_operations}{the
usual \textquotedblleft PEMDAS\textquotedblright\ rules for the order of
operations} when interpreting expressions involving the operations defined in
Definition \ref{def.eqrel.Z/n.op}, Definition \ref{def.eqrel.Z/n.scaling} and
Definition \ref{def.eqrel.Z/n.kpower}\footnote{The scaling operation (defined
in Definition \ref{def.eqrel.Z/n.scaling}) is treated exactly like
multiplication.}. Thus, for example, the expression \textquotedblleft%
$\alpha\cdot\beta+\gamma\cdot\delta$\textquotedblright\ means $\left(
\alpha\cdot\beta\right)  +\left(  \gamma\cdot\delta\right)  $ and not
$\alpha\cdot\left(  \beta+\gamma\right)  \cdot\delta$. Likewise, the
expression \textquotedblleft$\alpha\beta^{k}+r\gamma$\textquotedblright\ (with
$r\in\mathbb{Z}$) should be understood as \textquotedblleft$\left(
\alpha\left(  \beta^{k}\right)  \right)  +\left(  r\gamma\right)
$\textquotedblright\ and not in any other way.
\end{convention}

We shall now study some properties of the many \textquotedblleft
arithmetical\textquotedblright\ operations we have defined on $\mathbb{Z}/n$.

\begin{theorem}
\label{thm.eqrel.Z/n.rules}The following rules for addition, subtraction,
multiplication and scaling in $\mathbb{Z}/n$ hold:

\textbf{(a)} We have $\alpha+\beta=\beta+\alpha$ for any $\alpha,\beta
\in\mathbb{Z}/n$.

\textbf{(b)} We have $\alpha+\left(  \beta+\gamma\right)  =\left(
\alpha+\beta\right)  +\gamma$ for any $\alpha,\beta,\gamma\in\mathbb{Z}/n$.

\textbf{(c)} We have $\alpha+\left[  0\right]  _{n}=\left[  0\right]
_{n}+\alpha=\alpha$ for any $\alpha\in\mathbb{Z}/n$.

\textbf{(d)} We have $\alpha\cdot\left[  1\right]  _{n}=\left[  1\right]
_{n}\cdot\alpha=\alpha$ for any $\alpha\in\mathbb{Z}/n$.

\textbf{(e)} We have $\alpha\cdot\beta=\beta\cdot\alpha$ for any $\alpha
,\beta\in\mathbb{Z}/n$.

\textbf{(f)} We have $\alpha\cdot\left(  \beta\cdot\gamma\right)  =\left(
\alpha\cdot\beta\right)  \cdot\gamma$ for any $\alpha,\beta,\gamma
\in\mathbb{Z}/n$.

\textbf{(g)} We have $\alpha\cdot\left(  \beta+\gamma\right)  =\alpha
\beta+\alpha\gamma$ and $\left(  \alpha+\beta\right)  \cdot\gamma=\alpha
\gamma+\beta\gamma$ for any $\alpha,\beta,\gamma\in\mathbb{Z}/n$.

\textbf{(h)} We have $\alpha\cdot\left[  0\right]  _{n}=\left[  0\right]
_{n}\cdot\alpha=\left[  0\right]  _{n}$ for any $\alpha\in\mathbb{Z}/n$.

\textbf{(i)} If $\alpha,\beta,\gamma\in\mathbb{Z}/n$, then we have the
equivalence $\left(  \alpha-\beta=\gamma\right)  \Longleftrightarrow\left(
\alpha=\beta+\gamma\right)  $.

\textbf{(j)} We have $r\left(  \alpha+\beta\right)  =r\alpha+r\beta$ for any
$r\in\mathbb{Z}$ and $\alpha,\beta\in\mathbb{Z}/n$.

\textbf{(k)} We have $\left(  r+s\right)  \alpha=r\alpha+s\alpha$ for any
$r,s\in\mathbb{Z}$ and $\alpha\in\mathbb{Z}/n$.

\textbf{(l)} We have $r\left(  s\alpha\right)  =\left(  rs\right)  \alpha$ for
any $r,s\in\mathbb{Z}$ and $\alpha\in\mathbb{Z}/n$.

\textbf{(m)} We have $r\left(  \alpha\beta\right)  =\left(  r\alpha\right)
\beta=\alpha\left(  r\beta\right)  $ for any $r\in\mathbb{Z}$ and
$\alpha,\beta\in\mathbb{Z}/n$.

\textbf{(n)} We have $-\left(  r\alpha\right)  =\left(  -r\right)
\alpha=r\left(  -\alpha\right)  $ for any $r\in\mathbb{Z}$ and $\alpha
\in\mathbb{Z}/n$.

\textbf{(o)} We have $1\alpha=\alpha$ for any $\alpha\in\mathbb{Z}/n$.

\textbf{(p)} We have $\left(  -1\right)  \alpha=-\alpha$ for any $\alpha
\in\mathbb{Z}/n$.

\textbf{(q)} We have $-\left(  \alpha+\beta\right)  =\left(  -\alpha\right)
+\left(  -\beta\right)  $ for any $\alpha,\beta\in\mathbb{Z}/n$.

\textbf{(r)} We have $-\left[  0\right]  _{n}=\left[  0\right]  _{n}$.

\textbf{(s)} We have $-\left(  -\alpha\right)  =\alpha$ for any $\alpha
\in\mathbb{Z}/n$.

\textbf{(t)} We have $-\left(  \alpha\beta\right)  =\left(  -\alpha\right)
\beta=\alpha\left(  -\beta\right)  $ for any $\alpha,\beta\in\mathbb{Z}/n$.

\textbf{(u)} We have $\alpha-\beta-\gamma=\alpha-\left(  \beta+\gamma\right)
$ for any $\alpha,\beta,\gamma\in\mathbb{Z}/n$. (Here and in the following,
\textquotedblleft$\alpha-\beta-\gamma$\textquotedblright\ should be read as
\textquotedblleft$\left(  \alpha-\beta\right)  -\gamma$\textquotedblright.)
\end{theorem}

These properties should all look familiar, as they mirror the classical
properties of the arithmetic operations on integers, rational numbers and real
numbers (with the caveat that the residue classes $\left[  0\right]  _{n}$ and
$\left[  1\right]  _{n}$ take on the roles of the numbers $0$ and $1$). For
example, Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(g)} corresponds to the
laws of distributivity for numbers. Parts \textbf{(a)}, \textbf{(b)},
\textbf{(c)}, \textbf{(i)}, \textbf{(j)}, \textbf{(k)}, \textbf{(l)} and
\textbf{(o)} of Theorem \ref{thm.eqrel.Z/n.rules} furthermore are reminiscent
of the axioms for a vector space (with the caveat that scaling by $r$ is only
defined for integers $r$ here, so $\mathbb{Z}/n$ is not precisely a vector space).

\begin{proof}
[Proof of Theorem \ref{thm.eqrel.Z/n.rules}.]Let us first prove Theorem
\ref{thm.eqrel.Z/n.rules} \textbf{(f)}:

\textbf{(f)} Let $\alpha,\beta,\gamma\in\mathbb{Z}/n$. Proposition
\ref{prop.eqrel.Z/n.ab} \textbf{(a)} shows that each element of $\mathbb{Z}/n$
can be written in the form $\left[  s\right]  _{n}$ for some integer $s$.
Thus, in particular, the element $\alpha$ can be written in this form. In
other words, there exists an integer $a$ such that $\alpha=\left[  a\right]
_{n}$. Similarly, there exists an integer $b$ such that $\beta=\left[
b\right]  _{n}$. Similarly, there exists an integer $c$ such that
$\gamma=\left[  c\right]  _{n}$. Consider these integers $a,b,c$.

Now,%
\begin{align}
\underbrace{\alpha}_{=\left[  a\right]  _{n}}\cdot\left(  \underbrace{\beta
}_{=\left[  b\right]  _{n}}\cdot\underbrace{\gamma}_{=\left[  c\right]  _{n}%
}\right)   &  =\left[  a\right]  _{n}\cdot\underbrace{\left(  \left[
b\right]  _{n}\cdot\left[  c\right]  _{n}\right)  }_{\substack{=\left[  b\cdot
c\right]  _{n}\\\text{(by Definition \ref{def.eqrel.Z/n.op} \textbf{(c)})}%
}}=\left[  a\right]  _{n}\cdot\left[  b\cdot c\right]  _{n}\nonumber\\
&  =\left[  a\cdot\left(  b\cdot c\right)  \right]  _{n}
\label{pf.thm.eqrel.Z/n.rules.f.1}%
\end{align}
(by Definition \ref{def.eqrel.Z/n.op} \textbf{(c)}) and%
\begin{align}
\left(  \underbrace{\alpha}_{=\left[  a\right]  _{n}}\cdot\underbrace{\beta
}_{=\left[  b\right]  _{n}}\right)  \cdot\underbrace{\gamma}_{=\left[
c\right]  _{n}}  &  =\underbrace{\left(  \left[  a\right]  _{n}\cdot\left[
b\right]  _{n}\right)  }_{\substack{=\left[  a\cdot b\right]  _{n}\\\text{(by
Definition \ref{def.eqrel.Z/n.op} \textbf{(c)})}}}\cdot\left[  c\right]
_{n}=\left[  a\cdot b\right]  _{n}\cdot\left[  c\right]  _{n}\nonumber\\
&  =\left[  \left(  a\cdot b\right)  \cdot c\right]  _{n}
\label{pf.thm.eqrel.Z/n.rules.f.2}%
\end{align}
(by Definition \ref{def.eqrel.Z/n.op} \textbf{(c)}).

But it is well-known that multiplication of integers is associative. Thus,
$a\cdot\left(  b\cdot c\right)  =\left(  a\cdot b\right)  \cdot c$. Hence,
$\left[  a\cdot\left(  b\cdot c\right)  \right]  _{n}=\left[  \left(  a\cdot
b\right)  \cdot c\right]  _{n}$. In other words, the right hand sides of the
equalities (\ref{pf.thm.eqrel.Z/n.rules.f.1}) and
(\ref{pf.thm.eqrel.Z/n.rules.f.2}) are equal. Hence, the left hand sides of
these equalities must also be equal. In other words, $\alpha\cdot\left(
\beta\cdot\gamma\right)  =\left(  \alpha\cdot\beta\right)  \cdot\gamma$. This
proves Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(f)}.

The idea of the above proof of Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(f)}
was simple: We fixed a representative for each residue class involved (namely,
we fixed representatives $a,b,c$ for the residue classes $\alpha,\beta,\gamma
$), and rewrote each of the two sides of the alleged equality (which, in our
case, was $\alpha\cdot\left(  \beta\cdot\gamma\right)  =\left(  \alpha
\cdot\beta\right)  \cdot\gamma$) in terms of these representatives (obtaining
$\left[  a\cdot\left(  b\cdot c\right)  \right]  _{n}$ for the left hand side,
and $\left[  \left(  a\cdot b\right)  \cdot c\right]  _{n}$ for the right hand
side). Thus, the equality that we had to prove followed from the analogous
equality for integers (in our case, $a\cdot\left(  b\cdot c\right)  =\left(
a\cdot b\right)  \cdot c$), which was well-known. In short, we have realized
that the equality $\alpha\cdot\left(  \beta\cdot\gamma\right)  =\left(
\alpha\cdot\beta\right)  \cdot\gamma$ for $\alpha,\beta,\gamma\in\mathbb{Z}/n$
is \textquotedblleft inherited from $\mathbb{Z}$\textquotedblright\ (in the
sense that it follows straightforwardly from the corresponding property
$a\cdot\left(  b\cdot c\right)  =\left(  a\cdot b\right)  \cdot c$ of integers
$a,b,c\in\mathbb{Z}$). This strategy proves all the other parts of Theorem
\ref{thm.eqrel.Z/n.rules} in the same way, except for part \textbf{(i)}%
.\footnote{The reason why this works is that the operations $+,-,\cdot$ on
$\mathbb{Z}/n$ as well as scaling by integers are defined by picking a
representative of each residue class and doing the analogous operation
\textbf{with the representatives} (and then taking the residue class again).}
Part \textbf{(i)} does not lend itself to such a proof, since it claims not an
equality but rather an equivalence between two equalities. So let us prove
part \textbf{(i)} separately:

\textbf{(i)} Let $\alpha,\beta,\gamma\in\mathbb{Z}/n$. Proposition
\ref{prop.eqrel.Z/n.ab} \textbf{(a)} shows that each element of $\mathbb{Z}/n$
can be written in the form $\left[  s\right]  _{n}$ for some integer $s$.
Thus, in particular, the element $\alpha$ can be written in this form. In
other words, there exists an integer $a$ such that $\alpha=\left[  a\right]
_{n}$. Similarly, there exists an integer $b$ such that $\beta=\left[
b\right]  _{n}$. Similarly, there exists an integer $c$ such that
$\gamma=\left[  c\right]  _{n}$. Consider these integers $a,b,c$.

We have $\underbrace{\alpha}_{=\left[  a\right]  _{n}}-\underbrace{\beta
}_{=\left[  b\right]  _{n}}=\left[  a\right]  _{n}-\left[  b\right]
_{n}=\left[  a-b\right]  _{n}$ (by Definition \ref{def.eqrel.Z/n.op}
\textbf{(b)}) and $\underbrace{\beta}_{=\left[  b\right]  _{n}}%
+\underbrace{\gamma}_{=\left[  c\right]  _{n}}=\left[  b\right]  _{n}+\left[
c\right]  _{n}=\left[  b+c\right]  _{n}$ (by Definition \ref{def.eqrel.Z/n.op}
\textbf{(a)}). Now, we have the following chain of logical equivalences:%
\begin{align}
\left(  \alpha-\beta=\gamma\right)  \  &  \Longleftrightarrow\ \left(  \left[
a-b\right]  _{n}=\left[  c\right]  _{n}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\alpha-\beta=\left[  a-b\right]  _{n}\text{ and }\gamma=\left[
c\right]  _{n}\right) \nonumber\\
&  \Longleftrightarrow\ \left(  a-b\equiv c\operatorname{mod}n\right)
\label{pf.thm.eqrel.Z/n.rules.i.1}%
\end{align}
(since Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $a-b$ and
$c$ instead of $a$ and $b$) shows that we have $\left[  a-b\right]
_{n}=\left[  c\right]  _{n}$ if and only if $a-b\equiv c\operatorname{mod}n$).
Also, we have the following chain of logical equivalences:%
\begin{align}
\left(  \alpha=\beta+\gamma\right)  \  &  \Longleftrightarrow\ \left(  \left[
a\right]  _{n}=\left[  b+c\right]  _{n}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\alpha=\left[  a\right]  _{n}\text{ and }\beta+\gamma=\left[
b+c\right]  _{n}\right) \nonumber\\
&  \Longleftrightarrow\ \left(  a\equiv b+c\operatorname{mod}n\right)
\label{pf.thm.eqrel.Z/n.rules.i.2}%
\end{align}
(since Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $b+c$
instead of $b$) shows that we have $\left[  a\right]  _{n}=\left[  b+c\right]
_{n}$ if and only if $a\equiv b+c\operatorname{mod}n$). Finally, Exercise
\ref{exe.ent.mod.diff} shows that we have $a-b\equiv c\operatorname{mod}n$ if
and only if $a\equiv b+c\operatorname{mod}n$; thus, we have the equivalence
$\left(  a-b\equiv c\operatorname{mod}n\right)  \ \Longleftrightarrow\ \left(
a\equiv b+c\operatorname{mod}n\right)  $.

Now, we have the following chain of logical equivalences:%
\begin{align*}
\left(  \alpha-\beta=\gamma\right)  \  &  \Longleftrightarrow\ \left(
a-b\equiv c\operatorname{mod}n\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{pf.thm.eqrel.Z/n.rules.i.1})}\right) \\
&  \Longleftrightarrow\ \left(  a\equiv b+c\operatorname{mod}n\right)
\ \Longleftrightarrow\ \left(  \alpha=\beta+\gamma\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.thm.eqrel.Z/n.rules.i.2}%
)}\right)  .
\end{align*}
This proves Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(i)}.
\end{proof}

Recall the concept of a finite sum of integers (i.e., a sum of the form
$\sum_{i\in I}a_{i}$, where $I$ is a finite set and $a_{i}$ is an integer for
each $i\in I$), and the analogous concept of a finite product of integers
(i.e., a product of the form $\prod_{i\in I}a_{i}$). These concepts are
defined recursively\footnote{See \cite[\S 1.4.1 and \S 1.4.3]{detnotes} for
their definitions, and \cite[\S 2.14]{detnotes} for a proof that these are
well-defined.} and satisfy various rules\footnote{such as $\sum_{i\in
I}\left(  a_{i}+b_{i}\right)  =\sum_{i\in I}a_{i}+\sum_{i\in I}b_{i}$ (where
$a_{i}$ and $b_{i}$ are two integers for each $i\in I$) or $\sum_{i\in I}%
a_{i}=\sum_{i\in J}a_{i}+\sum_{i\in I\setminus J}a_{i}$ (where $J$ is a subset
of $I$)}. See \cite[\S 1.4]{detnotes} for a comprehensive list of these rules
and \cite[\S 2.14]{detnotes} for their proofs.

\begin{definition}
\label{def.eqrel.Z/n.sums}In the same vein, we define the concept of a finite
sum of residue classes in $\mathbb{Z}/n$ (i.e., a sum of the form $\sum_{i\in
I}\alpha_{i}$, where $I$ is a finite set and $\alpha_{i}\in\mathbb{Z}/n$ for
each $i\in I$), and the analogous concept of a finite product of residue
classes in $\mathbb{Z}/n$ (i.e., a product of the form $\prod_{i\in I}%
\alpha_{i}$, where $I$ is a finite set and $\alpha_{i}\in\mathbb{Z}/n$ for
each $i\in I$).

More precisely, the concept of a finite sum $\sum_{i\in I}\alpha_{i}$ (with
$I$ being a finite set, and with $\alpha_{i}\in\mathbb{Z}/n$ for each $i\in
I$) is defined recursively as follows:

\begin{itemize}
\item If the set $I$ is empty (that is, $\left\vert I\right\vert =0$), then
$\sum_{i\in I}\alpha_{i}$ is defined to be $\left[  0\right]  _{n}%
\in\mathbb{Z}/n$ (and called an empty sum).

\item Otherwise, we pick an arbitrary element $t\in I$, and set%
\[
\sum_{i\in I}\alpha_{i}=\alpha_{t}+\sum_{i\in I\setminus\left\{  t\right\}
}\alpha_{i}.
\]
(The sum $\sum_{i\in I\setminus\left\{  t\right\}  }\alpha_{i}$ on the right
hand side is a sum over a smaller set than $I$, whence we can assume it to
already be defined in this recursive definition.)
\end{itemize}

This definition is well-defined (i.e., the choice of element $t$ does not
influence the final value of the sum), by Proposition
\ref{prop.eqrel.Z/n.sums.wd} \textbf{(a)} below.

The concept of a finite product $\prod_{i\in I}\alpha_{i}$ is defined
similarly, except that we use multiplication instead of addition (and we
define the empty product to be $\left[  1\right]  _{n}$ instead of $\left[
0\right]  _{n}$).
\end{definition}

We will use the usual shorthands for special kinds of finite sums and
products. For example, if $I$ is an interval $\left\{  p,p+1,\ldots,q\right\}
$ of integers (and if $\alpha_{i}\in\mathbb{Z}/n$ for each $i\in I$), then the
sum $\sum_{i\in I}\alpha_{i}$ will also be denoted by $\sum_{i=p}^{q}%
\alpha_{i}$ or $\alpha_{p}+\alpha_{p+1}+\cdots+\alpha_{q}$. Likewise for
products. Thus, for example, $\alpha_{1}+\alpha_{2}+\cdots+\alpha_{k}$ and
$\alpha_{1}\alpha_{2}\cdots\alpha_{k}$ are well-defined whenever $\alpha
_{1},\alpha_{2},\ldots,\alpha_{k}\in\mathbb{Z}/n$.

\begin{proposition}
\label{prop.eqrel.Z/n.sums.wd}\textbf{(a)} Definition \ref{def.eqrel.Z/n.sums}
is well-defined.

\textbf{(b)} Finite sums ($\sum_{i\in I}\alpha_{i}$) and finite products
($\prod_{i\in I}\alpha_{i}$) of elements $\alpha_{i}\in\mathbb{Z}/n$ satisfy
the same rules that finite sums and finite products of integers satisfy.

\textbf{(c)} If $a_{1},a_{2},\ldots,a_{k}$ are $k$ integers, then
\begin{align*}
\left[  a_{1}\right]  _{n}+\left[  a_{2}\right]  _{n}+\cdots+\left[
a_{k}\right]  _{n}  &  =\left[  a_{1}+a_{2}+\cdots+a_{k}\right]
_{n}\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left[  a_{1}\right]  _{n}\cdot\left[  a_{2}\right]  _{n}\cdot\cdots
\cdot\left[  a_{k}\right]  _{n}  &  =\left[  a_{1}a_{2}\cdots a_{k}\right]
_{n}.
\end{align*}

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.eqrel.Z/n.sums.wd}.]\textbf{(a)} In
\cite[Theorem 2.118 \textbf{(a)}]{detnotes}, it is proven that finite sums of
integers are well-defined. The same argument (but relying on Theorem
\ref{thm.eqrel.Z/n.rules} instead of the usual rules of commutativity,
associativity etc. for integers) shows that finite sums of elements
$\alpha_{i}\in\mathbb{Z}/n$ are well-defined. The analogous fact for products
is proven in the same way, except that we need to replace $\left[  0\right]
_{n}$ by $\left[  1\right]  _{n}$ and properties of addition by corresponding
properties of multiplication.

\textbf{(b)} The proofs of the properties of finite sums and finite products
of elements of $\mathbb{Z}/n$ are identical to the analogous proofs for
integers, but (again) rely on Theorem \ref{thm.eqrel.Z/n.rules} instead of the
usual rules of commutativity, associativity etc. for integers.

\textbf{(c)} This can be proven by a straightforward induction on $k$.
\end{proof}

Also, the standard rules for exponents apply to residue classes:

\begin{theorem}
\label{thm.eqrel.Z/n.rules-exp}\textbf{(a)} We have $\alpha^{0}=\left[
1\right]  _{n}$ for any $\alpha\in\mathbb{Z}/n$.

\textbf{(b)} We have $\alpha^{1}=\alpha$ for any $\alpha\in\mathbb{Z}/n$.

\textbf{(c)} We have $\alpha^{k}=\underbrace{\alpha\alpha\cdots\alpha
}_{k\text{ times}}$ for any $\alpha\in\mathbb{Z}/n$ and $k\in\mathbb{N}$.

\textbf{(d)} We have $\alpha^{u+v}=\alpha^{u}\alpha^{v}$ for any $\alpha
\in\mathbb{Z}/n$ and any $u,v\in\mathbb{N}$.

\textbf{(e)} We have $\left(  \alpha\beta\right)  ^{k}=\alpha^{k}\beta^{k}$
for any $\alpha,\beta\in\mathbb{Z}/n$ and $k\in\mathbb{N}$.

\textbf{(f)} We have $\left(  \alpha^{u}\right)  ^{v}=\alpha^{uv}$ for any
$\alpha\in\mathbb{Z}/n$ and any $u,v\in\mathbb{N}$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.eqrel.Z/n.rules-exp}.]Each part of Theorem
\ref{thm.eqrel.Z/n.rules-exp} follows from the analogous property of integers,
in the same way as we derived Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(f)}
from the associativity of multiplication for integers. (Note that Proposition
\ref{prop.eqrel.Z/n.sums.wd} \textbf{(c)} has to be used in proving Theorem
\ref{thm.eqrel.Z/n.rules-exp} \textbf{(c)}.)
\end{proof}

Also, the binomial formula holds for residue classes:

\begin{theorem}
\label{thm.eqrel.Z/n.binf}Let $\alpha,\beta\in\mathbb{Z}/n$ and $m\in
\mathbb{N}$. Then,%
\[
\left(  \alpha+\beta\right)  ^{m}=\sum_{k=0}^{m}\dbinom{m}{k}\alpha^{k}%
\beta^{m-k}.
\]

\end{theorem}

\begin{proof}
This follows from Theorem \ref{thm.binom.binf}, in the same way as we derived
Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(f)} from the associativity of
multiplication for integers.
\end{proof}

\subsection{\label{sect.equiv.modinv}Modular inverses revisited}

\begin{convention}
For the whole Section \ref{sect.equiv.modinv}, we fix a positive integer $n$.
\end{convention}

In this section, we will see how modular inverses become actual inverses when
we consider residue classes instead of numbers.

Recall that if $a$ is an integer, then an \textit{inverse of }$a$\textit{ in
}$\mathbb{Z}$ means an integer $a^{\prime}\in\mathbb{Z}$ satisfying
$aa^{\prime}=1$. The only two integers that have an inverse in $\mathbb{Z}$
are $1$ and $-1$. The integer $1$ has only one inverse (namely, itself). The
integer $-1$ has only one inverse (namely, itself). Thus, \textquotedblleft
inverse in $\mathbb{Z}$\textquotedblright\ is not a very interesting notion.

Let us now define an analogous notion for $\mathbb{Z}/n$:

\begin{definition}
\label{def.equiv.modinv.inverse}Let $\alpha\in\mathbb{Z}/n$. An
\textit{inverse} of $\alpha$ means an $\alpha^{\prime}\in\mathbb{Z}/n$ such
that $\alpha\cdot\alpha^{\prime}=\left[  1\right]  _{n}$.
\end{definition}

For example, $\left[  2\right]  _{5}$ is an inverse of $\left[  3\right]
_{5}$ for $n=5$, since $\left[  3\right]  _{5}\cdot\left[  2\right]
_{5}=\left[  3\cdot2\right]  _{5}=\left[  6\right]  _{5}=\left[  1\right]
_{5}$.

It turns out that inverses of residue classes $\alpha\in\mathbb{Z}/n$ exist
much more frequently than inverses of integers in $\mathbb{Z}$:

\begin{proposition}
\label{prop.equiv.modinv.exiuni}Let $a\in\mathbb{Z}$.

\textbf{(a)} If $\left[  a\right]  _{n}\in\mathbb{Z}/n$ has an inverse, then
$a\perp n$.

\textbf{(b)} If $a\perp n$, then $\left[  a\right]  _{n}\in\mathbb{Z}/n$ has a
unique inverse.
\end{proposition}

As we will see in the proof of this proposition, the inverse of a residue
class $\left[  a\right]  _{n}$ is simply the residue class $\left[  a^{\prime
}\right]  _{n}$ of a modular inverse $a^{\prime}$ of $a$ modulo $n$; thus, the
existence part of Proposition \ref{prop.equiv.modinv.exiuni} \textbf{(b)}
(i.e., the claim that $\left[  a\right]  _{n}$ has an inverse) is just Theorem
\ref{thm.ent.coprime.modinv} \textbf{(b)} in disguise. However, before we
start proving Proposition \ref{prop.equiv.modinv.exiuni}, let us state the
uniqueness part (i.e., the claim that the inverse of $\left[  a\right]  _{n}$
is unique) as a separate fact:

\begin{proposition}
\label{prop.equiv.modinv.uni}Let $\alpha\in\mathbb{Z}/n$. Then, $\alpha$ has
\textbf{at most one} inverse.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.equiv.modinv.uni}.]Let $\beta$ and $\gamma$ be
two inverses of $\alpha$. We shall show that $\beta=\gamma$.

We have $\alpha\cdot\beta=\left[  1\right]  _{n}$ (since $\beta$ is an inverse
of $\alpha$) and $\alpha\cdot\gamma=\left[  1\right]  _{n}$ (since $\gamma$ is
an inverse of $\alpha$). Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(e)}
(applied to $\gamma$ and $\alpha$ instead of $\alpha$ and $\beta$) yields
$\gamma\cdot\alpha=\alpha\cdot\gamma=\left[  1\right]  _{n}$.

Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(d)} (applied to $\gamma$ instead of
$\alpha$) yields $\gamma\cdot\left[  1\right]  _{n}=\left[  1\right]
_{n}\cdot\gamma=\gamma$. Also, Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(d)}
(applied to $\beta$ instead of $\alpha$) yields $\beta\cdot\left[  1\right]
_{n}=\left[  1\right]  _{n}\cdot\beta=\beta$.

Theorem \ref{thm.eqrel.Z/n.rules} \textbf{(f)} (applied to $\gamma$, $\alpha$
and $\beta$ instead of $\alpha$, $\beta$ and $\gamma$) shows that $\gamma
\cdot\left(  \alpha\cdot\beta\right)  =\left(  \gamma\cdot\alpha\right)
\cdot\beta$. Now, comparing
\[
\gamma\cdot\left(  \underbrace{\alpha\cdot\beta}_{=\left[  1\right]  _{n}%
}\right)  =\gamma\cdot\left[  1\right]  _{n}=\gamma
\]
with%
\[
\gamma\cdot\left(  \alpha\cdot\beta\right)  =\left(  \underbrace{\gamma
\cdot\alpha}_{=\left[  1\right]  _{n}}\right)  \cdot\beta=\left[  1\right]
_{n}\cdot\beta=\beta,
\]
we obtain $\beta=\gamma$.

Now, forget that we fixed $\beta$ and $\gamma$. We thus have proven that if
$\beta$ and $\gamma$ are two inverses of $\alpha$, then $\beta=\gamma$. In
other words, any two inverses of $\alpha$ must be equal. In other words,
$\alpha$ has at most one inverse. This proves Proposition
\ref{prop.equiv.modinv.uni}.
\end{proof}

Note that in the above proof of Proposition \ref{prop.equiv.modinv.uni}, we
have never had to pick a representative of the residue class $\alpha$ (nor of
any other class). This is because this proof is actually an instance of a much
more general argument. And indeed, you might recall that a very similar
argument is used to prove the classical facts that

\begin{itemize}
\item a map has at most one inverse;

\item a matrix has at most one inverse.
\end{itemize}

\noindent To be more precise, the proofs of these two facts differ slightly
from our proof of Proposition \ref{prop.equiv.modinv.uni}, because the
definitions of an inverse of a map and of an inverse of a matrix differ from
Definition \ref{def.equiv.modinv.inverse}. Indeed, in Definition
\ref{def.equiv.modinv.inverse}, we have only required the inverse
$\alpha^{\prime}$ of $\alpha\in\mathbb{Z}/n$ to satisfy the \textbf{single}
equation $\alpha\cdot\alpha^{\prime}=\left[  1\right]  _{n}$, whereas an
inverse $g$ of a map $f$ is required to satisfy the \textbf{two} equations
$f\circ g=\operatorname*{id}$ and $g\circ f=\operatorname*{id}$ (and likewise,
an inverse $B$ of a matrix $A$ is required to satisfy the \textbf{two}
equations $AB=I$ and $BA=I$ for the appropriate identity matrices $I$). But
this difference is not substantial: The multiplication of residue classes in
$\mathbb{Z}/n$ is commutative (by Theorem \ref{thm.eqrel.Z/n.rules}
\textbf{(e)}) (unlike the composition of maps or the multiplication of
matrices); thus, the single equation $\alpha\cdot\alpha^{\prime}=\left[
1\right]  _{n}$ automatically implies $\alpha^{\prime}\cdot\alpha=\left[
1\right]  _{n}$. Hence, we could have as well required $\alpha^{\prime}$ to
satisfy both equations $\alpha\cdot\alpha^{\prime}=\left[  1\right]  _{n}$ and
$\alpha^{\prime}\cdot\alpha=\left[  1\right]  _{n}$ in Definition
\ref{def.equiv.modinv.inverse}, and nothing would change.

Let us now prove Proposition \ref{prop.equiv.modinv.exiuni}:

\begin{proof}
[Proof of Proposition \ref{prop.equiv.modinv.exiuni}.]\textbf{(a)} Assume that
$\left[  a\right]  _{n}\in\mathbb{Z}/n$ has an inverse. Let $\beta$ be this
inverse. Write the residue class $\beta\in\mathbb{Z}/n$ in the form $\left[
b\right]  _{n}$ for some integer $b$. Now, $\beta$ is an inverse of $\left[
a\right]  _{n}$. In other words, $\left[  a\right]  _{n}\cdot\beta=\left[
1\right]  _{n}$ (by the definition of \textquotedblleft
inverse\textquotedblright). But $\left[  a\right]  _{n}\cdot\underbrace{\beta
}_{=\left[  b\right]  _{n}}=\left[  a\right]  _{n}\cdot\left[  b\right]
_{n}=\left[  a\cdot b\right]  _{n}$ (by the definition of multiplication on
$\mathbb{Z}/n$). Comparing this with $\left[  a\right]  _{n}\cdot\beta=\left[
1\right]  _{n}$, we obtain $\left[  a\cdot b\right]  _{n}=\left[  1\right]
_{n}$. By Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $a\cdot
b$ and $1$ instead of $a$ and $b$), this yields $a\cdot b\equiv
1\operatorname{mod}n$. Hence, there exists an $a^{\prime}\in\mathbb{Z}$ such
that $aa^{\prime}\equiv1\operatorname{mod}n$ (namely, $a^{\prime}=b$). Thus,
Theorem \ref{thm.ent.coprime.modinv} \textbf{(c)} yields $a\perp n$. This
proves Proposition \ref{prop.equiv.modinv.exiuni} \textbf{(a)}.

\textbf{(b)} Assume that $a\perp n$. Hence, Theorem
\ref{thm.ent.coprime.modinv} \textbf{(b)} yields that there exists an
$a^{\prime}\in\mathbb{Z}$ such that $aa^{\prime}\equiv1\operatorname{mod}n$.
Consider this $a^{\prime}$. From $aa^{\prime}\equiv1\operatorname{mod}n$, we
obtain $\left[  aa^{\prime}\right]  _{n}=\left[  1\right]  _{n}$ (by
Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)}, applied to $aa^{\prime}$ and
$1$ instead of $a$ and $b$). But the definition of multiplication on
$\mathbb{Z}/n$ yields $\left[  a\right]  _{n}\cdot\left[  a^{\prime}\right]
_{n}=\left[  a\cdot a^{\prime}\right]  _{n}=\left[  aa^{\prime}\right]
_{n}=\left[  1\right]  _{n}$. In other words, $\left[  a^{\prime}\right]
_{n}$ is an inverse of $\left[  a\right]  _{n}$. Hence, $\left[  a\right]
_{n}$ has \textbf{at least }one inverse (namely, $\left[  a^{\prime}\right]
_{n}$).

But Proposition \ref{prop.equiv.modinv.uni} (applied to $\alpha=\left[
a\right]  _{n}$) shows that $\left[  a\right]  _{n}$ has \textbf{at most }one inverse.

Thus, we conclude that $\left[  a\right]  _{n}$ has a unique inverse (since we
already know that $\left[  a\right]  _{n}$ has \textbf{at least }one inverse
and has \textbf{at most }one inverse). This proves Proposition
\ref{prop.equiv.modinv.exiuni}.
\end{proof}

\begin{corollary}
\label{cor.equiv.modinv.Unphi}Let $U_{n}$ be the set of all residue classes
$\alpha\in\mathbb{Z}/n$ that have an inverse. Then:

\textbf{(a)} For an integer $a$, we have the logical equivalence $\left(
\left[  a\right]  _{n}\in U_{n}\right)  \Longleftrightarrow\left(  a\perp
n\right)  $.

\textbf{(b)} We have $\left\vert U_{n}\right\vert =\phi\left(  n\right)  $.
\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.equiv.modinv.Unphi}.]\textbf{(a)} Let $a$ be an
integer. Proposition \ref{prop.equiv.modinv.exiuni} \textbf{(a)} yields the
logical implication
\begin{equation}
\left(  \left[  a\right]  _{n}\text{ has an inverse}\right)  \ \Longrightarrow
\ \left(  a\perp n\right)  . \label{pf.cor.equiv.modinv.Unphi.a.1}%
\end{equation}
But Proposition \ref{prop.equiv.modinv.exiuni} \textbf{(b)} yields the logical
implication
\begin{equation}
\left(  a\perp n\right)  \ \Longrightarrow\ \left(  \left[  a\right]
_{n}\text{ has a unique inverse}\right)  \ \Longrightarrow\ \left(  \left[
a\right]  _{n}\text{ has an inverse}\right)  .
\label{pf.cor.equiv.modinv.Unphi.a.2}%
\end{equation}
Combining the two implications (\ref{pf.cor.equiv.modinv.Unphi.a.1}) and
(\ref{pf.cor.equiv.modinv.Unphi.a.2}), we obtain the equivalence%
\begin{equation}
\left(  \left[  a\right]  _{n}\text{ has an inverse}\right)
\ \Longleftrightarrow\ \left(  a\perp n\right)  .
\label{pf.cor.equiv.modinv.Unphi.a.3}%
\end{equation}
But $U_{n}$ was defined as the set of all residue classes $\alpha\in
\mathbb{Z}/n$ that have an inverse. Hence, we have the following chain of
equivalences:%
\[
\left(  \left[  a\right]  _{n}\in U_{n}\right)  \ \Longleftrightarrow\ \left(
\left[  a\right]  _{n}\text{ has an inverse}\right)  \ \Longleftrightarrow
\ \left(  a\perp n\right)
\]
(by (\ref{pf.cor.equiv.modinv.Unphi.a.3})). This proves Corollary
\ref{cor.equiv.modinv.Unphi} \textbf{(a)}.

\textbf{(b)} Theorem \ref{thm.eqrel.Z/n.explicit} says that the set
$\mathbb{Z}/n$ has exactly $n$ elements, namely \newline$\left[  0\right]
_{n},\left[  1\right]  _{n},\ldots,\left[  n-1\right]  _{n}$ (and in
particular, these $n$ elements are all distinct). Thus, the map%
\begin{align*}
P:\left\{  0,1,\ldots,n-1\right\}   &  \rightarrow\mathbb{Z}/n,\\
s  &  \mapsto\left[  s\right]  _{n}%
\end{align*}
is bijective\footnote{We also have explicitly proven this fact during our
proof of Theorem \ref{thm.eqrel.Z/n.explicit}.}. Consider this map $P$. For
each integer $a$, we have the logical equivalence%
\begin{equation}
\left(  \underbrace{P\left(  a\right)  }_{\substack{=\left[  a\right]
_{n}\\\text{(by the definition of }P\text{)}}}\in U_{n}\right)
\ \Longleftrightarrow\ \left(  \left[  a\right]  _{n}\in U_{n}\right)
\ \Longleftrightarrow\ \left(  a\perp n\right)
\label{pf.cor.equiv.modinv.Unphi.b.equiv}%
\end{equation}
(by Corollary \ref{cor.equiv.modinv.Unphi} \textbf{(a)}).

But the map $P$ is bijective. Hence, we can substitute $P\left(  a\right)  $
for $\alpha$ when counting the number of $\alpha\in U_{n}$. We thus obtain%
\begin{align*}
&  \left(  \text{the number of }\alpha\in U_{n}\right) \\
&  =\left(  \text{the number of }a\in\left\{  0,1,\ldots,n-1\right\}  \text{
such that }P\left(  a\right)  \in U_{n}\right) \\
&  =\left(  \text{the number of }a\in\left\{  0,1,\ldots,n-1\right\}  \text{
such that }a\perp n\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because for each }a\in\left\{  0,1,\ldots,n-1\right\}  \text{, we have
the logical}\\
\text{equivalence }\left(  P\left(  a\right)  \in U_{n}\right)
\ \Longleftrightarrow\ \left(  a\perp n\right)  \text{ (by
(\ref{pf.cor.equiv.modinv.Unphi.b.equiv}))}%
\end{array}
\right) \\
&  =\left\vert \left\{  a\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ a\perp
n\right\}  \right\vert \\
&  =\left\vert \left\{  i\in\left\{  0,1,\ldots,n-1\right\}  \ \mid\ i\perp
n\right\}  \right\vert \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we have renamed
the index }a\text{ as }i\right) \\
&  =\phi\left(  n\right)
\end{align*}
(by Lemma \ref{lem.ent.euler.phi0}). This proves Corollary
\ref{cor.equiv.modinv.Unphi} \textbf{(b)}.
\end{proof}

\begin{definition}
Let $\alpha\in\mathbb{Z}/n$ be a residue class that has an inverse. Then,
Proposition \ref{prop.equiv.modinv.uni} shows that $\alpha$ has \textbf{a
unique} inverse. This inverse can thus be called \textquotedblleft%
\textbf{the}\textit{ inverse}\textquotedblright\ of $\alpha$; it will be
denoted by $\alpha^{-1}$.
\end{definition}

For example, $\left(  \left[  3\right]  _{5}\right)  ^{-1}=\left[  2\right]
_{5}$ for $n=5$, since $\left[  2\right]  _{5}$ is an inverse (and thus
\textbf{the} inverse) of $\left[  3\right]  _{5}$.

Let us state a couple properties of inverses in $\mathbb{Z}/n$:

\begin{exercise}
\label{exe.equiv.modinv.ab}\textbf{(a)} Let $\alpha\in\mathbb{Z}/n$ be a
residue class that has an inverse. Prove that its inverse $\alpha^{-1}$ has an
inverse as well, and this inverse is $\left(  \alpha^{-1}\right)  ^{-1}%
=\alpha$.

\textbf{(b)} Let $\alpha,\beta\in\mathbb{Z}/n$ be two residue classes that
have inverses. Prove that their product $\alpha\beta$ has an inverse as well,
and this inverse is $\left(  \alpha\beta\right)  ^{-1}=\alpha^{-1}\beta^{-1}$.
\end{exercise}

The concept of inverses in $\mathbb{Z}/n$ lets us prove Theorem
\ref{thm.ent.wilson} (Wilson's theorem) again -- or, rather, restate our
previous proof of Theorem \ref{thm.ent.wilson} in more natural terms:

\begin{proof}
[Second proof of Theorem \ref{thm.ent.wilson} (sketched).]Theorem
\ref{thm.eqrel.Z/n.explicit} (applied to $n=p$) shows that the set
$\mathbb{Z}/p$ has exactly $p$ elements, namely $\left[  0\right]
_{p},\left[  1\right]  _{p},\ldots,\left[  p-1\right]  _{p}$. In particular,
these elements $\left[  0\right]  _{p},\left[  1\right]  _{p},\ldots,\left[
p-1\right]  _{p}$ are distinct.

If $p=2$, then the claim of Theorem \ref{thm.ent.wilson} is easy to check (as
we have done in our First proof above). Thus, we WLOG assume that $p\neq2$ for
the rest of this proof. Thus, $p-1\neq1$; in other words, the numbers $1$ and
$p-1$ are distinct. But $p$ is a prime; thus, $p>1$, so that the elements $1$
and $p-1$ belong to the set $\left\{  0,1,\ldots,p-1\right\}  $. Thus, the two
residue classes $\left[  1\right]  _{p}$ and $\left[  p-1\right]  _{p}$ are
distinct\footnote{\textit{Proof.} Recall that the elements $\left[  0\right]
_{p},\left[  1\right]  _{p},\ldots,\left[  p-1\right]  _{p}$ are distinct. In
other words, if $i$ and $j$ are two distinct elements of $\left\{
0,1,\ldots,p-1\right\}  $, then $\left[  i\right]  _{p}\neq\left[  j\right]
_{p}$. We can apply this to $i=1$ and $j=p-1$, since $1$ and $p-1$ are
distinct. Thus, we obtain $\left[  1\right]  _{p}\neq\left[  p-1\right]  _{p}%
$. In other words, the two residue classes $\left[  1\right]  _{p}$ and
$\left[  p-1\right]  _{p}$ are distinct.}.

Recall that%
\[
\left(  p-1\right)  !=1\cdot2\cdot\cdots\cdot\left(  p-1\right)  .
\]
Thus,%
\[
\left[  \left(  p-1\right)  !\right]  _{p}=\left[  1\cdot2\cdot\cdots
\cdot\left(  p-1\right)  \right]  _{p}=\left[  1\right]  _{p}\cdot\left[
2\right]  _{p}\cdot\cdots\cdot\left[  p-1\right]  _{p}%
\]
(by Proposition \ref{prop.eqrel.Z/n.sums.wd} \textbf{(c)}).

Let $U_{p}$ be the set of all residue classes $\alpha\in\mathbb{Z}/p$ that
have an inverse. Then, $\left[  0\right]  _{p}\notin U_{p}$%
\ \ \ \ \footnote{\textit{Proof.} We have $p>1$; thus, we don't have
$\left\vert p\right\vert =1$. But Exercise \ref{exe.ent.coprime.01}
\textbf{(b)} (applied to $a=p$) shows that we have $0\perp p$ if and only if
$\left\vert p\right\vert =1$. Thus, we don't have $0\perp p$ (since we don't
have $\left\vert p\right\vert =1$).
\par
Corollary \ref{cor.equiv.modinv.Unphi} \textbf{(a)} (applied to $n=p$ and
$a=0$) shows that we have the logical equivalence $\left(  \left[  0\right]
_{p}\in U_{p}\right)  \Longleftrightarrow\left(  0\perp p\right)  $. Since we
don't have $0\perp p$, we thus conclude that we don't have $\left[  0\right]
_{p}\in U_{p}$. In other words, we have $\left[  0\right]  _{p}\notin U_{p}$%
.}. On the other hand, the $p-1$ residue classes $\left[  1\right]
_{p},\left[  2\right]  _{p},\ldots,\left[  p-1\right]  _{p}$ all belong to
$U_{p}$\ \ \ \ \footnote{\textit{Proof.} We must show that $\left[  i\right]
_{p}\in U_{p}$ for each $i\in\left\{  1,2,\ldots,p-1\right\}  $.
\par
So let $i\in\left\{  1,2,\ldots,p-1\right\}  $. Then, Proposition
\ref{prop.ent.prime.each-i-coprime} shows that $i$ is coprime to $p$. In other
words, $i\perp p$.
\par
But Corollary \ref{cor.equiv.modinv.Unphi} \textbf{(a)} (applied to $n=p$ and
$a=i$) yields the equivalence $\left(  \left[  i\right]  _{p}\in U_{p}\right)
\Longleftrightarrow\left(  i\perp p\right)  $. Hence, we have $\left[
i\right]  _{p}\in U_{p}$ (since $i\perp p$). Qed.}. Combining these two
sentences, we conclude that the $p-1$ residue classes $\left[  1\right]
_{p},\left[  2\right]  _{p},\ldots,\left[  p-1\right]  _{p}$ are precisely the
elements of $U_{p}$ (since the set $\mathbb{Z}/p$ has exactly $p$ elements,
namely $\left[  0\right]  _{p},\left[  1\right]  _{p},\ldots,\left[
p-1\right]  _{p}$). Thus, these $p-1$ residue classes have inverses (because
belonging to $U_{p}$ means having an inverse), and their inverses in turn have
inverses (by Exercise \ref{exe.equiv.modinv.ab} \textbf{(a)}) and thus belong
to $U_{p}$ (because belonging to $U_{p}$ means having an inverse). Thus, the
map%
\begin{align*}
J:U_{p}  &  \rightarrow U_{p},\\
\alpha &  \mapsto\alpha^{-1}%
\end{align*}
(sending each of the $p-1$ residue classes $\left[  1\right]  _{p},\left[
2\right]  _{p},\ldots,\left[  p-1\right]  _{p}$ to its inverse) is
well-defined. Moreover, each $\alpha\in U_{p}$ satisfies $\left(  \alpha
^{-1}\right)  ^{-1}=\alpha$; in other words, each $\alpha\in U_{p}$ satisfies
$J\left(  J\left(  \alpha\right)  \right)  =\alpha$. In other words, $J\circ
J=\operatorname*{id}$. Hence, the map $J$ is inverse to itself. In particular,
this shows that $J$ is invertible, i.e., bijective.

\begin{fineprint}
(Note that this map $J$ is similar to the map $J$ constructed back in our
first proof of Theorem \ref{thm.ent.wilson} above, but unlike the latter, it
acts on residue classes, not on actual numbers.)
\end{fineprint}

Note that
\[
\left[  1\right]  _{p}\cdot\left[  2\right]  _{p}\cdot\cdots\cdot\left[
p-1\right]  _{p}=\prod_{\alpha\in U_{p}}\alpha,
\]
since the $p-1$ residue classes $\left[  1\right]  _{p},\left[  2\right]
_{p},\ldots,\left[  p-1\right]  _{p}$ are precisely the elements of $U_{p}$
(and are distinct).

Now, we shall complete the proof using the same \textquotedblleft
pairing\textquotedblright\ that we used in our first proof of Theorem
\ref{thm.ent.wilson}, except that we will now be pairing up residue classes
rather than numbers. Namely, we will use the map $J$ to establish a pairing
between the factors of the product $\left[  1\right]  _{p}\cdot\left[
2\right]  _{p}\cdot\cdots\cdot\left[  p-1\right]  _{p}=\prod_{\alpha\in U_{p}%
}\alpha$ (pairing up each factor $\alpha$ with the factor $J\left(
\alpha\right)  =\alpha^{-1}$), which will pair up almost all of them -- more
precisely, all of them except for the very first and very last factors (since
these two factors would have to pair up with themselves)\footnote{The reason
\textbf{why} it is precisely these two factors that will not be paired up is
the following:
\par
Clearly, the factors $\left[  a\right]  _{p}$ that cannot be paired up are
exactly the factors $\left[  a\right]  _{p}$ that satisfy $J\left(  \left[
a\right]  _{p}\right)  =\left[  a\right]  _{p}$ -- i.e., the ones that are
their own inverses. So we must prove that a residue class $\left[  a\right]
_{p}$ with $a\in\left\{  1,2,\ldots,p-1\right\}  $ is its own inverse if and
only if $a$ is either $1$ or $p-1$. But this follows from the following chain
of equivalences:%
\begin{align*}
&  \ \left(  \text{the residue class }\left[  a\right]  _{p}\text{ is its own
inverse}\right) \\
&  \Longleftrightarrow\ \left(  \left[  a\right]  _{p}\cdot\left[  a\right]
_{p}=\left[  1\right]  _{p}\right)  \ \Longleftrightarrow\ \left(  \left[
a^{2}\right]  _{p}=\left[  1\right]  _{p}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\left[  a\right]  _{p}\cdot\left[  a\right]  _{p}=\left[  a\cdot
a\right]  _{p}=\left[  a^{2}\right]  _{p}\right) \\
&  \Longleftrightarrow\ \left(  a^{2}\equiv1\operatorname{mod}p\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.eqrel.Z/n.ab}
\textbf{(b)}}\right) \\
&  \Longleftrightarrow\ \left(  a\equiv1\operatorname{mod}p\text{ or }%
a\equiv-1\operatorname{mod}p\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{indeed, Exercise \ref{exe.ent.prime.aa-1} yields the}\\
\text{implication }\left(  a^{2}\equiv1\operatorname{mod}p\right)
\ \Longrightarrow\ \left(  a\equiv1\operatorname{mod}p\text{ or }%
a\equiv-1\operatorname{mod}p\right)  \text{;}\\
\text{but the converse implication is easy to check}%
\end{array}
\right) \\
&  \Longleftrightarrow\ \left(  \left[  a\right]  _{p}=\left[  1\right]
_{p}\text{ or }\left[  a\right]  _{p}=\left[  -1\right]  _{p}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition \ref{prop.eqrel.Z/n.ab}
\textbf{(b)}}\right) \\
&  \Longleftrightarrow\ \left(  \left[  a\right]  _{p}=\left[  1\right]
_{p}\text{ or }\left[  a\right]  _{p}=\left[  p-1\right]  _{p}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left[  -1\right]  _{p}=\left[
p-1\right]  _{p}\text{ (because }-1\equiv p-1\operatorname{mod}p\text{)}%
\right) \\
&  \Longleftrightarrow\ \left(  a=1\text{ or }a=p-1\right)
\end{align*}
(since the elements $\left[  0\right]  _{p},\left[  1\right]  _{p}%
,\ldots,\left[  p-1\right]  _{p}$ are distinct).}. For example, if $p=11$,
then we have the following table of values of $J$:%
\[%
\begin{tabular}
[c]{|c||c|c|c|c|c|c|c|c|c|c||}\hline
$\alpha$ & $\left[  1\right]  _{11}$ & $\left[  2\right]  _{11}$ & $\left[
3\right]  _{11}$ & $\left[  4\right]  _{11}$ & $\left[  5\right]  _{11}$ &
$\left[  6\right]  _{11}$ & $\left[  7\right]  _{11}$ & $\left[  8\right]
_{11}$ & $\left[  9\right]  _{11}$ & $\left[  10\right]  _{11}$\\\hline
$J\left(  \alpha\right)  $ & $\left[  1\right]  _{11}$ & $\left[  6\right]
_{11}$ & $\left[  4\right]  _{11}$ & $\left[  3\right]  _{11}$ & $\left[
9\right]  _{11}$ & $\left[  2\right]  _{11}$ & $\left[  8\right]  _{11}$ &
$\left[  7\right]  _{11}$ & $\left[  5\right]  _{11}$ & $\left[  10\right]
_{11}$\\\hline
\end{tabular}
\]
(since, for example, $J\left(  \left[  2\right]  _{11}\right)  =\left(
\left[  2\right]  _{11}\right)  ^{-1}=\left[  6\right]  _{11}$), and thus we
pair up the factors of the product $\left[  1\right]  _{p}\cdot\left[
2\right]  _{p}\cdot\cdots\cdot\left[  p-1\right]  _{p}$ as follows:%
\begin{align}
&  \left[  1\right]  _{p}\cdot\left[  2\right]  _{p}\cdot\cdots\cdot\left[
p-1\right]  _{p}\nonumber\\
&  =\left[  1\right]  _{11}\cdot\left[  2\right]  _{11}\cdot\left[  3\right]
_{11}\cdot\left[  4\right]  _{11}\cdot\left[  5\right]  _{11}\cdot\left[
6\right]  _{11}\cdot\left[  7\right]  _{11}\cdot\left[  8\right]  _{11}%
\cdot\left[  9\right]  _{11}\cdot\left[  10\right]  _{11}\nonumber\\
&  =\left[  1\right]  _{11}\cdot\left(  \left[  2\right]  _{11}\cdot\left[
6\right]  _{11}\right)  \cdot\left(  \left[  3\right]  _{11}\cdot\left[
4\right]  _{11}\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \cdot\left(  \left[  5\right]  _{11}\cdot\left[
9\right]  _{11}\right)  \cdot\left(  \left[  7\right]  _{11}\cdot\left[
8\right]  _{11}\right)  \cdot\left[  10\right]  _{11}.
\label{pf.thm.ent.wilson.2nd.11-1}%
\end{align}
By the definition of the map $J$, each pair has the form $\left(
\alpha,J\left(  \alpha\right)  \right)  =\left(  \alpha,\alpha^{-1}\right)  $
for some $\alpha\in U_{p}$, and thus the product of any two different factors
paired up with each other is $\left[  1\right]  _{p}$ (since $\alpha
\alpha^{-1}=\left[  1\right]  _{p}$). For example, if $p=11$, then we have%
\begin{align*}
&  \left[  1\right]  _{p}\cdot\left[  2\right]  _{p}\cdot\cdots\cdot\left[
p-1\right]  _{p}\\
&  =\left[  1\right]  _{11}\cdot\underbrace{\left(  \left[  2\right]
_{11}\cdot\left[  6\right]  _{11}\right)  }_{=\left[  1\right]  _{11}}%
\cdot\underbrace{\left(  \left[  3\right]  _{11}\cdot\left[  4\right]
_{11}\right)  }_{=\left[  1\right]  _{11}}\cdot\underbrace{\left(  \left[
5\right]  _{11}\cdot\left[  9\right]  _{11}\right)  }_{=\left[  1\right]
_{11}}\cdot\underbrace{\left(  \left[  7\right]  _{11}\cdot\left[  8\right]
_{11}\right)  }_{=\left[  1\right]  _{11}}\cdot\left[  10\right]  _{11}\\
&  =\left[  1\right]  _{11}\cdot\left[  10\right]  _{11}.
\end{align*}
Thus, any two different factors paired up with each other \textquotedblleft
neutralize\textquotedblright\ each other when being multiplied. Hence, the
product of all the $p-1$ factors will reduce to the product of the two factors
that have not been paired up, which will be $\left[  1\right]  _{p}%
\cdot\left[  p-1\right]  _{p}=\left[  p-1\right]  _{p}$. Since this product
was $\left[  \left(  p-1\right)  !\right]  _{p}$, we thus obtain
\begin{equation}
\left[  \left(  p-1\right)  !\right]  _{p}=\left[  p-1\right]  _{p}.
\label{pf.thm.ent.wilson.2nd.main-arg}%
\end{equation}
In other words, $\left(  p-1\right)  !\equiv p-1\equiv-1\operatorname{mod}p$.
Hence, Theorem \ref{thm.ent.wilson} is proven again.

\begin{fineprint}
Once again, if you like your proofs rigorous and formal, you may be wondering
how this \textquotedblleft pairing up\textquotedblright\ argument can be
formalized. Here is one way to do so: We proceed similarly to how we
formalized our first proof of Theorem \ref{thm.ent.wilson} above, but with a
minor complication. We want to call an element $\alpha$ of $U_{p}$

\begin{itemize}
\item \textit{small} if $\alpha<J\left(  \alpha\right)  $;

\item \textit{medium} if $\alpha=J\left(  \alpha\right)  $;

\item \textit{large} if $\alpha>J\left(  \alpha\right)  $.
\end{itemize}

\noindent However, in order for this definition to make sense, we need to
define two relations $<$ and $>$ on the set $\mathbb{Z}/p$; otherwise, it is
not clear what \textquotedblleft$\alpha<J\left(  \alpha\right)  $%
\textquotedblright\ and \textquotedblleft$\alpha>J\left(  \alpha\right)
$\textquotedblright\ should mean. Fortunately, this is easy: For example, we can

\begin{itemize}
\item consider the bijection $R:\mathbb{Z}/p\rightarrow\left\{  0,1,\ldots
,p-1\right\}  $ defined in Proposition \ref{prop.eqrel.Z/n.PR} \textbf{(a)}
(applied to $n=p$);

\item define the binary relation $<$ on the set $\mathbb{Z}/p$ by setting
\[
\left(  \alpha<\beta\right)  \ \Longleftrightarrow\ \left(  R\left(
\alpha\right)  <R\left(  \beta\right)  \right)  \ \ \ \ \ \ \ \ \ \ \text{for
any }\alpha,\beta\in\mathbb{Z}/p;
\]


\item define the binary relation $>$ on the set $\mathbb{Z}/p$ by setting
\[
\left(  \alpha>\beta\right)  \ \Longleftrightarrow\ \left(  R\left(
\alpha\right)  >R\left(  \beta\right)  \right)  \ \ \ \ \ \ \ \ \ \ \text{for
any }\alpha,\beta\in\mathbb{Z}/p.
\]

\end{itemize}

\noindent The two relations we have just defined have the property that each
$\alpha,\beta\in\mathbb{Z}/p$ satisfy either $\alpha<\beta$ or $\alpha=\beta$
or $\alpha>\beta$ but never two or more of these three statements
simultaneously (indeed, this follows easily from the fact that $R$ is a
bijection). Thus, each element of $U_{p}$ is either small or medium or large
(and there is no overlap between these three classes of elements). Hence, the
argument that we used to prove (\ref{pf.thm.ent.wilson.8}) in our first proof
of Theorem \ref{thm.ent.wilson}\footnote{viz., by splitting up the product
into a product over small elements, a product over medium elements, and a
product over large elements} can be adapted in order to prove $\left[  \left(
p-1\right)  !\right]  _{p}=\left[  -1\right]  _{p}$, except that we have to
use residue classes in $U_{p}$ instead of elements of $A$. (We could have just
as well used any other bijection from $\mathbb{Z}/p$ to $\left\{
0,1,\ldots,p-1\right\}  $ instead of $R$ here.) Of course, $\left[  \left(
p-1\right)  !\right]  _{p}=\left[  -1\right]  _{p}$ immediately yields
$\left(  p-1\right)  !\equiv-1\operatorname{mod}p$ (by an application of
Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)}), and thus the proof of
Theorem \ref{thm.ent.wilson} is complete.

\begin{noncompile}
(The following is an unfinished stub of a second formalization of the proof of
(\ref{pf.thm.ent.wilson.2nd.main-arg}).)

\textit{Second formalization of the proof of
(\ref{pf.thm.ent.wilson.2nd.main-arg}):} Let us show another way to formalize
the \textquotedblleft pairing up\textquotedblright\ argument, which avoids a
choice of order relations $<$ and $>$ on $\mathbb{Z}/p$ and even avoids using
the map $J$ (at least explicitly). This second formalization foreshadows some
constructions we shall perform later when studying group actions.

We define a binary relation $\sim$ on the set $U_{p}$ by%
\begin{align*}
\left(  \alpha\sim\beta\right)  \  &  \Longleftrightarrow\ \left(
\alpha=\beta\text{ or }\alpha\beta=\left[  1\right]  _{p}\right) \\
\  &  \Longleftrightarrow\ \left(  \text{the residue classes }\alpha\text{ and
}\beta\text{ are equal or mutually inverse}\right)  .
\end{align*}
(Note that this relation $\sim$ is defined on a set of equivalence classes of
another relation. This may appear somewhat incestuous, but is completely legitimate.)

It is easy to see that this relation $\sim$ is reflexive (since $\alpha
=\alpha$ for any $\alpha\in U_{p}$) and symmetric (since $\alpha\beta
=\beta\alpha$ for any two residue classes $\alpha$ and $\beta$) and
transitive\footnote{\textit{Proof.} Let $\alpha,\beta,\gamma\in U_{p}$ be such
that $\alpha\sim\beta$ and $\beta\sim\gamma$. We must prove that $\alpha
\sim\gamma$.
\par
If $\alpha=\beta$, then this follows trivially from $\beta\sim\gamma$. Hence,
for the rest of this proof, we WLOG assume that $\alpha\neq\beta$. But from
$\alpha\sim\beta$, we conclude that either $\alpha=\beta$ or $\alpha
\beta=\left[  1\right]  _{p}$ (by the definition of the relation $\sim$).
Thus, $\alpha\beta=\left[  1\right]  _{p}$ (since $\alpha\neq\beta$). Hence,
$\beta\alpha=\alpha\beta=\left[  1\right]  _{p}$. In other words, $\alpha$ is
an inverse of $\beta$.
\par
We must prove that $\alpha\sim\gamma$. If $\beta=\gamma$, then this follows
trivially from $\alpha\sim\beta$. Hence, for the rest of this proof, we WLOG
assume that $\beta\neq\gamma$. But from $\beta\sim\gamma$, we conclude that
either $\beta=\gamma$ or $\beta\gamma=\left[  1\right]  _{p}$ (by the
definition of the relation $\sim$). Thus, $\beta\gamma=\left[  1\right]  _{p}$
(since $\beta\neq\gamma$). In other words, $\gamma$ is an inverse of $\beta$.
\par
Proposition \ref{prop.equiv.modinv.uni} (applied to $\beta$ instead of
$\alpha$) shows that $\beta\in\mathbb{Z}/n$ has at most one inverse. Since
both $\alpha$ and $\gamma$ are inverses of $\beta$, we thus obtain
$\alpha=\gamma$. Hence, $\alpha\sim\gamma$ (since the relation $\sim$ is
reflexive). Qed.}. Hence, $\sim$ is an equivalence relation. Consider its
equivalence classes (which, of course, are sets whose elements are equivalence
classes of integers). These classes belong to the set $U_{p}/\sim$. Each
$\alpha\in U_{p}$ has its residue class $\left[  \alpha\right]  _{\sim}\in
U_{p}$. Thus, the product $\prod_{\alpha\in U_{p}}\alpha$ can be split up as
follows:%
\begin{equation}
\prod_{\alpha\in U_{p}}\alpha=\prod_{C\in U_{p}/\sim}\prod_{\substack{\alpha
\in U_{p};\\\left[  \alpha\right]  _{\sim}=C}}\alpha.
\label{pf.thm.ent.wilson.2nd.main-arg.f2.1}%
\end{equation}
(What we have done here is simply breaking up the product into smaller
sub-products, each of which covers one specific equivalence class of $\sim$.
This is the general version of the splitting that we did in
(\ref{pf.thm.ent.wilson.2nd.11-1}) in the case $p=11$.)

Now, we shall discuss the sub-products $\prod_{\alpha\in C}\alpha$ on the
right hand side of (\ref{pf.thm.ent.wilson.2nd.main-arg.f2.1}). First, let us
take a closer look at the equivalence classes, starting with the ones whose
size is $\neq1$:

\begin{statement}
\textit{Claim 1:} Let $C\in U_{p}/\sim$ be an equivalence class such that
$\left\vert C\right\vert \neq1$. Then, $\prod_{\substack{\alpha\in
U_{p};\\\left[  \alpha\right]  _{\sim}=C}}\alpha=\left[  1\right]  _{p}$.
\end{statement}

[\textit{Proof of Claim 1:} We know that $C\in U_{p}/\sim$. In other words,
$C$ is an equivalence class of the relation $\sim$. In other words, $C=\left[
\beta\right]  _{\sim}$ for some $\beta\in U_{p}$. Consider this $\beta$.
Proposition \ref{prop.eqrel.eqcl.aina} (applied to $S=U_{p}$ and $a=\beta$)
yields $\beta\in\left[  \beta\right]  _{\sim}=C$. Hence, $\left\vert
C\setminus\left\{  \beta\right\}  \right\vert =\left\vert C\right\vert
-1\neq0$ (since $\left\vert C\right\vert \neq1$), so that $C\setminus\left\{
\beta\right\}  \neq\varnothing$.

On the other hand, the residue class $\beta$ is an element of $U_{p}$, and
thus has an inverse $\beta^{-1}$ (by the definition of $U_{p}$). Each element
of $C\setminus\left\{  \beta\right\}  $ must equal this inverse $\beta^{-1}%
$\ \ \ \ \footnote{\textit{Proof.} Let $\gamma$ be an element of
$C\setminus\left\{  \beta\right\}  $. We must show that $\gamma=\beta^{-1}$.
\par
We have $\gamma\in C\setminus\left\{  \beta\right\}  $. In other words,
$\gamma\in C$ and $\gamma\neq\beta$. From $\gamma\in C=\left[  \beta\right]
_{\sim}$, we obtain $\gamma\sim\beta$ (because Theorem
\ref{thm.eqrel.eqcl.disj} \textbf{(c)} (applied to $S=U_{p}$, $x=\gamma$ and
$y=\beta$) shows that we have $\gamma\sim\beta$ if and only if $\gamma
\in\left[  \beta\right]  _{\sim}$). In other words, $\gamma=\beta$ or
$\gamma\beta=1$ (by the definition of $\sim$). Since $\gamma\neq\beta$, we
thus obtain $\gamma\beta=1$. Hence, $\beta\gamma=\gamma\beta=1$, so that
$\gamma$ is an inverse of $\beta$. In other words, $\gamma=\beta^{-1}$ (since
$\beta^{-1}$ is the only inverse of $\beta$). Qed.}. Thus, $C\setminus\left\{
\beta\right\}  \subseteq\left\{  \beta^{-1}\right\}  $. Hence, the set
$C\setminus\left\{  \beta\right\}  $ is either $\varnothing$ or $\left\{
\beta^{-1}\right\}  $. Since $C\setminus\left\{  \beta\right\}  \neq
\varnothing$, we thus obtain $C\setminus\left\{  \beta\right\}  =\left\{
\beta^{-1}\right\}  $. Hence, the set $C$ has exactly two elements, namely
$\beta$ and $\beta^{-1}$ (and these two elements are distinct).

If $\alpha\in U_{p}$, then we have the following chain of logical
equivalences:%
\begin{align*}
\left(  \left[  \alpha\right]  _{\sim}=\underbrace{C}_{=\left[  \beta\right]
_{\sim}}\right)  \  &  \Longleftrightarrow\ \left(  \left[  \alpha\right]
_{\sim}=\left[  \beta\right]  _{\sim}\right)  \ \Longleftrightarrow\ \left(
\alpha\sim\beta\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem \ref{thm.eqrel.eqcl.disj}
\textbf{(e)}, applied to }S=U_{p}\text{, }x=\alpha\text{ and }y=\beta\right)
\\
&  \Longleftrightarrow\ \left(  \alpha\in\underbrace{\left[  \beta\right]
_{\sim}}_{=C}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem \ref{thm.eqrel.eqcl.disj}
\textbf{(c)}, applied to }S=U_{p}\text{, }x=\alpha\text{ and }y=\beta\right)
\\
&  \Longleftrightarrow\ \left(  \alpha\in C\right)  .
\end{align*}
Hence, we have the following equality between product signs:\footnote{An
equality between two product signs should be interpreted as saying that
whatever we put after these product signs, the results will be equal.}%
\[
\prod_{\substack{\alpha\in U_{p};\\\left[  \alpha\right]  _{\sim}=C}%
}=\prod_{\substack{\alpha\in U_{p};\\\alpha\in C}}=\prod_{\alpha\in
C}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }C\subseteq U_{p}\right)  .
\]
Thus,%
\begin{align*}
\prod_{\substack{\alpha\in U_{p};\\\left[  \alpha\right]  _{\sim}=C}}\alpha &
=\prod_{\alpha\in C}\alpha=\beta\beta^{-1}\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the set }C\text{ has exactly two elements,}\\
\text{namely }\beta\text{ and }\beta^{-1}\text{ (and these two elements}\\
\text{are distinct)}%
\end{array}
\right) \\
&  =\left[  1\right]  _{p}.
\end{align*}
This proves Claim 1.]

Next, we classify the equivalence classes of size $1$ (which correspond to the
unpaired factors in the computation (\ref{pf.thm.ent.wilson.2nd.11-1})):

\begin{statement}
\textit{Claim 2:} Let $\alpha\in U_{p}$. Then, $\left\vert \left[
\alpha\right]  _{\sim}\right\vert =1$ holds if and only if $\alpha$ is either
$\left[  1\right]  _{p}$ or $\left[  p-1\right]  _{p}$.
\end{statement}

[\textit{Proof of Claim 2:} Let $C\in U_{p}/\sim$ be an equivalence class. Our
plan is to understand when $\left\vert C\right\vert =1$ holds.

We know that $C$ is an equivalence class of the relation $\sim$. In other
words, $C=\left[  \beta\right]  _{\sim}$ for some $\beta\in U_{p}$. Consider
this $\beta$. Just as in the proof of Claim 1, we can show that $\beta\in C$
and $\left\vert C\setminus\left\{  \beta\right\}  \right\vert =\left\vert
C\right\vert -1$ and $C\setminus\left\{  \beta\right\}  \subseteq\left\{
\beta^{-1}\right\}  $.

Moreover, $\beta^{-1}\beta=\left[  1\right]  _{p}$ and therefore $\beta
^{-1}\sim\beta$ (by the definition of the relation $\sim$). Hence, $\beta
^{-1}\in\left[  \beta\right]  _{\sim}$ (because Theorem
\ref{thm.eqrel.eqcl.disj} \textbf{(c)} (applied to $S=U_{p}$, $x=\beta^{-1}$
and $y=\beta$) shows that we have $\beta^{-1}\sim\beta$ if and only if
$\beta^{-1}\in\left[  \beta\right]  _{\sim}$). Thus, $\beta^{-1}\in\left[
\beta\right]  _{\sim}=C$. From this and $C\setminus\left\{  \beta\right\}
\subseteq\left\{  \beta^{-1}\right\}  $, we can easily obtain $C\setminus
\left\{  \beta\right\}  =\left\{  \beta^{-1}\right\}  \setminus\left\{
\beta\right\}  $\ \ \ \ \footnote{\textit{Proof.} We have $\beta^{-1}\in C$,
thus $\left\{  \beta^{-1}\right\}  \subseteq C$, so that $\underbrace{\left\{
\beta^{-1}\right\}  }_{\subseteq C}\setminus\left\{  \beta\right\}  \subseteq
C\setminus\left\{  \beta\right\}  $. But from $C\setminus\left\{
\beta\right\}  \subseteq\left\{  \beta^{-1}\right\}  $, we obtain
$\underbrace{\left(  C\setminus\left\{  \beta\right\}  \right)  }%
_{\subseteq\left\{  \beta^{-1}\right\}  }\setminus\left\{  \beta\right\}
\subseteq\left\{  \beta^{-1}\right\}  \setminus\left\{  \beta\right\}  $. In
view of $\left(  C\setminus\left\{  \beta\right\}  \right)  \setminus\left\{
\beta\right\}  =C\setminus\left\{  \beta\right\}  $, this rewrites as
$C\setminus\left\{  \beta\right\}  \subseteq\left\{  \beta^{-1}\right\}
\setminus\left\{  \beta\right\}  $. Combining this with $\left\{  \beta
^{-1}\right\}  \setminus\left\{  \beta\right\}  \subseteq C\setminus\left\{
\beta\right\}  $, we find $C\setminus\left\{  \beta\right\}  =\left\{
\beta^{-1}\right\}  \setminus\left\{  \beta\right\}  $.}.

We have $\beta\in U_{p}=\left\{  \left[  1\right]  _{p},\left[  2\right]
_{p},\ldots,\left[  p-1\right]  _{p}\right\}  $ (since the $p-1$ residue
classes $\left[  1\right]  _{p},\left[  2\right]  _{p},\ldots,\left[
p-1\right]  _{p}$ are precisely the elements of $U_{p}$). In other words,
$\beta=\left[  b\right]  _{p}$ for some $b\in\left\{  1,2,\ldots,p-1\right\}
$. Consider this $b$.

Now, we have the following chain of logical equivalences:%
\begin{align*}
\left(  \left\vert C\right\vert =1\right)  \  &  \Longleftrightarrow\ \left(
\underbrace{\left\vert C\right\vert -1}_{=\left\vert C\setminus\left\{
\beta\right\}  \right\vert }=0\right)  \ \Longleftrightarrow\ \left(
\left\vert C\setminus\left\{  \beta\right\}  \right\vert =0\right)
\ \Longleftrightarrow\ \left(  \underbrace{C\setminus\left\{  \beta\right\}
}_{=\left\{  \beta^{-1}\right\}  \setminus\left\{  \beta\right\}
}=\varnothing\right) \\
&  \Longleftrightarrow\ \left(  \left\{  \beta^{-1}\right\}  \setminus\left\{
\beta\right\}  =\varnothing\right)  \ \Longleftrightarrow\ \left(  \left\{
\beta^{-1}\right\}  \subseteq\left\{  \beta\right\}  \right)
\ \Longleftrightarrow\ \left(  \beta^{-1}\in\left\{  \beta\right\}  \right)
\ \Longleftrightarrow\ \left(  \beta^{-1}=\beta\right) \\
&  \Longleftrightarrow\ \left(  \beta\text{ is an inverse of }\beta\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since the only inverse of }\beta\text{ is
}\beta^{-1}\right) \\
&  \Longleftrightarrow\ \left(  \beta\beta=\left[  1\right]  _{p}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of \textquotedblleft
inverse\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  \left[  b^{2}\right]  _{p}=\left[  1\right]
_{p}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\underbrace{\beta
}_{=\left[  b\right]  _{p}}\underbrace{\beta}_{=\left[  b\right]  _{p}%
}=\left[  b\right]  _{p}\left[  b\right]  _{p}=\left[  b^{2}\right]
_{p}\right) \\
&  \Longleftrightarrow\ \left(  b^{2}\equiv1\operatorname{mod}p\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by an application of Proposition
\ref{prop.eqrel.Z/n.ab} \textbf{(b)}}\right) \\
&  \Longleftrightarrow\ \left(  b\equiv1\operatorname{mod}p\text{ or }%
b\equiv-1\operatorname{mod}p\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{indeed, Exercise \ref{exe.ent.prime.aa-1} (applied to }a=b\text{) yields
the}\\
\text{implication }\left(  b^{2}\equiv1\operatorname{mod}p\right)
\ \Longrightarrow\ \left(  b\equiv1\operatorname{mod}p\text{ or }%
b\equiv-1\operatorname{mod}p\right)  \text{;}\\
\text{but the converse implication is easy to check}%
\end{array}
\right) \\
&  \Longleftrightarrow\ \left(  \underbrace{\left[  b\right]  _{p}}_{=\beta
}=\left[  1\right]  _{p}\text{ or }\underbrace{\left[  b\right]  _{p}}%
_{=\beta}=\left[  -1\right]  _{p}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)}}\right) \\
&  \Longleftrightarrow\ \left(  \beta=\left[  1\right]  _{p}\text{ or }%
\beta=\left[  -1\right]  _{p}\right) \\
&  \Longleftrightarrow\ \left(  \beta=\left[  1\right]  _{p}\text{ or }%
\beta=\left[  p-1\right]  _{p}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\left[  -1\right]  _{p}=\left[  p-1\right]  _{p}\text{ (because }-1\equiv
p-1\operatorname{mod}p\text{)}\right)  .
\end{align*}
Thus, $\left\vert C\right\vert =1$ holds if and only if $\beta$ is either
$\left[  1\right]  _{p}$ or $\left[  p-1\right]  _{p}$. From this, we can
easily conclude that the equivalence classes $C\in U_{p}/\sim$ such that
$\left\vert C\right\vert =1$ are precisely the two classes $\left[  \left[
1\right]  _{p}\right]  _{\sim}=\left\{  \left[  1\right]  _{p}\right\}  $ and
$\left[  \left[  p-1\right]  _{p}\right]  _{\sim}=\left\{  \left[  p-1\right]
_{p}\right\}  $. This proves Claim 2.]

Finish this!
\end{noncompile}
\end{fineprint}
\end{proof}

\subsection{\label{sect.equiv.CRT-bij}The Chinese Remainder Theorem as a
bijection between residue classes}

\begin{definition}
\label{def.eqrel.Z/n.pind}Let $n$ be a positive integer. Let $d$ be a positive
divisor of $n$. Then, define the map%
\begin{align*}
\pi_{n,d}:\mathbb{Z}/n  &  \rightarrow\mathbb{Z}/d,\\
\left[  s\right]  _{n}  &  \mapsto\left[  s\right]  _{d}.
\end{align*}
(This is well-defined, according to Proposition \ref{prop.eqrel.Z/n.pind.wd}.)
\end{definition}

See Example \ref{exa.eqrel.Z/n.pind.wd} \textbf{(a)} for what this map looks like.

We can now state another version of the \textquotedblleft Chinese Remainder
Theorem\textquotedblright, which claims the existence of a certain bijection.
We have already seen such a version (Theorem \ref{thm.ent.CRT-bij}), but that
one claimed a bijection between two sets of \textbf{remainders}, whereas the
following version claims a bijection between two sets of \textbf{residue
classes}. Other than that, the two versions are rather similar.

\begin{theorem}
\label{thm.eqrel.CRT2}Let $m$ and $n$ be two coprime positive integers. Then,
the map%
\begin{align*}
S_{m,n}:\mathbb{Z}/\left(  mn\right)   &  \rightarrow\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  ,\\
\alpha &  \mapsto\left(  \pi_{mn,m}\left(  \alpha\right)  ,\pi_{mn,n}\left(
\alpha\right)  \right)
\end{align*}
is well-defined and is a bijection. It sends each $\left[  s\right]  _{mn}$
(with $s\in\mathbb{Z}$) to the pair $\left(  \left[  s\right]  _{m},\left[
s\right]  _{n}\right)  $.
\end{theorem}

\begin{example}
\textbf{(a)} Theorem \ref{thm.eqrel.CRT2} (applied to $m=3$ and $n=2$) says
that the map%
\begin{align*}
S_{3,2}:\mathbb{Z}/6  &  \rightarrow\left(  \mathbb{Z}/3\right)  \times\left(
\mathbb{Z}/2\right)  ,\\
\alpha &  \mapsto\left(  \pi_{6,3}\left(  \alpha\right)  ,\pi_{6,2}\left(
\alpha\right)  \right)
\end{align*}
is a bijection. This map sends%
\[%
\begin{array}
[c]{cccccccc}%
\left[  0\right]  _{6}, & \left[  1\right]  _{6}, & \left[  2\right]  _{6}, &
\left[  3\right]  _{6}, & \left[  4\right]  _{6}, & \left[  5\right]  _{6} &
& \text{to}\\
\left(  \left[  0\right]  _{3},\left[  0\right]  _{2}\right)  , & \left(
\left[  1\right]  _{3},\left[  1\right]  _{2}\right)  , & \left(  \left[
2\right]  _{3},\left[  2\right]  _{2}\right)  , & \left(  \left[  3\right]
_{3},\left[  3\right]  _{2}\right)  , & \left(  \left[  4\right]  _{3},\left[
4\right]  _{2}\right)  , & \left(  \left[  5\right]  _{3},\left[  5\right]
_{2}\right)  , &  &
\end{array}
\]
respectively. In other words, it sends%
\[%
\begin{array}
[c]{cccccccc}%
\left[  0\right]  _{6}, & \left[  1\right]  _{6}, & \left[  2\right]  _{6}, &
\left[  3\right]  _{6}, & \left[  4\right]  _{6}, & \left[  5\right]  _{6} &
& \text{to}\\
\left(  \left[  0\right]  _{3},\left[  0\right]  _{2}\right)  , & \left(
\left[  1\right]  _{3},\left[  1\right]  _{2}\right)  , & \left(  \left[
2\right]  _{3},\left[  0\right]  _{2}\right)  , & \left(  \left[  0\right]
_{3},\left[  1\right]  _{2}\right)  , & \left(  \left[  1\right]  _{3},\left[
0\right]  _{2}\right)  , & \left(  \left[  2\right]  _{3},\left[  1\right]
_{2}\right)  , &  &
\end{array}
\]
respectively (since $\left[  2\right]  _{2}=\left[  0\right]  _{2}$ and
$\left[  3\right]  _{3}=\left[  0\right]  _{3}$ and $\left[  3\right]
_{2}=\left[  1\right]  _{2}$ and so on). This list of values shows that this
map is bijective (since it takes on every possible value in $\left(
\mathbb{Z}/3\right)  \times\left(  \mathbb{Z}/2\right)  $ exactly once).
Theorem \ref{thm.eqrel.CRT2} says that this holds for arbitrary coprime $m$
and $n$.

\textbf{(b)} Let us see how Theorem \ref{thm.eqrel.CRT2} fails when $m$ and
$n$ are \textbf{not} coprime. For example, take $m=6$ and $n=4$. Then, the map%
\begin{align*}
S_{6,4}:\mathbb{Z}/24  &  \rightarrow\left(  \mathbb{Z}/6\right)
\times\left(  \mathbb{Z}/4\right)  ,\\
\alpha &  \mapsto\left(  \pi_{24,6}\left(  \alpha\right)  ,\pi_{24,4}\left(
\alpha\right)  \right)
\end{align*}
is \textbf{not} a bijection. Indeed, it is neither injective (for example, it
sends both $\left[  0\right]  _{24}$ and $\left[  12\right]  _{24}$ to the
same pair $\left(  \left[  0\right]  _{6},\left[  0\right]  _{4}\right)  $)
nor surjective (for example, it never takes the value $\left(  \left[
1\right]  _{6},\left[  2\right]  _{4}\right)  $).
\end{example}

The following proof of Theorem \ref{thm.eqrel.CRT2} has the same structure as
our proof of Theorem \ref{thm.ent.CRT-bij} above, but is shorter since residue
classes are easier to deal with than remainders.

\begin{proof}
[Proof of Theorem \ref{thm.eqrel.CRT2}.]The maps $\pi_{mn,m}$ and $\pi_{mn,n}$
are well-defined, since $m$ and $n$ are positive divisors of $mn$. Thus, the
map%
\begin{align*}
S_{m,n}:\mathbb{Z}/\left(  mn\right)   &  \rightarrow\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  ,\\
\alpha &  \mapsto\left(  \pi_{mn,m}\left(  \alpha\right)  ,\pi_{mn,n}\left(
\alpha\right)  \right)
\end{align*}
is well-defined. Consider this map $S_{m,n}$. Clearly, for each $s\in
\mathbb{Z}$, we have%
\begin{align}
S_{m,n}\left(  \left[  s\right]  _{mn}\right)   &  =\left(  \underbrace{\pi
_{mn,m}\left(  \left[  s\right]  _{mn}\right)  }_{\substack{=\left[  s\right]
_{m}\\\text{(by the definition of }\pi_{mn,m}\text{)}}},\underbrace{\pi
_{mn,n}\left(  \left[  s\right]  _{mn}\right)  }_{\substack{=\left[  s\right]
_{n}\\\text{(by the definition of }\pi_{mn,n}\text{)}}}\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }S_{m,n}\right)
\nonumber\\
&  =\left(  \left[  s\right]  _{m},\left[  s\right]  _{n}\right)  .
\label{pf.thm.eqrel.CRT2.Ss=}%
\end{align}
In other words, the map $S_{m,n}$ sends each $\left[  s\right]  _{mn}$ (with
$s\in\mathbb{Z}$) to the pair $\left(  \left[  s\right]  _{m},\left[
s\right]  _{n}\right)  $.

It thus remains to prove that $S_{m,n}$ is a bijection. To that aim, we shall
prove that $S_{m,n}$ is injective and surjective.

[\textit{Proof that the map }$S_{m,n}$ \textit{is injective:} Let
$\alpha,\beta\in\mathbb{Z}/\left(  mn\right)  $ be such that $S_{m,n}\left(
\alpha\right)  =S_{m,n}\left(  \beta\right)  $. We want to prove $\alpha
=\beta$.

Write the residue classes $\alpha$ and $\beta$ in the forms $\alpha=\left[
a\right]  _{mn}$ and $\beta=\left[  b\right]  _{mn}$ for two integers $a$ and
$b$. (This is possible, because of Proposition \ref{prop.eqrel.Z/n.ab}
\textbf{(a)}.) From $\alpha=\left[  a\right]  _{mn}$, we obtain $S_{m,n}%
\left(  \alpha\right)  =S_{m,n}\left(  \left[  a\right]  _{mn}\right)
=\left(  \left[  a\right]  _{m},\left[  a\right]  _{n}\right)  $ (by
(\ref{pf.thm.eqrel.CRT2.Ss=}), applied to $s=a$). Similarly, $S_{m,n}\left(
\beta\right)  =\left(  \left[  b\right]  _{m},\left[  b\right]  _{n}\right)
$. Thus, the equality $S_{m,n}\left(  \alpha\right)  =S_{m,n}\left(
\beta\right)  $ (which we have assumed to hold) rewrites as $\left(  \left[
a\right]  _{m},\left[  a\right]  _{n}\right)  =\left(  \left[  b\right]
_{m},\left[  b\right]  _{n}\right)  $. In other words, $\left[  a\right]
_{m}=\left[  b\right]  _{m}$ and $\left[  a\right]  _{n}=\left[  b\right]
_{n}$.

Now, we have $\left[  a\right]  _{m}=\left[  b\right]  _{m}$; equivalently,
$a\equiv b\operatorname{mod}m$ (by Proposition \ref{prop.eqrel.Z/n.ab}
\textbf{(b)}); in other words, $m\mid a-b$. Similarly, $n\mid a-b$.

Now, we have $m\perp n$ (since $m$ and $n$ are coprime) and $m\mid a-b$ and
$n\mid a-b$. Hence, Theorem \ref{thm.ent.coprime.combine} (applied to $m$, $n$
and $a-b$ instead of $a$, $b$ and $c$) yields $mn\mid a-b$. In other words,
$a\equiv b\operatorname{mod}mn$. In other words, $\left[  a\right]
_{mn}=\left[  b\right]  _{mn}$ (by Proposition \ref{prop.eqrel.Z/n.ab}
\textbf{(b)}). In other words, $\alpha=\beta$ (since $\alpha=\left[  a\right]
_{mn}$ and $\beta=\left[  b\right]  _{mn}$).

Now, forget that we fixed $\alpha$ and $\beta$. We thus have shown that if
$\alpha,\beta\in\mathbb{Z}/\left(  mn\right)  $ are such that $S_{m,n}\left(
\alpha\right)  =S_{m,n}\left(  \beta\right)  $, then $\alpha=\beta$. In other
words, the map $S_{m,n}$ is injective.]

[\textit{Proof that the map }$S_{m,n}$ \textit{is surjective:} Fix $\left(
\alpha,\beta\right)  \in\left(  \mathbb{Z}/m\right)  \times\left(
\mathbb{Z}/n\right)  $. We want to find a $\gamma\in\mathbb{Z}/\left(
mn\right)  $ such that $S_{m,n}\left(  \gamma\right)  =\left(  \alpha
,\beta\right)  $.

We have $\alpha\in\mathbb{Z}/m$. Thus, we can write the residue class $\alpha$
as $\alpha=\left[  a\right]  _{m}$ for some integer $a$ (because of
Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(a)}). Similarly, we can write the
residue class $\beta$ as $\beta=\left[  b\right]  _{n}$ for some integer $b$.
Consider these two integers $a$ and $b$. Theorem \ref{thm.ent.crt1}
\textbf{(a)} shows that there exists an integer $x\in\mathbb{Z}$ such that%
\[
\left(  x\equiv a\operatorname{mod}m\text{ and }x\equiv b\operatorname{mod}%
n\right)  .
\]
Consider such an $x$. We have $\left[  x\right]  _{m}=\left[  a\right]  _{m}$
(since $x\equiv a\operatorname{mod}m$) and $\left[  x\right]  _{n}=\left[
b\right]  _{n}$ (since $x\equiv b\operatorname{mod}n$). Now,
(\ref{pf.thm.eqrel.CRT2.Ss=}) (applied to $s=x$) yields
\[
S_{m,n}\left(  \left[  x\right]  _{mn}\right)  =\left(  \underbrace{\left[
x\right]  _{m}}_{=\left[  a\right]  _{m}=\alpha},\underbrace{\left[  x\right]
_{n}}_{=\left[  b\right]  _{n}=\beta}\right)  =\left(  \alpha,\beta\right)  .
\]
Thus, there exists a $\gamma\in\mathbb{Z}/\left(  mn\right)  $ such that
$S_{m,n}\left(  \gamma\right)  =\left(  \alpha,\beta\right)  $ (namely,
$\gamma=\left[  x\right]  _{mn}$).

Now, forget that we fixed $\left(  \alpha,\beta\right)  $. We thus have shown
that for any $\left(  \alpha,\beta\right)  \in\left(  \mathbb{Z}/m\right)
\times\left(  \mathbb{Z}/n\right)  $, there exists a $\gamma\in\mathbb{Z}%
/\left(  mn\right)  $ such that $S_{m,n}\left(  \gamma\right)  =\left(
\alpha,\beta\right)  $. In other words, the map $S_{m,n}$ is surjective.]

We have now proven that the map $S_{m,n}$ is both injective and surjective.
Hence, this map $S_{m,n}$ is bijective, i.e., is a bijection. This completes
the proof of Theorem \ref{thm.eqrel.CRT2}.

[\textit{Remark:} As in the proof of Theorem \ref{thm.ent.CRT-bij}, we could
have saved ourselves some of the work by invoking the Pigeonhole Principle.
Indeed, our goal was to show that the map $S_{m,n}$ is bijective. By the
Pigeonhole Principle, it suffices to prove that it is injective \textbf{or}
that it is surjective, since $\mathbb{Z}/\left(  mn\right)  $ and $\left(
\mathbb{Z}/m\right)  \times\left(  \mathbb{Z}/n\right)  $ are finite sets of
the same size. But such a proof would be harder to generalize to certain
settings that we might later want to generalize Theorem \ref{thm.eqrel.CRT2} to.]
\end{proof}

\begin{center}
\textbf{2019-02-27 lecture}
\end{center}

We have already proven Theorem \ref{thm.ent.phi.mult} using Theorem
\ref{thm.ent.CRT-bij}. Let us now reprove it using Theorem
\ref{thm.eqrel.CRT2} instead (by a rather similar argument, but using residue
classes instead of remainders):

\begin{proof}
[Second proof of Theorem \ref{thm.ent.phi.mult}.]For every positive integer
$g$, we let $U_{g}$ be the set of all residue classes $\alpha\in\mathbb{Z}/g$
that have an inverse. Then, $U_{n}$ is exactly the set that was called $U_{n}$
in Corollary \ref{cor.equiv.modinv.Unphi}. Hence, Corollary
\ref{cor.equiv.modinv.Unphi} \textbf{(b)} yields $\phi\left(  n\right)
=\left\vert U_{n}\right\vert $. Similarly, $\phi\left(  m\right)  =\left\vert
U_{m}\right\vert $ and $\phi\left(  mn\right)  =\left\vert U_{mn}\right\vert $.

Theorem \ref{thm.eqrel.CRT2} says that the map%
\begin{align*}
S_{m,n}:\mathbb{Z}/\left(  mn\right)   &  \rightarrow\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  ,\\
\alpha &  \mapsto\left(  \pi_{mn,m}\left(  \alpha\right)  ,\pi_{mn,n}\left(
\alpha\right)  \right)
\end{align*}
is well-defined and is a bijection. Consider this map $S_{m,n}$. This map
$S_{m,n}$ is a bijection, i.e., is injective and surjective. Moreover, the
definition of $S_{m,n}$ yields%
\[
S_{m,n}\left(  \left[  1\right]  _{mn}\right)  =\left(  \underbrace{\pi
_{mn,m}\left(  \left[  1\right]  _{mn}\right)  }_{\substack{=\left[  1\right]
_{m}\\\text{(by the definition of }\pi_{mn,m}\text{)}}},\underbrace{\pi
_{mn,n}\left(  \left[  1\right]  _{mn}\right)  }_{\substack{=\left[  1\right]
_{n}\\\text{(by the definition of }\pi_{mn,n}\text{)}}}\right)  =\left(
\left[  1\right]  _{m},\left[  1\right]  _{n}\right)  .
\]


Let us first prove a trivial fact:

\begin{statement}
\textit{Claim 1:} Let $\alpha,\beta\in\mathbb{Z}/\left(  mn\right)  $. Then,
$\pi_{mn,m}\left(  \alpha\beta\right)  =\pi_{mn,m}\left(  \alpha\right)
\cdot\pi_{mn,m}\left(  \beta\right)  $.
\end{statement}

[\textit{Proof of Claim 1:} Write the residue classes $\alpha$ and $\beta$ as
$\alpha=\left[  a\right]  _{mn}$ and $\beta=\left[  b\right]  _{mn}$ for some
integers $a$ and $b$. (This can be done because of Proposition
\ref{prop.eqrel.Z/n.ab} \textbf{(a)}.) Now, $\underbrace{\alpha}_{=\left[
a\right]  _{mn}}\cdot\underbrace{\beta}_{=\left[  b\right]  _{mn}}=\left[
a\right]  _{mn}\cdot\left[  b\right]  _{mn}=\left[  ab\right]  _{mn}$ (by the
definition of multiplication on $\mathbb{Z}/\left(  mn\right)  $). Hence,
\[
\pi_{mn,m}\left(  \underbrace{\alpha\beta}_{=\left[  ab\right]  _{mn}}\right)
=\pi_{mn,m}\left(  \left[  ab\right]  _{mn}\right)  =\left[  ab\right]
_{m}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\pi_{mn,m}\right)
.
\]


On the other hand, from $\alpha=\left[  a\right]  _{mn}$, we obtain
$\pi_{mn,m}\left(  \alpha\right)  =\pi_{mn,m}\left(  \left[  a\right]
_{mn}\right)  =\left[  a\right]  _{m}$ (by the definition of $\pi_{mn,m}$).
Similarly, $\pi_{mn,m}\left(  \beta\right)  =\left[  b\right]  _{m}$. Hence,%
\[
\underbrace{\pi_{mn,m}\left(  \alpha\right)  }_{=\left[  a\right]  _{m}}%
\cdot\underbrace{\pi_{mn,m}\left(  \beta\right)  }_{=\left[  b\right]  _{m}%
}=\left[  a\right]  _{m}\cdot\left[  b\right]  _{m}=\left[  ab\right]  _{m}%
\]
(by the definition of multiplication on $\mathbb{Z}/m$). Comparing this with
$\pi_{mn,m}\left(  \alpha\beta\right)  =\left[  ab\right]  _{m}$, we obtain
$\pi_{mn,m}\left(  \alpha\right)  \cdot\pi_{mn,m}\left(  \beta\right)  $. This
proves Claim 1.]

Also, from $U_{m}\subseteq\mathbb{Z}/m$ and $U_{n}\subseteq\mathbb{Z}/n$, we
obtain $U_{m}\times U_{n}\subseteq\left(  \mathbb{Z}/m\right)  \times\left(
\mathbb{Z}/n\right)  $.

Now, we claim that%
\begin{equation}
S_{m,n}\left(  U_{mn}\right)  \subseteq U_{m}\times U_{n}.
\label{pf.thm.ent.phi.mult.2nd.1}%
\end{equation}


[\textit{Proof of (\ref{pf.thm.ent.phi.mult.2nd.1}):} Let $\zeta\in
S_{m,n}\left(  U_{mn}\right)  $. Thus, $\zeta=S_{m,n}\left(  \alpha\right)  $
for some $\alpha\in U_{mn}$. Consider this $\alpha$.

We have $\alpha\in U_{mn}$. In other words, $\alpha$ is a residue class in
$\mathbb{Z}/\left(  mn\right)  $ that has an inverse (since $U_{mn}$ was
defined as the set of all residue classes in $\mathbb{Z}/\left(  mn\right)  $
that have an inverse). Thus, $\alpha$ is a residue class in $\mathbb{Z}%
/\left(  mn\right)  $ and has an inverse $\beta\in\mathbb{Z}/\left(
mn\right)  $. Consider this $\beta$. We know that $\beta$ is an inverse of
$\alpha$; in other words, $\alpha\beta=\left[  1\right]  _{mn}$ (by the
definition of \textquotedblleft inverse\textquotedblright).

Now, Claim 1 yields $\pi_{mn,m}\left(  \alpha\beta\right)  =\pi_{mn,m}\left(
\alpha\right)  \cdot\pi_{mn,m}\left(  \beta\right)  $, and thus%
\[
\pi_{mn,m}\left(  \alpha\right)  \cdot\pi_{mn,m}\left(  \beta\right)
=\pi_{mn,m}\left(  \underbrace{\alpha\beta}_{=\left[  1\right]  _{mn}}\right)
=\pi_{mn,m}\left(  \left[  1\right]  _{mn}\right)  =\left[  1\right]  _{m}%
\]
(by the definition of $\pi_{mn,m}$). Thus, $\pi_{mn,m}\left(  \beta\right)  $
is an inverse of $\pi_{mn,m}\left(  \alpha\right)  $ in $\mathbb{Z}/m$ (by the
definition of \textquotedblleft inverse\textquotedblright). Hence, $\pi
_{mn,m}\left(  \alpha\right)  $ is a residue class in $\mathbb{Z}/m$ that has
an inverse (namely, $\pi_{mn,m}\left(  \beta\right)  $). In other words,
$\pi_{mn,m}\left(  \alpha\right)  \in U_{m}$ (since $U_{m}$ was defined as the
set of all residue classes in $\mathbb{Z}/m$ that have an inverse). Similarly,
$\pi_{mn,n}\left(  \alpha\right)  \in U_{n}$. Now,
\begin{align*}
\zeta &  =S_{m,n}\left(  \alpha\right)  =\left(  \underbrace{\pi_{mn,m}\left(
\alpha\right)  }_{\in U_{m}},\underbrace{\pi_{mn,n}\left(  \alpha\right)
}_{\in U_{n}}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of
}S_{m,n}\right) \\
&  \in U_{m}\times U_{n}.
\end{align*}


Now, forget that we fixed $\zeta$. We thus have proven that $\zeta\in
U_{m}\times U_{n}$ for each $\zeta\in S_{m,n}\left(  U_{mn}\right)  $. In
other words, $S_{m,n}\left(  U_{mn}\right)  \subseteq U_{m}\times U_{n}$. This
proves (\ref{pf.thm.ent.phi.mult.2nd.1}).]

Next, we claim that%
\begin{equation}
U_{m}\times U_{n}\subseteq S_{m,n}\left(  U_{mn}\right)  .
\label{pf.thm.ent.phi.mult.2nd.2}%
\end{equation}


[\textit{Proof of (\ref{pf.thm.ent.phi.mult.2nd.2}):} Let $\theta\in
U_{m}\times U_{n}$. We shall prove that $\theta\in S_{m,n}\left(
U_{mn}\right)  $.

We have $\theta\in U_{m}\times U_{n}\subseteq\left(  \mathbb{Z}/m\right)
\times\left(  \mathbb{Z}/n\right)  =S_{m,n}\left(  \mathbb{Z}/\left(
mn\right)  \right)  $ (since the map $S_{m,n}$ is a bijection). In other
words, there exists some $\alpha\in\mathbb{Z}/\left(  mn\right)  $ such that
$\theta=S_{m,n}\left(  \alpha\right)  $. Consider this $\alpha$. The
definition of $S_{m,n}$ yields $S_{m,n}\left(  \alpha\right)  =\left(
\pi_{mn,m}\left(  \alpha\right)  ,\pi_{mn,n}\left(  \alpha\right)  \right)  $.
Hence,%
\[
\left(  \pi_{mn,m}\left(  \alpha\right)  ,\pi_{mn,n}\left(  \alpha\right)
\right)  =S_{m,n}\left(  \alpha\right)  =\theta\in U_{m}\times U_{n}.
\]
In other words, $\pi_{mn,m}\left(  \alpha\right)  \in U_{m}$ and $\pi
_{mn,n}\left(  \alpha\right)  \in U_{n}$.

We have $\pi_{mn,m}\left(  \alpha\right)  \in U_{m}$. In other words,
$\pi_{mn,m}\left(  \alpha\right)  $ is a residue class in $\mathbb{Z}/m$ that
has an inverse (since $U_{m}$ was defined as the set of all residue classes in
$\mathbb{Z}/m$ that have an inverse). In other words, $\pi_{mn,m}\left(
\alpha\right)  $ is a residue class in $\mathbb{Z}/m$ and has an inverse
$\gamma\in\mathbb{Z}/m$. Likewise, $\pi_{mn,n}\left(  \alpha\right)  $ is a
residue class in $\mathbb{Z}/n$ and has an inverse $\delta\in\mathbb{Z}/n$.
Consider these $\gamma$ and $\delta$.

We have $\left(  \gamma,\delta\right)  \in\left(  \mathbb{Z}/m\right)
\times\left(  \mathbb{Z}/n\right)  $. Since the map $S_{m,n}$ is surjective,
we can thus find a $\beta\in\mathbb{Z}/\left(  mn\right)  $ such that
$S_{m,n}\left(  \beta\right)  =\left(  \gamma,\delta\right)  $. Consider this
$\beta$. We have%
\[
\left(  \gamma,\delta\right)  =S_{m,n}\left(  \beta\right)  =\left(
\pi_{mn,m}\left(  \beta\right)  ,\pi_{mn,n}\left(  \beta\right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }S_{m,n}\right)  .
\]
In other words, $\gamma=\pi_{mn,m}\left(  \beta\right)  $ and $\delta
=\pi_{mn,n}\left(  \beta\right)  $.

Now, we want to prove that $\beta$ is an inverse of $\alpha$ (in
$\mathbb{Z}/\left(  mn\right)  $).

Indeed,
\begin{align*}
\pi_{mn,m}\left(  \alpha\beta\right)   &  =\pi_{mn,m}\left(  \alpha\right)
\cdot\underbrace{\pi_{mn,m}\left(  \beta\right)  }_{=\gamma}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Claim 1}\right) \\
&  =\pi_{mn,m}\left(  \alpha\right)  \cdot\gamma=\left[  1\right]
_{m}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\gamma\text{ is an inverse of
}\pi_{mn,m}\left(  \alpha\right)  \right)
\end{align*}
and similarly $\pi_{mn,n}\left(  \alpha\beta\right)  =\left[  1\right]  _{n}$.
Now, the definition of $S_{m,n}$ yields%
\[
S_{m,n}\left(  \alpha\beta\right)  =\left(  \underbrace{\pi_{mn,m}\left(
\alpha\beta\right)  }_{=\left[  1\right]  _{m}},\underbrace{\pi_{mn,n}\left(
\alpha\beta\right)  }_{=\left[  1\right]  _{n}}\right)  =\left(  \left[
1\right]  _{m},\left[  1\right]  _{n}\right)  .
\]
Comparing this with $S_{m,n}\left(  \left[  1\right]  _{mn}\right)  =\left(
\left[  1\right]  _{m},\left[  1\right]  _{n}\right)  $, we obtain
$S_{m,n}\left(  \alpha\beta\right)  =S_{m,n}\left(  \left[  1\right]
_{mn}\right)  $. Since the map $S_{m,n}$ is injective, we thus conclude that
$\alpha\beta=\left[  1\right]  _{mn}$. In other words, $\beta$ is an inverse
of $\alpha$ (by the definition of \textquotedblleft inverse\textquotedblright%
). Hence, $\alpha$ is a residue class in $\mathbb{Z}/\left(  mn\right)  $ that
has an inverse (namely, $\beta$). In other words, $\alpha\in U_{mn}$ (since
$U_{mn}$ was defined as the set of all residue classes in $\mathbb{Z}/\left(
mn\right)  $ that have an inverse). Now, $\theta=S_{m,n}\left(
\underbrace{\alpha}_{\in U_{mn}}\right)  \in S_{m,n}\left(  U_{mn}\right)  $.

Now, forget that we fixed $\theta$. We thus have shown that $\theta\in
S_{m,n}\left(  U_{mn}\right)  $ for each $\theta\in U_{m}\times U_{n}$. In
other words, $U_{m}\times U_{n}\subseteq S_{m,n}\left(  U_{mn}\right)  $. This
proves (\ref{pf.thm.ent.phi.mult.2nd.2}).]

Combining (\ref{pf.thm.ent.phi.mult.2nd.1}) with
(\ref{pf.thm.ent.phi.mult.2nd.2}), we obtain
\begin{equation}
S_{m,n}\left(  U_{mn}\right)  =U_{m}\times U_{n}.
\label{pf.thm.ent.phi.mult.2nd.1+2}%
\end{equation}


It is well-known that any two finite sets $A$ and $B$ satisfy $\left\vert
A\times B\right\vert =\left\vert A\right\vert \cdot\left\vert B\right\vert
$\ \ \ \ \footnote{This is the so-called \textit{product rule} in its simplest
form (see, e.g., \cite[1.5]{Loehr-BC} or \cite[\S 15.2.1]{LeLeMe}).}. Applying
this to $A=U_{m}$ and $B=U_{n}$, we obtain%
\[
\left\vert U_{m}\times U_{n}\right\vert =\underbrace{\left\vert U_{m}%
\right\vert }_{=\phi\left(  m\right)  }\cdot\underbrace{\left\vert
U_{n}\right\vert }_{=\phi\left(  n\right)  }=\phi\left(  m\right)  \cdot
\phi\left(  n\right)  .
\]


Note that $U_{mn}$ is a subset of $\mathbb{Z}/\left(  mn\right)  $ (by its definition).

Recall that the map $S_{m,n}$ is injective. Hence, $\left\vert S_{m,n}\left(
T\right)  \right\vert =\left\vert T\right\vert $ for each subset $T$ of
$\mathbb{Z}/\left(  mn\right)  $\ \ \ \ \footnote{This follows from the
following general principle: If $f:X\rightarrow Y$ is an injective map between
two finite sets $X$ and $Y$, then $\left\vert f\left(  T\right)  \right\vert
=\left\vert T\right\vert $ for each subset $T$ of $X$.}. Applying this to
$T=U_{mn}$, we obtain $\left\vert S_{m,n}\left(  U_{mn}\right)  \right\vert
=\left\vert U_{mn}\right\vert $. Thus,%
\[
\left\vert U_{mn}\right\vert =\left\vert \underbrace{S_{m,n}\left(
U_{mn}\right)  }_{\substack{=U_{m}\times U_{n}\\\text{(by
(\ref{pf.thm.ent.phi.mult.2nd.1+2}))}}}\right\vert =\left\vert U_{m}\times
U_{n}\right\vert =\phi\left(  m\right)  \cdot\phi\left(  n\right)  .
\]
Hence, $\phi\left(  mn\right)  =\left\vert U_{mn}\right\vert =\phi\left(
m\right)  \cdot\phi\left(  n\right)  $. So Theorem \ref{thm.ent.phi.mult} is
proven again.
\end{proof}

\subsection{Substitutivity and chains of congruences revisited}

Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} can be stated as follows:
Given an integer $n$, two integers $a$ and $b$ are congruent to each other
modulo $n$ if and only if their residue classes $\left[  a\right]  _{n}$ and
$\left[  b\right]  _{n}$ are equal. This lets us see congruences modulo $n$ in
a new light (namely, as equalities). In particular, some previous results
about congruences now become trivial. For example, we can obtain a very short
proof of Proposition \ref{prop.mod.chain} using residue classes:

\begin{proof}
[Proof of Proposition \ref{prop.mod.chain}.]We have the chain of congruences
$a_{1}\equiv a_{2}\equiv\cdots\equiv a_{k}\operatorname{mod}n$. In other
words,%
\[
a_{i}\equiv a_{i+1}\operatorname{mod}n\text{ holds for each }i\in\left\{
1,2,\ldots,k-1\right\}
\]
(by Definition \ref{def.mod.chain}). Thus, for each $i\in\left\{
1,2,\ldots,k-1\right\}  $, we have $a_{i}\equiv a_{i+1}\operatorname{mod}n$
and therefore $\left[  a_{i}\right]  _{n}=\left[  a_{i+1}\right]  _{n}$ (by
Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)}, applied to $a=a_{i}$ and
$b=a_{i+1}$). In other words, we have the chain of equalities $\left[
a_{1}\right]  _{n}=\left[  a_{2}\right]  _{n}=\cdots=\left[  a_{k}\right]
_{n}$. From this chain, we immediately obtain $\left[  a_{u}\right]
_{n}=\left[  a_{v}\right]  _{n}$ (by Proposition \ref{prop.mod.chain-eq},
applied to $\left[  a_{i}\right]  _{n}$ instead of $a_{i}$). Hence,
Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $a=a_{u}$ and
$b=a_{v}$) shows that $a_{u}\equiv a_{v}\operatorname{mod}n$. This proves
Proposition \ref{prop.mod.chain}.
\end{proof}

We can also prove the Principle of substitutivity of congruences (which we
informally stated in Section \ref{sect.ent.subst-mod}, and abbreviated as
\textquotedblleft PSC\textquotedblright):

\begin{proof}
[Proof of the PSC (informal).]We have $x\equiv x^{\prime}\operatorname{mod}n$.
Hence, Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $a=x$ and
$b=x^{\prime}$) yields $\left[  x\right]  _{n}=\left[  x^{\prime}\right]
_{n}$.

Now, let $\alpha$ be the expression $A$, except that each integer appearing in
it has been replaced by its residue class modulo $n$. (For example, if $A$ is
the expression \textquotedblleft$3-2\cdot7+6$\textquotedblright, then $\alpha$
will be \textquotedblleft$\left[  3\right]  _{n}-\left[  2\right]  _{n}%
\cdot\left[  7\right]  _{n}+\left[  6\right]  _{n}$\textquotedblright.)

Likewise, let $\alpha^{\prime}$ be the expression $A^{\prime}$, except that
each integer appearing in it has been replaced by its residue class modulo $n$.

The expression $A^{\prime}$ differs from $A$ only in that some appearance of
$x$ in it has been replaced by $x^{\prime}$. Thus, the expression
$\alpha^{\prime}$ differs from $\alpha$ only in that some appearance of
$\left[  x\right]  _{n}$ in it has been replaced by $\left[  x^{\prime
}\right]  _{n}$. This replacement does not change the value of the expression,
since $\left[  x\right]  _{n}=\left[  x^{\prime}\right]  _{n}$. Thus,
\[
\left(  \text{the value of }\alpha^{\prime}\right)  =\left(  \text{the value
of }\alpha\right)  .
\]


We have defined $\alpha$ to be the expression $A$, except that each integer
appearing in it has been replaced by its residue class modulo $n$. Thus, the
value of $\alpha$ is the residue class of the value of $A$ modulo $n$. (For
example, if $A$ is \textquotedblleft$3-2\cdot7+6$\textquotedblright, then
$\alpha$ will be \textquotedblleft$\left[  3\right]  _{n}-\left[  2\right]
_{n}\cdot\left[  7\right]  _{n}+\left[  6\right]  _{n}$\textquotedblright, and
thus%
\begin{align*}
\left(  \text{the value of }\alpha\right)   &  =\left[  3\right]
_{n}-\underbrace{\left[  2\right]  _{n}\cdot\left[  7\right]  _{n}%
}_{\substack{=\left[  2\cdot7\right]  _{n}\\\text{(by Definition
\ref{def.eqrel.Z/n.op} \textbf{(c)})}}}+\left[  6\right]  _{n}%
=\underbrace{\left[  3\right]  _{n}-\left[  2\cdot7\right]  _{n}%
}_{\substack{=\left[  3-2\cdot7\right]  _{n}\\\text{(by Definition
\ref{def.eqrel.Z/n.op} \textbf{(b)})}}}+\left[  6\right]  _{n}\\
&  =\left[  3-2\cdot7\right]  _{n}+\left[  6\right]  _{n}=\left[
3-2\cdot7+6\right]  _{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{by Definition
\ref{def.eqrel.Z/n.op} \textbf{(a)}}\right)  ,
\end{align*}
which is precisely the residue class of the value of $A$ modulo $n$.) In other
words, we have%
\[
\left(  \text{the value of }\alpha\right)  =\left[  \text{the value of
}A\right]  _{n}.
\]
Similarly,%
\[
\left(  \text{the value of }\alpha^{\prime}\right)  =\left[  \text{the value
of }A^{\prime}\right]  _{n}.
\]
Hence,%
\[
\left[  \text{the value of }A^{\prime}\right]  _{n}=\left(  \text{the value of
}\alpha^{\prime}\right)  =\left(  \text{the value of }\alpha\right)  =\left[
\text{the value of }A\right]  _{n}.
\]
Hence, Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(b)} (applied to $a=\left(
\text{the value of }A^{\prime}\right)  $ and $b=\left(  \text{the value of
}A\right)  $) yields $\left(  \text{the value of }A^{\prime}\right)
\equiv\left(  \text{the value of }A\right)  \operatorname{mod}n$. In other
words, the value of the expression $A^{\prime}$ is congruent to the value of
$A$ modulo $n$. This proves the PSC.
\end{proof}

\subsection{\label{sect.equiv.apps}A couple of applications of elementary
number theory}

In the following short section, we shall see two practical applications of the
above number-theoretical studies. The first is a method for encrypting
information (the RSA cryptosystem); the second is a trick by which
computations with large integers can be split up into more manageable pieces
(and distributed across several computers, or parallelized across several
cores). We shall be brief, since applications are not a focus of these notes;
for further details, see \cite{Gallier-RSA} and the MathOverflow answer
\url{https://mathoverflow.net/a/10022/} . If you are interested in further
applications, you may also want to consult the other answers to
\url{https://mathoverflow.net/questions/10014} (for a list of uses of the
Chinese Remainder Theorem -- mostly, but not entirely, inside mathematics), as
well as \cite[Appendix to Chapter VII]{Uspensky-Heaslet} (for applications of
modular arithmetic to calendar computations), and
\href{https://en.wikipedia.org/wiki/Universal_hashing}{the Wikipedia page on
\textquotedblleft Universal hashing\textquotedblright} (for an application of
residue classes modulo primes).

\subsubsection{\label{subsect.equiv.apps.RSA}The RSA cryptosystem}

Let us present \href{https://en.wikipedia.org/wiki/RSA_(cryptosystem)}{the
\textit{RSA cryptosystem}}. This is one of the first modern methods for
encrypting data. (The name \textquotedblleft RSA\textquotedblright\ stands for
the initials of its three authors: Rivest, Shamir and Adleman.)

This cryptosystem addresses a fairly standard situation: Albert and Julia want
to communicate secretly (i.e., Albert wants to send messages to Julia, and
Julia to Albert), \textbf{without} having to give each other keys in advance.

Albert wants to send encrypted messages that only Julia can read, and receive
encrypted messages that only he can read. The channel of communication may
have eavesdroppers.\footnote{We assume that Albert and Julia are merely trying
to keep the \textbf{content} of their messages secret from the eavesdroppers;
the eavesdroppers can still see \textbf{that they are sending each other
something}. If Albert and Julia want to keep even this fact secret, they need
a different branch of science -- \textit{steganography}, not cryptography.
(For reasons that become obvious after a bit of thought, steganography is much
less of an exact science than cryptography, and has a lot to do with real-life
situations.)} How can they do that?

\textbf{Setup:}

\begin{itemize}
\item Albert generates two distinct large and sufficiently random primes $p$
and $q$. (This involves a lot of technicalities like actually finding large
primes. See Keith Conrad's note \textit{The Solovay-Strassen test}
\cite{Conrad*} for an algorithm for generating large primes\footnote{More
precisely, the Solovay-Strassen test is an algorithm for checking (not with
100\% surety, but with high probability, which suffices in practice) whether a
given integer is prime. To make this into an algorithm for generating large
primes, you can simply keep randomly picking large numbers until you hit one
that is prime. This doesn't take \textbf{too} long, because
\href{https://en.wikipedia.org/wiki/Prime_number_theorem}{the prime number
theorem} says that (very roughly speaking!) the probability for a $k$-digit
number to be prime is $\approx1/k$. (A precise statement of this result would
require us to introduce notions that have nothing to do with algebra; it is
commonly done in courses on \textit{analytic number theory}. Needless to say,
it is perfectly possible to profit from this result in practice without
proving it.)}, and \cite{Gallier-RSA} for a more comprehensive treatment. As
to what \textquotedblleft large\textquotedblright\ means, we refer to
\href{https://en.wikipedia.org/wiki/Key_size}{the Wikipedia article on
\textquotedblleft key size\textquotedblright}.)

\item Albert computes the positive integer $m=pq$. This number $m$ (called the
\textit{modulus}) he makes public. (Note that factoring a number into a
product of primes is computationally a lot harder than multiplying a bunch of
primes\footnote{See
\href{https://en.wikipedia.org/wiki/Integer_factorization}{the Wikipedia page
on \textquotedblleft Integer factorization\textquotedblright} for details on
what this means. Note that this is not a proven theorem; any day, someone
could come up with a quick algorithm for factoring integers into products of
primes. You would hear about it in the news, though.}. Thus, eavesdroppers
will not (likely) be able to reconstruct the primes $p$ and $q$ from their
(public) product $m$.)

\item Albert computes the positive integer $\ell=\left(  p-1\right)  \left(
q-1\right)  $, but keeps this number private.

\item Albert randomly picks an $e\in\left\{  2,3,\ldots,\ell-1\right\}  $ such
that $e\perp\ell$. (Again, we omit the details of how to pick such an $e$
randomly\footnote{The rough idea is \textquotedblleft pick $e\in\left\{
2,3,\ldots,\ell-1\right\}  $ randomly; check (using the Euclidean algorithm)
whether $e\perp\ell$; if not, then pick another $e$, and keep repeating this
until you hit an $e$ such that $e\perp\ell$\textquotedblright. In theory, you
could be unlucky and keep picking bad $e$'s forever; but in reality, you will
soon hit an $e$ that satisfies $e\perp\ell$.}.) This number $e$ will be called
the \textit{encryption key}, and Albert keeps it private.

\item Albert computes a positive modular inverse $d$ of $e$ modulo $\ell$
(that is, a positive integer $d$ such that $ed\equiv1\operatorname{mod}\ell$).
This number $d$ exists by Theorem \ref{thm.ent.coprime.modinv} \textbf{(b)};
it will be called the \textit{decryption key}.

\item Albert publishes the pair $\left(  e,m\right)  $ as his \textit{public
key}.

\item We assume that the messages that Albert and Julia want to send to each
other are elements of $\left\{  0,1,\ldots,m-1\right\}  $. This assumption is
perfectly reasonable, because these messages originally exist in \textbf{some}
digital form (e.g., as bitstrings), and it is easy to translate them from this
form into elements of $\left\{  0,1,\ldots,m-1\right\}  $ by some universally
agreed rule (e.g., if a bitstring $\left(  a_{1},a_{2},\ldots,a_{k}\right)  $
is short enough, then the integer $a_{1}2^{k-1}+a_{2}2^{k-2}+\cdots
+a_{k}2^{k-k}$ will belong to $\left\{  0,1,\ldots,m-1\right\}  $, and thus we
can translate this bitstring into this latter integer; otherwise, we break it
up into shorter chunks and send those as separate messages).
\end{itemize}

\textbf{Encrypting a message:}

If Julia wants to send a message $a\in\left\{  0,1,\ldots,m-1\right\}  $ to
Albert, then she does the following:

\begin{itemize}
\item She computes the residue class $\alpha:=\left[  a\right]  _{m}%
\in\mathbb{Z}/m$.

\item She computes $\alpha^{e}$ in $\mathbb{Z}/m$. (This can be computed
quickly using \textit{binary exponentiation}: If $\beta\in\mathbb{Z}/m$, then
all powers of $\beta$ can be computed recursively via the formulas $\beta
^{2k}=\left(  \beta^{k}\right)  ^{2}$ and $\beta^{2k+1}=\left(  \beta
^{k}\right)  ^{2}\beta$.)

\item She sends the residue class $\alpha^{e}$ (or, more precisely, its unique
representative in the set $\left\{  0,1,\ldots,m-1\right\}  $%
\ \ \ \ \footnote{This unique representative exists by Proposition
\ref{prop.eqrel.Z/n.PR} \textbf{(b)} (and can be computed by picking an
arbitrary representative $b$ first, and then taking its remainder $b\%m$).})
to Albert.
\end{itemize}

\textbf{Decrypting a message:}

Albert receives the residue class $\beta=\alpha^{e}$ (or, more precisely, a
representative thereof, which he can easily turn into the residue class), and
recovers the original message $a$ as follows:

\begin{itemize}
\item He sets $\gamma=\beta^{d}$. This $\gamma$ is the same $\alpha$ that
Julia computed, as we shall see below.

\item He recovers the original message $a\in\left\{  0,1,\ldots,m-1\right\}  $
as the unique representative of the residue class $\gamma=\alpha$ in $\left\{
0,1,\ldots,m-1\right\}  $ (since Julia defined $\alpha$ as the residue class
of $a$).
\end{itemize}

This way, Julia can send a message to Albert that no eavesdropper can read --
unless said eavesdropper knows $d$, or possesses an algorithm hitherto unknown
to the world, or has an incredibly fast computer, or Albert's randomly picked
numbers were not random enough\footnote{Computers cannot generate
\textquotedblleft truly\textquotedblright\ random numbers (whatever this would
even mean!); thus, you have to get by with number generators which try their
best at being unpredictable. Lots of creativity has gone into finding ways to
\href{https://en.wikipedia.org/wiki/Random_number_generation}{come up with
numbers that are \textquotedblleft as random as possible\textquotedblright}.
Software alone is, per se, deterministic and thus can at most come up with
numbers that \textquotedblleft look random\textquotedblright%
\ (\href{https://en.wikipedia.org/wiki/Pseudorandom_number_generator}{\textquotedblleft
pseudorandom number generators\textquotedblright}). Nondeterministic input
must come from the outside world. This is why certain programs that generate
keys ask you to move your mouse around the screen -- they are, in fact, using
your mouse movements as a source of randomness. Better randomness comes from
\href{https://en.wikipedia.org/wiki/Hardware_random_number_generator}{hardware
random number generators}, such as Geiger counters or
\href{https://www.popularmechanics.com/technology/security/news/a28921/lava-lamp-security-cloudflare/}{lava
lamps}.
\par
What happens if your randomly picked prime numbers are not random enough? In
the worst case, you never find two distinct primes to begin with. In a more
realistic case, your distinct primes will all belong to a small and
predictable set, and an eavesdropper can easily find them simply by checking
all possibilities. In less obvious cases, different keys you generate for
different purposes will occasionally have some primes in common, in which case
an easy application of the Chinese Remainder Theorem will allow an
eavesdropper to reconstruct them and decrypt your messages. See
\url{https://factorable.net} for a study of RSA keys in the wild, which found
a lot of common primes.}, or one of myriad other practical mistakes has been
made. The proper implementation of the RSA cryptosystem, and the real-life
considerations needed to prevent \textquotedblleft leakage\textquotedblright%
\ of sensitive data such as the decryption key $d$, are a subject in its own
right, which we shall not discuss here.

Albert's method for recovering Julia's message relies on the following fact
(which we shall prove a bit later):

\begin{lemma}
\label{lem.ent.rsa.rsa-lem}Let $p$ and $q$ be two distinct primes. Let $N$ be
a positive integer such that $N\equiv1\operatorname{mod}\left(  p-1\right)
\left(  q-1\right)  $. Then:

\textbf{(a)} Each $a\in\mathbb{Z}$ satisfies $a^{N}\equiv a\operatorname{mod}%
pq$.

\textbf{(b)} Each $\alpha\in\mathbb{Z}/\left(  pq\right)  $ satisfies
$\alpha^{N}=\alpha$.
\end{lemma}

Now, when Albert receives $\beta=\alpha^{e}$ from Julia, we have%
\[
\beta^{d}=\left(  \alpha^{e}\right)  ^{d}=\alpha^{ed}.
\]
But $d$ was a modular inverse of $e$ modulo $\ell$; thus, $ed\equiv
1\operatorname{mod}\ell$. Since $\ell=\left(  p-1\right)  \left(  q-1\right)
$, we thus have $ed\equiv1\operatorname{mod}\left(  p-1\right)  \left(
q-1\right)  $. Hence, Lemma \ref{lem.ent.rsa.rsa-lem} \textbf{(b)} (applied to
$N=ed$) yields $\alpha^{ed}=\alpha$ (since $\alpha\in\mathbb{Z}/\underbrace{m}%
_{=pq}=\mathbb{Z}/\left(  pq\right)  $). Thus, $\beta^{d}=\alpha^{ed}=\alpha$.
Thus, the residue class $\gamma=\beta^{d}$ that Albert computes is exactly
Julia's $\alpha$; hence, Albert correctly recovers the message.

\begin{proof}
[Proof of Lemma \ref{lem.ent.rsa.rsa-lem} (sketched).]\textbf{(a)} Let
$a\in\mathbb{Z}$. We need to show that $a^{N}\equiv a\operatorname{mod}pq$. In
other words, we need to show that $pq\mid a^{N}-a$. Since $p\perp q$, it
suffices to prove that $p\mid a^{N}-a$ and $q\mid a^{N}-a$ (because then,
Theorem \ref{thm.ent.coprime.combine} will yield $pq\mid a^{N}-a$).

Let us prove that $p\mid a^{N}-a$ first. Two cases are possible:

\textit{Case 1:} We have $p\mid a$.

\textit{Case 2:} We have $p\nmid a$.

Let us first consider Case 1. In this case, we have $p\mid a$. Thus,
$a\equiv0\operatorname{mod}p$. Hence, $a^{N}\equiv0^{N}=0\operatorname{mod}p$
(since $N$ is positive). Thus, $\underbrace{a^{N}}_{\equiv0\operatorname{mod}%
p}-\underbrace{a}_{\equiv0\operatorname{mod}p}\equiv0-0=0\operatorname{mod}p$,
so that $p\mid a^{N}-a$. Thus, we have proven $p\mid a^{N}-a$ in Case 1.

Now, let us consider Case 2. In this case, we have $p\nmid a$. But we have
$p-1\mid\left(  p-1\right)  \left(  q-1\right)  $ and $N\equiv
1\operatorname{mod}\left(  p-1\right)  \left(  q-1\right)  $; hence,
Proposition \ref{prop.ent.mod.basics} \textbf{(e)} (applied to $\left(
p-1\right)  \left(  q-1\right)  $, $p-1$, $N$ and $1$ instead of $n$, $m$, $a$
and $b$) yields $N\equiv1\operatorname{mod}p-1$. Hence, Exercise
\ref{exe.ent.fermat.uv} (applied to $u=N$ and $v=1$) yields $a^{N}\equiv
a^{1}=a\operatorname{mod}p$. In other words, $p\mid a^{N}-a$. Thus, we have
proven $p\mid a^{N}-a$ in Case 2.

So we have proven $p\mid a^{N}-a$ in both Cases. Hence, $p\mid a^{N}-a$ always
holds. Similarly, we can prove $q\mid a^{N}-a$. This completes our proof of
Lemma \ref{lem.ent.rsa.rsa-lem} \textbf{(a)}.

\textbf{(b)} Let $\alpha\in\mathbb{Z}/\left(  pq\right)  $. Then, we can write
$\alpha$ in the form $\alpha=\left[  a\right]  _{pq}$ for some $a\in
\mathbb{Z}$ (by Proposition \ref{prop.eqrel.Z/n.ab} \textbf{(a)}). Consider
this $a$. From $\alpha=\left[  a\right]  _{pq}$, we obtain $\alpha^{N}=\left(
\left[  a\right]  _{pq}\right)  ^{N}=\left[  a^{N}\right]  _{pq}=\left[
a\right]  _{pq}$ (since Lemma \ref{lem.ent.rsa.rsa-lem} \textbf{(a)} yields
$a^{N}\equiv a\operatorname{mod}pq$). Hence, $\alpha^{N}=\left[  a\right]
_{pq}=\alpha$. This proves Lemma \ref{lem.ent.rsa.rsa-lem} \textbf{(b)}.
\end{proof}

\subsubsection{\label{subsect.equiv.apps.CRT}Computing using the Chinese
Remainder Theorem}

Next, let us outline a simple yet unexpected application of the Chinese
Remainder Theorem.

Assume that you have an expression $a$ that is made of integers, addition,
subtraction and multiplication. For example, say%
\begin{equation}
a=400\cdot405\cdot409\cdot413-401\cdot404\cdot408\cdot414.
\label{eq.eqrel.app.crt.1}%
\end{equation}


Assume that computing $a$ directly is too hard, because the intermediate
results will be forbiddingly huge numbers, but you know (e.g., from some
estimates) that the final result will be a fairly small number. Let's say (for
simplicity) that you know that $0\leq a<500\ 000$.

How can you use this information to compute $a$ quickly?

One simple trick is to work with residue classes modulo $500\ 000$ instead of
working with integer. Thus, instead of computing the number $a$ directly
through the equality (\ref{eq.eqrel.app.crt.1}), we can instead compute its
residue class%
\begin{align*}
\left[  a\right]  _{500\ 000}  &  =\left[  400\cdot405\cdot409\cdot
413-401\cdot404\cdot408\cdot414\right]  _{500\ 000}\\
&  =\left[  400\right]  _{500\ 000}\cdot\left[  405\right]  _{500\ 000}%
\cdot\left[  409\right]  _{500\ 000}\cdot\left[  413\right]  _{500\ 000}\\
&  \ \ \ \ \ \ \ \ \ \ -\left[  401\right]  _{500\ 000}\cdot\left[
404\right]  _{500\ 000}\cdot\left[  408\right]  _{500\ 000}\cdot\left[
414\right]  _{500\ 000}%
\end{align*}
(which is an easier task, because we can always reduce our intermediate
results using the fact that every integer $a$ satisfies $\left[  a\right]
_{500\ 000}=\left[  a\ \%\ 500\ 000\right]  _{500\ 000}$), and then recover
$a$ by observing that $a$ must be the unique representative of its residue
class $\left[  a\right]  _{500\ 000}$ that belongs to $\left\{  0,1,\ldots
,499\ 999\right\}  $ (since $0\leq a<500\ 000$). This is actually how integer
arithmetic works in most low-level programming languages; for example, the
most popular integer type of the C++ language is \textquotedblleft%
\texttt{int}\textquotedblright, which stands not for integers but rather for
residue classes modulo $2^{64}$ (when working on a 64-bit system). (This is
where integer overflow comes from.)

Computing $\left[  a\right]  _{500\ 000}$ instead of computing $a$ is already
an improvement, but in practice, the \textquotedblleft$500\ 000$%
\textquotedblright\ might actually be a significantly bigger number. Assume,
for example, that instead of $0\leq a<500\ 000$, you merely know that $0\leq
a<N$ for some fixed number $N$ which is small enough that computing in
$\mathbb{Z}/N$ is possible, but large enough that doing the \textbf{whole}
computation of $\left[  a\right]  _{N}$ in $\mathbb{Z}/N$ is unviable. What
can we do then?

One thing we can do is to compute the residue classes $\left[  a\right]  _{n}$
for several coprime \textquotedblleft small\textquotedblright\ integers $n$.
For example, we can compute $\left[  a\right]  _{2}$ (by performing the whole
computation of $a$ using residue classes modulo $2$ instead of integers) and
similarly $\left[  a\right]  _{3}$ and $\left[  a\right]  _{5}$ and $\left[
a\right]  _{7}$ etc.. (We are using prime numbers for $n$ here, which has
certain advantages, but is not strictly necessary; all we need is that the
values of $n$ we are using are coprime.\footnote{Note that the computations of
$\left[  a\right]  _{n}$ for different values of $n$ are independent of each
other, which comes handy if you have several processors.})

The Chinese Remainder Theorem (in the form of Theorem \ref{thm.eqrel.CRT2})
shows that if $m$ and $n$ are two coprime positive integers, then the map
$S_{m,n}$ from Theorem \ref{thm.eqrel.CRT2} (sending each $\left[  s\right]
_{mn}$ to the pair $\left(  \left[  s\right]  _{m},\left[  s\right]
_{n}\right)  $) is a bijection. In our proof of Theorem \ref{thm.eqrel.CRT2}
(when proving the surjectivity of $S_{m,n}$), we gave an explicit way of
constructing preimages under this map $S_{m,n}$ (using Bezout's theorem, which
has a fast algorithm underlying it --
\href{https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm}{the Extended
Euclidean algorithm}). Thus, we have an explicit way of recovering the residue
class $\left[  s\right]  _{mn}$ from the pair $\left(  \left[  s\right]
_{m},\left[  s\right]  _{n}\right)  $ whenever $s$ is an (unknown) integer
(and $m$ and $n$ are two coprime positive integers). We shall now refer to
this way as the \textquotedblleft patching procedure\textquotedblright\ (since
it lets us \textquotedblleft patch\textquotedblright\ two residue classes
$\left[  s\right]  _{m}$ and $\left[  s\right]  _{n}$ together to a residue
class $\left[  s\right]  _{mn}$).

Now, having computed a bunch of residue classes $\left[  a\right]
_{2},\left[  a\right]  _{3},\left[  a\right]  _{5},\left[  a\right]  _{7}$ of
our unknown integer $a$ modulo coprime small integers, we can
\textquotedblleft patch\textquotedblright\ these classes together:

\begin{itemize}
\item From $\left[  a\right]  _{2}$ and $\left[  a\right]  _{3}$, we get
$\left[  a\right]  _{2\cdot3}$ by the \textquotedblleft patching
procedure\textquotedblright.

\item From $\left[  a\right]  _{2\cdot3}$ and $\left[  a\right]  _{5}$, we get
$\left[  a\right]  _{2\cdot3\cdot5}$ by the \textquotedblleft patching
procedure\textquotedblright.

\item From $\left[  a\right]  _{2\cdot3\cdot5}$ and $\left[  a\right]  _{7}$,
we get $\left[  a\right]  _{2\cdot3\cdot5\cdot7}$ by the \textquotedblleft
patching procedure\textquotedblright.

\item and so on.
\end{itemize}

\noindent We keep \textquotedblleft patching\textquotedblright\ until the
product $2\cdot3\cdot5\cdot7\cdot\cdots$ becomes larger than our $N$ (which
will happen fairly soon, since this product grows super-exponentially with the
number of \textquotedblleft patching\textquotedblright\ steps). At that point,
we have found the residue class $\left[  a\right]  _{m}$ of our unknown
integer $a$ modulo some integer $m>N$. Since $0\leq a<N<m$, we can thus
recover $a$ itself (as the unique representative of the class $\left[
a\right]  _{m}$ that lies in the set $\left\{  0,1,\ldots,m-1\right\}  $).

This technique has been used a lot (for an example, see \cite[pp.
1031--1033]{Vogan07}).

\begin{noncompile}
I think computer algebra software uses a slightly more complicated version of
this technique, e.g., for factoring integer polynomials. (Not sure -- maybe
they're just using one prime.)
\end{noncompile}

\begin{center}
\textbf{2019-03-01 lecture}
\end{center}

\subsection{\label{sect.eqrel.primroot1}Primitive roots: an introduction}

\subsubsection{\label{subsect.eqrel.primroot1.def}Definition and examples}

Let us finally discuss a kind of residue classes that come very useful when
they exist: the \textit{primitive roots} (modulo a positive integer $n$). We
are not yet able to ascertain when they exist and when they don't (this will
require some more abstract algebra); but we can already see some examples of them:

\begin{convention}
For the whole Subsection \ref{subsect.eqrel.primroot1.def}, we fix a positive
integer $n$.
\end{convention}

\begin{definition}
\label{def.eqrel.primroot1.def.primroot}Let $\alpha\in\mathbb{Z}/n$ be a
residue class.

\textbf{(a)} We say that $\alpha$ is \textit{invertible} if $\alpha$ has an inverse.

\textbf{(b)} A \textit{power of }$\alpha$ means a residue class of the form
$\alpha^{m}$ for some $m\in\mathbb{N}$.

\textbf{(c)} Assume that $\alpha$ is invertible. Then, $\alpha$ is said to be
a \textit{primitive root modulo }$n$ if every invertible residue class
$\beta\in\mathbb{Z}/n$ is a power of $\alpha$.
\end{definition}

\begin{example}
\label{exa.eqrel.primroot1.def.primroot9}Let $n=9$. The invertible residue
classes in $\mathbb{Z}/9$ are $\left[  1\right]  _{9},\left[  2\right]
_{9},\left[  4\right]  _{9},\left[  5\right]  _{9},\left[  7\right]
_{9},\left[  8\right]  _{9}$.

Clearly, the residue class $\left[  1\right]  _{9}$ is not a primitive root
modulo $9$, since all its powers equal $\left[  1\right]  _{9}$.

The powers of $\left[  2\right]  _{9}$ are
\begin{align*}
\left(  \left[  2\right]  _{9}\right)  ^{0}  &  =\left[  1\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{1}  &  =\left[  2\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{2}  &  =\left[  4\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{3}  &  =\left[  8\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{4}  &  =\left[  7\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{5}  &  =\left[  5\right]  _{9},\\
&  \ldots.
\end{align*}
\footnotemark\ Thus, they cover all the six invertible residue classes
$\left[  1\right]  _{9},\left[  2\right]  _{9},\left[  4\right]  _{9},\left[
5\right]  _{9},\left[  7\right]  _{9},\left[  8\right]  _{9}$. Hence, $\left[
2\right]  _{9}$ is a primitive root modulo $9$.

It is easy to see that $\left[  5\right]  _{9}$ also is a primitive root
modulo $9$, and these two primitive roots are the only ones.
\end{example}

\footnotetext{Here is a fast way to compute these powers:%
\begin{align*}
\left(  \left[  2\right]  _{9}\right)  ^{0}  &  =\left[  1\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{1}  &  =\left[  2\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{2}  &  =\left[  \underbrace{2^{2}%
}_{=4}\right]  _{9}=\left[  4\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{3}  &  =\left[  \underbrace{2^{3}%
}_{=8}\right]  _{9}=\left[  8\right]  _{9},\\
\left(  \left[  2\right]  _{9}\right)  ^{4}  &  =\left[  \underbrace{2^{4}%
}_{=16}\right]  _{9}=\left[  16\right]  _{9}=\left[  7\right]  _{9}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }16\equiv7\operatorname{mod}9\right)
,\\
\left(  \left[  2\right]  _{9}\right)  ^{5}  &  =\left[  2\right]  _{9}%
\cdot\underbrace{\left(  \left[  2\right]  _{9}\right)  ^{4}}_{=\left[
7\right]  _{9}}=\left[  2\right]  _{9}\cdot\left[  7\right]  _{9}=\left[
\underbrace{2\cdot7}_{=14}\right]  _{9}=\left[  14\right]  _{9}=\left[
5\right]  _{9}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }14\equiv
5\operatorname{mod}9\right)  ,\\
&  \ldots.
\end{align*}
}Note that Corollary \ref{cor.equiv.modinv.Unphi} \textbf{(b)} shows that
there are exactly $\phi\left(  n\right)  $ invertible residue classes in
$\mathbb{Z}/n$. It is easy to see that any power of an invertible residue
class is again invertible.

Euler's theorem (Theorem \ref{thm.ent.euler}) yields that if $\alpha
\in\mathbb{Z}/n$ is an invertible residue class, then $\alpha^{\phi\left(
n\right)  }=\left[  1\right]  _{n}$ (because Corollary
\ref{cor.equiv.modinv.Unphi} \textbf{(a)} shows that $\alpha$ can be written
in the form $\alpha=\left[  a\right]  _{n}$ for some integer $a$ satisfying
$a\perp n$). Thus, it is easy to see that an invertible residue class
$\alpha\in\mathbb{Z}/n$ has at most $\phi\left(  n\right)  $ distinct powers.
When an invertible residue class $\alpha\in\mathbb{Z}/n$ has \textbf{exactly}
$\phi\left(  n\right)  $ distinct powers, it is a primitive root (since there
are exactly $\phi\left(  n\right)  $ invertible residue classes in
$\mathbb{Z}/n$).

\begin{example}
\label{exa.eqrel.primroot1.def.primroot8}Let $n=8$. The invertible residue
classes in $\mathbb{Z}/8$ are $\left[  1\right]  _{8},\left[  3\right]
_{8},\left[  5\right]  _{8},\left[  7\right]  _{8}$.

Again, $\left[  1\right]  _{8}$ is certainly not a primitive root.

The powers of $\left[  3\right]  _{8}$ are
\begin{align*}
\left(  \left[  3\right]  _{8}\right)  ^{0}  &  =\left[  1\right]  _{8},\\
\left(  \left[  3\right]  _{8}\right)  ^{1}  &  =\left[  3\right]  _{8},\\
\left(  \left[  3\right]  _{8}\right)  ^{2}  &  =\left[  9\right]
_{8}=\left[  1\right]  _{8},\\
&  \ldots
\end{align*}
(so the even powers are $\left[  1\right]  _{8}$ and the odd powers are
$\left[  3\right]  _{8}$). So $\left[  3\right]  _{8}$ is not a primitive root.

The same behavior prevents $\left[  5\right]  _{8}$ and $\left[  7\right]
_{8}$ from being primitive roots.

Thus, we see that there are no primitive roots modulo $8$.
\end{example}

Examples \ref{exa.eqrel.primroot1.def.primroot8} and
\ref{exa.eqrel.primroot1.def.primroot9} suggest the following questions: For
what $n$ does a primitive root modulo $n$ exist, and when it does, how many of
them are there? The following theorem -- a result proven in 1801 by Gauss --
answers both of these questions:

\begin{theorem}
\label{thm.eqrel.primroot.gauss}\textbf{(a)} A primitive root modulo $n$
exists if and only if $n$ is

\begin{itemize}
\item either $1$,

\item or a prime $p$,

\item or a power $p^{k}$ of an odd prime\footnotemark$\ p$ (with $k$ being a
positive integer),

\item or $4$,

\item or $2p^{k}$ for an odd prime $p$ (with $k$ being a positive integer).
\end{itemize}

\textbf{(b)} If a primitive root modulo $n$ exists, then there are precisely
$\phi\left(  \phi\left(  n\right)  \right)  $ many of them.
\end{theorem}

\footnote{Recall: Odd primes are the same as primes $\neq2$.} This theorem
would be fairly difficult to prove at this point, but will be doable with some
abstract algebra (at least in the case $n=p$). See \cite[Chapter
4]{Gallier-RSA} for a proof.

\section{\label{chp.CC}Complex numbers and Gaussian integers}

\subsection{\label{sect.CC.CC}Complex numbers}

\subsubsection{An informal introduction}

We now leave (at least for the time being) the study of integers and proceed
to consider a much larger \textquotedblleft number system\textquotedblright:
\href{https://en.wikipedia.org/wiki/Complex_number}{the \textit{complex
numbers}}.

Before we define these numbers rigorously, let me sketch the idea behind their
construction. Please suspend your disbelief about the not-quite-kosher
reasoning that will follow; we will return to rigorous mathematics in
Definition \ref{def.CC.CC} below.

We know that the number $-1$ (like any other negative number) has no square
root in $\mathbb{R}$ (because the square of any real number is $\geq0$). But
let us audaciously pretend that it does have a square root somewhere else. In
other words, let us pretend that there exists a mythical \textquotedblleft
number\textquotedblright\ $i$ such that $i^{2}=-1$. Of course, such a
\textquotedblleft number\textquotedblright\ $i$ will not be a real number, but
let us assume (without real justification, for now) that it behaves like a
usual number would (to some extent). In particular, let us assume that it can
be added, subtracted and multiplied like the numbers that we know and love.

So we have extended the set $\mathbb{R}$ of real numbers by a new number $i$.
Now, by applying addition, subtraction and multiplication to this new number
(and our old numbers), we get a bunch of further new numbers -- namely, all
numbers of the form $a_{0}+a_{1}i+a_{2}i^{2}+\cdots+a_{k}i^{k}$, where
$k\in\mathbb{N}$ and where $a_{0},a_{1},\ldots,a_{k}$ are real numbers. (These
can be described as the polynomials in $i$ with real coefficients.) However,
some of these numbers will be equal; in fact, any number of this form can be
reduced to a number of the form $a+bi$ (with $a,b\in\mathbb{R}$),
because\footnote{Of course, we are assuming that the standard rules -- such as
associativity of multiplication -- apply to our \textquotedblleft
new\textquotedblright\ numbers.}
\begin{align*}
i^{2}  &  =-1,\ \ \ \ \ \ \ \ \ \ i^{3}=i\underbrace{i^{2}}_{=-1}%
=-i,\ \ \ \ \ \ \ \ \ \ i^{4}=i\underbrace{i^{3}}_{=-i}=-\underbrace{i^{2}%
}_{=-1}=-\left(  -1\right)  =1,\\
i^{5}  &  =i\underbrace{i^{4}}_{=1}=i,\ \ \ \ \ \ \ \ \ \ \text{etc..}%
\end{align*}
For example, the number $3+5i+9i^{2}+7i^{3}$ equals $3+5i+9\left(  -1\right)
+7\left(  -i\right)  =\left(  3-9\right)  +\left(  5-7\right)  i=-6-2i$.

So all our new numbers have the form $a+bi$ for two reals $a$ and $b$. We call
them \textquotedblleft complex numbers\textquotedblright. (As we have said, we
will give a rigorous definition later.) Since we are assuming that the
standard rules of arithmetic still hold for our new numbers, we can easily
find formulas for computing the sum, the difference, the product and the
quotient of two complex numbers written in the form $a+bi$: Namely, for any
two complex numbers $a+bi$ and $c+di$ (with $a,b,c,d\in\mathbb{R}$), we have%
\begin{align}
\left(  a+bi\right)  +\left(  c+di\right)   &  =\left(  a+c\right)  +\left(
b+d\right)  i;\label{eq.CC.motivate.+}\\
\left(  a+bi\right)  -\left(  c+di\right)   &  =\left(  a-c\right)  +\left(
b-d\right)  i;\label{eq.CC.motivate.-}\\
\left(  a+bi\right)  \left(  c+di\right)   &  =ac+adi+bci+bd\underbrace{i^{2}%
}_{=-1}=ac+adi+bci-bd\nonumber\\
&  =\left(  ac-bd\right)  +\left(  ad+bc\right)  i;\label{eq.CC.motivate.*}\\
\dfrac{a+bi}{c+di}  &  =\dfrac{\left(  a+bi\right)  \left(  c-di\right)
}{\left(  c+di\right)  \left(  c-di\right)  }=\dfrac{ac-adi+bci+bdi^{2}%
}{cc-cdi+dci-ddi^{2}}=\dfrac{ac-adi+bci+bd\left(  -1\right)  }%
{cc-cdi+dci-dd\left(  -1\right)  }\nonumber\\
&  =\dfrac{\left(  ac+bd\right)  +\left(  bc-ad\right)  i}{c^{2}+d^{2}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{if }c,d\text{ are not both }0\right)  .
\label{eq.CC.motivate./}%
\end{align}
(Note that the latter formula is an analogue of the standard procedure for
rationalizing denominators that involve square roots:%
\[
\dfrac{a+b\sqrt{2}}{c+d\sqrt{2}}=\dfrac{\left(  a+b\sqrt{2}\right)  \left(
c-d\sqrt{2}\right)  }{\left(  c+d\sqrt{2}\right)  \left(  c-d\sqrt{2}\right)
}=\dfrac{\left(  ac-2bd\right)  +\left(  bc-ad\right)  \sqrt{2}}{c^{2}-2d^{2}%
},
\]
except that the square root that we are trying to exorcise from the
denominator is not $\sqrt{2}$ but $\sqrt{-1}=i$ now.)

However, not all features of real numbers carry over to complex numbers:
Inequalities do not make sense for complex numbers. Indeed, if they would make
sense, then we would get a contradiction as follows:

\begin{itemize}
\item If $i\geq0$, then $i^{2}\geq0$, contradicting $i^{2}=-1<0$.

\item If $i<0$, then $i^{2}=\left(  -i\right)  ^{2}>0$ (since $i<0$ yields
$-i>0$), contradicting $i^{2}=-1<0$.
\end{itemize}

Here, we have assumed two things about our relations: First, we have assumed
that $i$ is either $\geq0$ or $<0$; and second, we have assumed that the
square of a nonnegative complex number is nonnegative. Sure, we could avoid
the contradiction by forfeiting one of these assumptions; but then, the $\geq$
and $<$ relations would not be worth their names any more.

So we appear to be able to extend the four operations $+,-,\cdot,/$ to our
weird new numbers, but not the relations $<,\leq,>,\geq$ (at least not in any
meaningful way). But how can we be sure that the four operations $+,-,\cdot,/$
don't already lead to some contradictions?

To answer this question, let us forget our daring postulation of the existence
of $i$, and instead give a formal definition of complex numbers:

\subsubsection{Rigorous definition of the complex numbers}

\begin{definition}
\label{def.CC.CC}\textbf{(a)} A \textit{complex number} is defined as a pair
$\left(  a,b\right)  $ of two real numbers.

\textbf{(b)} We let $\mathbb{C}$ be the set of all complex numbers.

\textbf{(c)} For each real number $r$, we denote the complex number $\left(
r,0\right)  $ by $r_{\mathbb{C}}$.

\textbf{(d)} We let $i$ be the complex number $\left(  0,1\right)  $. When the
notation \textquotedblleft$i$\textquotedblright\ is ambiguous, I will be
calling it \textquotedblleft$i_{\mathbb{C}}$\textquotedblright\ instead. (Some
authors call it $j$ or $\iota$ or $\sqrt{-1}$.)

\textbf{(e)} We define three binary operations $+$, $-$ and $\cdot$ on
$\mathbb{C}$ by setting%
\begin{align*}
\left(  a,b\right)  +\left(  c,d\right)   &  =\left(  a+c,b+d\right)  ,\\
\left(  a,b\right)  -\left(  c,d\right)   &  =\left(  a-c,b-d\right)
,\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  a,b\right)  \cdot\left(  c,d\right)   &  =\left(  ac-bd,ad+bc\right)
\end{align*}
for all $\left(  a,b\right)  \in\mathbb{C}$ and $\left(  c,d\right)
\in\mathbb{C}$.

\textbf{(f)} If $\alpha$ and $\beta$ are two complex numbers, then we write
$\alpha\beta$ for $\alpha\cdot\beta$.

\textbf{(g)} If $\alpha$ is a complex number, then the complex number
$0_{\mathbb{C}}-\alpha$ shall be denoted by $-\alpha$.
\end{definition}

For example, the definition of the operation $\cdot$ on $\mathbb{C}$ yields%
\[
\underbrace{i}_{=\left(  0,1\right)  }\underbrace{i}_{=\left(  0,1\right)
}=\left(  0,1\right)  \left(  0,1\right)  =\left(  \underbrace{0\cdot
0-1\cdot1}_{=-1},\underbrace{0\cdot1+1\cdot0}_{=0}\right)  =\left(
-1,0\right)  =\left(  -1\right)  _{\mathbb{C}}.
\]
We will later\footnote{in Convention \ref{conv.CC.RRtoCC.embed}} equate the
complex number $\left(  -1\right)  _{\mathbb{C}}$ with the real number $-1$;
thus, this equation will simplify to $ii=-1$. So $i$ \textquotedblleft behaves
like a square root of $-1$\textquotedblright. But we also have $\left(
-i\right)  \left(  -i\right)  =\left(  -1\right)  _{\mathbb{C}}$, so $-i$ fits
the same bill. Thus, we didn't have to postulate the existence of a mythical
number $i$ satisfying $i^{2}=1$; we simply found such a number in the set
$\mathbb{C}$.

The definitions of the operations $+$, $-$ and $\cdot$ in Definition
\ref{def.CC.CC} are not chosen by accident. We shall later identify each
complex number $\left(  a,b\right)  $ with $a+bi$; then, these definitions
will become exactly the equalities (\ref{eq.CC.motivate.+}),
(\ref{eq.CC.motivate.-}) and (\ref{eq.CC.motivate.*}) that we derived unrigorously.

We are leaving division of complex numbers undefined so far, because we will
later get it more or less for free.

We shall follow \href{https://en.wikipedia.org/wiki/Order_of_operations}{the
usual \textquotedblleft PEMDAS\textquotedblright\ rules for the order of
operations} when interpreting expressions involving the operations $+$, $-$
and $\cdot$ on $\mathbb{C}$. Thus, for example, the expression
\textquotedblleft$\alpha+\beta\cdot\gamma$\textquotedblright\ shall mean
$\alpha+\left(  \beta\cdot\gamma\right)  $ and not $\left(  \alpha
+\beta\right)  \cdot\gamma$.

\subsubsection{Rules for $+$, $-$ and $\cdot$}

So we have defined complex numbers as pairs of real numbers, and we have
defined three operations on them which we called $+$, $-$ and $\cdot$. But do
these operations really deserve these names? Do they still behave as nicely as
the corresponding operations on real numbers? Do they, in particular, satisfy
the standard rules of arithmetic such as commutativity, associativity and
distributivity? The next theorem shows that they indeed do:

\begin{theorem}
\label{thm.CC.CC.rules}The following rules for addition, subtraction and
multiplication in $\mathbb{C}$ hold:

\textbf{(a)} We have $\alpha+\beta=\beta+\alpha$ for any $\alpha,\beta
\in\mathbb{C}$.

\textbf{(b)} We have $\alpha+\left(  \beta+\gamma\right)  =\left(
\alpha+\beta\right)  +\gamma$ for any $\alpha,\beta,\gamma\in\mathbb{C}$.

\textbf{(c)} We have $\alpha+0_{\mathbb{C}}=0_{\mathbb{C}}+\alpha=\alpha$ for
any $\alpha\in\mathbb{C}$.

\textbf{(d)} We have $\alpha\cdot1_{\mathbb{C}}=1_{\mathbb{C}}\cdot
\alpha=\alpha$ for any $\alpha\in\mathbb{C}$.

\textbf{(e)} We have $\alpha\cdot\beta=\beta\cdot\alpha$ for any $\alpha
,\beta\in\mathbb{C}$.

\textbf{(f)} We have $\alpha\cdot\left(  \beta\cdot\gamma\right)  =\left(
\alpha\cdot\beta\right)  \cdot\gamma$ for any $\alpha,\beta,\gamma
\in\mathbb{C}$.

\textbf{(g)} We have $\alpha\cdot\left(  \beta+\gamma\right)  =\alpha
\beta+\alpha\gamma$ and $\left(  \alpha+\beta\right)  \cdot\gamma=\alpha
\gamma+\beta\gamma$ for any $\alpha,\beta,\gamma\in\mathbb{C}$.

\textbf{(h)} We have $\alpha\cdot0_{\mathbb{C}}=0_{\mathbb{C}}\cdot
\alpha=0_{\mathbb{C}}$ for any $\alpha\in\mathbb{C}$.

\textbf{(i)} If $\alpha,\beta,\gamma\in\mathbb{C}$, then we have the
equivalence $\left(  \alpha-\beta=\gamma\right)  \Longleftrightarrow\left(
\alpha=\beta+\gamma\right)  $.

\textbf{(j)} We have $-\left(  \alpha+\beta\right)  =\left(  -\alpha\right)
+\left(  -\beta\right)  $ for any $\alpha,\beta\in\mathbb{C}$.

\textbf{(k)} We have $-0_{\mathbb{C}}=0_{\mathbb{C}}$.

\textbf{(l)} We have $-\left(  -\alpha\right)  =\alpha$ for any $\alpha
\in\mathbb{C}$.

\textbf{(m)} We have $-\left(  \alpha\beta\right)  =\left(  -\alpha\right)
\beta=\alpha\left(  -\beta\right)  $ for any $\alpha,\beta\in\mathbb{C}$.

\textbf{(n)} We have $\alpha-\beta-\gamma=\alpha-\left(  \beta+\gamma\right)
$ for any $\alpha,\beta,\gamma\in\mathbb{C}$. (Here and in the following,
\textquotedblleft$\alpha-\beta-\gamma$\textquotedblright\ should be read as
\textquotedblleft$\left(  \alpha-\beta\right)  -\gamma$\textquotedblright.)
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.CC.CC.rules}.]All parts of this theorem are
straightforward. I will only prove the two parts \textbf{(f)} and \textbf{(i)}.

\textbf{(f)} Let $\alpha,\beta,\gamma\in\mathbb{C}$. Thus, $\alpha$ is a
complex number; in other words, $\alpha$ is a pair of two real numbers (by the
definition of complex numbers). Hence, we can write $\alpha$ in the form
$\alpha=\left(  a,a^{\prime}\right)  $ for two real numbers $a,a^{\prime}$.
Similarly, we can write $\beta$ and $\gamma$ in the forms $\beta=\left(
b,b^{\prime}\right)  $ and $\gamma=\left(  c,c^{\prime}\right)  $ for four
real numbers $b,b^{\prime},c,c^{\prime}$. Consider these six real numbers
$a,a^{\prime},b,b^{\prime},c,c^{\prime}$. Now, from the equalities
$\alpha=\left(  a,a^{\prime}\right)  $, $\beta=\left(  b,b^{\prime}\right)  $
and $\gamma=\left(  c,c^{\prime}\right)  $, we obtain%
\begin{align*}
\alpha\cdot\left(  \beta\cdot\gamma\right)   &  =\left(  a,a^{\prime}\right)
\cdot\underbrace{\left(  \left(  b,b^{\prime}\right)  \cdot\left(
c,c^{\prime}\right)  \right)  }_{\substack{=\left(  bc-b^{\prime}c^{\prime
},bc^{\prime}+b^{\prime}c\right)  \\\text{(by the definition of}\\\text{the
operation }\cdot\text{ on }\mathbb{C}\text{)}}}\\
&  =\left(  a,a^{\prime}\right)  \cdot\left(  bc-b^{\prime}c^{\prime
},bc^{\prime}+b^{\prime}c\right) \\
&  =\left(  \underbrace{a\left(  bc-b^{\prime}c^{\prime}\right)  -a^{\prime
}\left(  bc^{\prime}+b^{\prime}c\right)  }_{=abc-ab^{\prime}c^{\prime
}-a^{\prime}bc^{\prime}-a^{\prime}b^{\prime}c},\underbrace{a\left(
bc^{\prime}+b^{\prime}c\right)  +a^{\prime}\left(  bc-b^{\prime}c^{\prime
}\right)  }_{=abc^{\prime}+ab^{\prime}c+a^{\prime}bc-a^{\prime}b^{\prime
}c^{\prime}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the operation }%
\cdot\text{ on }\mathbb{C}\right) \\
&  =\left(  abc-ab^{\prime}c^{\prime}-a^{\prime}bc^{\prime}-a^{\prime
}b^{\prime}c,abc^{\prime}+ab^{\prime}c+a^{\prime}bc-a^{\prime}b^{\prime
}c^{\prime}\right)
\end{align*}
\newline and%
\begin{align*}
\left(  \alpha\cdot\beta\right)  \cdot\gamma &  =\underbrace{\left(  \left(
a,a^{\prime}\right)  \cdot\left(  b,b^{\prime}\right)  \right)  }%
_{\substack{=\left(  ab-a^{\prime}b^{\prime},ab^{\prime}+a^{\prime}b\right)
\\\text{(by the definition of}\\\text{the operation }\cdot\text{ on
}\mathbb{C}\text{)}}}\cdot\left(  c,c^{\prime}\right) \\
&  =\left(  ab-a^{\prime}b^{\prime},ab^{\prime}+a^{\prime}b\right)
\cdot\left(  c,c^{\prime}\right) \\
&  =\left(  \underbrace{\left(  ab-a^{\prime}b^{\prime}\right)  c-\left(
ab^{\prime}+a^{\prime}b\right)  c^{\prime}}_{=abc-ab^{\prime}c^{\prime
}-a^{\prime}bc^{\prime}-a^{\prime}b^{\prime}c},\underbrace{\left(
ab-a^{\prime}b^{\prime}\right)  c^{\prime}+\left(  ab^{\prime}+a^{\prime
}b\right)  c}_{=abc^{\prime}+ab^{\prime}c+a^{\prime}bc-a^{\prime}b^{\prime
}c^{\prime}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the operation }%
\cdot\text{ on }\mathbb{C}\right) \\
&  =\left(  abc-ab^{\prime}c^{\prime}-a^{\prime}bc^{\prime}-a^{\prime
}b^{\prime}c,abc^{\prime}+ab^{\prime}c+a^{\prime}bc-a^{\prime}b^{\prime
}c^{\prime}\right)  .
\end{align*}
Comparing these two equalities, we see that $\alpha\cdot\left(  \beta
\cdot\gamma\right)  =\left(  \alpha\cdot\beta\right)  \cdot\gamma$. So Theorem
\ref{thm.CC.CC.rules} \textbf{(f)} is proven.

\textbf{(i)} Let $\alpha,\beta,\gamma\in\mathbb{C}$. Thus, $\alpha$ is a
complex number; in other words, $\alpha$ is a pair of two real numbers (by the
definition of complex numbers). Hence, we can write $\alpha$ in the form
$\alpha=\left(  a,a^{\prime}\right)  $ for two real numbers $a,a^{\prime}$.
Similarly, we can write $\beta$ and $\gamma$ in the forms $\beta=\left(
b,b^{\prime}\right)  $ and $\gamma=\left(  c,c^{\prime}\right)  $ for four
real numbers $b,b^{\prime},c,c^{\prime}$. Consider these six real numbers
$a,a^{\prime},b,b^{\prime},c,c^{\prime}$. Now, we have the following chain of
logical equivalences:%
\begin{align*}
&  \ \left(  \underbrace{\alpha}_{=\left(  a,a^{\prime}\right)  }%
-\underbrace{\beta}_{=\left(  b,b^{\prime}\right)  }=\underbrace{\gamma
}_{=\left(  c,c^{\prime}\right)  }\right) \\
&  \Longleftrightarrow\ \left(  \underbrace{\left(  a,a^{\prime}\right)
-\left(  b,b^{\prime}\right)  }_{\substack{=\left(  a-b,a^{\prime}-b^{\prime
}\right)  \\\text{(by the definition of the}\\\text{operation }-\text{ on
}\mathbb{C}\text{)}}}=\left(  c,c^{\prime}\right)  \right) \\
&  \Longleftrightarrow\ \left(  \left(  a-b,a^{\prime}-b^{\prime}\right)
=\left(  c,c^{\prime}\right)  \right)  \ \Longleftrightarrow\ \left(
\underbrace{a-b=c}_{\Longleftrightarrow\ \left(  a=b+c\right)  }\text{ and
}\underbrace{a^{\prime}-b^{\prime}=c^{\prime}}_{\Longleftrightarrow\ \left(
a^{\prime}=b^{\prime}+c^{\prime}\right)  }\right) \\
&  \Longleftrightarrow\ \left(  a=b+c\text{ and }a^{\prime}=b^{\prime
}+c^{\prime}\right)  \ \Longleftrightarrow\ \left(  \left(  a,a^{\prime
}\right)  =\left(  b+c,b^{\prime}+c^{\prime}\right)  \right) \\
&  \Longleftrightarrow\ \left(  \underbrace{\left(  a,a^{\prime}\right)
}_{=\alpha}=\underbrace{\left(  b,b^{\prime}\right)  }_{=\beta}%
+\underbrace{\left(  c,c^{\prime}\right)  }_{=\gamma}\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\left(  b+c,b^{\prime}+c^{\prime}\right)  =\left(  b,b^{\prime
}\right)  +\left(  c,c^{\prime}\right) \\
\text{(by the definition of the}\\
\text{operation }+\text{ on }\mathbb{C}\text{)}%
\end{array}
\right) \\
&  \Longleftrightarrow\ \left(  \alpha=\beta+\gamma\right)  .
\end{align*}
This proves Theorem \ref{thm.CC.CC.rules} \textbf{(i)}.

All the other parts of Theorem \ref{thm.CC.CC.rules} can be proven by direct
computations, just as we proved Theorem \ref{thm.CC.CC.rules} \textbf{(f)}.
\end{proof}

\subsubsection{Finite sums and finite products}

Recall the concept of a finite sum of real numbers (i.e., a sum of the form
$\sum_{i\in I}a_{i}$, where $I$ is a finite set and $a_{i}$ is a real number
for each $i\in I$), and the analogous concept of a finite product of real
numbers (i.e., a product of the form $\prod_{i\in I}a_{i}$).

\begin{definition}
\label{def.CC.CC.sums}In the same vein, we define the concept of a finite sum
of complex numbers (i.e., a sum of the form $\sum_{i\in I}\alpha_{i}$, where
$I$ is a finite set and $\alpha_{i}\in\mathbb{C}$ for each $i\in I$), and the
analogous concept of a finite product of complex numbers (i.e., a product of
the form $\prod_{i\in I}\alpha_{i}$, where $I$ is a finite set and $\alpha
_{i}\in\mathbb{C}$ for each $i\in I$).

These concepts are well-defined, by Proposition \ref{prop.CC.CC.sums.wd}
\textbf{(a)} below.
\end{definition}

We will use the usual shorthands for special kinds of finite sums and
products. For example, if $I$ is an interval $\left\{  p,p+1,\ldots,q\right\}
$ of integers (and if $\alpha_{i}\in\mathbb{C}$ for each $i\in I$), then the
sum $\sum_{i\in I}\alpha_{i}$ will also be denoted by $\sum_{i=p}^{q}%
\alpha_{i}$ or $\alpha_{p}+\alpha_{p+1}+\cdots+\alpha_{q}$. Likewise for
products. Thus, for example, $\alpha_{1}+\alpha_{2}+\cdots+\alpha_{k}$ and
$\alpha_{1}\alpha_{2}\cdots\alpha_{k}$ are well-defined whenever $\alpha
_{1},\alpha_{2},\ldots,\alpha_{k}\in\mathbb{C}$.

\begin{proposition}
\label{prop.CC.CC.sums.wd}\textbf{(a)} Definition \ref{def.CC.CC.sums} is well-defined.

\textbf{(b)} Finite sums ($\sum_{i\in I}\alpha_{i}$) and finite products
($\prod_{i\in I}\alpha_{i}$) of complex numbers $\alpha_{i}\in\mathbb{C}$
satisfy the same rules that finite sums and finite products of real numbers satisfy.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.CC.CC.sums.wd}.]\textbf{(a)} In \cite[Theorem
2.118 \textbf{(a)}]{detnotes}, it is proven that finite sums of real numbers
are well-defined. The same argument (but relying on Theorem
\ref{thm.CC.CC.rules} instead of the usual rules of commutativity,
associativity etc. for real numbers) shows that finite sums of complex numbers
$\alpha_{i}\in\mathbb{C}$ are well-defined. The analogous fact for products is
proven in the same way, except that we need to replace $0$ by $1$ and
properties of addition by corresponding properties of multiplication.

\textbf{(b)} The proofs of the properties of finite sums and finite products
of elements of $\mathbb{C}$ are identical to the analogous proofs for real
numbers, but (again) rely on Theorem \ref{thm.CC.CC.rules} instead of the
usual rules of commutativity, associativity etc. for real numbers.
\end{proof}

\subsubsection{Embedding $\mathbb{R}$ into $\mathbb{C}$}

\begin{theorem}
\label{thm.CC.RRtoCC.hom}For any real numbers $a$ and $b$, we have%
\begin{align}
\left(  a+b\right)  _{\mathbb{C}}  &  =a_{\mathbb{C}}+b_{\mathbb{C}%
}\ \ \ \ \ \ \ \ \ \ \text{and}\label{eq.thm.CC.RRtoCC.hom.1}\\
\left(  a-b\right)  _{\mathbb{C}}  &  =a_{\mathbb{C}}-b_{\mathbb{C}%
}\ \ \ \ \ \ \ \ \ \ \text{and}\label{eq.thm.CC.RRtoCC.hom.2}\\
\left(  ab\right)  _{\mathbb{C}}  &  =a_{\mathbb{C}}b_{\mathbb{C}}.
\label{eq.thm.CC.RRtoCC.hom.3}%
\end{align}

\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.CC.RRtoCC.hom}.]Let $a$ and $b$ be two real
numbers. Then, the definitions of $a_{\mathbb{C}}$, $b_{\mathbb{C}}$ and
$\left(  ab\right)  _{\mathbb{C}}$ yield $a_{\mathbb{C}}=\left(  a,0\right)  $
and $b_{\mathbb{C}}=\left(  b,0\right)  $ and $\left(  ab\right)
_{\mathbb{C}}=\left(  ab,0\right)  $. Now, (\ref{eq.thm.CC.RRtoCC.hom.3})
follows from%
\begin{align*}
\underbrace{a_{\mathbb{C}}}_{=\left(  a,0\right)  }\underbrace{b_{\mathbb{C}}%
}_{=\left(  b,0\right)  }  &  =\left(  a,0\right)  \left(  b,0\right)
=\left(  a,0\right)  \cdot\left(  b,0\right)  =\left(  \underbrace{ab-0\cdot
0}_{=ab},\underbrace{a\cdot0+0\cdot b}_{=0}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the operation }%
\cdot\text{ on }\mathbb{C}\right) \\
&  =\left(  ab,0\right)  =\left(  ab\right)  _{\mathbb{C}}.
\end{align*}
Similar straightforward computations prove the equalities
(\ref{eq.thm.CC.RRtoCC.hom.1}) and (\ref{eq.thm.CC.RRtoCC.hom.2}). Thus,
Theorem \ref{thm.CC.RRtoCC.hom} is proven.
\end{proof}

\begin{remark}
\label{rmk.CC.RRtoCC.homk}If $a_{1},a_{2},\ldots,a_{k}$ are $k$ reals, then
\begin{align*}
\left(  a_{1}\right)  _{\mathbb{C}}+\left(  a_{2}\right)  _{\mathbb{C}}%
+\cdots+\left(  a_{k}\right)  _{\mathbb{C}}  &  =\left(  a_{1}+a_{2}%
+\cdots+a_{k}\right)  _{\mathbb{C}}\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  a_{1}\right)  _{\mathbb{C}}\cdot\left(  a_{2}\right)  _{\mathbb{C}%
}\cdot\cdots\cdot\left(  a_{k}\right)  _{\mathbb{C}}  &  =\left(  a_{1}%
a_{2}\cdots a_{k}\right)  _{\mathbb{C}}.
\end{align*}

\end{remark}

\begin{proof}
[Proof of Remark \ref{rmk.CC.RRtoCC.homk}.]This can be proven by a
straightforward induction on $k$.
\end{proof}

\begin{convention}
\label{conv.CC.RRtoCC.embed}From now on, for each real number $r$, we shall
identify the real number $r$ with the complex number $r_{\mathbb{C}}=\left(
r,0\right)  $.
\end{convention}

Identifying different things is always risky in mathematics; for example, we
have seen above why it would be a bad idea to identify residue classes
$\left[  a\right]  _{n}$ of integers modulo a positive integer $n$ with the
corresponding remainders $a\%n$ (even though there is a 1-to-1 correspondence
between the former and the latter). Nevertheless, the identification made in
Convention \ref{conv.CC.RRtoCC.embed} is harmless, due to Theorem
\ref{thm.CC.RRtoCC.hom}\footnote{Why does Theorem \ref{thm.CC.RRtoCC.hom}
matter here? Well, let us assume for a moment that Theorem
\ref{thm.CC.RRtoCC.hom} was false; specifically, let us assume that there are
two real numbers $a$ and $b$ such that $\left(  ab\right)  _{\mathbb{C}}\neq
a_{\mathbb{C}}b_{\mathbb{C}}$. Consider these $a$ and $b$. Now, Convention
\ref{conv.CC.RRtoCC.embed} lets us identify the real numbers $a$, $b$ and $ab$
with the complex numbers $a_{\mathbb{C}}$, $b_{\mathbb{C}}$ and $\left(
ab\right)  _{\mathbb{C}}$. Thus, $ab=\left(  ab\right)  _{\mathbb{C}}%
\neq\underbrace{a_{\mathbb{C}}}_{=a}\underbrace{b_{\mathbb{C}}}_{=b}=ab$,
which is nonsense. To make sure that Convention \ref{conv.CC.RRtoCC.embed}
cannot spawn such absurdities, we had to prove Theorem \ref{thm.CC.RRtoCC.hom}%
.} and because the map
\[
\mathbb{R}\rightarrow\mathbb{C},\ \ \ \ \ \ \ \ \ \ r\mapsto r_{\mathbb{C}}%
\]
is injective (so we are not identifying two different real numbers with one
and the same complex numbers).

So we have identified each real number with a complex number. Thus, the
complex numbers can be seen as an extension of the real numbers:
$\mathbb{R}\subseteq\mathbb{C}$. (Of course, this is not \textbf{literally}
true, since formally speaking $r_{\mathbb{C}}$ is a pair while $r$ is a single
real number. Nevertheless, we will work as if this was true, and hope that the
reader can insert \textquotedblleft$_{\mathbb{C}}$\textquotedblright%
\ subscripts wherever necessary in order to make our computations literally true.)

When we defined complex numbers as pairs of real numbers in Definition
\ref{def.CC.CC}, we were intending that the pair $\left(  a,b\right)  $ would
correspond to the complex number $a+bi$ in our previous informal construction
of the complex numbers. Convention \ref{conv.CC.RRtoCC.embed} makes this
actually hold:

\begin{proposition}
\label{prop.CC.RRtoCC.a+bi}For any $\left(  a,b\right)  \in\mathbb{C}$, we
have $\left(  a,b\right)  =a+bi$.
\end{proposition}

\begin{proof}
Let $\left(  a,b\right)  \in\mathbb{C}$. Thus, $a$ and $b$ are real numbers.
By Convention \ref{conv.CC.RRtoCC.embed}, we identify these real numbers $a$
and $b$ with the complex numbers $a_{\mathbb{C}}=\left(  a,0\right)  $ and
$b_{\mathbb{C}}=\left(  b,0\right)  $, respectively. Thus, $a=a_{\mathbb{C}%
}=\left(  a,0\right)  $ and $b=b_{\mathbb{C}}=\left(  b,0\right)  $. Hence,%
\begin{align*}
\underbrace{a}_{=\left(  a,0\right)  }+\underbrace{b}_{=\left(  b,0\right)
}\underbrace{i}_{=\left(  0,1\right)  }  &  =\left(  a,0\right)
+\underbrace{\left(  b,0\right)  \left(  0,1\right)  }_{\substack{=\left(
b\cdot0-0\cdot1,b\cdot1+0\cdot0\right)  \\\text{(by the definition
of}\\\text{the operation }\cdot\text{ on }\mathbb{C}\text{)}}}=\left(
a,0\right)  +\left(  \underbrace{b\cdot0-0\cdot1}_{=0},\underbrace{b\cdot
1+0\cdot0}_{=b}\right) \\
&  =\left(  a,0\right)  +\left(  0,b\right)  =\left(  \underbrace{a+0}%
_{=a},\underbrace{0+b}_{=b}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the operation
}+\text{ on }\mathbb{C}\right) \\
&  =\left(  a,b\right)  .
\end{align*}
This proves Proposition \ref{prop.CC.RRtoCC.a+bi}.
\end{proof}

The next proposition shows that if we multiply a complex number $\left(
b,c\right)  $ with a \textbf{real} number $a$ (of course, understanding this
real number $a$ as the complex number $a_{\mathbb{C}}=\left(  a,0\right)  $),
then the result will simply be $\left(  ab,ac\right)  $ (that is, multiplying
a complex number by $a$ merely multiplies both of its entries by $a$):

\begin{proposition}
\label{prop.CC.CC.a(b,c)}For any $a\in\mathbb{R}$ and $\left(  b,c\right)
\in\mathbb{C}$, we have $a\left(  b,c\right)  =\left(  ab,ac\right)  $. (Here,
of course, \textquotedblleft$a\left(  b,c\right)  $\textquotedblright\ means
the product $a_{\mathbb{C}}\left(  b,c\right)  $.)
\end{proposition}

\begin{proof}
This is straightforward: Let $a\in\mathbb{R}$ and $\left(  b,c\right)
\in\mathbb{C}$. By Convention \ref{conv.CC.RRtoCC.embed}, we identify the real
number $a$ with the complex number $a_{\mathbb{C}}=\left(  a,0\right)  $.
Hence, $a=a_{\mathbb{C}}=\left(  a,0\right)  $. Now,%
\begin{align*}
\underbrace{a}_{=\left(  a,0\right)  }\left(  b,c\right)   &  =\left(
a,0\right)  \cdot\left(  b,c\right)  =\left(  \underbrace{ab-0c}%
_{=ab},\underbrace{ac+0b}_{=ac}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the operation }%
\cdot\text{ on }\mathbb{C}\right) \\
&  =\left(  ab,ac\right)  .
\end{align*}
This proves Proposition \ref{prop.CC.CC.a(b,c)}.
\end{proof}

\subsubsection{Inverses and division of complex numbers}

\begin{definition}
A complex number $\alpha$ is said to be \textit{nonzero} if and only if it is
distinct from the complex number $0_{\mathbb{C}}=\left(  0,0\right)  $.
\end{definition}

In other words, a complex number $\alpha$ is nonzero if and only if it is
distinct from $0$ (since we are identifying the real number $0$ with
$0_{\mathbb{C}}$). Equivalently, a complex number $\alpha=\left(  a,b\right)
$ is nonzero if and only if $\left(  a,b\right)  \neq\left(  0,0\right)  $ as
pairs (i.e., if and only if at least one of the real numbers $a$ and $b$ are nonzero).

We have so far been adding, subtracting and multiplying complex numbers, but
never dividing them (except briefly, before we formally defined them). We
could define division in the same way as we defined addition, subtraction and
multiplication -- namely, by an explicit formula for $\dfrac{\left(
a,b\right)  }{\left(  c,d\right)  }$ whenever $\left(  c,d\right)  $ is
nonzero\footnote{This formula would be
\[
\dfrac{\left(  a,b\right)  }{\left(  c,d\right)  }=\left(  \dfrac{ac+bd}%
{c^{2}+d^{2}},\dfrac{bc-ad}{c^{2}+d^{2}}\right)  .
\]
}. However, it is more instructive to proceed differently, and construct the
division from the multiplication that was already defined. After all, if our
division is to deserve its name, it should undo multiplication; and this
determines it uniquely. We will not define division right away; instead, we
start out by defining an \textit{inverse} of a complex number:

\begin{definition}
\label{def.CC.CC.inverse.inverse}Let $\alpha$ be a complex number. An
\textit{inverse} of $\alpha$ means a complex number $\beta$ such that
$\alpha\beta=1$. (Recall that $1=1_{\mathbb{C}}$ by Convention
\ref{conv.CC.RRtoCC.embed}.)
\end{definition}

The complex number $0$ has no inverse (because $0\beta=0\neq1$, no matter what
$\beta$ is). But it turns out that all the other complex numbers have one:

\begin{theorem}
\label{thm.CC.CC.inverse.unique}Let $\alpha$ be a nonzero complex number.
Then, $\alpha$ has a unique inverse.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.CC.CC.inverse.unique}.]We shall separately prove
the existence and the uniqueness of an inverse of $\alpha$.

\textit{Proof of the existence of the inverse:} Write the complex number
$\alpha$ as $\alpha=\left(  c,d\right)  $ for two real numbers $c$ and $d$.
Then, $\left(  c,d\right)  =\alpha\neq0$ (since $\alpha$ is nonzero). Thus,
$\left(  c,d\right)  \neq0=\left(  0,0\right)  $. In other words, at least one
of the two real numbers $c$ and $d$ is nonzero. Hence, at least one of the two
real numbers $c^{2}$ and $d^{2}$ is positive\footnote{since the square of a
nonzero real number is always positive}. The other among these two numbers
must, of course, be nonnegative\footnote{since the square of a real number is
always nonnegative}. Hence, $c^{2}+d^{2}$ is the sum of a positive real number
with a nonnegative real number. Therefore, $c^{2}+d^{2}$ itself is positive.
Thus, $c^{2}+d^{2}$ is a nonzero real number; hence, we can divide by
$c^{2}+d^{2}$. In particular, we can define a complex number $\beta$ by%
\[
\beta=\left(  \dfrac{c}{c^{2}+d^{2}},\dfrac{-d}{c^{2}+d^{2}}\right)  .
\]
Consider this $\beta$. Multiplying the equalities $\alpha=\left(  c,d\right)
$ and $\beta=\left(  \dfrac{c}{c^{2}+d^{2}},\dfrac{-d}{c^{2}+d^{2}}\right)  $,
we find
\begin{align*}
\alpha\beta &  =\left(  c,d\right)  \left(  \dfrac{c}{c^{2}+d^{2}},\dfrac
{-d}{c^{2}+d^{2}}\right) \\
&  =\left(  \underbrace{c\cdot\dfrac{c}{c^{2}+d^{2}}-d\cdot\dfrac{-d}%
{c^{2}+d^{2}}}_{=1},\underbrace{c\cdot\dfrac{-d}{c^{2}+d^{2}}+d\cdot\dfrac
{c}{c^{2}+d^{2}}}_{=0}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the operation }%
\cdot\text{ on }\mathbb{C}\right) \\
&  =\left(  1,0\right)  =1_{\mathbb{C}}.
\end{align*}
Thus, $\beta$ is an inverse of $\alpha$ (by the definition of an inverse of
$\alpha$). Hence, $\alpha$ has \textbf{at least one} inverse (namely, $\beta$).

\textit{Proof of the uniqueness of the inverse:} We must prove that $\alpha$
has at most one inverse. This is exactly the statement of Proposition
\ref{prop.equiv.modinv.uni}, except that our $\alpha$ is an element of
$\mathbb{C}$ rather than of $\mathbb{Z}/n$. But the same argument that we used
to prove Proposition \ref{prop.equiv.modinv.uni} can be applied to $\alpha
\in\mathbb{C}$ instead of $\alpha\in\mathbb{Z}/n$\ \ \ \ \footnote{Of course,
we need to make some obvious modifications, such as replacing every appearance
of \textquotedblleft$\left[  1\right]  _{n}$\textquotedblright\ by
\textquotedblleft$1$\textquotedblright, and replacing every reference to
Theorem \ref{thm.eqrel.Z/n.rules} with a reference to Theorem
\ref{thm.CC.CC.rules}.}. Hence, we obtain that $\alpha$ has \textbf{at most
one} inverse.

We have now shown that $\alpha$ has at least one inverse, and we have shown
that $\alpha$ has at most one inverse. Combining these two results, we
conclude that $\alpha$ has a unique inverse. This proves Theorem
\ref{thm.CC.CC.inverse.unique}.
\end{proof}

\begin{definition}
\label{def.CC.CC.inverse.notations}\textbf{(a)} Let $\beta$ be a nonzero
complex number. Theorem \ref{thm.CC.CC.inverse.unique} shows that $\beta$ has
a unique inverse. This inverse is called $\beta^{-1}$, and will be referred to
as \textit{the inverse} of $\beta$.

\textbf{(b)} Let $\alpha$ and $\beta$ be two complex numbers such that
$\beta\neq0$. Then, the quotient $\dfrac{\alpha}{\beta}$ is defined to be the
complex number $\alpha\cdot\beta^{-1}$. It is sometimes also denoted by
$\alpha/\beta$.

\textbf{(c)} The operation that transforms a pair $\left(  \alpha
,\beta\right)  $ of two complex numbers (with $\beta$ nonzero) into
$\alpha/\beta$ is called \textit{division}.
\end{definition}

It is easy to see that division undoes multiplication:

\begin{proposition}
\label{prop.CC.CC.inverse.undo}Let $\alpha,\beta,\gamma$ be three complex
numbers with $\beta\neq0$. Then, we have the equivalence%
\[
\left(  \gamma=\dfrac{\alpha}{\beta}\right)  \ \Longleftrightarrow\ \left(
\alpha=\beta\gamma\right)  .
\]

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.CC.CC.inverse.undo}.]We have $\beta\neq0$.
Thus, $\beta$ has a well-defined inverse $\beta^{-1}$. The definition of this
inverse yields $\beta\beta^{-1}=1$; now, Theorem \ref{thm.CC.CC.rules}
\textbf{(e)} yields $\beta^{-1}\beta=\beta\beta^{-1}=1$. Also, Theorem
\ref{thm.CC.CC.rules} \textbf{(e)} yields $\gamma\beta=\beta\gamma$ and
$\beta^{-1}\alpha=\alpha\beta^{-1}$. The definition of $\dfrac{\alpha}{\beta}$
yields $\dfrac{\alpha}{\beta}=\alpha\cdot\beta^{-1}=\alpha\beta^{-1}$.

We have to prove the equivalence $\left(  \gamma=\dfrac{\alpha}{\beta}\right)
\ \Longleftrightarrow\ \left(  \alpha=\beta\gamma\right)  $. Let us prove the
\textquotedblleft$\Longrightarrow$\textquotedblright\ and \textquotedblleft%
$\Longleftarrow$\textquotedblright\ directions of this equivalence separately:

$\Longrightarrow:$ Assume that $\gamma=\dfrac{\alpha}{\beta}$. We shall show
that $\alpha=\beta\gamma$.

We have $\gamma=\dfrac{\alpha}{\beta}=\alpha\beta^{-1}$. Multiplying both
sides of this equality with $\beta$, we obtain
\[
\gamma\beta=\alpha\underbrace{\beta^{-1}\beta}_{=1}=\alpha\cdot1=\alpha.
\]
Hence, $\alpha=\gamma\beta=\beta\gamma$. This proves the \textquotedblleft%
$\Longrightarrow$\textquotedblright\ direction of the equivalence $\left(
\gamma=\dfrac{\alpha}{\beta}\right)  \ \Longleftrightarrow\ \left(
\alpha=\beta\gamma\right)  $.

$\Longleftarrow:$ Assume that $\alpha=\beta\gamma$. We shall show that
$\gamma=\dfrac{\alpha}{\beta}$.

We have $\beta^{-1}\underbrace{\alpha}_{=\beta\gamma}=\underbrace{\beta
^{-1}\beta}_{=1}\gamma=1\gamma=\gamma1=\gamma$, so that $\gamma=\beta
^{-1}\alpha=\alpha\beta^{-1}=\dfrac{\alpha}{\beta}$. This proves the
\textquotedblleft$\Longleftarrow$\textquotedblright\ direction of the
equivalence $\left(  \gamma=\dfrac{\alpha}{\beta}\right)
\ \Longleftrightarrow\ \left(  \alpha=\beta\gamma\right)  $.

Thus, the equivalence $\left(  \gamma=\dfrac{\alpha}{\beta}\right)
\ \Longleftrightarrow\ \left(  \alpha=\beta\gamma\right)  $ holds (since we
have proven both of its directions). That is, we have proven Proposition
\ref{prop.CC.CC.inverse.undo}.
\end{proof}

Inverses also have the following properties:

\begin{proposition}
\label{prop.CC.CC.inverse.ab}\textbf{(a)} Let $\alpha\in\mathbb{C}$ be a
complex number that has an inverse (i.e., is nonzero). Then, its inverse
$\alpha^{-1}$ has an inverse as well, and this inverse is $\left(  \alpha
^{-1}\right)  ^{-1}=\alpha$.

\textbf{(b)} Let $\alpha,\beta\in\mathbb{C}$ be two complex numbers that have
inverses (i.e., are nonzero). Then, their product $\alpha\beta$ has an inverse
as well, and this inverse is $\left(  \alpha\beta\right)  ^{-1}=\alpha
^{-1}\beta^{-1}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.CC.CC.inverse.ab}.]This proof is completely
analogous to the solution to Exercise \ref{exe.equiv.modinv.ab}. (Just replace
$\mathbb{Z}/n$ by $\mathbb{C}$.)
\end{proof}

\begin{corollary}
\label{cor.CC.CC.intdom}Let $\alpha,\beta\in\mathbb{C}$ be two nonzero complex
numbers. Then, the complex number $\alpha\beta$ is nonzero as well.
\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.CC.CC.intdom} (sketched).]The complex numbers
$\alpha$ and $\beta$ are nonzero, and thus have inverses (by Theorem
\ref{thm.CC.CC.inverse.unique}). Hence, Proposition
\ref{prop.CC.CC.inverse.ab} \textbf{(b)} shows that their product $\alpha
\beta$ has an inverse as well. Thus, $\alpha\beta\neq0$ (since $0$ has no
inverse). This proves Corollary \ref{cor.CC.CC.intdom}.
\end{proof}

\subsubsection{Powers of complex numbers}

Let us now define powers of complex numbers, where the exponent is a
nonnegative integer.

\begin{definition}
\label{def.CC.CC.power}Let $\alpha\in\mathbb{C}$ and $n\in\mathbb{N}$. We
define a complex number $\alpha^{n}$ (called the $n$\textit{-th power of
}$\alpha$) by setting $\alpha^{n}=\underbrace{\alpha\alpha\cdots\alpha
}_{n\text{ times}}$.
\end{definition}

Definition \ref{def.CC.CC.power} yields%
\[
i^{2}=ii=\left(  -1\right)  _{\mathbb{C}}=-1.
\]
Moreover, Definition \ref{def.CC.CC.power} yields
\begin{align*}
\alpha^{0}  &  =\underbrace{\alpha\alpha\cdots\alpha}_{0\text{ times}}=\left(
\text{empty product}\right)  =1\ \ \ \ \ \ \ \ \ \ \text{and}\\
\alpha^{1}  &  =\underbrace{\alpha\alpha\cdots\alpha}_{1\text{ times}}=\alpha
\end{align*}
for each $\alpha\in\mathbb{C}$.

For another example, Definition \ref{def.CC.CC.power} yields%
\[
\left(  1+i\right)  ^{2}=\left(  1+i\right)  \left(  1+i\right)
=1+i+i+\underbrace{ii}_{=-1}=1+i+i+\left(  -1\right)  =i+i=2i
\]
and%
\[
\left(  1+i\right)  ^{4}=\underbrace{\left(  1+i\right)  \left(  1+i\right)
}_{=2i}\underbrace{\left(  1+i\right)  \left(  1+i\right)  }_{=2i}%
=2i\cdot2i=4\underbrace{ii}_{=-1}=4\left(  -1\right)  =-4.
\]


We shall use the PEMDAS convention for the order of operations when powers are
involved. For example, the expression \textquotedblleft$\alpha\beta^{k}%
+\gamma$\textquotedblright\ means $\left(  \alpha\left(  \beta^{k}\right)
\right)  +\gamma$ rather than (say) $\left(  \alpha\beta\right)  ^{k}+\gamma$.

Recall that any nonzero complex number $\alpha$ has an inverse $\alpha^{-1}$
(by Definition \ref{def.CC.CC.inverse.notations} \textbf{(a)}). This allows us
to extend our definition of $\alpha^{n}$ to \textbf{negative} $n$ as well:

\begin{definition}
\label{def.CC.CC.power-}Let $\alpha\in\mathbb{C}$ be nonzero. For any negative
$n\in\mathbb{Z}$, we define a complex number $\alpha^{n}$ (called the
$n$\textit{-th power of }$\alpha$) by $\alpha^{n}=\left(  \alpha^{-1}\right)
^{-n}$. (This is well-defined, since $\left(  \alpha^{-1}\right)  ^{-n}$ is
already defined by Definition \ref{def.CC.CC.power} (because $n$ is negative
and thus $-n\in\mathbb{N}$).)
\end{definition}

The attentive reader will have noticed that Definition \ref{def.CC.CC.power-}
redefines $\alpha^{-1}$ when $\alpha$ is nonzero (indeed, $-1$ is a negative
integer, and thus can be substituted for $n$ in Definition
\ref{def.CC.CC.power-}). Fortunately, this new definition of $\alpha^{-1}$
does not clash with the original definition (Definition
\ref{def.CC.CC.inverse.notations} \textbf{(a)}), because if we set $n=-1$ in
Definition \ref{def.CC.CC.power-}, then we get $\alpha^{-1}=\left(
\alpha^{-1}\right)  ^{1}=\alpha^{-1}$ (where the \textquotedblleft$\alpha
^{-1}$\textquotedblright\ on the left hand side is the new meaning defined in
Definition \ref{def.CC.CC.power-}, whereas the \textquotedblleft$\alpha^{-1}%
$\textquotedblright\ on the right hand side is the old meaning defined in
Definition \ref{def.CC.CC.inverse.notations} \textbf{(a)}).

If $\alpha=0$ and if $n\in\mathbb{Z}$ is negative, then we leave $\alpha^{n}$ undefined.

Powers of complex numbers satisfy the usual rules for exponents:

\begin{proposition}
\label{prop.CC.CC.power-rules}\textbf{(a)} We have $\alpha^{n+1}=\alpha
\alpha^{n}$ for all $\alpha\in\mathbb{C}$ and $n\in\mathbb{N}$.

\textbf{(b)} We have $\alpha^{n+m}=\alpha^{n}\alpha^{m}$ for all $\alpha
\in\mathbb{C}$ and $n,m\in\mathbb{N}$.

\textbf{(c)} We have $\left(  \alpha\beta\right)  ^{n}=\alpha^{n}\beta^{n}$
for all $\alpha,\beta\in\mathbb{C}$ and $n\in\mathbb{N}$.

\textbf{(d)} We have $\left(  \alpha^{n}\right)  ^{m}=\alpha^{nm}$ for all
$\alpha\in\mathbb{C}$ and $n,m\in\mathbb{N}$.

\textbf{(e)} We have $1^{n}=1$ for all $n\in\mathbb{N}$.

\textbf{(f)} We have $\alpha^{n+1}=\alpha\alpha^{n}$ for all nonzero
$\alpha\in\mathbb{C}$ and all $n\in\mathbb{Z}$.

\textbf{(g)} We have $\alpha^{-n}=\left(  \alpha^{-1}\right)  ^{n}$ for all
nonzero $\alpha\in\mathbb{C}$ and all $n\in\mathbb{Z}$.

\textbf{(h)} We have $\alpha^{n+m}=\alpha^{n}\alpha^{m}$ for all nonzero
$\alpha\in\mathbb{C}$ and all $n,m\in\mathbb{Z}$.

\textbf{(i)} We have $\left(  \alpha\beta\right)  ^{n}=\alpha^{n}\beta^{n}$
for all nonzero $\alpha,\beta\in\mathbb{C}$ and all $n\in\mathbb{Z}$.

\textbf{(j)} We have $1^{n}=1$ for all $n\in\mathbb{Z}$.

\textbf{(k)} We have $\left(  \alpha^{n}\right)  ^{-1}=\alpha^{-n}$ for all
nonzero $\alpha\in\mathbb{C}$ and all $n\in\mathbb{Z}$. (In particular,
$\alpha^{n}$ is nonzero, so that $\left(  \alpha^{n}\right)  ^{-1}$ is well-defined.)

\textbf{(l)} We have $\left(  \alpha^{n}\right)  ^{m}=\alpha^{nm}$ for all
nonzero $\alpha\in\mathbb{C}$ and all $n,m\in\mathbb{Z}$. (In particular,
$\alpha^{n}$ is nonzero, so that $\left(  \alpha^{n}\right)  ^{m}$ is
well-defined for all $m\in\mathbb{Z}$.)

\textbf{(m)} Complex numbers satisfy the binomial formula: That is, if
$\alpha,\beta\in\mathbb{C}$, then%
\[
\left(  \alpha+\beta\right)  ^{n}=\sum_{k=0}^{n}\dbinom{n}{k}\alpha^{k}%
\beta^{n-k}\ \ \ \ \ \ \ \ \ \ \text{for }n\in\mathbb{N}\text{.}%
\]

\end{proposition}

Proposition \ref{prop.CC.CC.power-rules} can be proven in the same way as the
corresponding claims are proven for real (or rational) numbers:

\begin{exercise}
\label{exe.CC.CC.power-rules}Prove Proposition \ref{prop.CC.CC.power-rules}.
\end{exercise}

It may be tempting to try to extend Definition \ref{def.CC.CC.power-} further
by defining fractional powers (such as $\alpha^{1/2}$). There is a way to do
so, but such a definition would be of questionable use and somewhat fragile
(in the sense that it would fail to satisfy the rules of exponents). For
example, if you wanted to define $\left(  -1\right)  ^{1/2}$, then the only
reasonable choices would be $i$ and $-i$ (since these are the only two complex
numbers whose squares are $-1$); but with either option, the equality $\left(
\alpha\beta\right)  ^{1/2}=\alpha^{1/2}\beta^{1/2}$ would fail if we took
$\alpha=-1$ and $\beta=-1$. Thus, we prefer to leave powers of the form
$\alpha^{n}$ for $n\notin\mathbb{Z}$ undefined.

\subsubsection{\label{subsect.CC.CC.argand}The Argand diagram}

Let us next make a small detour to demonstrate a geometric representation of
the complex numbers which, while not strictly necessary for what we intend to
do with them, is conducive both to understanding them and to applying them.

Recall that a complex number was defined as a pair of real numbers. On the
other hand, a point in the Cartesian plane is also defined as a pair of real
numbers (its x-coordinate and its y-coordinate). Thus, it is natural to
identify each complex number $\left(  a,b\right)  =a+bi$ with the point
$\left(  a,b\right)  \in\mathbb{R}^{2}$ on the Cartesian plane (i.e., the
point with x-coordinate $a$ and y-coordinate $b$). This identification equates
each complex number with a unique point in the Cartesian plane, and vice
versa:%
\[
\begin{tikzpicture}[scale=2.5]
\draw[step=1cm,gray,very thin] (-0.5, -0.5) grid (2.4,2.4);
\draw[->] (-0.6,0) -- (2.5,0);
\draw[->] (0,-0.6) -- (0,2.5);
\node (p) at (1.3 cm, 1.7 cm) {};
\node (o) at (0 cm, 0 cm) {};
\node (xproj) at (1.3 cm, 0 cm) {};
\fill (p) circle (1pt) node[above right] {$a+bi = \left(a,b\right)$};
\fill (xproj) circle (1pt);
\fill (o) circle (1pt);
\draw[very thick, blue] (p) -- node[right=1pt, fill=white] {$b$} (xproj);
\draw[very thick, red] (xproj) -- node[below=1pt, fill=white] {$a$} (o);
\end{tikzpicture}
.
\]
The picture below shows some of the points (specifically, all the $25$ points
$\left(  a,b\right)  \in\left\{  -2,-1,0,1,2\right\}  ^{2}$ whose both
coordinates are integers between $-2$ and $2$) labeled with the corresponding
complex numbers:%
\[
\begin{tikzpicture}[scale=2.5]
\draw[step=1cm,gray,very thin] (-2.4,-2.4) grid (2.4,2.4);
\draw[->] (-2.5,0) -- (2.5,0);
\draw[->] (0,-2.5) -- (0,2.5);
\draw (0,0) circle [radius=1cm];
\foreach \x/\xtext in {-2, -1, 0, 1, 2}
\fill (\x cm, 0) circle (1pt) node[above left=2pt]{$\xtext$};
\foreach \x/\xtext in {-2, -1, 1, 2}
\fill (\x cm, 1 cm) circle (1pt) node[above left=2pt]{$\xtext + i$};
\fill (0, 1 cm) circle (1pt) node[above left=2pt] {$i$};
\foreach \x/\xtext in {-2, -1, 1, 2}
\fill (\x cm, -1 cm) circle (1pt) node[above left=2pt]{$\xtext - i$};
\fill (0, -1 cm) circle (1pt) node[above left=2pt] {$-i$};
\foreach \x/\xtext in {-2, -1, 1, 2}
\fill (\x cm, 2 cm) circle (1pt) node[above left=2pt]{$\xtext + 2i$};
\fill (0, 2 cm) circle (1pt) node[above left=2pt] {$2i$};
\foreach \x/\xtext in {-2, -1, 1, 2}
\fill (\x cm, -2 cm) circle (1pt) node[above left=2pt]{$\xtext - 2i$};
\fill (0, -2 cm) circle (1pt) node[above left=2pt] {$-2i$};
\end{tikzpicture}
\]
(as well as the unit circle, which passes through the four points labeled
$1,i,-1,-i$; we will encounter these four points rather often in the following).

This identification of complex numbers with points is called
\href{https://en.wikipedia.org/wiki/Complex_plane}{the \textit{Argand diagram}
or the \textit{complex plane}} (although the latter word has yet another,
different meaning). The complex number $0$ corresponds to the origin $\left(
0,0\right)  $ of the plane.

In Definition \ref{def.CC.CC} \textbf{(e)}, we have introduced three
operations on complex numbers; what do they mean geometrically for the
corresponding points? The two operations $+$ and $-$ are easiest to
understand: They are exactly the usual operations of addition and subtraction
for vectors. Thus, if $\alpha$ and $\beta$ are two complex numbers, then the
points labeled by the four complex numbers $0$, $\alpha$, $\alpha+\beta$ and
$\beta$ form a parallelogram:%
\[
\begin{tikzpicture}[scale=2.5]
\draw[step=1cm,gray,very thin] (-0.5, -0.5) grid (2.4,2.4);
\draw[->] (-0.6,0) -- (2.5,0);
\draw[->] (0,-0.6) -- (0,2.5);
\node (a) at (1.2 cm, 0.6 cm) {};
\node (b) at (0.5 cm, 1.5 cm) {};
\node (ab) at (1.7 cm, 2.1 cm) {};
\node (o) at (0 cm, 0 cm) {};
\fill (a) circle (1pt) node[below right] {$\alpha$};
\fill (b) circle (1pt) node[above left] {$\beta$};
\fill (ab) circle (1pt) node[above left] {$\alpha+\beta$};
\fill (o) circle (1pt) node[above left] {$0$};
\draw[very thick, blue] (a) -- (ab);
\draw[very thick, blue] (o) -- (b);
\draw[very thick, red] (b) -- (ab);
\draw[very thick, red] (o) -- (a);
\end{tikzpicture}
.
\]
Likewise, the points labeled by the four complex numbers $0$, $\alpha$,
$\beta$ and $\beta-\alpha$ form a parallelogram. These parallelograms can be
degenerate; in particular, the point $-\alpha$ is the reflection of the point
$\alpha$ through the origin:\footnote{We no longer say \textquotedblleft the
point labeled by $\alpha$\textquotedblright, but simply equate $\alpha$ with
that point now.}%
\[
\begin{tikzpicture}[scale=2.5]
\draw[step=1cm,gray,very thin] (-1.2, -1.2) grid (1.2, 1.2);
\draw[->] (-1.3,0) -- (1.3,0);
\draw[->] (0,-1.3) -- (0,1.3);
\node (a) at (0.4 cm, 0.6 cm) {};
\node (ma) at (-0.4 cm, -0.6 cm) {};
\node (o) at (0 cm, 0 cm) {};
\fill (a) circle (1pt) node[below right] {$\alpha$};
\fill (ma) circle (1pt) node[above left] {$-\alpha$};
\fill (o) circle (1pt) node[above left] {$0$};
\draw[very thick, blue] (a) -- (o);
\draw[very thick, blue] (o) -- (ma);
\end{tikzpicture}
.
\]


Multiplication is less evident. The easiest case is multiplying by $i$: If
$\alpha$ is a complex number, then the point $i\alpha$ is obtained from the
point $\alpha$ by a $90^{\circ}$ rotation (counterclockwise) around the
origin. Thus, the four points $\alpha$, $i\alpha$, $-\alpha$ and $-i\alpha$
are the vertices of a square centered at the origin:%
\[
\begin{tikzpicture}[scale=2.5]
\draw[step=1cm,gray,very thin] (-1.2, -1.2) grid (1.2, 1.2);
\draw[->] (-1.3,0) -- (1.3,0);
\draw[->] (0,-1.3) -- (0,1.3);
\node (a) at (0.4 cm, 0.6 cm) {};
\node (ma) at (-0.4 cm, -0.6 cm) {};
\node (ia) at (-0.6 cm, 0.4 cm) {};
\node (mia) at (0.6 cm, -0.4 cm) {};
\node (o) at (0 cm, 0 cm) {};
\fill (a) circle (1pt) node[below right] {$\alpha$};
\fill (ma) circle (1pt) node[above left] {$-\alpha$};
\fill (ia) circle (1pt) node[above left] {$i\alpha$};
\fill (mia) circle (1pt) node[above left] {$-i\alpha$};
\fill (o) circle (1pt) node[above left] {$0$};
\draw[very thick, red] (a) -- (ia);
\draw[very thick, red] (ia) -- (ma);
\draw[very thick, red] (ma) -- (mia);
\draw[very thick, red] (mia) -- (a);
\end{tikzpicture}.
\]


More generally, if $\beta$ is a complex number, then multiplication by $\beta$
(that is, the map $\mathbb{C}\rightarrow\mathbb{C},\ \alpha\mapsto\alpha\beta
$) is a similitude transformation (so it preserves angles and ratios of
lengths); more precisely it is a rotation around the origin composed with a
homothety from the origin. Combined with the fact that it sends $1$ to $\beta
$, this uniquely determines it.

This is just the beginning of a rather helpful dictionary between elementary
plane geometry and the algebra of complex numbers. See \cite{AndAnd14} for
many applications of this point of view, particularly to proving results in
plane geometry.

\subsubsection{Norms and conjugates}

Let us now define some further features of complex numbers.

\begin{definition}
\label{def.CC.norm.norm}Let $\alpha=\left(  a,b\right)  $ be a complex number.

The \textit{norm} of $\alpha$ is defined to be the real number $a^{2}+b^{2}%
\in\mathbb{R}$. This norm is called $\operatorname*{N}\left(  \alpha\right)  $.
\end{definition}

\begin{proposition}
\label{prop.CC.norm.basics}Let $\alpha$ be a complex number.

\textbf{(a)} We have $\operatorname*{N}\left(  \alpha\right)  \geq0$.

\textbf{(b)} We have $\operatorname*{N}\left(  \alpha\right)  =0$ if and only
if $\alpha=0$.

\textbf{(c)} If $\alpha\neq0$, then $\operatorname*{N}\left(  \alpha\right)
>0$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.CC.norm.basics}.]Write the complex number
$\alpha$ in the form $\alpha=\left(  a,b\right)  $ for two real numbers $a$
and $b$. Then, $\operatorname*{N}\left(  \alpha\right)  =a^{2}+b^{2}$ (by the
definition of the norm). But $a^{2}$ and $b^{2}$ are squares of real numbers
and thus $\geq0$ (since a square of a real number is always $\geq0$). Hence,
$\operatorname*{N}\left(  \alpha\right)  =\underbrace{a^{2}}_{\geq
0}+\underbrace{b^{2}}_{\geq0}\geq0$. This proves Proposition
\ref{prop.CC.norm.basics} \textbf{(a)}.

\textbf{(b)} We know that $a^{2}$ and $b^{2}$ are $\geq0$. In other words,
$a^{2}$ and $b^{2}$ are two nonnegative reals. But the sum of two nonnegative
reals is $0$ if and only if both of these reals are $0$. Applying this to the
two nonnegative reals $a^{2}$ and $b^{2}$, we conclude that $a^{2}+b^{2}=0$ if
and only if both $a^{2}$ and $b^{2}$ are $0$. In other words, we have the
logical equivalence $\left(  a^{2}+b^{2}=0\right)  \ \Longleftrightarrow
\ \left(  \text{both }a^{2}\text{ and }b^{2}\text{ are }0\right)  $.

Now, we have the following chain of equivalences:%
\begin{align*}
\left(  \operatorname*{N}\left(  \alpha\right)  =0\right)  \  &
\Longleftrightarrow\ \left(  a^{2}+b^{2}=0\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\operatorname*{N}\left(  \alpha\right)  =a^{2}+b^{2}\right) \\
&  \Longleftrightarrow\ \left(  \text{both }a^{2}\text{ and }b^{2}\text{ are
}0\right) \\
&  \Longleftrightarrow\ \left(  a^{2}=0\text{ and }b^{2}=0\right)
\ \Longleftrightarrow\ \left(  a=0\text{ and }b=0\right) \\
&  \Longleftrightarrow\ \left(  \underbrace{\left(  a,b\right)  }_{=\alpha
}=\underbrace{\left(  0,0\right)  }_{=0_{\mathbb{C}}}\right)
\ \Longleftrightarrow\ \left(  \alpha=0_{\mathbb{C}}\right)
\ \Longleftrightarrow\ \left(  \alpha=0\right)  .
\end{align*}
This proves Proposition \ref{prop.CC.norm.basics} \textbf{(b)}.

\textbf{(c)} Assume that $\alpha\neq0$. But Proposition
\ref{prop.CC.norm.basics} \textbf{(b)} shows that we have $\operatorname*{N}%
\left(  \alpha\right)  =0$ if and only if $\alpha=0$. Hence, we have
$\operatorname*{N}\left(  \alpha\right)  \neq0$ (since $\alpha\neq0$).
Combining this with $\operatorname*{N}\left(  \alpha\right)  \geq0$, we obtain
$\operatorname*{N}\left(  \alpha\right)  >0$. This proves Proposition
\ref{prop.CC.norm.basics} \textbf{(c)}.
\end{proof}

\begin{proposition}
\label{prop.CC.norm.aa}Let $a\in\mathbb{R}$. Then, $\operatorname*{N}\left(
a_{\mathbb{C}}\right)  =a^{2}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.CC.norm.aa}.]We have $a_{\mathbb{C}}=\left(
a,0\right)  $ (by the definition of $a_{\mathbb{C}}$). Hence, the definition
of the norm yields $\operatorname*{N}\left(  a_{\mathbb{C}}\right)
=a^{2}+0^{2}=a^{2}$. This proves Proposition \ref{prop.CC.norm.aa}.
\end{proof}

\begin{definition}
\label{def.CC.conj.conj}Let $\alpha=\left(  a,b\right)  \in\mathbb{C}$.

The \textit{conjugate} $\overline{\alpha}$ of $\alpha$ is defined to be the
complex number $\left(  a,-b\right)  \in\mathbb{C}$.
\end{definition}

From the viewpoint of the Argand diagram, the conjugate $\overline{\alpha}$ of
a complex number $\alpha$ is simply the result of reflecting $\alpha$ (or, to
be pedantic, the point labeled by $\alpha$) across the x-axis:%
\[
\begin{tikzpicture}[scale=2.5]
\draw[step=1cm,gray,very thin] (-1.2, -1.2) grid (1.2, 1.2);
\draw[->] (-1.3,0) -- (1.3,0);
\draw[->] (0,-1.3) -- (0,1.3);
\node (a) at (0.3 cm, 0.6 cm) {};
\node (ca) at (0.3 cm, -0.6 cm) {};
\node (o) at (0 cm, 0 cm) {};
\fill (a) circle (1pt) node[below right] {$\alpha$};
\fill (ca) circle (1pt) node[above right] {$\overline{\alpha}$};
\fill (o) circle (1pt) node[above left] {$0$};
\draw[very thick, blue] (o) -- (a);
\draw[very thick, blue] (o) -- (ca);
\end{tikzpicture}
.
\]
Thus, the following is completely self-evident:

\begin{proposition}
\label{prop.CC.conj.conjconj}Let $\alpha\in\mathbb{C}$.

\textbf{(a)} We have $\alpha=\overline{\alpha}$ if and only if $\alpha
\in\mathbb{R}$. (Keep in mind that we are following Convention
\ref{conv.CC.RRtoCC.embed}, so that the statement \textquotedblleft$\alpha
\in\mathbb{R}$\textquotedblright\ (for a complex number $\alpha$) actually
means \textquotedblleft$\alpha=r_{\mathbb{C}}$ for some $r\in\mathbb{R}%
$\textquotedblright.)

\textbf{(b)} We always have $\overline{\overline{\alpha}}=\alpha$.
\end{proposition}

Since we don't want to depend on geometric reasoning, let us nevertheless
prove this fact algebraically:

\begin{proof}
[Proof of Proposition \ref{prop.CC.conj.conjconj}.]Write the complex number
$\alpha$ in the form $\alpha=\left(  a,b\right)  $ for two real numbers $a$
and $b$. Then, $\overline{\alpha}=\left(  a,-b\right)  $ (by the definition of
$\overline{\alpha}$). Hence, the definition of $\overline{\overline{\alpha}}$
yields $\overline{\overline{\alpha}}=\left(  a,\underbrace{-\left(  -b\right)
}_{=b}\right)  =\left(  a,b\right)  =\alpha$. This proves Proposition
\ref{prop.CC.conj.conjconj} \textbf{(b)}.

\textbf{(a)} $\Longleftarrow:$ Assume that $\alpha\in\mathbb{R}$. We must
prove that $\alpha=\overline{\alpha}$.

We have $\alpha\in\mathbb{R}$. In other words, there exists an $r\in
\mathbb{R}$ such that $\alpha=r_{\mathbb{C}}$. Consider this $r$. We have
$\alpha=r_{\mathbb{C}}=\left(  r,0\right)  $ (by the definition of
$r_{\mathbb{C}}$). Hence, the definition of $\overline{\alpha}$ yields
$\overline{\alpha}=\left(  r,\underbrace{-0}_{=0}\right)  =\left(  r,0\right)
=\alpha$. Thus, $\alpha=\overline{\alpha}$. This proves the \textquotedblleft%
$\Longleftarrow$\textquotedblright\ direction of Proposition
\ref{prop.CC.conj.conjconj} \textbf{(a)}.

$\Longrightarrow:$ Assume that $\alpha=\overline{\alpha}$. We must prove that
$\alpha\in\mathbb{R}$.

We have $\alpha=\overline{\alpha}$. Thus, $\left(  a,b\right)  =\alpha
=\overline{\alpha}=\left(  a,-b\right)  $. In other words, $a=a$ and $b=-b$.
From $b=-b$, we obtain $2b=0$, thus $b=0$. Hence, $\alpha=\left(
a,\underbrace{b}_{=0}\right)  =\left(  a,0\right)  =a_{\mathbb{C}}$ (since
$a_{\mathbb{C}}$ is defined to be $\left(  a,0\right)  $). Thus, there exists
an $r\in\mathbb{R}$ such that $\alpha=r_{\mathbb{C}}$ (namely, $r=a$). In
other words, $\alpha\in\mathbb{R}$. This proves the \textquotedblleft%
$\Longrightarrow$\textquotedblright\ direction of Proposition
\ref{prop.CC.conj.conjconj} \textbf{(a)}.
\end{proof}

\begin{proposition}
\label{prop.CC.norm.conj}Let $\alpha\in\mathbb{C}$.

\textbf{(a)} We have $\operatorname*{N}\left(  \alpha\right)  =\alpha
\overline{\alpha}$ (or, more formally: $\left(  \operatorname*{N}\left(
\alpha\right)  \right)  _{\mathbb{C}}=\alpha\overline{\alpha}$).

\textbf{(b)} We have $\operatorname*{N}\left(  \overline{\alpha}\right)
=\operatorname*{N}\left(  \alpha\right)  $.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.CC.norm.conj}.]Write the complex number
$\alpha$ in the form $\alpha=\left(  a,b\right)  $ for two real numbers $a$
and $b$. Then, $\overline{\alpha}=\left(  a,-b\right)  $ (by the definition of
$\overline{\alpha}$) and $\operatorname*{N}\left(  \alpha\right)  =a^{2}%
+b^{2}$ (by the definition of $\operatorname*{N}\left(  \alpha\right)  $).

\textbf{(a)} Multiplying the equalities $\alpha=\left(  a,b\right)  $ and
$\overline{\alpha}=\left(  a,-b\right)  $, we obtain%
\begin{align*}
\alpha\overline{\alpha}  &  =\left(  a,b\right)  \left(  a,-b\right)  =\left(
\underbrace{aa-b\left(  -b\right)  }_{=a^{2}+b^{2}},\underbrace{a\left(
-b\right)  +ba}_{=0}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the operation }%
\cdot\text{ on }\mathbb{C}\right) \\
&  =\left(  \underbrace{a^{2}+b^{2}}_{=\operatorname*{N}\left(  \alpha\right)
},0\right)  =\left(  \operatorname*{N}\left(  \alpha\right)  ,0\right)
=\left(  \operatorname*{N}\left(  \alpha\right)  \right)  _{\mathbb{C}}%
\end{align*}
(since $\operatorname*{N}\left(  \alpha\right)  _{\mathbb{C}}$ is defined to
be $\left(  \operatorname*{N}\left(  \alpha\right)  ,0\right)  $). In other
words, $\left(  \operatorname*{N}\left(  \alpha\right)  \right)  _{\mathbb{C}%
}=\alpha\overline{\alpha}$. According to Convention \ref{conv.CC.RRtoCC.embed}%
, we are equating the real number $\operatorname*{N}\left(  \alpha\right)  $
with the complex number $\left(  \operatorname*{N}\left(  \alpha\right)
\right)  _{\mathbb{C}}$; hence, this equality rewrites as $\operatorname*{N}%
\left(  \alpha\right)  =\alpha\overline{\alpha}$. This proves Proposition
\ref{prop.CC.norm.conj} \textbf{(a)}.

\textbf{(b)} Recall that $\overline{\alpha}=\left(  a,-b\right)  $. Thus, the
definition of $\operatorname*{N}\left(  \overline{\alpha}\right)  $ yields
$\operatorname*{N}\left(  \overline{\alpha}\right)  =a^{2}+\underbrace{\left(
-b\right)  ^{2}}_{=b^{2}}=a^{2}+b^{2}=\operatorname*{N}\left(  \alpha\right)
$. This proves Proposition \ref{prop.CC.norm.conj} \textbf{(b)}.
\end{proof}

\begin{center}
\textbf{2019-03-04 lecture}
\end{center}

\begin{proposition}
\label{prop.CC.conj.hom}Let $\alpha$ and $\beta$ be two complex numbers. Then:

\textbf{(a)} We have $\overline{\alpha+\beta}=\overline{\alpha}+\overline
{\beta}$.

\textbf{(b)} We have $\overline{\alpha-\beta}=\overline{\alpha}-\overline
{\beta}$.

\textbf{(c)} We have $\overline{\alpha\cdot\beta}=\overline{\alpha}%
\cdot\overline{\beta}$.

\textbf{(d)} We have $\operatorname*{N}\left(  \alpha\beta\right)
=\operatorname*{N}\left(  \alpha\right)  \cdot\operatorname*{N}\left(
\beta\right)  $.

\textbf{(e)} If $\beta\neq0$, then $\operatorname*{N}\left(  \dfrac{\alpha
}{\beta}\right)  =\dfrac{\operatorname*{N}\left(  \alpha\right)
}{\operatorname*{N}\left(  \beta\right)  }$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.CC.conj.hom}.]Write the complex number
$\alpha$ in the form $\alpha=\left(  a,b\right)  $ for two real numbers $a$
and $b$. Then, $\overline{\alpha}=\left(  a,-b\right)  $ (by the definition of
$\overline{\alpha}$) and $\operatorname*{N}\left(  \alpha\right)  =a^{2}%
+b^{2}$ (by the definition of $\operatorname*{N}\left(  \alpha\right)  $).

Write the complex number $\beta$ in the form $\beta=\left(  c,d\right)  $ for
two real numbers $c$ and $d$. Then, $\overline{\beta}=\left(  c,-d\right)  $
(by the definition of $\overline{\beta}$) and $\operatorname*{N}\left(
\beta\right)  =c^{2}+d^{2}$ (by the definition of $\operatorname*{N}\left(
\beta\right)  $).

\textbf{(c)} Multiplying the equalities $\alpha=\left(  a,b\right)  $ and
$\beta=\left(  c,d\right)  $, we obtain $\alpha\cdot\beta=\left(  a,b\right)
\left(  c,d\right)  =\left(  ac-bd,ad+bc\right)  $ (by the definition of the
operation $\cdot$ on $\mathbb{C}$). Hence, Definition \ref{def.CC.conj.conj}
yields $\overline{\alpha\cdot\beta}=\left(  ac-bd,-\left(  ad+bc\right)
\right)  $.

On the other hand, multiplying the equalities $\overline{\alpha}=\left(
a,-b\right)  $ and $\overline{\beta}=\left(  c,-d\right)  $ yields%
\[
\overline{\alpha}\cdot\overline{\beta}=\left(  \underbrace{ac-\left(
-b\right)  \left(  -d\right)  }_{=ac-bd},\underbrace{a\left(  -d\right)
+b\left(  -c\right)  }_{=-\left(  ad+bc\right)  }\right)  =\left(
ac-bd,-\left(  ad+bc\right)  \right)
\]
(by the definition of the operation $\cdot$ on $\mathbb{C}$). Comparing this
with \newline$\overline{\alpha\cdot\beta}=\left(  ac-bd,-\left(  ad+bc\right)
\right)  $, we obtain $\overline{\alpha\cdot\beta}=\overline{\alpha}%
\cdot\overline{\beta}$. This proves Proposition \ref{prop.CC.conj.hom}
\textbf{(c)}.

Parts \textbf{(a)} and \textbf{(b)} of Proposition \ref{prop.CC.conj.hom}
follow by similar (but easier) computations.

\textbf{(d)} Proposition \ref{prop.CC.norm.conj} \textbf{(a)} yields
$\operatorname*{N}\left(  \alpha\right)  =\alpha\overline{\alpha}$. Similarly,
$\operatorname*{N}\left(  \beta\right)  =\beta\overline{\beta}$ and
$\operatorname*{N}\left(  \alpha\beta\right)  =\alpha\beta\overline
{\alpha\beta}$. Hence,%
\[
\operatorname*{N}\left(  \alpha\beta\right)  =\alpha\beta\underbrace{\overline
{\alpha\beta}}_{\substack{=\overline{\alpha\cdot\beta}=\overline{\alpha}%
\cdot\overline{\beta}\\\text{(by Proposition \ref{prop.CC.conj.hom}
\textbf{(c)})}}}=\alpha\beta\overline{\alpha}\cdot\overline{\beta
}=\underbrace{\left(  \alpha\overline{\alpha}\right)  }_{=\operatorname*{N}%
\left(  \alpha\right)  }\cdot\underbrace{\left(  \beta\overline{\beta}\right)
}_{=\operatorname*{N}\left(  \beta\right)  }=\operatorname*{N}\left(
\alpha\right)  \cdot\operatorname*{N}\left(  \beta\right)  .
\]
This proves Proposition \ref{prop.CC.conj.hom} \textbf{(d)}.

\textbf{(e)} Assume that $\beta\neq0$. Thus, the quotient $\dfrac{\alpha
}{\beta}\in\mathbb{C}$ is defined (by Definition
\ref{def.CC.CC.inverse.notations} \textbf{(b)}). Proposition
\ref{prop.CC.conj.hom} \textbf{(d)} (applied to $\dfrac{\alpha}{\beta}$
instead of $\alpha$) yields $\operatorname*{N}\left(  \dfrac{\alpha}{\beta
}\cdot\beta\right)  =\operatorname*{N}\left(  \dfrac{\alpha}{\beta}\right)
\cdot\operatorname*{N}\left(  \beta\right)  $. In view of $\dfrac{\alpha
}{\beta}\cdot\beta=\alpha$, this rewrites as
\begin{equation}
\operatorname*{N}\left(  \alpha\right)  =\operatorname*{N}\left(
\dfrac{\alpha}{\beta}\right)  \cdot\operatorname*{N}\left(  \beta\right)  .
\label{pf.prop.CC.conj.hom.e.1}%
\end{equation}
Also, Proposition \ref{prop.CC.norm.basics} \textbf{(c)} (applied to $\beta$
instead of $\alpha$) yields that we have $\operatorname*{N}\left(
\beta\right)  >0$ (since $\beta\neq0$); thus, $\operatorname*{N}\left(
\beta\right)  \neq0$. Thus, we can divide both sides of the equality
(\ref{pf.prop.CC.conj.hom.e.1}) by $\operatorname*{N}\left(  \beta\right)  $.
We thus obtain $\dfrac{\operatorname*{N}\left(  \alpha\right)  }%
{\operatorname*{N}\left(  \beta\right)  }=\operatorname*{N}\left(
\dfrac{\alpha}{\beta}\right)  $. Proposition \ref{prop.CC.conj.hom}
\textbf{(e)} follows.
\end{proof}

The properties of the norm of a complex numbers let us see an old fact in new
light: Remember the Brahmagupta--Fibonacci identity
(\ref{eq.intro.sum-of-2sq.sum*sum}), which said that%
\[
\left(  a^{2}+b^{2}\right)  \left(  c^{2}+d^{2}\right)  =\left(  ad+bc\right)
^{2}+\left(  ac-bd\right)  ^{2}%
\]
for $a,b,c,d\in\mathbb{R}$. This identity is equivalent to the identity%
\[
\operatorname*{N}\left(  \alpha\right)  \cdot\operatorname*{N}\left(
\beta\right)  =\operatorname*{N}\left(  \alpha\beta\right)
\]
for the complex numbers $\alpha=\left(  a,b\right)  =a+bi$ and $\beta=\left(
c,d\right)  =c+di$. Thus, the identity (\ref{eq.intro.sum-of-2sq.sum*sum}) is
just Proposition \ref{prop.CC.conj.hom} \textbf{(d)}, restated without the use
of complex numbers. This answers the question of how you could have come up
with this identity -- at least if you know complex numbers. (Brahmagupta must
have found it in a different way, since complex numbers were not known to him.)

\begin{corollary}
\label{cor.CC.norm.pow}Let $\alpha\in\mathbb{C}$ and $k\in\mathbb{N}$. Then:

\textbf{(a)} We have $\overline{\alpha^{k}}=\overline{\alpha}^{k}$.

\textbf{(b)} We have $\operatorname*{N}\left(  \alpha^{k}\right)  =\left(
\operatorname*{N}\left(  \alpha\right)  \right)  ^{k}$.
\end{corollary}

\begin{proof}
[Proof of Corollary \ref{cor.CC.norm.pow}.]\textbf{(a)} This follows by
induction on $k$, using Proposition \ref{prop.CC.conj.hom} \textbf{(c)} and
the fact that $\overline{1}=1$.

\textbf{(b)} This follows by induction on $k$, using Proposition
\ref{prop.CC.conj.hom} \textbf{(d)} and the fact that $\operatorname*{N}%
\left(  1\right)  =1$.
\end{proof}

Using the norm of a complex number, we can define a notion of absolute value
of a complex number:

\begin{definition}
\label{def.CC.norm.abs}Let $\alpha=\left(  a,b\right)  $ be a complex number.
The \textit{absolute value} (or \textit{modulus} or \textit{length}) of
$\alpha$ is defined to be $\sqrt{\operatorname*{N}\left(  \alpha\right)
}=\sqrt{a^{2}+b^{2}}\in\mathbb{R}$. (This is well-defined, because Proposition
\ref{prop.CC.norm.basics} \textbf{(a)} shows that $\operatorname*{N}\left(
\alpha\right)  \geq0$.)

The absolute value of $\alpha$ is denoted by $\left\vert \alpha\right\vert $.
(This notation does not conflict with the classical notation $\left\vert
a\right\vert $ for the absolute value of a real number $a$, because if $a$ is
a real number, then Proposition \ref{prop.CC.norm.aa} yields
$\operatorname*{N}\left(  a_{\mathbb{C}}\right)  =a^{2}$ and therefore
$\sqrt{\operatorname*{N}\left(  a_{\mathbb{C}}\right)  }=\sqrt{a^{2}%
}=\left\vert a\right\vert $, where \textquotedblleft$\left\vert a\right\vert
$\textquotedblright\ means the classical concept of absolute value of $a$.)
\end{definition}

In the Argand diagram, the absolute value $\left\vert \alpha\right\vert $ of a
complex number $\alpha$ is simply the distance of $\alpha$ from the origin.
The reason for this is the Pythagorean theorem:%

\[
\begin{tikzpicture}[scale=2.5]
\draw[step=1cm,gray,very thin] (-0.5, -0.5) grid (2.4,2.4);
\draw[->] (-0.6,0) -- (2.5,0);
\draw[->] (0,-0.6) -- (0,2.5);
\node (p) at (1.3 cm, 1.7 cm) {};
\node (o) at (0 cm, 0 cm) {};
\node (xproj) at (1.3 cm, 0 cm) {};
\fill (p) circle (1pt) node[above right] {$\alpha = a+bi$};
\fill (xproj) circle (1pt);
\fill (o) circle (1pt);
\draw[very thick, blue] (p) -- node[right=1pt, fill=white] {$b$} (xproj);
\draw[very thick, red] (xproj) -- node[below=1pt, fill=white] {$a$} (o);
\draw[very thick, green!50!black] (o) --node[above left=1pt, fill=white] {$\left|\alpha\right| = \sqrt{a^2 + b^2}$} (p);
\end{tikzpicture}
.
\]


Good references for the basic properties of complex numbers are
\cite{LaNaSc16} and \cite[\S 3.9--\S 3.12]{Swanso18}. The book \cite{AndAnd14}
is a treasure trove of applications and exercises.

\subsubsection{$\operatorname*{Re}$, $\operatorname*{Im}$ and the $2\times
2$-matrix representation}

We define some more attributes of a complex number.

\begin{definition}
\label{def.CC.ReIm}Let $\alpha=\left(  a,b\right)  $ be a complex number (so
that $a$ and $b$ are real numbers and $\alpha=a+bi$).

Then, $a$ is called the \textit{real part} of $\alpha$ and denoted
$\operatorname*{Re}\alpha$ (or $\mathfrak{R}\alpha$).

Also, $b$ is called the \textit{imaginary part} of $\alpha$ and denoted
$\operatorname*{Im}\alpha$ (or $\mathfrak{I}\alpha$).
\end{definition}

The following proposition assigns a real $2\times2$-matrix to each complex number:

\begin{proposition}
\label{prop.CC.as-matrices.mu}Let $\mathbb{R}^{2\times2}$ be the set of all
$2\times2$-matrices with real entries.

Define a map $\mu:\mathbb{C}\rightarrow\mathbb{R}^{2\times2}$ by setting%
\[
\mu\left(  a,b\right)  =\left(
\begin{array}
[c]{cc}%
a & b\\
-b & a
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \text{for each }\left(  a,b\right)  \in
\mathbb{C}.
\]


\textbf{(a)} We have $\mu\left(  \alpha+\beta\right)  =\mu\left(
\alpha\right)  +\mu\left(  \beta\right)  $ for all $\alpha,\beta\in\mathbb{C}$.

\textbf{(b)} We have $\mu\left(  \alpha-\beta\right)  =\mu\left(
\alpha\right)  -\mu\left(  \beta\right)  $ for all $\alpha,\beta\in\mathbb{C}$.

\textbf{(c)} We have $\mu\left(  \alpha\cdot\beta\right)  =\mu\left(
\alpha\right)  \cdot\mu\left(  \beta\right)  $ for all $\alpha,\beta
\in\mathbb{C}$.

\textbf{(d)} The map $\mu$ is injective.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.CC.as-matrices.mu}.]\textbf{(c)} This is a
straightforward computation: Let $\alpha,\beta\in\mathbb{C}$. Write the
complex number $\alpha$ in the form $\alpha=\left(  a,b\right)  $ for two real
numbers $a$ and $b$. Write the complex number $\beta$ in the form
$\beta=\left(  c,d\right)  $ for two real numbers $c$ and $d$. Multiplying the
equalities $\alpha=\left(  a,b\right)  $ and $\beta=\left(  c,d\right)  $, we
obtain%
\[
\alpha\cdot\beta=\left(  a,b\right)  \cdot\left(  c,d\right)  =\left(
ac-bd,ad+bc\right)
\]
(by the definition of $\cdot$). Hence,
\begin{equation}
\mu\left(  \alpha\cdot\beta\right)  =\mu\left(  ac-bd,ad+bc\right)  =\left(
\begin{array}
[c]{cc}%
ac-bd & ad+bc\\
-\left(  ad+bc\right)  & ac-bd
\end{array}
\right)  \label{pf.prop.CC.as-matrices.mu.c.1}%
\end{equation}
(by the definition of $\mu$). On the other hand, from $\alpha=\left(
a,b\right)  $, we obtain%
\[
\mu\left(  \alpha\right)  =\mu\left(  a,b\right)  =\left(
\begin{array}
[c]{cc}%
a & b\\
-b & a
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\mu\right)
,
\]
and similarly we can find%
\[
\mu\left(  \beta\right)  =\left(
\begin{array}
[c]{cc}%
c & d\\
-d & c
\end{array}
\right)  .
\]
Multiplying these two equalities together, we find%
\begin{align*}
\mu\left(  \alpha\right)  \cdot\mu\left(  \beta\right)   &  =\left(
\begin{array}
[c]{cc}%
a & b\\
-b & a
\end{array}
\right)  \cdot\left(
\begin{array}
[c]{cc}%
c & d\\
-d & c
\end{array}
\right)  =\left(
\begin{array}
[c]{cc}%
ac+b\left(  -d\right)  & ad+bc\\
\left(  -b\right)  c+a\left(  -d\right)  & \left(  -b\right)  d+ac
\end{array}
\right) \\
&  =\left(
\begin{array}
[c]{cc}%
ac-bd & ad+bc\\
-\left(  ad+bc\right)  & ac-bd
\end{array}
\right)  .
\end{align*}
Comparing this with (\ref{pf.prop.CC.as-matrices.mu.c.1}), we find $\mu\left(
\alpha\cdot\beta\right)  =\mu\left(  \alpha\right)  \cdot\mu\left(
\beta\right)  $. This proves Proposition \ref{prop.CC.as-matrices.mu}
\textbf{(c)}.

Similar (but much simpler) computations prove parts \textbf{(a)} and
\textbf{(b)} of Proposition \ref{prop.CC.as-matrices.mu}.

\textbf{(d)} We need to show that a complex number $\alpha$ can always be
recovered from its image $\mu\left(  \alpha\right)  $.

But this is easy: If $\alpha=\left(  a,b\right)  $ is a complex number, then
$\mu\left(  \alpha\right)  =\mu\left(  a,b\right)  =\left(
\begin{array}
[c]{cc}%
a & b\\
-b & a
\end{array}
\right)  $ (by the definition of $\mu$), and therefore we can recover $a$ and
$b$ from $\mu\left(  \alpha\right)  $ (namely, $a$ and $b$ are the two entries
of the first row of the matrix $\mu\left(  \alpha\right)  $). Hence, we can
recover $\alpha$ from $\mu\left(  \alpha\right)  $. This shows that the map
$\mu$ is injective; this proves Proposition \ref{prop.CC.as-matrices.mu}
\textbf{(d)}.
\end{proof}

Proposition \ref{prop.CC.as-matrices.mu} really says that (instead of
regarding complex numbers as pairs of real numbers) we can regard complex
numbers as a specific kind of $2\times2$-matrices with real entries (by
identifying each complex number $\alpha$ with the matrix $\mu\left(
\alpha\right)  $). This viewpoint has the advantage that multiplication of
complex numbers becomes a particular case of matrix multiplication. (We could
have saved ourselves the trouble of proving the associativity of
multiplication for complex numbers if we had taken this viewpoint.)

\subsubsection{The fundamental theorem of algebra}

Finally, let me mention without proof the so-called \textit{Fundamental
Theorem of Algebra}:

\begin{theorem}
\label{thm.CC.FTA.factor}Let $p\left(  x\right)  $ be a polynomial of degree
$n$ with complex coefficients. Then, there exist complex numbers $\alpha
_{1},\alpha_{2},\ldots,\alpha_{n}$ and $\beta$ such that%
\[
p\left(  x\right)  =\beta\left(  x-\alpha_{1}\right)  \left(  x-\alpha
_{2}\right)  \cdots\left(  x-\alpha_{n}\right)  .
\]

\end{theorem}

In other words, any polynomial with complex coefficients can be factored into
linear factors. This is in contrast to real numbers, where polynomials can at
best be factored into linear and quadratic factors. (For example, the
polynomial $x^{2}+1$ cannot be factored further over the real numbers, but
factors as $\left(  x+i\right)  \left(  x-i\right)  $ over the complex numbers.)

The Fundamental Theorem of Algebra is not actually a theorem of algebra. It
relies heavily on the concepts of real and complex numbers. So it is actually
a theorem of analysis. For a proof, see \cite[Theorem 3.2.2]{LaNaSc16}.

\subsection{Gaussian integers}

Inside the set $\mathbb{C}$ of all complex numbers (an uncountable set) lies a
much smaller (countable) set of numbers, which are much closer to integers
than even to real numbers. We shall study them partly for their own sake,
partly as an instructive example of what will later call a commutative ring,
and partly in order to answer the questions from Section
\ref{sect.intro.sum-of-2sq} (although complex numbers were never mentioned in
that section).

We shall follow Keith Conrad's notes \cite{Conrad-Gauss} for most of this
section (but at the end we will go a bit further in order to answer Question
\ref{quest.intro.sum-of-2sq.2} \textbf{(b)}).

\subsubsection{Definitions and basics}

We shall now define the \textit{Gaussian integers}: a middle ground between
integers and complex numbers.

\begin{definition}
\label{def.Z[i].gauss.gauss}A \textit{Gaussian integer} is a complex number
$\left(  a,b\right)  $ with $a,b\in\mathbb{Z}$.
\end{definition}

For example, $3+5i=\left(  3,5\right)  $ and $3-7i=\left(  3,-7\right)  $ are
Gaussian integers. So are $0=\left(  0,0\right)  $, $1=\left(  1,0\right)  $
and $i=\left(  0,1\right)  $. Every integer is a Gaussian
integer\footnote{This relies on Convention \ref{conv.CC.RRtoCC.embed}, of
course. If we avoid this convention, then we should instead say that for every
integer $r$, the complex number $r_{\mathbb{C}}=\left(  r,0\right)  $ is a
Gaussian integer.}. But $\dfrac{1}{2}+3i=\left(  \dfrac{1}{2},3\right)  $ and
$\sqrt{2}+4i=\left(  \sqrt{2},4\right)  $ are not Gaussian integers.

\begin{remark}
In Definition \ref{def.Z[i].gauss.gauss}, we have defined Gaussian integers
using complex numbers. This can be viewed as somewhat of an overkill, as the
notion of complex numbers depends on the notion of real numbers, which are
mostly useless for Gaussian integers. Thus, one might ask for a different
definition of Gaussian integers -- one which relies only on integers and not
on real numbers.

Such a definition is easy to make: Just replace every appearance of real
numbers in Definition \ref{def.CC.CC} by integers! Thus, define the Gaussian
integers as pairs of two integers; let $\mathbb{C}_{\mathbb{Z}}$ be the set of
these pairs; denote the Gaussian integer $\left(  r,0\right)  $ by
$r_{\mathbb{C}}$ whenever $r$ is an integer; define the operations $+$, $-$
and $\cdot$ on the set $\mathbb{C}_{\mathbb{Z}}$ by the same formulas as in
Definition \ref{def.CC.CC} \textbf{(e)}; likewise, adapt the rest of
Definition \ref{def.CC.CC} to integers. Most of what we have done in Section
\ref{sect.CC.CC} can be straightforwardly adapted to this notion of Gaussian
integers (by making the obvious changes -- i.e., mostly, replacing real
numbers by integers); the main exceptions are the following:

\begin{itemize}
\item Not every nonzero Gaussian integer has an inverse (in the set of
Gaussian integers). (In fact, as we will soon see, the only Gaussian integers
that have inverses are $1,i,-1,-i$.) Thus, division and negative powers of
Gaussian integers are usually not defined (without leaving the set of Gaussian integers).

\item The absolute value $\left\vert \alpha\right\vert $ of a Gaussian integer
$\alpha$ will usually not be an integer (since it is defined as a square root).
\end{itemize}

This alternative definition of Gaussian integers is equivalent to Definition
\ref{def.Z[i].gauss.gauss}; we are using the latter mainly because it is shorter.

Likewise, we could have defined \textquotedblleft Gaussian
rationals\textquotedblright\ by adapting Definition \ref{def.CC.CC} to
rational (instead of real) numbers. Unlike the Gaussian integers, these
\textquotedblleft Gaussian rationals\textquotedblright\ do have inverses (when
they are nonzero), and thus division and negative powers are well-defined for them.
\end{remark}

\begin{definition}
\label{def.Z[i].gauss.Z[i]}We let $\mathbb{Z}\left[  i\right]  $ be the set of
all Gaussian integers.
\end{definition}

Elementary number theory concerns itself with integers (mostly). Our goal in
this section is to replicate as much as we can of this theory in the setting
of Gaussian integers, and then see how it can be applied back to answer some
questions about the usual integers.

We will try to use Greek letters for Gaussian integers and Roman letters for integers.

\begin{proposition}
\label{prop.Z[i].gauss.ring}\textbf{(a)} If $\alpha$ and $\beta$ are two
Gaussian integers, then $\alpha+\beta$, $\alpha-\beta$ and $\alpha\cdot\beta$
are Gaussian integers.

\textbf{(b)} If $\alpha$ is a Gaussian integer, then $-\alpha$ is a Gaussian integer.

\textbf{(c)} Sums and products of finitely many Gaussian integers are Gaussian integers.
\end{proposition}

\begin{proof}
[Proposition \ref{prop.Z[i].gauss.ring}.]\textbf{(a)} Let $\alpha$ and $\beta$
be two Gaussian integers. Write the complex numbers $\alpha$ and $\beta$ as
$\alpha=\left(  a,b\right)  $ and $\beta=\left(  c,d\right)  $, respectively
(with $a,b,c,d\in\mathbb{R}$). The definition of a Gaussian integer shows that
$a,b\in\mathbb{Z}$ (since $\left(  a,b\right)  =\alpha$ is a Gaussian integer)
and that $c,d\in\mathbb{Z}$ (since $\left(  c,d\right)  =\beta$ is a Gaussian
integer). Now,
\[
\underbrace{\alpha}_{=\left(  a,b\right)  }\cdot\underbrace{\beta}_{=\left(
c,d\right)  }=\left(  a,b\right)  \cdot\left(  c,d\right)  =\left(
ac-bd,ad+bc\right)
\]
(by the definition of the operation $\cdot$ on $\mathbb{C}$). Since
$ac-bd,ad+bc\in\mathbb{Z}$ (because $a,b,c,d\in\mathbb{Z}$), this entails that
$\alpha\cdot\beta$ is a Gaussian integer (by the definition of a Gaussian
integer). Similarly (using the definitions of the operations $+$ and $-$ on
$\mathbb{C}$), we can see that $\alpha+\beta$ and $\alpha-\beta$ are Gaussian
integers. This proves Proposition \ref{prop.Z[i].gauss.ring} \textbf{(a)}.

\textbf{(b)} Let $\alpha$ be a Gaussian integer. Recall that $0$ is a Gaussian
integer. Thus, Proposition \ref{prop.Z[i].gauss.ring} \textbf{(a)} (applied to
$0$ and $\alpha$ instead of $\alpha$ and $\beta$) yields that $0+\alpha$,
$0-\alpha$ and $0\cdot\alpha$ is a Gaussian integer. Thus, in particular,
$0-\alpha$ is a Gaussian integer. In other words, $-\alpha$ is a Gaussian
integer (since $0-\alpha=-\alpha$). This proves Proposition
\ref{prop.Z[i].gauss.ring} \textbf{(b)}.

\textbf{(c)} This follows by induction. (The induction base relies on the fact
that $0$ and $1$ are Gaussian integers; the induction step uses Proposition
\ref{prop.Z[i].gauss.ring} \textbf{(a)}.)
\end{proof}

\begin{proposition}
\label{prop.Z[i].gauss.conj}Let $\alpha$ be a Gaussian integer. Then,
$\overline{\alpha}$ is a Gaussian integer.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.conj}.]Write the complex number
$\alpha$ as $\alpha=\left(  a,b\right)  $ with $a,b\in\mathbb{R}$. Then,
$a,b\in\mathbb{Z}$ (since $\alpha$ is a Gaussian integer). Hence,
$a,-b\in\mathbb{Z}$. Now, the definition of $\overline{\alpha}$ yields
$\overline{\alpha}=\left(  a,-b\right)  $. Hence, $\overline{\alpha}$ is a
Gaussian integer (since $a,-b\in\mathbb{Z}$). This proves Proposition
\ref{prop.Z[i].gauss.conj}.
\end{proof}

\begin{proposition}
\label{prop.Z[i].gauss.Norm-N}Let $\alpha\in\mathbb{Z}\left[  i\right]  $.
Then, $\operatorname*{N}\left(  \alpha\right)  \in\mathbb{N}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.Norm-N}.]Write the complex number
$\alpha$ as $\alpha=\left(  a,b\right)  $ with $a,b\in\mathbb{R}$. Then,
$a,b\in\mathbb{Z}$ (since $\alpha$ is a Gaussian integer). In other words, $a$
and $b$ are integers. Hence, $a^{2}$ and $b^{2}$ are nonnegative integers
(since the square of an integer is always a nonnegative integer). In other
words, $a^{2},b^{2}\in\mathbb{N}$. Hence, $a^{2}+b^{2}\in\mathbb{N}$. But the
definition of $\operatorname*{N}\left(  \alpha\right)  $ yields
$\operatorname*{N}\left(  \alpha\right)  =a^{2}+b^{2}\in\mathbb{N}$. This
proves Proposition \ref{prop.Z[i].gauss.Norm-N}.
\end{proof}

\subsubsection{Units and unit-equivalence}

\begin{definition}
\label{def.Z[i].gauss.unit}\textbf{(a)} A Gaussian integer $\alpha
\in\mathbb{Z}\left[  i\right]  $ is said to be \textit{invertible in}\textbf{
}$\mathbb{Z}\left[  i\right]  $ if it has an inverse in $\mathbb{Z}\left[
i\right]  $.

A \textit{unit} will mean a Gaussian integer that is invertible in
$\mathbb{Z}\left[  i\right]  $.

\textbf{(b)} We define a relation $\sim$ on $\mathbb{Z}\left[  i\right]  $ by%
\[
\left(  \alpha\sim\beta\right)  \Longleftrightarrow\left(  \alpha=\gamma
\beta\text{ for some unit }\gamma\in\mathbb{Z}\left[  i\right]  \right)  .
\]
This relation will be called \textit{unit-equivalence} (or \textit{equality up
to unit}). We say that two Gaussian integers $\alpha$ and $\beta$ are
\textit{unit-equivalent} if $\alpha\sim\beta$.
\end{definition}

For comparison, let us consider analogous concepts for integers instead of
Gaussian integers. The units of $\mathbb{Z}$ (that is, the integers that are
invertible in $\mathbb{Z}$) are $1$ and $-1$. So if we defined a relation
$\underset{\mathbb{Z}}{\sim}$ on $\mathbb{Z}$ in the same way as we defined
the relation $\sim$ on $\mathbb{Z}\left[  i\right]  $ (but requiring
$\gamma\in\mathbb{Z}$ instead of $\gamma\in\mathbb{Z}\left[  i\right]  $),
then this relation would just be given by%
\begin{align}
\left(  a\underset{\mathbb{Z}}{\sim}b\right)   &  \Longleftrightarrow\left(
a=cb\text{ for some }c\in\left\{  1,-1\right\}  \right) \nonumber\\
&  \Longleftrightarrow\left(  a=b\text{ or }a=-b\right)  \Longleftrightarrow
\left(  \left\vert a\right\vert =\left\vert b\right\vert \right)  .
\label{eq.Z[i].gauss.unit-Z}%
\end{align}
So the relation $\underset{\mathbb{Z}}{\sim}$ is not very exciting: it is
simply \textquotedblleft equality up to sign\textquotedblright.\footnote{In
other words, it is precisely the relation $\underset{\operatorname*{abs}%
}{\equiv}$, where $\operatorname*{abs}:\mathbb{Z}\rightarrow\mathbb{N}$ is the
map sending each integer $n$ to its absolute value $\left\vert n\right\vert $.
(See Example \ref{exa.eqrel.eqrel.eqrelf} for how this relation
$\underset{\operatorname*{abs}}{\equiv}$ is defined.)} But the relation $\sim$
on $\mathbb{Z}\left[  i\right]  $ cannot be described as simply as this: It is
easy to find two Gaussian integers $\alpha$ and $\beta$ such that $\left\vert
\alpha\right\vert =\left\vert \beta\right\vert $ holds but $\alpha\sim\beta$
does not (for example, the Gaussian integers $\alpha=16+63i$ and
$\beta=33+56i$ both have absolute value $65$ but are not unit-equivalent).

\begin{proposition}
\label{prop.Z[i].gauss.uniteq.eqrel}The relation $\sim$ on $\mathbb{Z}\left[
i\right]  $ is an equivalence relation.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.uniteq.eqrel}.]Observe the following:

\begin{itemize}
\item The relation $\sim$ is reflexive.

\begin{fineprint}
[\textit{Proof:} Let $\alpha\in\mathbb{Z}\left[  i\right]  $. Then,
$\alpha=1\alpha$. But $1$ is a unit (since $1^{-1}=1\in\mathbb{Z}\left[
i\right]  $). Hence, $\alpha=\gamma\alpha$ for some unit $\gamma\in
\mathbb{Z}\left[  i\right]  $ (namely, $\gamma=1$). In other words,
$\alpha\sim\alpha$ (by the definition of the relation $\sim$).

Now, forget that we fixed $\alpha$. We thus have shown that every $\alpha
\in\mathbb{Z}\left[  i\right]  $ satisfies $\alpha\sim\alpha$. In other words,
the relation $\sim$ is reflexive.]
\end{fineprint}

\item The relation $\sim$ is symmetric.

\begin{fineprint}
[\textit{Proof:} Let $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ be such
that $\alpha\sim\beta$. We shall prove that $\beta\sim\alpha$.

We have $\alpha\sim\beta$. In other words, $\alpha=\delta\beta$ for some unit
$\delta\in\mathbb{Z}\left[  i\right]  $ (by the definition of the relation
$\sim$). Consider this $\delta$. Note that $\delta$ is a unit; in other words,
$\delta$ is a Gaussian integer that has an inverse in $\mathbb{Z}\left[
i\right]  $. Thus, $\delta^{-1}$ is well-defined (since $\delta$ has an
inverse), and $\delta^{-1}\in\mathbb{Z}\left[  i\right]  $ (since $\delta$ has
an inverse in $\mathbb{Z}\left[  i\right]  $). Now, $\delta^{-1}$ is a
Gaussian integer (since $\delta^{-1}\in\mathbb{Z}\left[  i\right]  $) and
itself has an inverse in $\mathbb{Z}\left[  i\right]  $ (since its inverse is
$\left(  \delta^{-1}\right)  ^{-1}=\delta\in\mathbb{Z}\left[  i\right]  $). In
other words, $\delta^{-1}$ is a unit. Furthermore, dividing both sides of the
equality $\alpha=\delta\beta$ by $\delta$, we find $\delta^{-1}\alpha=\beta$,
so that $\beta=\delta^{-1}\alpha$. Thus, $\beta=\gamma\alpha$ for some unit
$\gamma\in\mathbb{Z}\left[  i\right]  $ (namely, for $\gamma=\delta^{-1}$). In
other words, $\beta\sim\alpha$ (by the definition of the relation $\sim$).

Now, forget that we fixed $\alpha$ and $\beta$. We thus have shown that every
$\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ satisfying $\alpha\sim\beta$
satisfy $\beta\sim\alpha$. In other words, the relation $\sim$ is symmetric.]
\end{fineprint}

\item The relation $\sim$ is transitive.

\begin{fineprint}
[\textit{Proof:} Let $\alpha,\beta,\gamma\in\mathbb{Z}\left[  i\right]  $ be
such that $\alpha\sim\beta$ and $\beta\sim\gamma$. We shall prove that
$\alpha\sim\gamma$.

From $\alpha\sim\beta$, we conclude that $\alpha=\delta\beta$ for some unit
$\delta\in\mathbb{Z}\left[  i\right]  $ (by the definition of the relation
$\sim$). From $\beta\sim\gamma$, we conclude that $\beta=\varepsilon\gamma$
for some unit $\varepsilon\in\mathbb{Z}\left[  i\right]  $ (by the definition
of the relation $\sim$). Consider these two units $\delta$ and $\varepsilon$.
Both $\delta$ and $\varepsilon$ are units, and thus have inverses in
$\mathbb{Z}\left[  i\right]  $ (by the definition of \textquotedblleft
unit\textquotedblright). In other words, they have inverses, and these
inverses $\delta^{-1}$ and $\varepsilon^{-1}$ belong to $\mathbb{Z}\left[
i\right]  $. Now, Proposition \ref{prop.CC.CC.inverse.ab} \textbf{(b)}
(applied to $\delta$ and $\varepsilon$ instead of $\alpha$ and $\beta$) yields
that the product $\delta\varepsilon$ has an inverse as well, and this inverse
is $\left(  \delta\varepsilon\right)  ^{-1}=\delta^{-1}\varepsilon^{-1}$.
Hence, $\left(  \delta\varepsilon\right)  ^{-1}=\delta^{-1}\varepsilon^{-1}%
\in\mathbb{Z}\left[  i\right]  $ (since both $\delta^{-1}$ and $\varepsilon
^{-1}$ belong to $\mathbb{Z}\left[  i\right]  $). Thus, $\delta\varepsilon$ is
a Gaussian integer (since $\delta$ and $\varepsilon$ are Gaussian integers)
that has an inverse in $\mathbb{Z}\left[  i\right]  $ (since $\left(
\delta\varepsilon\right)  ^{-1}\in\mathbb{Z}\left[  i\right]  $). In other
words, $\delta\varepsilon$ is a unit (by the definition of a \textquotedblleft
unit\textquotedblright). This unit $\delta\varepsilon$ satisfies
$\alpha=\left(  \delta\varepsilon\right)  \gamma$ (since $\alpha
=\delta\underbrace{\beta}_{=\varepsilon\gamma}=\delta\varepsilon\gamma=\left(
\delta\varepsilon\right)  \gamma$). Hence, $\alpha=\rho\gamma$ for some unit
$\rho\in\mathbb{Z}\left[  i\right]  $ (namely, for $\rho=\delta\varepsilon$).
In other words, $\alpha\sim\gamma$ (by the definition of the relation $\sim$).

Now, forget that we fixed $\alpha,\beta,\gamma$. We thus have shown that every
$\alpha,\beta,\gamma\in\mathbb{Z}\left[  i\right]  $ satisfying $\alpha
\sim\beta$ and $\beta\sim\gamma$ satisfy $\alpha\sim\gamma$. In other words,
the relation $\sim$ is transitive.]
\end{fineprint}
\end{itemize}

\noindent We have now proven that the relation $\sim$ is reflexive, symmetric
and transitive. In other words, $\sim$ is an equivalence relation (by the
definition of \textquotedblleft equivalence relation\textquotedblright). This
proves Proposition \ref{prop.Z[i].gauss.uniteq.eqrel}.
\end{proof}

\begin{proposition}
\label{prop.Z[i].gauss.norm1}Let $\alpha$ be a Gaussian integer.

\textbf{(a)} We have $\operatorname*{N}\left(  \alpha\right)  =0$ if and only
if $\alpha=0$.

\textbf{(b)} We have $\operatorname*{N}\left(  \alpha\right)  =1$ if and only
if $\alpha$ is a unit.

\textbf{(c)} If $\alpha$ is nonzero and not a unit, then $\operatorname*{N}%
\left(  \alpha\right)  >1$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.norm1}.]\textbf{(a)} This is a
particular case of Proposition \ref{prop.CC.norm.basics} \textbf{(b)}.

\textbf{(b)} $\Longrightarrow:$ Assume that $\operatorname*{N}\left(
\alpha\right)  =1$. We must prove that $\alpha$ is a unit.

Proposition \ref{prop.CC.norm.conj} \textbf{(a)} yields $\operatorname*{N}%
\left(  \alpha\right)  =\alpha\overline{\alpha}$.\ Hence, $\alpha
\overline{\alpha}=\operatorname*{N}\left(  \alpha\right)  =1$.

But Proposition \ref{prop.Z[i].gauss.conj} shows that $\overline{\alpha}$ is a
Gaussian integer. In other words, $\overline{\alpha}\in\mathbb{Z}\left[
i\right]  $. This Gaussian integer $\overline{\alpha}\in\mathbb{Z}\left[
i\right]  $ is an inverse of $\alpha$ (since $\alpha\overline{\alpha}=1$).
Thus, $\alpha$ has an inverse in $\mathbb{Z}\left[  i\right]  $ (namely,
$\overline{\alpha}$). In other words, $\alpha$ is a unit (by the definition of
\textquotedblleft unit\textquotedblright). This proves the \textquotedblleft%
$\Longrightarrow$\textquotedblright\ direction of Proposition
\ref{prop.Z[i].gauss.norm1} \textbf{(b)}.

$\Longleftarrow:$ Assume that $\alpha$ is a unit. We must prove that
$\operatorname*{N}\left(  \alpha\right)  =1$.

We know that $\alpha$ is a unit. In other words, $\alpha$ is invertible in
$\mathbb{Z}\left[  i\right]  $. In other words, $\alpha$ has an inverse
$\alpha^{-1}\in\mathbb{Z}\left[  i\right]  $.

This inverse $\alpha^{-1}$ satisfies $\alpha\alpha^{-1}=1=1_{\mathbb{C}%
}=\left(  1,0\right)  $, so that
\begin{align*}
\operatorname*{N}\left(  \alpha\alpha^{-1}\right)   &  =\operatorname*{N}%
\left(  \left(  1,0\right)  \right)  =1^{2}+0^{2}\ \ \ \ \ \ \ \ \ \ \left(
\text{by the definition of }\operatorname*{N}\left(  \left(  1,0\right)
\right)  \right) \\
&  =1.
\end{align*}
But Proposition \ref{prop.CC.conj.hom} \textbf{(d)} (applied to $\beta
=\alpha^{-1}$) yields $\operatorname*{N}\left(  \alpha\alpha^{-1}\right)
=\operatorname*{N}\left(  \alpha\right)  \cdot\operatorname*{N}\left(
\alpha^{-1}\right)  $. Hence, $\operatorname*{N}\left(  \alpha\right)
\cdot\operatorname*{N}\left(  \alpha^{-1}\right)  =\operatorname*{N}\left(
\alpha\alpha^{-1}\right)  =1$. But Proposition \ref{prop.Z[i].gauss.Norm-N}
yields $\operatorname*{N}\left(  \alpha\right)  \in\mathbb{N}$. The same
argument (applied to $\alpha^{-1}$ instead of $\alpha$) yields
$\operatorname*{N}\left(  \alpha^{-1}\right)  \in\mathbb{N}$ (since
$\alpha^{-1}\in\mathbb{Z}\left[  i\right]  $). Hence, the equality
$\operatorname*{N}\left(  \alpha\right)  \cdot\operatorname*{N}\left(
\alpha^{-1}\right)  =1$ entails that $\operatorname*{N}\left(  \alpha\right)
\mid1$. Consequently, $\operatorname*{N}\left(  \alpha\right)  =1$ (since
$\operatorname*{N}\left(  \alpha\right)  \in\mathbb{N}$). This proves the
\textquotedblleft$\Longleftarrow$\textquotedblright\ direction of Proposition
\ref{prop.Z[i].gauss.norm1} \textbf{(b)}.

\textbf{(c)} Assume that $\alpha$ is nonzero and not a unit. Then, $\alpha
\neq0$ (since $\alpha$ is nonzero). Hence, Proposition
\ref{prop.CC.norm.basics} \textbf{(c)} yields $\operatorname*{N}\left(
\alpha\right)  >0$. But Proposition \ref{prop.Z[i].gauss.Norm-N} yields
$\operatorname*{N}\left(  \alpha\right)  \in\mathbb{N}$. Combining this with
$\operatorname*{N}\left(  \alpha\right)  >0$, we obtain $\operatorname*{N}%
\left(  \alpha\right)  \geq1$. But Proposition \ref{prop.Z[i].gauss.norm1}
\textbf{(b)} shows that we have $\operatorname*{N}\left(  \alpha\right)  =1$
if and only if $\alpha$ is a unit. Hence, we don't have $\operatorname*{N}%
\left(  \alpha\right)  =1$ (since $\alpha$ is not a unit). In other words, we
have $\operatorname*{N}\left(  \alpha\right)  \neq1$. Combining this with
$\operatorname*{N}\left(  \alpha\right)  \geq1$, we find $\operatorname*{N}%
\left(  \alpha\right)  >1$. This proves Proposition
\ref{prop.Z[i].gauss.norm1} \textbf{(c)}.
\end{proof}

\begin{proposition}
\label{prop.Z[i].gauss.units}The units (in $\mathbb{Z}\left[  i\right]  $) are
$1,-1,i,-i$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.units}.]Each of the four Gaussian
integers $1,-1,i,-i$ is a unit\footnote{\textit{Proof.} We have $i\left(
-i\right)  =1$. Hence, the Gaussian integer $i$ has an inverse, namely
$i^{-1}=-i$. Similarly, the Gaussian integer $-i$ has an inverse, namely
$\left(  -i\right)  ^{-1}=i$.
\par
The Gaussian integer $1$ is invertible in $\mathbb{Z}\left[  i\right]  $
(since its inverse is $1^{-1}=1\in\mathbb{Z}\left[  i\right]  $), and thus is
a unit.
\par
The Gaussian integer $-1$ is invertible in $\mathbb{Z}\left[  i\right]  $
(since its inverse is $\left(  -1\right)  ^{-1}=-1\in\mathbb{Z}\left[
i\right]  $), and thus is a unit.
\par
The Gaussian integer $i$ is invertible in $\mathbb{Z}\left[  i\right]  $
(since its inverse is $i^{-1}=-i\in\mathbb{Z}\left[  i\right]  $), and thus is
a unit.
\par
The Gaussian integer $-i$ is invertible in $\mathbb{Z}\left[  i\right]  $
(since its inverse is $\left(  -i\right)  ^{-1}=i\in\mathbb{Z}\left[
i\right]  $), and thus is a unit.
\par
Thus, each of the four Gaussian integers $1,-1,i,-i$ is a unit.}. It remains
to prove that there are no other units.

So let $\alpha\in\mathbb{Z}\left[  i\right]  $ be a unit. We shall prove that
$\alpha$ is either $1$ or $-1$ or $i$ or $-i$.

Proposition \ref{prop.Z[i].gauss.norm1} \textbf{(b)} shows that we have
$\operatorname*{N}\left(  \alpha\right)  =1$ if and only if $\alpha$ is a
unit. Hence, we have $\operatorname*{N}\left(  \alpha\right)  =1$ (since
$\alpha$ is a unit).

Let us write the complex number $\alpha$ as $\alpha=\left(  a,b\right)  $.
Then, $a,b\in\mathbb{Z}$ (since $\alpha\in\mathbb{Z}\left[  i\right]  $).
Furthermore, the definition of $\operatorname*{N}\left(  \alpha\right)  $
yields $\operatorname*{N}\left(  \alpha\right)  =a^{2}+b^{2}$, so that
$a^{2}+b^{2}=\operatorname*{N}\left(  \alpha\right)  =1$. If both integers $a$
and $b$ were nonzero, then both their squares $a^{2}$ and $b^{2}$ would be
$\geq1$ (because the square of any nonzero integer is $\geq1$), and thus the
sum of these squares would be $\underbrace{a^{2}}_{\geq1}+\underbrace{b^{2}%
}_{\geq1}\geq1+1>1$; but this would contradict $a^{2}+b^{2}=1$. Hence, the two
integers $a$ and $b$ cannot both be nonzero. In other words, at least one of
them is $0$. In other words, we have $a=0$ or $b=0$. Thus, we are in one of
the following two cases:

\textit{Case 1:} We have $a=0$.

\textit{Case 2:} We have $b=0$.

(These two cases could theoretically overlap, though it is easy to see that
they don't.)

Let us first consider Case 1. In this case, we have $a=0$. Hence, $a^{2}%
+b^{2}=0^{2}+b^{2}=b^{2}$, so that $b^{2}=a^{2}+b^{2}=1$. Hence, $b$ is either
$1$ or $-1$. Thus, the complex number $\left(  0,b\right)  $ is either
$\left(  0,1\right)  $ or $\left(  0,-1\right)  $. In other words, the complex
number $\alpha$ is either $i$ or $-i$ (since $\alpha=\left(  \underbrace{a}%
_{=0},b\right)  =\left(  0,b\right)  $ and $i=\left(  0,1\right)  $ and
$-\underbrace{i}_{=\left(  0,1\right)  }=-\left(  0,1\right)  =\left(
0,-1\right)  $). Thus, $\alpha$ is either $1$ or $-1$ or $i$ or $-i$. So we
have shown in Case 1 that $\alpha$ is either $1$ or $-1$ or $i$ or $-i$.

Let us next consider Case 2. In this case, we have $b=0$. Hence, $a^{2}%
+b^{2}=a^{2}+0^{2}=a^{2}$, so that $a^{2}=a^{2}+b^{2}=1$. Hence, $a$ is either
$1$ or $-1$. Thus, the complex number $\left(  a,0\right)  $ is either
$\left(  1,0\right)  $ or $\left(  -1,0\right)  $. In other words, the complex
number $\alpha$ is either $1$ or $-1$ (since $\alpha=\left(  a,\underbrace{b}%
_{=0}\right)  =\left(  a,0\right)  $ and $1=\left(  1,0\right)  $ and
$-1=\left(  -1,0\right)  $). Thus, $\alpha$ is either $1$ or $-1$ or $i$ or
$-i$. So we have shown in Case 2 that $\alpha$ is either $1$ or $-1$ or $i$ or
$-i$.

We have now proven in both Cases 1 and 2 that $\alpha$ is either $1$ or $-1$
or $i$ or $-i$. Hence, this always holds.

Now, forget that we fixed $\alpha$. We thus have shown that if $\alpha
\in\mathbb{Z}\left[  i\right]  $ is a unit, then $\alpha$ is either $1$ or
$-1$ or $i$ or $-i$. Thus, $1,-1,i,-i$ are the only possible units. Since we
already know that $1,-1,i,-i$ are units, we thus conclude that the units are
$1,-1,i,-i$. This proves Proposition \ref{prop.Z[i].gauss.units}.
\end{proof}

As a consequence of Proposition \ref{prop.Z[i].gauss.units}, if we are given
two Gaussian integers $\alpha$ and $\beta$, we can easily check whether
$\alpha\sim\beta$ holds:

\begin{proposition}
\label{prop.Z[i].gauss.uniteq}Let $\alpha$ and $\beta$ be two Gaussian
integers. Then, we have $\alpha\sim\beta$ if and only if
\[
\left(  \alpha=\beta\text{ or }\alpha=-\beta\text{ or }\alpha=i\beta\text{ or
}\alpha=-i\beta\right)  .
\]

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.uniteq}.]Proposition
\ref{prop.Z[i].gauss.units} shows that the units are $1,-1,i,-i$. In other
words,%
\[
\left\{  \text{the units}\right\}  =\left\{  1,-1,i,-i\right\}  .
\]


Now, we have the following chain of logical equivalences:%
\begin{align*}
\left(  \alpha\sim\beta\right)  \  &  \Longleftrightarrow\ \left(
\alpha=\gamma\beta\text{ for some unit }\gamma\in\mathbb{Z}\left[  i\right]
\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the relation }%
\sim\right) \\
&  \Longleftrightarrow\ \left(  \alpha=\gamma\beta\text{ for some }\gamma
\in\underbrace{\left\{  \text{the units}\right\}  }_{=\left\{
1,-1,i,-i\right\}  }\right) \\
&  \Longleftrightarrow\ \left(  \alpha=\gamma\beta\text{ for some }\gamma
\in\left\{  1,-1,i,-i\right\}  \right) \\
&  \Longleftrightarrow\ \left(  \alpha=\underbrace{1\beta}_{=\beta}\text{ or
}\alpha=\underbrace{-1\beta}_{=-\beta}\text{ or }\alpha=i\beta\text{ or
}\alpha=-i\beta\right) \\
&  \Longleftrightarrow\ \left(  \alpha=\beta\text{ or }\alpha=-\beta\text{ or
}\alpha=i\beta\text{ or }\alpha=-i\beta\right)  .
\end{align*}
This proves Proposition \ref{prop.Z[i].gauss.uniteq}.
\end{proof}

\begin{definition}
\label{def.Z[i].gauss.uniteq.cl}We know from Proposition
\ref{prop.Z[i].gauss.uniteq.eqrel} that the relation $\sim$ on $\mathbb{Z}%
\left[  i\right]  $ is an equivalence relation.

The equivalence classes of this relation $\sim$ shall be called the
\textit{unit-equivalence classes}. More specifically, for each $\alpha
\in\mathbb{Z}\left[  i\right]  $, we shall denote the $\sim$-equivalence class
of $\alpha$ as the \textit{unit-equivalence class of }$\alpha$.
\end{definition}

\begin{proposition}
\label{prop.Z[i].gauss.uniteq.cl}\textbf{(a)} For each $\alpha\in
\mathbb{Z}\left[  i\right]  $, we have%
\[
\left(  \text{the unit-equivalence class of }\alpha\right)  =\left\{
\alpha,i\alpha,-\alpha,-i\alpha\right\}  .
\]


\textbf{(b)} The unit-equivalence classes are the sets of the form $\left\{
\alpha,i\alpha,-\alpha,-i\alpha\right\}  $ for some $\alpha\in\mathbb{Z}%
\left[  i\right]  $.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.uniteq.cl}.]\textbf{(a)} Let
$\alpha\in\mathbb{Z}\left[  i\right]  $. Thus, both $i$ and $\alpha$ belong to
$\mathbb{Z}\left[  i\right]  $. Hence, all four of the complex numbers
$\alpha,-\alpha,i\alpha,-i\alpha$ belong to $\mathbb{Z}\left[  i\right]  $ (by
Proposition \ref{prop.Z[i].gauss.ring} \textbf{(a)}).

If $b\in\mathbb{Z}\left[  i\right]  $ is any Gaussian integer, then we have
$b\sim\alpha$ if and only if \newline$\left(  b=\alpha\text{ or }%
b=-\alpha\text{ or }b=i\alpha\text{ or }b=-i\alpha\right)  $ (by Proposition
\ref{prop.Z[i].gauss.uniteq}, applied to $b$ and $\alpha$ instead of $\alpha$
and $\beta$). In other words, the logical equivalence%
\begin{equation}
\left(  b\sim\alpha\right)  \ \Longleftrightarrow\ \left(  b=\alpha\text{ or
}b=-\alpha\text{ or }b=i\alpha\text{ or }b=-i\alpha\right)
\label{pf.prop.Z[i].gauss.uniteq.cl.a.equiv}%
\end{equation}
holds for each $b\in\mathbb{Z}\left[  i\right]  $.

Then,%
\begin{align}
&  \left(  \text{the unit-equivalence class of }\alpha\right) \nonumber\\
&  =\left(  \text{the }\sim\text{-equivalence class of }\alpha\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Definition \ref{def.Z[i].gauss.uniteq.cl}%
}\right) \nonumber\\
&  =\left[  \alpha\right]  _{\sim}=\left\{  b\in\mathbb{Z}\left[  i\right]
\ \mid\ b\sim\alpha\right\}  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Definition
\ref{def.eqrel.eqcl.eqcl} \textbf{(a)}}\right) \nonumber\\
&  =\left\{  b\in\mathbb{Z}\left[  i\right]  \ \mid\ b=\alpha\text{ or
}b=-\alpha\text{ or }b=i\alpha\text{ or }b=-i\alpha\right\} \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since the equivalence
(\ref{pf.prop.Z[i].gauss.uniteq.cl.a.equiv}) holds for each }b\in
\mathbb{Z}\left[  i\right]  \right) \nonumber\\
&  =\left\{  \alpha,-\alpha,i\alpha,-i\alpha\right\}
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\alpha,-\alpha,i\alpha,-i\alpha\text{
belong to }\mathbb{Z}\left[  i\right]  \right) \nonumber\\
&  =\left\{  \alpha,i\alpha,-\alpha,-i\alpha\right\}  .
\label{pf.prop.Z[i].gauss.uniteq.cl.5}%
\end{align}
This proves Proposition \ref{prop.Z[i].gauss.uniteq.cl} \textbf{(a)}.

\textbf{(b)} The unit-equivalence classes are the sets of the form
\[
\left(  \text{the unit-equivalence class of }\alpha\right)
\ \ \ \ \ \ \ \ \ \ \text{for some }\alpha\in\mathbb{Z}\left[  i\right]  .
\]
Since each $\alpha\in\mathbb{Z}\left[  i\right]  $ satisfies
(\ref{pf.prop.Z[i].gauss.uniteq.cl.5}), this rewrites as follows: The
unit-equivalence classes are the sets of the form
\[
\left\{  \alpha,i\alpha,-\alpha,-i\alpha\right\}
\ \ \ \ \ \ \ \ \ \ \text{for some }\alpha\in\mathbb{Z}\left[  i\right]  .
\]
This proves Proposition \ref{prop.Z[i].gauss.uniteq.cl} \textbf{(b)}.
\end{proof}

Recall that (as we have seen in Subsection \ref{subsect.CC.CC.argand}) if
$\alpha$ is a complex number, then the four complex numbers $\alpha$,
$i\alpha$, $-\alpha$ and $-i\alpha$ (represented as points in the Argand
diagram) are the vertices of a square centered at the origin. But when
$\alpha$ is a Gaussian integer, these four complex numbers constitute the
unit-equivalence class of $\alpha$ (by Proposition
\ref{prop.Z[i].gauss.uniteq.cl} \textbf{(a)}). Thus, geometrically speaking,
the unit-equivalence class of a Gaussian integer $\alpha$ consists of the four
vertices of a square centered at the origin. (When $\alpha=0$, these four
vertices coincide.)

\begin{proposition}
\label{prop.Z[i].gauss.uniteq.1}Let $\alpha$ be a Gaussian integer. Then,
$\alpha\sim1$ if and only if $\alpha$ is a unit.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.uniteq.1}.]We have the following
chain of logical equivalences:%
\begin{align*}
\left(  \alpha\sim1\right)  \  &  \Longleftrightarrow\ \left(  \alpha
=\underbrace{\gamma\cdot1}_{=\gamma}\text{ for some unit }\gamma\in
\mathbb{Z}\left[  i\right]  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the relation }%
\sim\right) \\
&  \Longleftrightarrow\ \left(  \alpha=\gamma\text{ for some unit }\gamma
\in\mathbb{Z}\left[  i\right]  \right) \\
&  \Longleftrightarrow\ \left(  \alpha\text{ is a unit}\right)  .
\end{align*}
This proves Proposition \ref{prop.Z[i].gauss.uniteq.1}.
\end{proof}

\begin{proposition}
\label{prop.Z[i].gauss.uniteq.norm=norm}Let $\alpha$ and $\beta$ be two
unit-equivalent Gaussian integers. Then, $\operatorname*{N}\left(
\alpha\right)  =\operatorname*{N}\left(  \beta\right)  $.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.uniteq.norm=norm}.]We have
$\alpha\sim\beta$ (since $\alpha$ and $\beta$ are unit-equivalent). In other
words, we have $\alpha=\gamma\beta$ for some unit $\gamma\in\mathbb{Z}\left[
i\right]  $ (by the definition of the relation $\sim$). Consider this $\gamma
$. Since $\gamma$ is a unit, we have $\operatorname*{N}\left(  \gamma\right)
=1$ (by Proposition \ref{prop.Z[i].gauss.norm1} \textbf{(b)}, applied to
$\gamma$ instead of $\alpha$). Now,
\begin{align*}
\operatorname*{N}\left(  \underbrace{\alpha}_{=\gamma\beta}\right)   &
=\operatorname*{N}\left(  \gamma\beta\right)  =\underbrace{\operatorname*{N}%
\left(  \gamma\right)  }_{=1}\operatorname*{N}\left(  \beta\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Proposition \ref{prop.CC.conj.hom} \textbf{(d)},}\\
\text{applied to }\gamma\text{ instead of }\alpha
\end{array}
\right) \\
&  =\operatorname*{N}\left(  \beta\right)  .
\end{align*}
This proves Proposition \ref{prop.Z[i].gauss.uniteq.norm=norm}.
\end{proof}

The converse of Proposition \ref{prop.Z[i].gauss.uniteq.norm=norm} does not
hold: There exist Gaussian integers $\alpha$ and $\beta$ satisfying
$\operatorname*{N}\left(  \alpha\right)  =\operatorname*{N}\left(
\beta\right)  $ that are not unit-equivalent.

For the sake of the next subsection, let us state a simple property of integers:

\begin{lemma}
\label{lem.Z[i].gauss.div.no-clobber}Let $a$ and $b$ be two integers. Then, we
have the logical equivalence%
\[
\left(  a\mid b\right)  \ \Longleftrightarrow\ \left(  \text{there exists a
Gaussian integer }\gamma\text{ such that }b=a\gamma\right)  .
\]

\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.Z[i].gauss.div.no-clobber}.]$\Longrightarrow:$ Assume
that $a\mid b$. We must prove that there exists a Gaussian integer $\gamma$
such that $b=a\gamma$.

Thus, there exists an integer $c$ such that $b=ac$ (by the definition of
divisibility). Consider this $c$. Then, $c$ is an integer, and thus is a
Gaussian integer. Hence, there$\ $there exists a Gaussian integer $\gamma$
such that $b=a\gamma$ (namely, $\gamma=c$). Thus, the \textquotedblleft%
$\Longrightarrow$\textquotedblright\ direction of Lemma
\ref{lem.Z[i].gauss.div.no-clobber} is proven.

$\Longleftarrow:$ Assume that there exists a Gaussian integer $\gamma$ such
that $b=a\gamma$. We must prove that $a\mid b$.

We have assumed that there exists a Gaussian integer $\gamma$ such that
$b=a\gamma$. Consider this $\gamma$. Write the complex number $\gamma$ as
$\gamma=\left(  c,d\right)  $ with $c,d\in\mathbb{R}$. Then, $c,d\in
\mathbb{Z}$ (since $\gamma$ is a Gaussian integer). In other words, $c$ and
$d$ are integers. Furthermore, $b=a\underbrace{\gamma}_{=\left(  c,d\right)
}=a\left(  c,d\right)  =\left(  ac,ad\right)  $ (by Proposition
\ref{prop.CC.CC.a(b,c)}, applied to $\left(  c,d\right)  $ instead of $\left(
b,c\right)  $). This is an equality between a real number (namely, $b$) and a
complex number (namely, $\left(  ac,ad\right)  $); thus, it means
$b_{\mathbb{C}}=\left(  ac,ad\right)  $ (according to Convention
\ref{conv.CC.RRtoCC.embed}). But $b_{\mathbb{C}}=\left(  b,0\right)  $ (by the
definition of $b_{\mathbb{C}}$). Hence, $\left(  b,0\right)  =b_{\mathbb{C}%
}=\left(  ac,ad\right)  $. In other words, $b=ac$ and $0=ad$. Now, from
$b=ac$, we obtain $a\mid b$ (since $c$ is an integer). This proves the
\textquotedblleft$\Longleftarrow$\textquotedblright\ direction of Lemma
\ref{lem.Z[i].gauss.div.no-clobber}.
\end{proof}

\subsubsection{Divisibility and congruence}

Now, let us begin to do proper number theory with Gaussian integers. The next
definition is the straightforward analogue of Definition \ref{def.ent.div.div}.

\begin{definition}
\label{def.Z[i].gauss.div}Let $\alpha$ and $\beta$ be two Gaussian integers.
We say that $\alpha\mid\beta$ (or \textquotedblleft$\alpha$ \textit{divides}
$\beta$\textquotedblright\ or \textquotedblleft$\beta$ is \textit{divisible by
}$\alpha$\textquotedblright\ or \textquotedblleft$\beta$ is a
\textit{multiple} of $\alpha$\textquotedblright) if there exists a Gaussian
integer $\gamma$ such that $\beta=\alpha\gamma$.

We furthermore say that $\alpha\nmid\beta$ if $\alpha$ does not divide $\beta$.
\end{definition}

When making such a definition, we need to be careful: Potentially, it might
create a clash of notations. In fact, if $a$ and $b$ are integers, then the
statement \textquotedblleft$a\mid b$\textquotedblright\ already has a meaning
(explained in Definition \ref{def.ent.div.div}). Definition
\ref{def.Z[i].gauss.div} gives this statement a new meaning, because we can
consider our integers $a$ and $b$ as Gaussian integers (since every integer is
a Gaussian integer). If these two meanings are not equivalent, then the
statement \textquotedblleft$a\mid b$\textquotedblright\ becomes ambiguous (as
it now has two different meanings) -- so we have laid ourselves a landmine!

Fortunately, these two meanings \textbf{are} equivalent. That is: If $a$ and
$b$ are two integers, then the statement \textquotedblleft$a\mid
b$\textquotedblright\ interpreted according to Definition
\ref{def.ent.div.div} is equivalent to the statement \textquotedblleft$a\mid
b$\textquotedblright\ interpreted according to Definition
\ref{def.Z[i].gauss.div}. Indeed, if $a$ and $b$ are two integers, then we
have the following chain of equivalences:%
\begin{align*}
&  \ \left(  a\mid b\text{ in the sense of Definition \ref{def.ent.div.div}%
}\right) \\
&  \Longleftrightarrow\ \left(  \text{there exists a Gaussian integer }%
\gamma\text{ such that }b=a\gamma\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
Lemma \ref{lem.Z[i].gauss.div.no-clobber}}\right) \\
&  \Longleftrightarrow\ \left(  a\mid b\text{ in the sense of Definition
\ref{def.Z[i].gauss.div}}\right)  .
\end{align*}
Thus, the two possible meanings of \textquotedblleft$a\mid b$%
\textquotedblright\ are equivalent, and so we are spared of any ambiguity.

More generally, the following proposition holds:

\begin{proposition}
\label{prop.Z[i].gauss.div.int|gauss}Let $a\in\mathbb{Z}$ and $\beta=\left(
b,c\right)  \in\mathbb{Z}\left[  i\right]  $. Then, $a\mid\beta$ if and only
if $a$ divides both $b$ and $c$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.div.int|gauss}.]$\Longrightarrow:$
Assume that $a\mid\beta$. We must prove that $a$ divides both $b$ and $c$.

The statement $a\mid\beta$ means that there exists a Gaussian integer $\gamma$
such that $\beta=a\gamma$ (according to Definition \ref{def.Z[i].gauss.div}).
Thus, there exists a Gaussian integer $\gamma$ such that $\beta=a\gamma$
(since $a\mid\beta$). Consider this $\gamma$. Write the complex number
$\gamma$ in the form $\gamma=\left(  u,v\right)  $ for some $u,v\in\mathbb{R}%
$. Then, $u,v\in\mathbb{Z}$ (since $\gamma$ is a Gaussian integer). In other
words, $u$ and $v$ are integers.

Recall that $\beta=\left(  b,c\right)  $. Hence, $\left(  b,c\right)
=\beta=a\underbrace{\gamma}_{=\left(  u,v\right)  }=a\left(  u,v\right)
=\left(  au,av\right)  $ (by Proposition \ref{prop.CC.CC.a(b,c)}, applied to
$\left(  u,v\right)  $ instead of $\left(  b,c\right)  $). In other words,
$b=au$ and $c=av$. From $b=au$, we obtain $a\mid b$ (since $u$ is an integer).
From $c=av$, we obtain $a\mid c$ (since $v$ is an integer). Thus, we have
$a\mid b$ and $a\mid c$. In other words, $a$ divides both $b$ and $c$. This
proves the \textquotedblleft$\Longrightarrow$\textquotedblright\ direction of
Proposition \ref{prop.Z[i].gauss.div.int|gauss}.

$\Longleftarrow:$ Assume that $a$ divides both $b$ and $c$. We must prove that
$a\mid\beta$.

We have assumed that $a$ divides both $b$ and $c$. In other words, $a\mid b$
and $a\mid c$. From $a\mid b$, we conclude that there exists an integer $u$
such that $b=au$ (by the definition of divisibility). Consider this $u$. From
$a\mid c$, we conclude that there exists an integer $v$ such that $c=av$ (by
the definition of divisibility). Consider this $v$. Note that $u$ and $v$ are
integers; in other words, $u,v\in\mathbb{Z}$.

The complex number $\left(  u,v\right)  $ is a Gaussian integer (since
$u,v\in\mathbb{Z}$). Moreover, Proposition \ref{prop.CC.CC.a(b,c)} (applied to
$\left(  u,v\right)  $ instead of $\left(  b,c\right)  $) yields $a\left(
u,v\right)  =\left(  au,av\right)  $. Comparing this with $\beta=\left(
\underbrace{b}_{=au},\underbrace{c}_{=av}\right)  =\left(  au,av\right)  $, we
obtain $\beta=a\left(  u,v\right)  $. Hence, there exists a Gaussian integer
$\gamma$ such that $\beta=a\gamma$ (namely, $\gamma=\left(  u,v\right)  $).

The statement $a\mid\beta$ means that there exists a Gaussian integer $\gamma$
such that $\beta=a\gamma$ (according to Definition \ref{def.Z[i].gauss.div}).
Thus, $a\mid\beta$ (since there exists a Gaussian integer $\gamma$ such that
$\beta=a\gamma$). This proves the \textquotedblleft$\Longleftarrow
$\textquotedblright\ direction of Proposition
\ref{prop.Z[i].gauss.div.int|gauss}.
\end{proof}

The next proposition is a (partial) analogue of Proposition
\ref{prop.ent.div.1}:

\begin{proposition}
\label{prop.Z[i].gauss.div.1}Let $\alpha$ and $\beta$ be two Gaussian integers.

\textbf{(a)} If $\alpha\mid\beta$, then $\operatorname*{N}\left(
\alpha\right)  \mid\operatorname*{N}\left(  \beta\right)  $.

\textbf{(b)} If $\alpha\mid\beta$ and $\beta\neq0$, then $\operatorname*{N}%
\left(  \alpha\right)  \leq\operatorname*{N}\left(  \beta\right)  $.

\textbf{(c)} Assume that $\alpha\neq0$. Then, $\alpha\mid\beta$ if and only if
$\dfrac{\beta}{\alpha}\in\mathbb{Z}\left[  i\right]  $.
\end{proposition}

Note that we are using the norms $\operatorname*{N}\left(  \alpha\right)  $
and $\operatorname*{N}\left(  \beta\right)  $ as analogues of $\left\vert
a\right\vert $ and $\left\vert b\right\vert $ here, since the absolute values
$\left\vert \alpha\right\vert $ and $\left\vert \beta\right\vert $ of Gaussian
integers are often irrational and thus it makes no sense to talk of their
divisibility. (At least, this prevents us from using the absolute values of
$\alpha$ and $\beta$ in Proposition \ref{prop.Z[i].gauss.div.1} \textbf{(a)}.
We could use them in Proposition \ref{prop.Z[i].gauss.div.1} \textbf{(b)}.)

Note that the converse of Proposition \ref{prop.Z[i].gauss.div.1} \textbf{(a)}
does not hold. (That is, $\operatorname*{N}\left(  \alpha\right)
\mid\operatorname*{N}\left(  \beta\right)  $ does not yield $\alpha\mid\beta$.)

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].gauss.div.1}.]Proposition
\ref{prop.Z[i].gauss.Norm-N} yields $\operatorname*{N}\left(  \alpha\right)
\in\mathbb{N}$; thus, $\operatorname*{N}\left(  \alpha\right)  $ is an
integer. Similarly, $\operatorname*{N}\left(  \beta\right)  $ is an integer.
Hence, the statement \textquotedblleft$\operatorname*{N}\left(  \alpha\right)
\mid\operatorname*{N}\left(  \beta\right)  $\textquotedblright\ makes sense.

\textbf{(a)} Assume that $\alpha\mid\beta$. Thus, there exists a Gaussian
integer $\gamma$ such that $\beta=\alpha\gamma$ (by Definition
\ref{def.Z[i].gauss.div}). Consider this $\gamma$. We have $\operatorname*{N}%
\left(  \gamma\right)  \in\mathbb{N}$ (by Proposition
\ref{prop.Z[i].gauss.Norm-N}, applied to $\gamma$ instead of $\alpha$). Now,
from $\beta=\alpha\gamma$, we obtain $\operatorname*{N}\left(  \beta\right)
=\operatorname*{N}\left(  \alpha\gamma\right)  =\operatorname*{N}\left(
\alpha\right)  \cdot\operatorname*{N}\left(  \gamma\right)  $ (by Proposition
\ref{prop.CC.conj.hom} \textbf{(d)}, applied to $\gamma$ instead of $\beta$).
Thus, $\operatorname*{N}\left(  \alpha\right)  \mid\operatorname*{N}\left(
\beta\right)  $ (since $\operatorname*{N}\left(  \gamma\right)  \in\mathbb{N}%
$). This proves Proposition \ref{prop.Z[i].gauss.div.1} \textbf{(a)}.

\textbf{(b)} Assume that $\alpha\mid\beta$ and $\beta\neq0$. Proposition
\ref{prop.CC.norm.basics} \textbf{(c)} (applied to $\beta$ instead of $\alpha
$) shows that $\operatorname*{N}\left(  \beta\right)  >0$ (since $\beta\neq
0$). Hence, $\operatorname*{N}\left(  \beta\right)  \neq0$. Furthermore,
Proposition \ref{prop.Z[i].gauss.div.1} \textbf{(a)} yields $\operatorname*{N}%
\left(  \alpha\right)  \mid\operatorname*{N}\left(  \beta\right)  $. Thus,
Proposition \ref{prop.ent.div.1} \textbf{(b)} (applied to $a=\operatorname*{N}%
\left(  \alpha\right)  $ and $b=\operatorname*{N}\left(  \beta\right)  $)
yields $\left\vert \operatorname*{N}\left(  \alpha\right)  \right\vert
\leq\left\vert \operatorname*{N}\left(  \beta\right)  \right\vert $.

But recall that $\operatorname*{N}\left(  \alpha\right)  \in\mathbb{N}$, so
that $\operatorname*{N}\left(  \alpha\right)  \geq0$ and therefore $\left\vert
\operatorname*{N}\left(  \alpha\right)  \right\vert =\operatorname*{N}\left(
\alpha\right)  $. Similarly, $\left\vert \operatorname*{N}\left(
\beta\right)  \right\vert =\operatorname*{N}\left(  \beta\right)  $. Hence,
$\operatorname*{N}\left(  \alpha\right)  =\left\vert \operatorname*{N}\left(
\alpha\right)  \right\vert \leq\left\vert \operatorname*{N}\left(
\beta\right)  \right\vert =\operatorname*{N}\left(  \beta\right)  $. This
proves Proposition \ref{prop.Z[i].gauss.div.1} \textbf{(b)}.

\textbf{(c)} The proof of Proposition \ref{prop.Z[i].gauss.div.1} \textbf{(c)}
is analogous to the proof of Proposition \ref{prop.ent.div.1} \textbf{(c)}.
(Of course, we need to replace $a$ and $b$ by $\alpha$ and $\beta$, and
replace integers by Gaussian integers throughout the argument.)
\end{proof}

The next proposition is a straightforward analogue of Proposition
\ref{prop.ent.div.2}:

\begin{proposition}
\label{prop.Z[i].div.2}\textbf{(a)} We have $\alpha\mid\alpha$ for every
$\alpha\in\mathbb{Z}\left[  i\right]  $. (This is called the
\textit{reflexivity of divisibility} for Gaussian integers.)

\textbf{(b)} If $\alpha,\beta,\gamma\in\mathbb{Z}\left[  i\right]  $ satisfy
$\alpha\mid\beta$ and $\beta\mid\gamma$, then $\alpha\mid\gamma$. (This is
called the \textit{transitivity of divisibility} for Gaussian integers.)

\textbf{(c)} If $\alpha_{1},\alpha_{2},\beta_{1},\beta_{2}\in\mathbb{Z}\left[
i\right]  $ satisfy $\alpha_{1}\mid\beta_{1}$ and $\alpha_{2}\mid\beta_{2}$,
then $\alpha_{1}\alpha_{2}\mid\beta_{1}\beta_{2}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].div.2}.]This proof is completely
analogous to the proof of Proposition \ref{prop.ent.div.2}. (The only changes
you need to make are replacing the Roman letters $a,b,c,a_{1},a_{2}%
,b_{1},b_{2}$ by the corresponding Greek letters $\alpha,\beta,\gamma
,\alpha_{1},\alpha_{2},\beta_{1},\beta_{2}$, and replacing integers by
Gaussian integers. Of course, the resulting argument will use Proposition
\ref{prop.Z[i].gauss.ring} \textbf{(a)}, specifically the fact that the
product of two Gaussian integers is a Gaussian integer.)
\end{proof}

The next exercise is a Gaussian-integer analogue of Exercise
\ref{exe.ent.div.abba}:

\begin{exercise}
\label{exe.Z[i].div.abba}Let $\alpha$ and $\beta$ be two Gaussian integers
such that $\alpha\mid\beta$ and $\beta\mid\alpha$. Prove that $\alpha\sim
\beta$.
\end{exercise}

Note that the conclusion \textquotedblleft$\alpha\sim\beta$\textquotedblright%
\ in Exercise \ref{exe.Z[i].div.abba} is the proper Gaussian-integer analogue
of the conclusion \textquotedblleft$\left\vert a\right\vert =\left\vert
b\right\vert $\textquotedblright\ in Exercise \ref{exe.ent.div.abba} (since
(\ref{eq.Z[i].gauss.unit-Z}) shows that unit-equivalence on $\mathbb{Z}\left[
i\right]  $ is an analogue of the \textquotedblleft have the same absolute
value\textquotedblright\ relation on $\mathbb{Z}$). (We could have stated the
weaker conclusion $\left\vert \alpha\right\vert =\left\vert \beta\right\vert $
as well, but it would not be half as useful.)

A converse of Exercise \ref{exe.Z[i].div.abba} holds as well, so we have the
following equivalent description of unit-equivalence:

\begin{exercise}
\label{exe.Z[i].div.abba-conv}Let $\alpha$ and $\beta$ be two Gaussian
integers. Prove that we have the logical equivalence%
\[
\left(  \alpha\sim\beta\right)  \ \Longleftrightarrow\ \left(  \alpha\mid
\beta\text{ and }\beta\mid\alpha\right)  .
\]

\end{exercise}

The next exercise is an analogue of Exercise \ref{exe.ent.div.acbc}:

\begin{exercise}
\label{exe.Z[i].div.acbc}Let $\alpha,\beta,\gamma$ be three Gaussian integers
such that $\gamma\neq0$. Prove that $\alpha\mid\beta$ holds if and only if
$\alpha\gamma\mid\beta\gamma$.
\end{exercise}

The next exercise is an analogue of Exercise \ref{exe.ent.div.powers}:

\begin{exercise}
\label{exe.Z[i].div.powers}Let $\nu\in\mathbb{Z}\left[  i\right]  $. Let
$a,b\in\mathbb{N}$ be such that $a\leq b$. Prove that $\nu^{a}\mid\nu^{b}$.
\end{exercise}

Needless to say, the $a$ and $b$ in this exercise still have to be nonnegative
integers, since Gaussian integers make no sense as exponents.

The next exercise is an analogue of Exercise \ref{exe.ent.div.g|1}:

\begin{exercise}
\label{exe.Z[i].div.g|1}Let $\gamma$ be a Gaussian integer such that
$\gamma\mid1$. Prove that $\gamma\sim1$ (that is, $\gamma$ is a unit, i.e.,
either $1$ or $-1$ or $i$ or $-i$).
\end{exercise}

Next comes another trivial fact:

\begin{exercise}
\label{exe.Z[i].div.conj}Let $\alpha$ and $\beta$ be Gaussian integers such
that $\alpha\mid\beta$. Prove that $\overline{\alpha}\mid\overline{\beta}$.
\end{exercise}

\begin{center}
\textbf{2019-03-06 lecture}
\end{center}

We have defined congruence for integers in Definition \ref{def.ent.cong}. We
can repeat the same definition for Gaussian integers:

\begin{definition}
\label{def.Z[i].cong}Let $\nu,\alpha,\beta\in\mathbb{Z}\left[  i\right]  $. We
say that $\alpha$ \textit{is congruent to }$\beta$ \textit{modulo }$\nu$ if
and only if $\nu\mid\alpha-\beta$. We shall use the notation \textquotedblleft%
$\alpha\equiv\beta\operatorname{mod}\nu$\textquotedblright\ for
\textquotedblleft$\alpha$ is congruent to $\beta$ modulo $\nu$%
\textquotedblright.

We furthermore shall use the notation \textquotedblleft$\alpha\not \equiv
\beta\operatorname{mod}\nu$\textquotedblright\ for \textquotedblleft$\alpha$
is not congruent to $\beta$ modulo $\nu$\textquotedblright.
\end{definition}

Once again, such a definition risks sneaking in ambiguity, but fortunately
this one does not: If $n,a,b\in\mathbb{Z}$, then the statement
\textquotedblleft$a\equiv b\operatorname{mod}n$\textquotedblright\ interpreted
according to Definition \ref{def.ent.cong} is equivalent to the statement
\textquotedblleft$a\equiv b\operatorname{mod}n$\textquotedblright\ interpreted
according to Definition \ref{def.Z[i].cong} (by treating $n,a,b$ as Gaussian
integers). To do so, recall that both statements are defined to mean
\textquotedblleft$n\mid a-b$\textquotedblright, and the meaning of the latter
statement does not depend on whether we interpret $n,a,b$ as integers or as
Gaussian integers\footnote{We have proven this latter fact shortly after
Definition \ref{def.Z[i].gauss.div}.}.

The next proposition is a straightforward analogue of Proposition
\ref{prop.ent.mod.0}:

\begin{proposition}
\label{prop.Z[i].mod.0}Let $\nu\in\mathbb{Z}\left[  i\right]  $ and $\alpha
\in\mathbb{Z}\left[  i\right]  $. Then, $\alpha\equiv0\operatorname{mod}\nu$
if and only if $\nu\mid\alpha$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].mod.0}.]This proof is analogous to the
proof of Proposition \ref{prop.ent.mod.0}.
\end{proof}

The next proposition is a straightforward analogue of Proposition
\ref{prop.ent.mod.basics}:

\begin{proposition}
\label{prop.Z[i].mod.basics}Let $\nu\in\mathbb{Z}\left[  i\right]  $.

\textbf{(a)} We have $\alpha\equiv\alpha\operatorname{mod}\nu$ for every
$\alpha\in\mathbb{Z}\left[  i\right]  $.

\textbf{(b)} If $\alpha,\beta,\gamma\in\mathbb{Z}\left[  i\right]  $ satisfy
$\alpha\equiv\beta\operatorname{mod}\nu$ and $\beta\equiv\gamma
\operatorname{mod}\nu$, then $\alpha\equiv\gamma\operatorname{mod}\nu$.

\textbf{(c)} If $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ satisfy
$\alpha\equiv\beta\operatorname{mod}\nu$, then $\beta\equiv\alpha
\operatorname{mod}\nu$.

\textbf{(d)} If $\alpha_{1},\alpha_{2},\beta_{1},\beta_{2}\in\mathbb{Z}\left[
i\right]  $ satisfy $\alpha_{1}\equiv\beta_{1}\operatorname{mod}\nu$ and
$\alpha_{2}\equiv\beta_{2}\operatorname{mod}\nu$, then%
\begin{align}
\alpha_{1}+\alpha_{2}  &  \equiv\beta_{1}+\beta_{2}\operatorname{mod}%
\nu;\label{eq.prop.Z[i].mod.basics.d.1}\\
\alpha_{1}-\alpha_{2}  &  \equiv\beta_{1}-\beta_{2}\operatorname{mod}%
\nu;\label{eq.prop.Z[i].mod.basics.d.2}\\
\alpha_{1}\alpha_{2}  &  \equiv\beta_{1}\beta_{2}\operatorname{mod}\nu.
\label{eq.prop.Z[i].mod.basics.d.3}%
\end{align}


\textbf{(e)} Let $\mu\in\mathbb{Z}\left[  i\right]  $ be such that $\mu\mid
\nu$. If $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ satisfy $\alpha
\equiv\beta\operatorname{mod}\nu$, then $\alpha\equiv\beta\operatorname{mod}%
\mu$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].mod.basics}.]This proof is analogous to
the proof of Proposition \ref{prop.ent.mod.basics}. (Of course, it relies on
parts \textbf{(a)} and \textbf{(b)} of Proposition \ref{prop.Z[i].gauss.ring},
and it uses Proposition \ref{prop.Z[i].div.2} instead of Proposition
\ref{prop.ent.div.2}.)
\end{proof}

\begin{exercise}
\label{exe.Z[i].modn.split}Let $n$ be an integer. Let $\left(  a,b\right)  $
and $\left(  c,d\right)  $ be two Gaussian integers. Prove that we have the
following logical equivalence:%
\[
\left(  \left(  a,b\right)  \equiv\left(  c,d\right)  \operatorname{mod}%
n\right)  \ \Longleftrightarrow\ \left(  a\equiv c\operatorname{mod}n\text{
and }b\equiv d\operatorname{mod}n\right)  .
\]
(Of course, the statement \textquotedblleft$\left(  a,b\right)  \equiv\left(
c,d\right)  \operatorname{mod}n$\textquotedblright\ is to be understood by
treating the integer $n$ as a Gaussian integer.)
\end{exercise}

\begin{exercise}
\label{exe.Z[i].modn.classes}For any Gaussian integer $\tau$, we let
$\underset{\tau}{\equiv}$ be the binary relation on $\mathbb{Z}\left[
i\right]  $ defined by
\[
\left(  \alpha\underset{\tau}{\equiv}\beta\right)  \ \iff\ \left(
\alpha\equiv\beta\operatorname{mod}\tau\right)  .
\]


\textbf{(a)} Prove that the relation $\underset{\tau}{\equiv}$ is an
equivalence relation whenever $\tau\in\mathbb{Z}\left[  i\right]  $.

We shall refer to the equivalence classes of this relation $\underset{\tau
}{\equiv}$ as the \textit{Gaussian residue classes modulo }$\tau$; let
$\mathbb{Z}\left[  i\right]  /\tau$ be the set of all these classes.

\textbf{(b)} Let $n$ be a positive integer. Thus, a relation
$\underset{n}{\equiv}$ on $\mathbb{Z}\left[  i\right]  $ is defined (by
treating the integer $n$ as a Gaussian integer). Exercise
\ref{exe.Z[i].modn.classes} \textbf{(a)} (applied to $\tau=n$) shows that this
relation $\underset{n}{\equiv}$ is an equivalence relation.

Prove that the equivalence classes of the relation $\underset{n}{\equiv}$ (on
$\mathbb{Z}\left[  i\right]  $) are the $n^{2}$ classes $\left[  a+bi\right]
_{\underset{n}{\equiv}}$ for $\left(  a,b\right)  \in\left\{  0,1,\ldots
,n-1\right\}  ^{2}$, and that these $n^{2}$ classes are all distinct.
\end{exercise}

\begin{example}
For $n=3$, Exercise \ref{exe.Z[i].modn.classes} \textbf{(b)} is saying that
the equivalence classes of the relation $\underset{3}{\equiv}$ (on
$\mathbb{Z}\left[  i\right]  $) are the $3^{2}$ classes%
\begin{align*}
&  \left[  0+0i\right]  _{\underset{3}{\equiv}},\ \ \ \ \ \ \ \ \ \ \left[
0+1i\right]  _{\underset{3}{\equiv}},\ \ \ \ \ \ \ \ \ \ \left[  0+2i\right]
_{\underset{3}{\equiv}},\\
&  \left[  1+0i\right]  _{\underset{3}{\equiv}},\ \ \ \ \ \ \ \ \ \ \left[
1+1i\right]  _{\underset{3}{\equiv}},\ \ \ \ \ \ \ \ \ \ \left[  1+2i\right]
_{\underset{3}{\equiv}},\\
&  \left[  2+0i\right]  _{\underset{3}{\equiv}},\ \ \ \ \ \ \ \ \ \ \left[
2+1i\right]  _{\underset{3}{\equiv}},\ \ \ \ \ \ \ \ \ \ \left[  2+2i\right]
_{\underset{3}{\equiv}},
\end{align*}
and that these $3^{2}$ classes are distinct. In contrast, the equivalence
classes of the analogous relation $\underset{3}{\equiv}$ on $\mathbb{Z}$ are
merely the $3$ classes $\left[  0\right]  _{\underset{3}{\equiv}},\left[
1\right]  _{\underset{3}{\equiv}},\left[  2\right]  _{\underset{3}{\equiv}}$
(by Theorem \ref{thm.eqrel.Z/n.explicit}).
\end{example}

\begin{remark}
Exercise \ref{exe.Z[i].modn.classes} \textbf{(b)} yields $\left\vert
\mathbb{Z}\left[  i\right]  /n\right\vert =n^{2}=\operatorname{N}\left(
n\right)  $ for any positive integer $n$. This is essentially \cite[Lemma
7.15]{Conrad-Gauss}. (Conrad proves this \textquotedblleft by
example\textquotedblright; you can follow the argument but you should write it
up in full generality.)

More generally, $\left\vert \mathbb{Z}\left[  i\right]  /\tau\right\vert
=\operatorname{N}\left(  \tau\right)  $ for any nonzero Gaussian integer
$\tau$. This is proven in \cite[Theorem 7.14]{Conrad-Gauss} (using Exercise
\ref{exe.Z[i].modn.classes} as a stepping stone).
\end{remark}

\subsubsection{Division with remainder}

Now, let us try to make division with remainder work for Gaussian integers.
This turns out to be tricky: There is no straightforward analogue of Theorem
\ref{thm.ent.quorem.full} for Gaussian integers. (In fact, it is not clear
what $\left\{  0,1,\ldots,b-1\right\}  $ would mean if we let $b$ be a
Gaussian integer.) The best thing we can get for Gaussian integers is an
analogue of Exercise \ref{exe.ent.quo-rem.minrem} \textbf{(a)}:

\begin{theorem}
\label{thm.Z[i].gauss.quorem}Let $\alpha$ and $\beta\neq0$ be Gaussian
integers. There exist Gaussian integers $\gamma$ and $\rho$ such that
$\alpha=\gamma\beta+\rho$ and $\operatorname*{N}\left(  \rho\right)
\leq\operatorname*{N}\left(  \beta\right)  /2$.
\end{theorem}

Note that the pair $\left(  \gamma,\rho\right)  $ in this theorem is not
unique. As we have said, Theorem \ref{thm.Z[i].gauss.quorem} is an analogue of
Exercise \ref{exe.ent.quo-rem.minrem} \textbf{(a)} (with $\alpha$, $\beta$,
$\gamma$ and $\rho$ taking the roles of $u$, $n$, $q$ and $r$), not an
analogue of Theorem \ref{thm.ent.quorem.full}; nevertheless, it is the closest
we can get to Theorem \ref{thm.ent.quorem.full} in $\mathbb{Z}\left[
i\right]  $, and can often be substituted in places where one would usually
want to apply Theorem \ref{thm.ent.quorem.full} (as long as one does not try
to use uniqueness of quotient and remainder).

Theorem \ref{thm.Z[i].gauss.quorem} can be visualized geometrically (similarly
to the visualizations shown in Remark \ref{rmk.ent.quo-rem.full.geo} and
Remark \ref{rmk.ent.quo-rem.minrem.geo}, but using the Argand diagram). See
\cite[\S 7]{Conrad-Gauss} for the details.

The following proof of Theorem \ref{thm.Z[i].gauss.quorem} follows \cite[proof
of Theorem 3.1]{Conrad-Gauss}.

\begin{proof}
[Proof of Theorem \ref{thm.Z[i].gauss.quorem}.]Let $n=\operatorname*{N}\left(
\beta\right)  $. Then, $n=\operatorname*{N}\left(  \beta\right)  >0$ (by
Proposition \ref{prop.CC.norm.basics} \textbf{(c)}, applied to $\beta$ instead
of $\alpha$), since $\beta\neq0$. Also, Proposition
\ref{prop.Z[i].gauss.Norm-N} (applied to $\beta$ instead of $\alpha$) yields
$\operatorname*{N}\left(  \beta\right)  \in\mathbb{N}$. Thus,
$n=\operatorname*{N}\left(  \beta\right)  \in\mathbb{N}$. Hence, $n$ is a
positive integer (since $n>0$).

Proposition \ref{prop.CC.norm.conj} \textbf{(a)} (applied to $\beta$ instead
of $\alpha$) yields $\operatorname*{N}\left(  \beta\right)  =\beta
\overline{\beta}$. Thus, $\beta\overline{\beta}=\operatorname*{N}\left(
\beta\right)  =n$.

Furthermore, Proposition \ref{prop.CC.norm.conj} \textbf{(b)} (applied to
$\beta$ instead of $\alpha$) yields $\operatorname*{N}\left(  \overline{\beta
}\right)  =\operatorname*{N}\left(  \beta\right)  =n$.

Note that $\overline{\beta}$ is a Gaussian integer\footnote{by Proposition
\ref{prop.Z[i].gauss.conj}, applied to $\beta$ instead of $\alpha$}.
Furthermore, $\beta\overline{\beta}=n\neq0$, so that $\beta\neq0$ and
$\overline{\beta}\neq0$. Hence, we can divide complex numbers by $\beta$ and
by $\overline{\beta}$. Thus,%
\[
\dfrac{\alpha}{\beta}=\dfrac{\alpha\overline{\beta}}{\beta\overline{\beta}%
}=\dfrac{\alpha\overline{\beta}}{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\beta\overline{\beta}=n\right)  .
\]
Note that $\alpha\overline{\beta}$ is a Gaussian integer (since $\alpha$ and
$\overline{\beta}$ are Gaussian integers); thus, we can write it in the form
\[
\alpha\overline{\beta}=\left(  u_{1},u_{2}\right)
\ \ \ \ \ \ \ \ \ \ \text{for some }u_{1},u_{2}\in\mathbb{Z}.
\]
Consider these $u_{1},u_{2}$.

Exercise \ref{exe.ent.quo-rem.minrem} \textbf{(a)} (applied to $u=u_{1}$)
shows that there exists a pair $\left(  q_{1},r_{1}\right)  \in\mathbb{Z}%
\times\mathbb{Z}$ such that
\[
u_{1}=q_{1}n+r_{1}\ \ \ \ \ \ \ \ \ \ \text{and}\ \ \ \ \ \ \ \ \ \ \left\vert
r_{1}\right\vert \leq n/2.
\]
Consider this pair.

Exercise \ref{exe.ent.quo-rem.minrem} \textbf{(a)} (applied to $u=u_{2}$)
shows that there exists a pair $\left(  q_{2},r_{2}\right)  \in\mathbb{Z}%
\times\mathbb{Z}$ such that
\[
u_{2}=q_{2}n+r_{2}\ \ \ \ \ \ \ \ \ \ \text{and}\ \ \ \ \ \ \ \ \ \ \left\vert
r_{2}\right\vert \leq n/2.
\]
Consider this pair.

Squaring the inequality $\left\vert r_{1}\right\vert \leq n/2$, we obtain
$\left\vert r_{1}\right\vert ^{2}\leq\left(  n/2\right)  ^{2}$ (since
$\left\vert r_{1}\right\vert $ and $n/2$ are nonnegative (because $n>0$)). But
$\left\vert r_{1}\right\vert ^{2}=r_{1}^{2}$ (since $\left\vert r\right\vert
^{2}=r^{2}$ for every real $r$). Hence, $r_{1}^{2}=\left\vert r_{1}\right\vert
^{2}\leq\left(  n/2\right)  ^{2}=n^{2}/4$. Similarly, $r_{2}^{2}\leq n^{2}/4$.
Now, the complex number $r_{1}+r_{2}i=\left(  r_{1},r_{2}\right)  $ satisfies%
\begin{align*}
\operatorname*{N}\left(  r_{1}+r_{2}i\right)   &  =\underbrace{r_{1}^{2}%
}_{\leq n^{2}/4}+\underbrace{r_{2}^{2}}_{\leq n^{2}/4}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\operatorname*{N}%
\left(  r_{1}+r_{2}i\right)  \right) \\
&  \leq n^{2}/4+n^{2}/4=n^{2}/2.
\end{align*}
We can divide this inequality by $n$ (since $n>0$); thus, we find%
\begin{equation}
\dfrac{\operatorname*{N}\left(  r_{1}+r_{2}i\right)  }{n}\leq\dfrac{n^{2}%
/2}{n}=n/2=\operatorname*{N}\left(  \beta\right)  /2
\label{pf.thm.Z[i].gauss.quorem.norm-ineq}%
\end{equation}
(since $n=\operatorname*{N}\left(  \beta\right)  $).

But%
\begin{align}
\dfrac{\alpha}{\beta}  &  =\dfrac{\alpha\overline{\beta}}{n}=\dfrac{\left(
q_{1}n+r_{1}\right)  +\left(  q_{2}n+r_{2}\right)  i}{n}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\alpha\overline{\beta}=\left(
u_{1},u_{2}\right)  =\underbrace{u_{1}}_{=q_{1}n+r_{1}}+\underbrace{u_{2}%
}_{=q_{2}n+r_{2}}i=\left(  q_{1}n+r_{1}\right)  +\left(  q_{2}n+r_{2}\right)
i\right) \nonumber\\
&  =\left(  q_{1}+q_{2}i\right)  +\dfrac{r_{1}+r_{2}i}{n}.
\label{pf.thm.Z[i].gauss.quorem.4}%
\end{align}
Set $\gamma=q_{1}+q_{2}i$ and $\rho=\alpha-\gamma\beta$. Note that $\gamma$ is
a Gaussian integer (since $\gamma=q_{1}+q_{2}i=\left(  q_{1},q_{2}\right)  $
with $q_{1},q_{2}\in\mathbb{Z}$). Hence, all of $\alpha,\gamma,\beta$ are
Gaussian integers; thus, $\rho=\alpha-\gamma\beta$ is a Gaussian integer (by
multiple applications of Proposition \ref{prop.Z[i].gauss.ring}).

From $\rho=\alpha-\gamma\beta$, we obtain $\alpha=\gamma\beta+\rho$. Thus, it
remains to prove $\operatorname*{N}\left(  \rho\right)  \leq\operatorname*{N}%
\left(  \beta\right)  /2$.

The equation (\ref{pf.thm.Z[i].gauss.quorem.4}) rewrites as $\dfrac{\alpha
}{\beta}=\gamma+\dfrac{r_{1}+r_{2}i}{n}$ (since $q_{1}+q_{2}i=\gamma$).
Hence,
\[
\dfrac{r_{1}+r_{2}i}{n}=\dfrac{\alpha}{\beta}-\gamma=\dfrac{\alpha-\gamma
\beta}{\beta}=\dfrac{\rho}{\beta}%
\]
(since $\alpha-\gamma\beta=\rho$). Therefore,%
\begin{align*}
\rho &  =\beta\cdot\dfrac{r_{1}+r_{2}i}{n}=\beta\cdot\dfrac{r_{1}+r_{2}%
i}{\beta\overline{\beta}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }%
n=\beta\overline{\beta}\right) \\
&  =\dfrac{r_{1}+r_{2}i}{\overline{\beta}}%
\end{align*}
and thus%
\begin{align*}
\operatorname*{N}\left(  \rho\right)   &  =\operatorname*{N}\left(
\dfrac{r_{1}+r_{2}i}{\overline{\beta}}\right)  =\dfrac{\operatorname*{N}%
\left(  r_{1}+r_{2}i\right)  }{\operatorname*{N}\left(  \overline{\beta
}\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Proposition \ref{prop.CC.conj.hom} \textbf{(e)}, applied to }%
r_{1}+r_{2}i\\
\text{and }\overline{\beta}\text{ instead of }\alpha\text{ and }\beta
\end{array}
\right) \\
&  =\dfrac{\operatorname*{N}\left(  r_{1}+r_{2}i\right)  }{n}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\operatorname*{N}\left(
\overline{\beta}\right)  =n\right) \\
&  \leq\operatorname*{N}\left(  \beta\right)  /2\ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{pf.thm.Z[i].gauss.quorem.norm-ineq})}\right)  .
\end{align*}
Thus, we have found two Gaussian integers $\gamma$ and $\rho$ such that
$\alpha=\gamma\beta+\rho$ and $\operatorname*{N}\left(  \rho\right)
\leq\operatorname*{N}\left(  \beta\right)  /2$. This proves Theorem
\ref{thm.Z[i].gauss.quorem}.
\end{proof}

Note that we cannot define $\alpha//\beta$ or $\alpha\%\beta$ for Gaussian
integers $\alpha$ and $\beta$, since there is no uniqueness statement in
Theorem \ref{thm.Z[i].gauss.quorem}.

\subsubsection{Common divisors}

Next, we define the Gaussian divisors of a Gaussian integer (in analogy to
Definition \ref{def.ent.divisors.divisors}):

\begin{definition}
\label{def.Z[i].divisors.divisors}Let $\beta\in\mathbb{Z}\left[  i\right]  $.
The \textit{Gaussian divisors} of $\beta$ are defined as the Gaussian integers
that divide $\beta$.
\end{definition}

Note that we are calling them \textquotedblleft Gaussian
divisors\textquotedblright\ and not \textquotedblleft
divisors\textquotedblright, because when $\beta$ is an actual integer, there
are (usually) Gaussian divisors of $\beta$ that are not divisors of $\beta$
(in the sense of Definition \ref{def.ent.divisors.divisors}). For example,
$1+i$ is a Gaussian divisor of $2$ (since $2=\left(  1+i\right)  \left(
1-i\right)  $), but the only divisors of $2$ (in the sense of Definition
\ref{def.ent.divisors.divisors}) are $-2,-1,1,2$. This is one of those
situations where using the same name for a concept and its Gaussian-integer
analogue would lead to ambiguities.

The following is an analogue of Proposition \ref{prop.ent.divisors.find}:

\begin{proposition}
\label{prop.Z[i].divisors.find}\textbf{(a)} If $\beta\in\mathbb{Z}\left[
i\right]  $, then $1$ and $\beta$ are Gaussian divisors of $\beta$.

\textbf{(b)} The Gaussian divisors of $0$ are all the Gaussian integers.

\textbf{(c)} Let $\beta\in\mathbb{Z}\left[  i\right]  $ be nonzero. Then, all
Gaussian divisors of $\beta$ belong to the set%
\[
\left\{  x+yi\ \mid\ x,y\in\mathbb{Z}\text{ satisfying }x^{2}\leq
\operatorname*{N}\left(  \beta\right)  \text{ and }y^{2}\leq\operatorname*{N}%
\left(  \beta\right)  \right\}  .
\]

\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].divisors.find}.]\textbf{(a)} Let
$\beta\in\mathbb{Z}\left[  i\right]  $. Then, $\beta=1\beta$. Hence,
$1\mid\beta$ (since $\beta$ is a Gaussian integer). In other words, $1$ is a
Gaussian divisor of $\beta$.

Also, $\beta=\beta\cdot1$. Hence, $\beta\mid\beta$ (since $1$ is a Gaussian
integer). In other words, $\beta$ is a Gaussian divisor of $\beta$.

So we have shown that $1$ and $\beta$ are Gaussian divisors of $\beta$. This
proves Proposition \ref{prop.Z[i].divisors.find} \textbf{(a)}.

\textbf{(b)} If $\beta$ is a Gaussian integer, then $0=\beta\cdot0$, and thus
$\beta$ is a Gaussian divisor of $0$ (since $0$ is a Gaussian integer). In
other words, each Gaussian integer is a Gaussian divisor of $0$. Conversely,
each Gaussian divisor of $0$ is a Gaussian integer (by definition). Combining
these two statements, we conclude that the Gaussian divisors of $0$ are all
the Gaussian integers. This proves Proposition \ref{prop.Z[i].divisors.find}
\textbf{(b)}.

\textbf{(c)} Let $\alpha$ be a Gaussian divisor of $\beta$. Write the complex
number $\alpha$ in the form $\alpha=\left(  a,b\right)  $ with $a,b\in
\mathbb{C}$. Then, $a,b\in\mathbb{Z}$ (since $\alpha$ is a Gaussian integer)
and $\operatorname*{N}\left(  \alpha\right)  =a^{2}+b^{2}$ (by the definition
of $\operatorname*{N}\left(  \alpha\right)  $). But $\alpha\mid\beta$ (since
$\alpha$ is a Gaussian divisor of $\beta$) and $\beta\neq0$ (since $\beta$ is
nonzero). Hence, Proposition \ref{prop.Z[i].gauss.div.1} \textbf{(b)} yields
$\operatorname*{N}\left(  \alpha\right)  \leq\operatorname*{N}\left(
\beta\right)  $. But $a,b$ are reals, and thus $a^{2},b^{2}$ are nonnegative
reals (since the square of a real is always a nonnegative real). In other
words, $a^{2}\geq0$ and $b^{2}\geq0$.

Now, $\operatorname*{N}\left(  \alpha\right)  =a^{2}+\underbrace{b^{2}}%
_{\geq0}\geq a^{2}$, so that $a^{2}\leq\operatorname*{N}\left(  \alpha\right)
\leq\operatorname*{N}\left(  \beta\right)  $. Also, $\operatorname*{N}\left(
\alpha\right)  =\underbrace{a^{2}}_{\geq0}+b^{2}\geq b^{2}$, so that
$b^{2}\leq\operatorname*{N}\left(  \alpha\right)  \leq\operatorname*{N}\left(
\beta\right)  $. Also, $\alpha=\left(  a,b\right)  =a+bi$. Hence, we have
$\alpha=x+yi$ for some $x,y\in\mathbb{Z}$ satisfying $x^{2}\leq
\operatorname*{N}\left(  \beta\right)  $ and $y^{2}\leq\operatorname*{N}%
\left(  \beta\right)  $ (namely, for $x=a$ and $y=b$). In other words,%
\[
\alpha\in\left\{  x+yi\ \mid\ x,y\in\mathbb{Z}\text{ satisfying }x^{2}%
\leq\operatorname*{N}\left(  \beta\right)  \text{ and }y^{2}\leq
\operatorname*{N}\left(  \beta\right)  \right\}  .
\]


Now, forget that we fixed $\alpha$. We thus have shown that if $\alpha$ is a
Gaussian divisor of $\beta$, then%
\[
\alpha\in\left\{  x+yi\ \mid\ x,y\in\mathbb{Z}\text{ satisfying }x^{2}%
\leq\operatorname*{N}\left(  \beta\right)  \text{ and }y^{2}\leq
\operatorname*{N}\left(  \beta\right)  \right\}  .
\]
In other words, all Gaussian divisors of $\beta$ belong to the set%
\[
\left\{  x+yi\ \mid\ x,y\in\mathbb{Z}\text{ satisfying }x^{2}\leq
\operatorname*{N}\left(  \beta\right)  \text{ and }y^{2}\leq\operatorname*{N}%
\left(  \beta\right)  \right\}  .
\]
This proves Proposition \ref{prop.Z[i].divisors.find} \textbf{(c)}.
\end{proof}

Thus, again, finding all Gaussian divisors of a Gaussian integer $\beta$ is a
problem solvable in finite time. (Indeed, if $\beta=0$, then Proposition
\ref{prop.Z[i].divisors.find} \textbf{(b)} answers this question; but
otherwise, the set in Proposition \ref{prop.Z[i].divisors.find} \textbf{(c)}
is clearly finite.)

The following is a straightforward analogue of Definition \ref{def.ent.Div}:

\begin{definition}
\label{def.Z[i].Div}Let $\beta_{1},\beta_{2},\ldots,\beta_{k}$ be Gaussian
integers. Then, the \textit{common Gaussian divisors} of $\beta_{1},\beta
_{2},\ldots,\beta_{k}$ are defined to be the Gaussian integers $\alpha$ that
satisfy%
\begin{equation}
\left(  \alpha\mid\beta_{i}\text{ for all }i\in\left\{  1,2,\ldots,k\right\}
\right)  \label{eq.def.Z[i].Div.cond}%
\end{equation}
(in other words, that divide all of the Gaussian integers $\beta_{1},\beta
_{2},\ldots,\beta_{k}$). We let $\operatorname*{Div}\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \beta_{1},\beta_{2},\ldots,\beta_{k}\right)  $
denote the set of these common Gaussian divisors.
\end{definition}

The reason why I chose the notation $\operatorname*{Div}\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \beta_{1},\beta_{2},\ldots,\beta_{k}\right)  $
rather than the simpler notation $\operatorname*{Div}\left(  \beta_{1}%
,\beta_{2},\ldots,\beta_{k}\right)  $ is that the latter would be ambiguous.
In fact, when $\beta_{1},\beta_{2},\ldots,\beta_{k}$ are integers, the set
$\operatorname*{Div}\left(  \beta_{1},\beta_{2},\ldots,\beta_{k}\right)  $ of
common divisors of $\beta_{1},\beta_{2},\ldots,\beta_{k}$ is \textbf{not} the
set $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\beta_{1},\beta_{2},\ldots,\beta_{k}\right)  $ of common Gaussian divisors of
$\beta_{1},\beta_{2},\ldots,\beta_{k}$. (For example, the former set does not
contain $i$, while the latter does.)

We cannot directly define a \textquotedblleft greatest common Gaussian divisor
of $\beta_{1},\beta_{2},\ldots,\beta_{k}$\textquotedblright\ to be the
greatest element of $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \beta_{1},\beta_{2},\ldots,\beta_{k}\right)  $, since
\textquotedblleft greatest\textquotedblright\ does not make sense for complex
numbers. (Even if we wanted \textquotedblleft greatest in
norm\textquotedblright, it would not a-priori be obvious that there are no
ties, i.e., that such a greatest common Gaussian divisor is unique.)%

\[%
\begin{tabular}
[c]{||l||}\hline\hline
\textbf{You have reached the end of the finished part.}\\
\textbf{TODO: Write on from here.}\\\hline\hline
\end{tabular}
\ \
\]


However, it turns out that a \textquotedblleft greatest common Gaussian
divisor\textquotedblright\ $\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \beta_{1},\beta_{2},\ldots,\beta_{k}\right)  $ actually can be
defined reasonably (although only up to multiplication by units). Before we
can do so, let us state some basic properties of common Gaussian divisors:

\begin{proposition}
\label{prop.Z[i].gauss.divrules}\textbf{(a)} We have $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,0\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha\right)  $ for all $\alpha\in\mathbb{Z}\left[  i\right]  $.

\textbf{(b)} We have $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  =\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \beta,\alpha\right)  $ for all
$\alpha,\beta\in\mathbb{Z}\left[  i\right]  $.

\textbf{(c)} We have $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\eta\alpha+\beta\right)  =\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ for all
$\alpha,\beta,\eta\in\mathbb{Z}\left[  i\right]  $.

\textbf{(d)} If $\alpha,\beta,\gamma\in\mathbb{Z}\left[  i\right]  $ satisfy
$\beta\equiv\gamma\operatorname{mod}\alpha$, then $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\gamma\right)  $.

\textbf{(g)} We have $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \eta\alpha,\beta\right)  =\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ for all
$\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ for every unit $\eta
\in\mathbb{Z}\left[  i\right]  $.

\textbf{(h)} We have $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\eta\beta\right)  =\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ for all
$\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ for every unit $\eta
\in\mathbb{Z}\left[  i\right]  $.

\textbf{(i)} If $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ satisfy
$\alpha\mid\beta$, then $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  =\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha\right)  $.

\textbf{(j)} The common Gaussian divisors of the empty list of Gaussian
integers are $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  {}\right)  =\mathbb{Z}\left[  i\right]  $.
\end{proposition}

\begin{proof}
Most of these facts are analogues of Proposition \ref{prop.ent.gcd.props1}, or
rather of the corresponding properties of $\operatorname*{Div}\left(
a,b\right)  $ for two integers $a$ and $b$ that were proven during our proof
of Proposition \ref{prop.ent.gcd.props1}. Their proofs also are
straightforward adaptations of the proofs of the latter properties. Let us
only sketch the proof of \textbf{(g)}, since it may require some extra thinking:

\textbf{(g)} Let $\eta\in\mathbb{Z}\left[  i\right]  $ be a unit.

Claim: The Gaussian divisors of $\alpha$ are exactly the Gaussian divisors of
$\eta\alpha$.

(Indeed, any Gaussian divisor of $\alpha$ is clearly a Gaussian divisor of
$\eta\alpha$. Conversely, since $\eta^{-1}$ is a Gaussian integer, any
Gaussian divisor of $\eta\alpha$ is a Gaussian divisor of $\eta^{-1}\eta
\alpha=\alpha$.)

The rest is proven just as for integers, except that we don't make the final
step from $\operatorname*{Div}$ to $\gcd$.
\end{proof}

Now, we can compute $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  $ for Gaussian integers $\alpha$ and $\beta$ by
a version of the \textquotedblleft Euclidean algorithm\textquotedblright\ that
we used to compute $\gcd\left(  a,b\right)  $ for integers $a$ and $b$. For
example, we can compute $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  32+9i,4+11i\right)  $ as follows:\footnote{This is
\cite[Example 4.4]{Conrad-Gauss}.}%
\begin{align*}
&  \operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
32+9i,4+11i\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
4+11i,\underbrace{32+9i}_{=\left(  2-2i\right)  \left(  4+11i\right)  +\left(
2-5i\right)  }\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(b)}}\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
4+11i,\left(  2-2i\right)  \left(  4+11i\right)  +\left(  2-5i\right)  \right)
\\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
4+11i,2-5i\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(c)}}\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
2-5i,\underbrace{4+11i}_{=\left(  -2+i\right)  \left(  2-5i\right)  +\left(
3-i\right)  }\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(b)}}\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
2-5i,\left(  -2+i\right)  \left(  2-5i\right)  +\left(  3-i\right)  \right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
2-5i,3-i\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(c)}}\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
3-i,\underbrace{2-5i}_{=\left(  1-i\right)  \left(  3-i\right)  -i}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(b)}}\right)
\end{align*}%
\begin{align*}
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
3-i,\left(  1-i\right)  \left(  3-i\right)  -i\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
3-i,-i\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(c)}}\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
-i,\underbrace{3-i}_{=\left(  1+3i\right)  \left(  -i\right)  +0}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(b)}}\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
-i,\left(  1+3i\right)  \left(  -i\right)  +0\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
-i,0\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(c)}}\right) \\
&  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
-i\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition
\ref{prop.Z[i].gauss.divrules} \textbf{(a)}}\right) \\
&  =\left\{  1,i,-1,-i\right\}  .
\end{align*}
In the same way, for \textbf{any} two Gaussian integers $\alpha$ and $\beta$
we can find a Gaussian integer $\gamma$ such that $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\gamma\right)  $. This resulting $\gamma$ will actually be unique up to
multiplication by units (i.e., its unit-equivalence class will be unique).
Better yet, we have the following:

\begin{theorem}
\label{thm.Z[i].gauss.bezout}(Bezout's theorem for Gaussian integers:)

Let $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $. Then:

\textbf{(a)} There exists a $\mathbb{Z}\left[  i\right]  $-linear combination
$\gamma$ of $\alpha$ and $\beta$ that is a common Gaussian divisor of $\alpha$
and $\beta$. (Note: A $\mathbb{Z}\left[  i\right]  $\textbf{-linear
combination of }$\alpha$ \textbf{and }$\beta$ means a Gaussian integer of the
form $\lambda\alpha+\mu\beta$ with $\lambda,\mu\in\mathbb{Z}\left[  i\right]
$.)

\textbf{(b)} Any such $\gamma$ satisfies $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\gamma\right)  $.

\textbf{(c)} The unit-equivalence class of this $\gamma$ is uniquely determined.
\end{theorem}

This theorem is, in a sense, a generalization of Theorem
\ref{thm.ent.gcd.bezout}, even though (unlike the latter theorem) it does not
rely on an already existing concept of \textquotedblleft greatest common
divisor\textquotedblright\ but rather builds the foundation for such a
concept. With Theorem \ref{thm.Z[i].gauss.bezout} in hand, it makes sense to
call $\gamma$ the \textquotedblleft greatest common Gaussian
divisor\textquotedblright\ of $\alpha$ and $\beta$, but rigorously speaking
this name should be reserved for the unit-equivalence class of $\gamma$ since
$\gamma$ itself is not unique.

\begin{center}
\textbf{2019-03-08 lecture}
\end{center}

\begin{proof}
[Proof of Theorem \ref{thm.Z[i].gauss.bezout} (sketched).]\textbf{(a)} This is
somewhat similar to the proof of Lemma \ref{lem.ent.gcd.bezout.++}:

For any $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $, we let
$\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  $ be the set of all $\mathbb{Z}\left[  i\right]  $-linear
combinations of $\alpha$ and $\beta$. (This will be called the $\mathbb{Z}%
\left[  i\right]  $\textit{-linear span of }$\alpha$ \textit{and }$\beta$
later on, in analogy to spans in classical linear algebra.) Now, the claim of
Theorem \ref{thm.Z[i].gauss.bezout} \textbf{(a)} can be restated as follows:%
\begin{equation}
\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  \cap\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  \neq\varnothing
\label{pf.thm.Z[i].gauss.bezout.a.nem}%
\end{equation}
for any $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $.

We shall prove (\ref{pf.thm.Z[i].gauss.bezout.a.nem}) by strong induction on
$\operatorname*{N}\left(  \alpha\right)  +\operatorname*{N}\left(
\beta\right)  $.

So we fix $n\in\mathbb{N}$, and assume as the induction hypothesis that
(\ref{pf.thm.Z[i].gauss.bezout.a.nem}) holds for all $\alpha,\beta
\in\mathbb{Z}\left[  i\right]  $ satisfying $\operatorname*{N}\left(
\alpha\right)  +\operatorname*{N}\left(  \beta\right)  <n$. We must now prove
(\ref{pf.thm.Z[i].gauss.bezout.a.nem}) for all $\alpha,\beta\in\mathbb{Z}%
\left[  i\right]  $ satisfying $\operatorname*{N}\left(  \alpha\right)
+\operatorname*{N}\left(  \beta\right)  =n$.

So let $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ be such that
$\operatorname*{N}\left(  \alpha\right)  +\operatorname*{N}\left(
\beta\right)  =n$. We must prove $\operatorname*{Div}\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\beta\right)  \cap\operatorname*{Lin}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
\neq\varnothing$. We can WLOG assume $\operatorname*{N}\left(  \beta\right)
\geq\operatorname*{N}\left(  \alpha\right)  $, since otherwise we can swap
$\alpha$ with $\beta$ without changing any of the sets $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ and
$\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  $. Assume this. Furthermore, we WLOG assume that
$\alpha\neq0$ (since otherwise, the set $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
\cap\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  0,\beta\right)  \cap\operatorname*{Lin}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  0,\beta\right)  $ clearly
contains $\beta$ and thus is $\neq\varnothing$). Hence, $\operatorname*{N}%
\left(  \alpha\right)  >0$. Now, Theorem \ref{thm.Z[i].gauss.quorem} (applied
to $\beta$ and $\alpha$ instead of $\alpha$ and $\beta$) yields that there
exist Gaussian integers $\gamma$ and $\rho$ such that $\beta=\gamma\alpha
+\rho$ and $\operatorname*{N}\left(  \rho\right)  \leq\operatorname*{N}\left(
\alpha\right)  /2$. Consider these $\gamma$ and $\rho$. From $\beta
=\gamma\alpha+\rho$, we obtain $\rho=\beta-\gamma\alpha$ and $\beta
-\rho=\gamma\alpha$. From $\operatorname*{N}\left(  \rho\right)
\leq\operatorname*{N}\left(  \alpha\right)  /2$, we obtain
\[
\operatorname*{N}\left(  \rho\right)  \leq\operatorname*{N}\left(
\alpha\right)  /2<\operatorname*{N}\left(  \alpha\right)  .
\]
(This is the only inequality that we will need concerning $\operatorname*{N}%
\left(  \rho\right)  $. So, in a sense, the inequality $\operatorname*{N}%
\left(  \rho\right)  \leq\operatorname*{N}\left(  \alpha\right)  /2$ in
Theorem \ref{thm.Z[i].gauss.quorem} is better than we need it to be.)

The Gaussian integers $\beta$ and $\rho$ satisfy $\beta\equiv\rho
\operatorname{mod}\alpha$ (since $\alpha\mid\gamma\alpha=\beta-\rho$). Hence,
Proposition \ref{prop.Z[i].gauss.divrules} \textbf{(d)} yields
\begin{equation}
\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\rho\right)  .
\label{pf.thm.Z[i].gauss.bezout.a.Div=Div}%
\end{equation}
Also, it is easy to see that $\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  \subseteq\operatorname*{Lin}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\rho\right)  $ (since
every $\lambda,\mu\in\mathbb{Z}\left[  i\right]  $ satisfy%
\[
\lambda\alpha+\mu\underbrace{\beta}_{=\gamma\alpha+\rho}=\lambda\alpha
+\mu\left(  \gamma\alpha+\rho\right)  =\left(  \lambda+\mu\gamma\right)
\alpha+\mu\rho\in\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\rho\right)
\]
) and $\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\rho\right)  \subseteq\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  $ (since every $\lambda,\mu
\in\mathbb{Z}\left[  i\right]  $ satisfy%
\[
\lambda\alpha+\mu\underbrace{\rho}_{=\beta-\gamma\alpha}=\lambda\alpha
+\mu\left(  \beta-\gamma\alpha\right)  =\left(  \lambda-\mu\gamma\right)
\alpha+\mu\beta\in\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)
\]
). Combining these two relations, we obtain
\begin{equation}
\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  =\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\rho\right)  .
\label{pf.thm.Z[i].gauss.bezout.a.Lin=Lin}%
\end{equation}


Thus,%
\[
\underbrace{\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  }_{=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\rho\right)  }\cap\underbrace{\operatorname*{Lin}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
}_{=\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\rho\right)  }=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\rho\right)  \cap\operatorname*{Lin}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\rho\right)  .
\]
Hence, proving $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  \cap\operatorname*{Lin}\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\beta\right)  \neq\varnothing$ boils down to
proving $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\rho\right)  \cap\operatorname*{Lin}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\rho\right)  \neq\varnothing$. But this follows from
the induction hypothesis (applied to $\rho$ instead of $\beta$), since%
\[
\operatorname*{N}\left(  \alpha\right)  +\underbrace{\operatorname*{N}\left(
\rho\right)  }_{<\operatorname*{N}\left(  \alpha\right)  \leq\operatorname*{N}%
\left(  \beta\right)  }<\operatorname*{N}\left(  \alpha\right)
+\operatorname*{N}\left(  \beta\right)  =n.
\]
This completes the induction step. Hence,
(\ref{pf.thm.Z[i].gauss.bezout.a.nem}) (and thus Theorem
\ref{thm.Z[i].gauss.bezout} \textbf{(a)}) follows by strong induction.

\textbf{(b)} We shall prove $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  \subseteq\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \gamma\right)  $ and
$\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  \supseteq\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \gamma\right)  $ separately:

$\subseteq:$ Since $\gamma$ is a $\mathbb{Z}\left[  i\right]  $-linear
combination of $\alpha$ and $\beta$, every common Gaussian divisor of $\alpha$
and $\beta$ must also divide $\gamma$. Thus, $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
\subseteq\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\gamma\right)  $.

$\supseteq:$ Since $\gamma$ is a common Gaussian divisor of $\alpha$ and
$\beta$, every Gaussian divisor of $\gamma$ must be a common Gaussian divisor
of $\alpha$ and $\beta$. Thus, $\operatorname*{Div}\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\beta\right)  \supseteq\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \gamma\right)  $.

\textbf{(c)} Let $\gamma_{1}$ and $\gamma_{2}$ be two such $\gamma$'s. We must
prove that $\gamma_{1}\sim\gamma_{2}$.

We have $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \gamma_{1}\right)  $ and $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \gamma
_{2}\right)  $. Comparing these two equalities, we obtain $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \gamma_{1}\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \gamma
_{2}\right)  $. Now, $\gamma_{1}\in\operatorname*{Div}\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \gamma_{1}\right)  =\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \gamma_{2}\right)  $, thus
$\gamma_{1}\mid\gamma_{2}$. Similarly, $\gamma_{2}\mid\gamma_{1}$. Combining
these, we obtain $\gamma_{1}\sim\gamma_{2}$ (by Exercise
\ref{exe.Z[i].div.abba}). This proves Theorem \ref{thm.Z[i].gauss.bezout}
\textbf{(c)}.
\end{proof}

\begin{definition}
\label{def.Z[i].gauss.gcd}The \textit{greatest common Gaussian divisor} (or,
short, \textit{gcd}) of two Gaussian integers $\alpha$ and $\beta$ is defined
to be the $\gamma$ from Theorem \ref{thm.Z[i].gauss.bezout} \textbf{(a)}. It
is called $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha
,\beta\right)  $.

So it is a common Gaussian divisor of $\alpha$ and $\beta$ and also a
$\mathbb{Z}\left[  i\right]  $-linear combination of $\alpha$ and $\beta$ and
satisfies
\begin{equation}
\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
\right)  =\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  . \label{eq.def.Z[i].gauss.gcd.Div=Div}%
\end{equation}


However, it is only well-defined up to unit-equivalence. Thus, if you have
$\gamma_{1}=\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha
,\beta\right)  $ and $\gamma_{2}=\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  $, then you cannot conclude that $\gamma
_{1}=\gamma_{2}$ (you can only conclude $\gamma_{1}\sim\gamma_{2}$). So,
strictly speaking, we should have defined $\gcd\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  $ as a unit-equivalence class, not as
a concrete Gaussian integer. But we will allow ourselves this abuse of
notation. We shall not write equality signs like the one in \textquotedblleft%
$\gamma_{1}=\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha
,\beta\right)  $\textquotedblright, however; we instead prefer to write
\textquotedblleft$\gamma_{1}\sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  $\textquotedblright. Generally, whenever you see
$\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ in
a statement, you should be understanding the statement to hold for
\textbf{every} possible choice of $\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  $.
\end{definition}

\begin{proposition}
\label{prop.Z[i].gauss.gcd=gcd}Let $a$ and $b$ be two integers. Then,%
\[
\gcd\left(  a,b\right)  \sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  a,b\right)  .
\]
(Of course, the $\gcd$ on the left hand side is the gcd of the two integers
$a$ and $b$ as defined in Definition \ref{def.ent.gcd.gcd}, whereas the
$\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }$ on the right hand side is the
greatest common Gaussian divisor of the Gaussian integers $a$ and $b$.)
\end{proposition}

\begin{proof}
The integer $\gcd\left(  a,b\right)  $ is a common divisor of $a$ and $b$ and
also is a $\mathbb{Z}$-linear combination of $a$ and $b$ (by Bezout).
Therefore, it is also a common Gaussian divisor of the Gaussian integers $a$
and $b$ and also is a $\mathbb{Z}\left[  i\right]  $-linear combination of $a$
and $b$. But this yields that it is $\gcd\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  a,b\right)  $ (due to the definition of $\gcd
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  a,b\right)  $).
\end{proof}

This proposition allows us to write \textquotedblleft$\gcd$\textquotedblright%
\ for both concepts of gcd without having to disambiguate the meaning. (We
shall not do so, however.)

\begin{proposition}
\label{prop.Z[i].gauss.gcd-as-max}Let $\alpha$ and $\beta$ be two Gaussian
integers, not both equal to $0$. Then, the possible values of $\gcd
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ (that
is, strictly speaking, all four elements of the unit-equivalence class
$\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $)
are exactly the elements of $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  $ having the largest norm.
\end{proposition}

\begin{proof}
First of all, $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  $ is a common Gaussian divisor of $\alpha$ and $\beta$,
and thus is $\neq0$ (since $\alpha$ and $\beta$ are not both equal to $0$).
Thus, there are exactly four Gaussian integers unit-equivalent to
$\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $.
In other words, there are exactly four possible values of $\gcd
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $. We
must show that these values are exactly the elements of $\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ having
the largest norm.

In other words, we must show the following two claims:

\begin{statement}
\textit{Claim 1:} We have $\operatorname*{N}\left(  \gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\beta\right)  \right)  >\operatorname*{N}%
\left(  \gamma\right)  $ for each $\gamma\in\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ that
does not satisfy $\gamma\sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  $.
\end{statement}

\begin{statement}
\textit{Claim 2:} We have $\operatorname*{N}\left(  \gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\beta\right)  \right)  =\operatorname*{N}%
\left(  \gamma\right)  $ for each $\gamma\in\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ that
does satisfy $\gamma\sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  $.
\end{statement}

Claim 2 is obvious, since any two unit-equivalent Gaussian integers have the
same norm (by Proposition \ref{prop.Z[i].gauss.uniteq.norm=norm}).

[\textit{Proof of Claim 1:} Let $\gamma\in\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ do not
satisfy $\gamma\sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  $. Now, $\gamma\in\operatorname*{Div}%
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
\right)  $ (by (\ref{eq.def.Z[i].gauss.gcd.Div=Div})). Hence, $\gamma\mid
\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $.

Let us set $\delta=\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  $. So $\gamma\mid\delta$. We have $\delta\neq0$ (because
$\alpha$ and $\beta$ are not both zero) and thus $\gamma\neq0$ (since
$\gamma\mid\delta$). Thus, $\gamma\mid\delta$ yields that $\dfrac{\delta
}{\gamma}$ is a Gaussian integer, which is furthermore nonzero (since
$\delta\neq0$). If this Gaussian integer $\dfrac{\delta}{\gamma}$ was a unit,
then we would have $\gamma\sim\delta=\gcd\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  $, which would contradict the
assumption that $\gamma$ does not satisfy $\gamma\sim\gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\beta\right)  $. So $\dfrac{\delta}{\gamma}$
is a nonzero Gaussian integer that is not a unit. Hence, $\operatorname*{N}%
\left(  \dfrac{\delta}{\gamma}\right)  >1$ (because Proposition
\ref{prop.Z[i].gauss.norm1} yields that every nonzero Gaussian integer that is
not a unit must have norm $>1$). Now,%
\[
\operatorname*{N}\left(  \delta\right)  =\underbrace{\operatorname*{N}\left(
\dfrac{\delta}{\gamma}\right)  }_{>1}\cdot\operatorname*{N}\left(
\gamma\right)  >\operatorname*{N}\left(  \gamma\right)  .
\]
In other words, $\operatorname*{N}\left(  \gcd\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha,\beta\right)  \right)  >\operatorname*{N}\left(
\gamma\right)  $. This proves Claim 1.]
\end{proof}

Proposition \ref{prop.Z[i].gauss.gcd-as-max} shows that $\gcd
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ is
uniquely determined by the set $\operatorname*{Div}\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\beta\right)  $. (Yes, you have to consider
the case $\alpha=\beta=0$ separately in proving this.) Hence, Proposition
\ref{prop.Z[i].gauss.divrules} yields:

\begin{proposition}
\label{prop.Z[i].gauss.gcdrules}\textbf{(a)} We have $\gcd
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,0\right)  \sim
\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha\right)  $ for all
$\alpha\in\mathbb{Z}\left[  i\right]  $.

\textbf{(b)} We have $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  \sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\beta,\alpha\right)  $ for all $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $.

\textbf{(c)} We have $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\eta\alpha+\beta\right)  \sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  $ for all $\alpha,\beta,\eta\in\mathbb{Z}\left[
i\right]  $.

\textbf{(d)} If $\alpha,\beta,\gamma\in\mathbb{Z}\left[  i\right]  $ satisfy
$\beta\equiv\gamma\operatorname{mod}\alpha$, then $\gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\beta\right)  \sim\gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha,\gamma\right)  $.

\textbf{(g)} We have $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\eta\alpha,\beta\right)  \sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  $ for all $\alpha,\beta\in\mathbb{Z}\left[
i\right]  $ for every unit $\eta\in\mathbb{Z}\left[  i\right]  $.

\textbf{(h)} We have $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\eta\beta\right)  \sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \alpha,\beta\right)  $ for all $\alpha,\beta\in\mathbb{Z}\left[
i\right]  $ for every unit $\eta\in\mathbb{Z}\left[  i\right]  $.

\textbf{(i)} If $\alpha,\beta\in\mathbb{Z}\left[  i\right]  $ satisfy
$\alpha\mid\beta$, then $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  \sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha\right)  $.

\textbf{(j)} The greatest common Gaussian divisor of the empty list of
Gaussian integers is $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
{}\right)  =0$.
\end{proposition}

Theorem \ref{thm.ent.gcd.uniprop} still holds for Gaussian integers.

Theorem \ref{thm.ent.gcd.combine} still holds for Gaussian integers.

Theorem \ref{thm.ent.gcd.cancel} still holds for Gaussian integers.

Corollary \ref{cor.ent.gcd.sa,sb} has to be modified as follows:

\begin{corollary}
Let $\sigma,\alpha,\beta\in\mathbb{Z}\left[  i\right]  $. Then,
\[
\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \sigma\alpha,\sigma
\beta\right)  \sim\sigma\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  .
\]

\end{corollary}

Exercise \ref{exe.ent.gcd.div} still holds for Gaussian integers.

Exercise \ref{exe.ent.gcd.abs} becomes the claim that if $\alpha_{1}\sim
\alpha_{2}$ and $\beta_{1}\sim\beta_{2}$, then $\gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha_{1},\beta_{1}\right)  \sim\gcd
\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha_{2},\beta_{2}\right)
$. The solution does not carry over, but you can easily prove this new claim
by hand.

Greatest common Gaussian divisors of $k$ Gaussian integers can also be defined.

The next definition is an analogue of Definition \ref{def.ent.coprime.coprime}:

\begin{definition}
\label{def.Z[i].gauss.coprime}Let $\alpha$ and $\beta$ be two Gaussian
integers. We say that $\alpha$ is \textit{coprime} to $\beta$ if and only if
$\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
\sim1$ (that is, $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\alpha,\beta\right)  $ is a unit).
\end{definition}

Thus, any two coprime integers are also two coprime Gaussian integers (because
of Proposition \ref{prop.Z[i].gauss.gcd=gcd}), and vice versa (for the same
reason). This is why we can afford speaking of \textquotedblleft coprime
Gaussian integers\textquotedblright\ and not just \textquotedblleft
Gaussian-coprime Gaussian integers\textquotedblright.

Everything we said about coprimality of integers still holds for Gaussian
integers. In particular, Proposition \ref{prop.ent.coprime.perp-symm}, Theorem
\ref{thm.ent.coprime.cancel}, Theorem \ref{thm.ent.coprime.combine}, Theorem
\ref{thm.ent.coprime.modinv} and Theorem \ref{thm.ent.coprime.ab-to-c} still
hold if all integers are replaced by Gaussian integers (with the caveat that
the gcd is no longer unique, so for example \textquotedblleft$ab\equiv
\gcd\left(  a,n\right)  \operatorname{mod}n$\textquotedblright\ must be
interpreted as \textquotedblleft$ab$ is congruent to \textbf{some} of the
possible values of $\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
a,n\right)  $ modulo $n$\textquotedblright).

\begin{noncompile}
Let us generalize Theorem \ref{thm.Z[i].gauss.bezout} to $k$ Gaussian integers:

\begin{theorem}
(Bezout's theorem for $k$ Gaussian integers:)

Let $\alpha_{1},\alpha_{2},\ldots,\alpha_{k}\in\mathbb{Z}\left[  i\right]  $. Then:

\textbf{(a)} There exists a $\mathbb{Z}\left[  i\right]  $-linear combination
$\gamma$ of $\alpha_{1},\alpha_{2},\ldots,\alpha_{k}$ that is a common
Gaussian divisor of $\alpha_{1},\alpha_{2},\ldots,\alpha_{k}$. (Note: A
$\mathbb{Z}\left[  i\right]  $\textit{-linear combination of }$\alpha
_{1},\alpha_{2},\ldots,\alpha_{k}$ means a Gaussian integer of the form
$\lambda_{1}\alpha_{1}+\lambda_{2}\alpha_{2}+\cdots+\lambda_{k}\alpha_{k}$
with $\lambda_{1},\lambda_{2},\ldots,\lambda_{k}\in\mathbb{Z}\left[  i\right]
$.)

\textbf{(b)} It satisfies $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \alpha_{1},\alpha_{2},\ldots,\alpha_{k}\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\gamma\right)  $.

\textbf{(c)} The unit-equivalence class of $\gamma$ is uniquely determined.
\end{theorem}

\begin{proof}
[Proof sketch.]Induction on $k$, similar to the proof of Theorem
\ref{thm.ent.gcd.uniprop-mul}. The details are left to the reader.
\end{proof}

Again, the $\gamma$ from this theorem is called $\gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \alpha_{1},\alpha_{2},\ldots,\alpha_{k}\right)  $
and is unique up to unit-equivalence.

Theorem \ref{thm.ent.gcd.uniprop-mul} generalizes as follows:

\begin{theorem}
Let $\beta_{1},\beta_{2},\ldots,\beta_{k}$ be integers.

\textbf{(a)} For each $\mu\in\mathbb{Z}\left[  i\right]  $, we have the
following logical equivalence:%
\[
\left(  \mu\mid\beta_{i}\text{ for all }i\in\left\{  1,2,\ldots,k\right\}
\right)  \ \Longleftrightarrow\ \left(  \mu\mid\gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \beta_{1},\beta_{2},\ldots,\beta_{k}\right)
\right)  .
\]


\textbf{(b)} The common Gaussian divisors of $\beta_{1},\beta_{2},\ldots
,\beta_{k}$ are precisely the Gaussian divisors of $\gcd\nolimits_{\mathbb{Z}%
\left[  i\right]  }\left(  \beta_{1},\beta_{2},\ldots,\beta_{k}\right)  $.

\textbf{(c)} We have $\operatorname*{Div}\nolimits_{\mathbb{Z}\left[
i\right]  }\left(  \beta_{1},\beta_{2},\ldots,\beta_{k}\right)
=\operatorname*{Div}\nolimits_{\mathbb{Z}\left[  i\right]  }\left(
\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \beta_{1},\beta_{2}%
,\ldots,\beta_{k}\right)  \right)  $.

\textbf{(d)} If $k>0$, then%
\[
\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \beta_{1},\beta_{2}%
,\ldots,\beta_{k}\right)  \sim\gcd\nolimits_{\mathbb{Z}\left[  i\right]
}\left(  \gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \beta_{1}%
,\beta_{2},\ldots,\beta_{k-1}\right)  ,\beta_{k}\right)  .
\]

\end{theorem}

Theorem \ref{thm.ent.gcd.split} still holds for Gaussian integers, with the
obvious changes (the $=$ sign is replaced by $\sim$).
\end{noncompile}

We could define \textit{Gaussian rationals} (their set is called
$\mathbb{Q}\left[  i\right]  $) as complex numbers $a+bi$ with $a,b\in
\mathbb{Q}$. These are exactly the quotients of Gaussian integers.

Lowest common multiples of Gaussian integers still exist, but their definition
has to be modified. For example, we can define $\operatorname{lcm}%
_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)  $ as the (unique
up to unit-equivalence) Gaussian integer $\gamma$ such that the Gaussian
common multiples of $\alpha$ and $\beta$ are the Gaussian multiples of
$\gamma$. (We would have to prove that it actually is unique and exists.)
Theorem \ref{thm.ent.lcm.gcd*lcm} still holds, in the sense that
$\gcd\nolimits_{\mathbb{Z}\left[  i\right]  }\left(  \alpha,\beta\right)
\cdot\operatorname{lcm}_{\mathbb{Z}\left[  i\right]  }\left(  \alpha
,\beta\right)  \sim\alpha\beta$. Many other properties of lowest common
multiples extend to Gaussian integers.

The Chinese remainder theorem (Theorem \ref{thm.ent.crt1}) still holds for
coprime Gaussian integers $\mu$ and $\nu$. A similar fact holds for $k$
mutually coprime Gaussian integers.

\subsubsection{Gaussian primes}

The next definition is an analogue of Definition \ref{def.ent.prime}:

\begin{definition}
\label{def.Z[i].gauss.prime}Let $\pi$ be a nonzero Gaussian integer that is
not a unit. We say that $\pi$ is a \textit{Gaussian prime} if each Gaussian
divisor of $\pi$ is either a unit or unit-equivalent to $\pi$.
\end{definition}

The letter \textquotedblleft$\pi$\textquotedblright\ in this definition is
unrelated to the irrational number $\pi=3.14159\ldots$. It just happens to be
the Greek letter corresponding to the Roman \textquotedblleft$p$%
\textquotedblright.

The Gaussian primes are \textbf{not} a superset of the primes. For example:

\begin{example}
\label{exa.Z[i].gauss.2notprime}The Gaussian integer $2$ is not a Gaussian prime.
\end{example}

\begin{proof}
We have $2=\left(  1+i\right)  \left(  1-i\right)  $. The factors $1+i$ and
$1-i$ have norms $2$, which means that they are neither units themselves
(since units would have norm $1$) nor unit-equivalent to $2$ (since $2$ has
norm $4$, but unit-equivalent Gaussian integers have equal norms). Thus, $1+i$
is a Gaussian divisor of $2$ that is neither a unit nor is unit-equivalent to
$2$. Hence, $2$ is not a Gaussian prime (by the definition of
\textquotedblleft Gaussian prime\textquotedblright).
\end{proof}

So don't forget the word \textquotedblleft Gaussian\textquotedblright\ when
you mean it!

Let us search for Gaussian primes. So we know that $2$ is not a Gaussian
prime. What about $3$?

\begin{example}
The Gaussian integer $3$ is a Gaussian prime.
\end{example}

\begin{proof}
Assume the contrary. Thus, there exists a Gaussian divisor $\alpha$ of $3$
that is neither a unit nor unit-equivalent to $3$ (since $3$ is a nonzero
Gaussian integer that is not a unit). Consider this $\alpha$. We have
$3=\alpha\gamma$ for some Gaussian integer $\gamma$ (since $\alpha$ is a
Gaussian divisor $\gamma$ of $3$). Consider this $\gamma$.

If $\gamma$ was a unit, then we would have $3\sim\alpha$ (since $3=\alpha
\gamma$); but this would contradict the fact that $\alpha$ is not
unit-equivalent to $3$. Hence, $\gamma$ is not a unit. Thus,
$\operatorname*{N}\left(  \gamma\right)  \neq1$ (by Proposition
\ref{prop.Z[i].gauss.norm1} \textbf{(b)}). Also, $\alpha$ is not a unit;
hence, $\operatorname*{N}\left(  \alpha\right)  \neq1$ (by Proposition
\ref{prop.Z[i].gauss.norm1} \textbf{(b)}).

We have $3=\alpha\gamma$. Thus, $\operatorname*{N}\left(  3\right)
=\operatorname*{N}\left(  \alpha\gamma\right)  =\operatorname*{N}\left(
\alpha\right)  \cdot\operatorname*{N}\left(  \gamma\right)  $ (by Proposition
\ref{prop.CC.conj.hom} \textbf{(d)}). Hence, $\operatorname*{N}\left(
\alpha\right)  \cdot\operatorname*{N}\left(  \gamma\right)  =\operatorname*{N}%
\left(  3\right)  =3^{2}+0^{2}=9$. Since $\operatorname*{N}\left(
\alpha\right)  $ and $\operatorname*{N}\left(  \gamma\right)  $ are
nonnegative integers, this would mean that

\begin{itemize}
\item \textbf{either} $\operatorname*{N}\left(  \alpha\right)  =1$ and
$\operatorname*{N}\left(  \gamma\right)  =9$,

\item \textbf{or }$\operatorname*{N}\left(  \alpha\right)  =3$ and
$\operatorname*{N}\left(  \gamma\right)  =3$,

\item \textbf{or }$\operatorname*{N}\left(  \alpha\right)  =9$ and
$\operatorname*{N}\left(  \gamma\right)  =1$.
\end{itemize}

The first and the third of these three options are impossible, since
$\operatorname*{N}\left(  \alpha\right)  \neq1$ and $\operatorname*{N}\left(
\gamma\right)  \neq1$. So the second option must be true. Thus,
$\operatorname*{N}\left(  \alpha\right)  =3$ and $\operatorname*{N}\left(
\gamma\right)  =3$. But let us write the Gaussian integer $\alpha$ as $\left(
a,b\right)  $ for some $a,b\in\mathbb{Z}$. Thus, $\operatorname*{N}\left(
\alpha\right)  =a^{2}+b^{2}$, so that $a^{2}+b^{2}=\operatorname*{N}\left(
\alpha\right)  =3\equiv3\operatorname{mod}4$. This contradicts Exercise
\ref{exe.ent.even-odd-sumsq} \textbf{(c)}. This contradiction shows that our
assumption was false. So $3$ is a Gaussian prime.
\end{proof}

\begin{center}
\textbf{2019-03-11 lecture}
\end{center}

So we know that $3$ is a Gaussian prime, but $2$ is not. Is there a way to
tell which integers are Gaussian primes, without checking all Gaussian divisors?

Let us first state a positive criterion:

\begin{lemma}
\label{lem.Z[i].gauss.prime.3mod4}Let $p$ be a prime such that $p\equiv
3\operatorname{mod}4$. Then, $p$ is a Gaussian prime.
\end{lemma}

\begin{proof}
Assume the contrary. Thus, $p$ has a Gaussian divisor $\delta$ that is neither
a unit nor unit-equivalent to $p$. Consider this $\delta$. Thus, there exists
a Gaussian integer $\varepsilon$ such that $p=\delta\varepsilon$. Consider
this $\varepsilon$.

From $p=\delta\varepsilon$, we obtain $\operatorname*{N}\left(  p\right)
=\operatorname*{N}\left(  \delta\varepsilon\right)  =\operatorname*{N}\left(
\delta\right)  \cdot\operatorname*{N}\left(  \varepsilon\right)  $. Hence,
$\operatorname*{N}\left(  \delta\right)  \cdot\operatorname*{N}\left(
\varepsilon\right)  =\operatorname*{N}\left(  p\right)  =p^{2}+0^{2}=p^{2}$.
Since $\operatorname*{N}\left(  \delta\right)  $ and $\operatorname*{N}\left(
\varepsilon\right)  $ are nonnegative integers (and $p$ is prime), this leaves
only three options:

\begin{itemize}
\item \textbf{either} $\operatorname*{N}\left(  \delta\right)  =1$ and
$\operatorname*{N}\left(  \varepsilon\right)  =p^{2}$,

\item \textbf{or }$\operatorname*{N}\left(  \delta\right)  =p$ and
$\operatorname*{N}\left(  \varepsilon\right)  =p$,

\item \textbf{or }$\operatorname*{N}\left(  \delta\right)  =p^{2}$ and
$\operatorname*{N}\left(  \varepsilon\right)  =1$.
\end{itemize}

The first of these three options would cause $\delta$ to be a unit, which is
impossible (by the definition of $\delta$).

The third of these three options would cause $\delta$ to be unit-equivalent to
$p$ (since $\varepsilon$ would be a unit, and $p=\delta\varepsilon$), which is
impossible (by the definition of $\delta$).

Thus, the second of these three options must hold. In other words,
$\operatorname*{N}\left(  \delta\right)  =p$ and $\operatorname*{N}\left(
\varepsilon\right)  =p$. Now, write the Gaussian integer $\delta$ as
$\delta=\left(  a,b\right)  $ with integers $a,b$. Then, $\operatorname*{N}%
\left(  \delta\right)  =a^{2}+b^{2}$, so that $a^{2}+b^{2}=\operatorname*{N}%
\left(  \delta\right)  =p\equiv3\operatorname{mod}4$. This contradicts
Exercise \ref{exe.ent.even-odd-sumsq} \textbf{(c)}. Thus, Lemma
\ref{lem.Z[i].gauss.prime.3mod4} is proven.
\end{proof}

It is clear that no prime is divisible by $4$. Thus, there are three types of primes:

\begin{itemize}
\item \textit{Type 1:} Primes that are $\equiv1\operatorname{mod}4$: these are
$5,13,17,29,\ldots$.

\item \textit{Type 2:} Primes that are even: there is only one of these,
namely $2$.

\item \textit{Type 3:} Primes that are $\equiv3\operatorname{mod}4$: these are
$3,7,11,19,23,\ldots$.
\end{itemize}

(One can show that there are infinitely many primes of Type 1 and infinitely
many primes of Type 3. It can also be shown that there are \textquotedblleft
roughly the same amount\textquotedblright\ of Type-1 primes and of Type-3
primes \textquotedblleft in theory\textquotedblright, but \textquotedblleft in
practice\textquotedblright\ the Type-3 primes are more frequent. For the
concrete meaning of this weird paradoxical claim, google for
\href{https://en.wikipedia.org/wiki/Chebyshev's_bias}{\textquotedblleft
Chebyshev's bias\textquotedblright}.)

Lemma \ref{lem.Z[i].gauss.prime.3mod4} says that all Type-3 primes are
Gaussian primes. What about the other primes -- are they Gaussian primes? We
already know that $2$ is not, since $2=\left(  1+i\right)  \left(  1-i\right)
$. Likewise, $5$ is not, since $5=\left(  1+2i\right)  \left(  1-2i\right)  $.
Likewise, $13$ is not, since $13=\left(  2+3i\right)  \left(  2-3i\right)  $.

This may suggest that primes $p$ satisfying $p=2$ or $p\equiv
1\operatorname{mod}4$ (that is, primes of Type 1 or Type 2) not only factor
nontrivially, but actually factor as%
\[
p=\left(  x+yi\right)  \left(  x-yi\right)  \ \ \ \ \ \ \ \ \ \ \text{for some
integers }x\text{ and }y.
\]
Of course, this equation rewrites as $p=x^{2}+y^{2}$. Thus, we are back to
asking Question~\ref{quest.intro.sum-of-2sq.1}, at least for primes.

We shall now answer this question, and actually prove a bit more:

\begin{theorem}
\label{thm.Z[i].gauss.prime.1mod4}Let $p$ be a prime such that either $p=2$ or
$p\equiv1\operatorname{mod}4$.

\textbf{(a)} There exist integers $x$ and $y$ such that $p=x^{2}+y^{2}$.

\textbf{(b)} If $p\equiv1\operatorname{mod}4$, then there exist exactly $8$
pairs $\left(  x,y\right)  $ of integers such that $p=x^{2}+y^{2}$. (For
example, if $p=5$, then these $8$ pairs are $\left(  1,2\right)  $, $\left(
2,1\right)  $, $\left(  1,-2\right)  $, $\left(  -2,1\right)  $, $\left(
-1,2\right)  $, $\left(  2,-1\right)  $, $\left(  -1,-2\right)  $ and $\left(
-2,-1\right)  $.)

\textbf{(c)} There exists a Gaussian prime $\pi$ such that $p=\pi\overline
{\pi}$.

\textbf{(d)} The Gaussian integer $p$ itself is not a Gaussian prime.

\textbf{(e)} Assume that $p\equiv1\operatorname{mod}4$. Consider the Gaussian
prime $\pi$ from Theorem \ref{thm.Z[i].gauss.prime.1mod4} \textbf{(c)}. Then,
$\overline{\pi}$ is also a Gaussian prime, and we do not have $\pi
\sim\overline{\pi}$.
\end{theorem}

For example, the Type-1 prime $17$ satisfies%
\begin{align*}
17  &  =1^{2}+4^{2}=\left(  1+4i\right)  \left(  1-4i\right)  =\left(
1+4i\right)  \left(  \overline{1+4i}\right) \\
&  =\left(  1-4i\right)  \left(  \overline{1-4i}\right)  =\left(  4+i\right)
\left(  \overline{4+i}\right)  .
\end{align*}


Note that the claim of Theorem \ref{thm.Z[i].gauss.prime.1mod4} \textbf{(a)}
(at least for $p\neq2$) also appears in \cite[Proposition in Chapter
4]{AigZie}, with a very different proof.

Before we can prove Theorem \ref{thm.Z[i].gauss.prime.1mod4}, we will have to
build up the theory of Gaussian primes a bit more. We first state the
Gaussian-integer analogue of Proposition \ref{prop.ent.prime.div-or-coprime}:

\begin{proposition}
\label{prop.Z[i].prime.div-or-coprime}Let $\pi$ be a Gaussian prime. Let
$\alpha\in\mathbb{Z}\left[  i\right]  $. Then, either $\pi\mid\alpha$ or
$\pi\perp\alpha$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].prime.div-or-coprime}.]Analogous to our
proof of Proposition \ref{prop.ent.prime.div-or-coprime} above.
\end{proof}

Next, we state the analogue to Theorem \ref{thm.ent.prime.pab}:

\begin{theorem}
\label{thm.Z[i].prime.pab}Let $\pi$ be a Gaussian prime. Let $\alpha,\beta
\in\mathbb{Z}\left[  i\right]  $ such that $\pi\mid\alpha\beta$. Then,
$\pi\mid\alpha$ or $\pi\mid\beta$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.Z[i].prime.pab}.]Analogous to our proof of Theorem
\ref{thm.ent.prime.pab} above.
\end{proof}

We also need the following simple fact:

\begin{lemma}
\label{lem.Z[i].prime.Nprime}Let $\alpha$ be a Gaussian integer. If
$\operatorname*{N}\left(  \alpha\right)  $ is prime, then $\alpha$ is a
Gaussian prime.
\end{lemma}

This shows, for example, that $1+i$ and $1+2i$ are Gaussian primes. The
converse of Lemma \ref{lem.Z[i].prime.Nprime} does not hold (e.g., since $3$
is a Gaussian prime, but $\operatorname*{N}\left(  3\right)  =9$ is not prime).

\begin{proof}
[Proof of Lemma \ref{lem.Z[i].prime.Nprime}.]Assume that $\operatorname*{N}%
\left(  \alpha\right)  $ is prime. We must prove that $\alpha$ is a Gaussian prime.

Assume the contrary. Thus, $\alpha$ is not a Gaussian prime, but $\alpha$ is
neither zero nor a unit (since $\operatorname*{N}\left(  \alpha\right)  $ is
prime and therefore $>1$). Hence, $\alpha$ has a Gaussian divisor $\delta$
that is neither a unit nor unit-equivalent to $\alpha$. Consider this $\delta
$. Thus, there exists a Gaussian integer $\varepsilon$ such that
$\alpha=\delta\varepsilon$. Consider this $\varepsilon$.

From $\alpha=\delta\varepsilon$, we obtain $\operatorname*{N}\left(
\alpha\right)  =\operatorname*{N}\left(  \delta\varepsilon\right)
=\operatorname*{N}\left(  \delta\right)  \cdot\operatorname*{N}\left(
\varepsilon\right)  $. Hence, $\operatorname*{N}\left(  \delta\right)
\cdot\operatorname*{N}\left(  \varepsilon\right)  =\operatorname*{N}\left(
\alpha\right)  $. Since $\operatorname*{N}\left(  \delta\right)  $ and
$\operatorname*{N}\left(  \varepsilon\right)  $ are nonnegative integers and
$\operatorname*{N}\left(  \alpha\right)  $ is prime, this leaves only two options:

\begin{itemize}
\item \textbf{either} $\operatorname*{N}\left(  \delta\right)  =1$ and
$\operatorname*{N}\left(  \varepsilon\right)  =\operatorname*{N}\left(
\alpha\right)  $,

\item \textbf{or }$\operatorname*{N}\left(  \delta\right)  =\operatorname*{N}%
\left(  \alpha\right)  $ and $\operatorname*{N}\left(  \varepsilon\right)  =1$.
\end{itemize}

The first of these two options would cause $\delta$ to be a unit, which is
impossible (by the definition of $\delta$). Thus, the second option must be
true. In other words, we have $\operatorname*{N}\left(  \delta\right)
=\operatorname*{N}\left(  \alpha\right)  $ and $\operatorname*{N}\left(
\varepsilon\right)  =1$. But $\operatorname*{N}\left(  \varepsilon\right)  =1$
shows that $\varepsilon$ is a unit, and thus $\alpha\sim\delta$ (since
$\alpha=\delta\varepsilon$). This contradicts the assumption that $\delta$ is
not unit-equivalent to $\alpha$. This contradiction proves that our assumption
was wrong. Lemma \ref{lem.Z[i].prime.Nprime} is proven.
\end{proof}

Next, let us show that conjugation does not change Gaussian primeness:

\begin{lemma}
\label{lem.Z[i].prime.conj}Let $\pi$ be a Gaussian prime. Then, $\overline
{\pi}$ is a Gaussian prime, too.
\end{lemma}

\begin{proof}
Easy: Conjugation reflects everything across the x-axis, without changing any
properties. For example: If $\delta$ is a Gaussian divisor of $\pi$, then
$\overline{\delta}$ is a Gaussian divisor of $\overline{\pi}$, and vice versa.
If $\delta$ is not a unit, then $\overline{\delta}$ is not a unit, and vice
versa. If $\delta$ is not unit-equivalent to $\pi$, then $\overline{\delta}$
is not unit-equivalent to $\overline{\pi}$, and vice versa. If $\pi$ is
nonzero and not a unit, then $\overline{\pi}$ is nonzero and not a unit, and
vice versa. Thus, if you compare what it means for $\pi$ to be a Gaussian
prime with what it means for $\overline{\pi}$ to be a Gaussian prime, then you
will see that it means the same thing.
\end{proof}

Now, we can prove Theorem \ref{thm.Z[i].gauss.prime.1mod4}:

\begin{proof}
[Proof of Theorem \ref{thm.Z[i].gauss.prime.1mod4}.]\textbf{(d)} Assume the
contrary. Thus, $p$ is a Gaussian prime. But $2$ is not a Gaussian prime (by
Example \ref{exa.Z[i].gauss.2notprime}). Hence, $p\neq2$. Thus, $p\equiv
1\operatorname{mod}4$ (since we assumed that either $p=2$ or $p\equiv
1\operatorname{mod}4$). Therefore, $p=2k+1$ for some \textbf{even}
$k\in\mathbb{N}$. Consider this $k$.

Exercise \ref{exe.ent.wilson.-1qr} yields $k!^{2}\equiv-\underbrace{\left(
-1\right)  ^{k}}_{\substack{=1\\\text{(since }k\text{ is even)}}%
}=-1\operatorname{mod}p$. Set $u=k!$; thus, this becomes $u^{2}\equiv
-1\operatorname{mod}p$. In other words,
\[
p\mid u^{2}-\left(  -1\right)  =u^{2}-i^{2}=\left(  u+i\right)  \left(
u-i\right)  .
\]
This is a divisibility in $\mathbb{Z}$, thus also a divisibility in
$\mathbb{Z}\left[  i\right]  $.

Hence, Theorem \ref{thm.Z[i].prime.pab} (applied to $\pi=p$, $\alpha=u+i$ and
$\beta=u-i$) yields that $p\mid u+i$ or $p\mid u-i$ (since $p$ is a Gaussian
prime). But if $p\mid u-i$, then $p\mid u+i$ holds as well (since Exercise
\ref{exe.Z[i].div.conj} shows that $p\mid u-i$ implies $\overline{p}%
\mid\overline{u-i}=u+i$, which means $p=\overline{p}\mid u+i$). Hence, we have
$p\mid u+i$ in both cases.

This means that there exists a Gaussian integer $\gamma$ such that
$u+i=p\gamma$. Consider this $\gamma$. Write $\gamma$ as $\gamma=\left(
a,b\right)  $ with $a,b\in\mathbb{Z}$. Then, $\left(  u,1\right)
=u+i=p\underbrace{\gamma}_{=\left(  a,b\right)  }=p\left(  a,b\right)
=\left(  pa,pb\right)  $. Thus, $u=pa$ and $1=pb$. But $1=pb$ leads to
$p\mid1$ in $\mathbb{Z}$ (since $b\in\mathbb{Z}$), which is absurd (since $p$
is prime). This contradiction shows that our assumption was wrong. Thus,
Theorem \ref{thm.Z[i].gauss.prime.1mod4} \textbf{(d)} is proven.

\textbf{(a)} We have $\operatorname*{N}\left(  p\right)  =p^{2}+0^{2}=p^{2}>1$
(since $p>1$). Thus, $p$ is nonzero and not a unit. But Theorem
\ref{thm.Z[i].gauss.prime.1mod4} \textbf{(d)} shows that $p$ is not a Gaussian
prime. Since $p$ is nonzero and not a unit, this shows that $p$ has a Gaussian
divisor $\delta$ that is neither a unit nor unit-equivalent to $p$. Consider
this $\delta$. Thus, there exists a Gaussian integer $\varepsilon$ such that
$p=\delta\varepsilon$. Consider this $\varepsilon$.

From $p=\delta\varepsilon$, we obtain $\operatorname*{N}\left(  p\right)
=\operatorname*{N}\left(  \delta\varepsilon\right)  =\operatorname*{N}\left(
\delta\right)  \cdot\operatorname*{N}\left(  \varepsilon\right)  $. Hence,
$\operatorname*{N}\left(  \delta\right)  \cdot\operatorname*{N}\left(
\varepsilon\right)  =\operatorname*{N}\left(  p\right)  =p^{2}+0^{2}=p^{2}$.
Since $\operatorname*{N}\left(  \delta\right)  $ and $\operatorname*{N}\left(
\varepsilon\right)  $ are nonnegative integers (and $p$ is prime), this leaves
only three options:

\begin{itemize}
\item \textbf{either} $\operatorname*{N}\left(  \delta\right)  =1$ and
$\operatorname*{N}\left(  \varepsilon\right)  =p^{2}$,

\item \textbf{or }$\operatorname*{N}\left(  \delta\right)  =p$ and
$\operatorname*{N}\left(  \varepsilon\right)  =p$,

\item \textbf{or }$\operatorname*{N}\left(  \delta\right)  =p^{2}$ and
$\operatorname*{N}\left(  \varepsilon\right)  =1$.
\end{itemize}

The first of these three options would cause $\delta$ to be a unit, which is
impossible (by the definition of $\delta$).

The third of these three options would cause $\delta$ to be unit-equivalent to
$p$ (since $\varepsilon$ would be a unit, and $p=\delta\varepsilon$), which is
impossible (by the definition of $\delta$).

Thus, the second of these three options must hold. In other words,
$\operatorname*{N}\left(  \delta\right)  =p$ and $\operatorname*{N}\left(
\varepsilon\right)  =p$. Now, write the Gaussian integer $\delta$ as
$\delta=\left(  a,b\right)  $ with integers $a,b$. Then, $\operatorname*{N}%
\left(  \delta\right)  =a^{2}+b^{2}$, so that $a^{2}+b^{2}=\operatorname*{N}%
\left(  \delta\right)  =p$. Hence, there exist integers $x$ and $y$ such that
$p=x^{2}+y^{2}$ (namely, $x=a$ and $y=b$). This proves Theorem
\ref{thm.Z[i].gauss.prime.1mod4} \textbf{(a)}.

\textbf{(c)} Theorem \ref{thm.Z[i].gauss.prime.1mod4} \textbf{(a)} shows that
there exist integers $x$ and $y$ such that $p=x^{2}+y^{2}$. Consider these $x$
and $y$. Let $\pi$ be the Gaussian integer $x+iy$. Then, $\pi\overline{\pi
}=\left(  x+iy\right)  \left(  \overline{x+iy}\right)  =x^{2}+y^{2}=p$. Thus,
$p=\pi\overline{\pi}$. It remains to prove that $\pi$ is a Gaussian prime.

The norm of $\pi$ is $\operatorname*{N}\left(  \pi\right)  =x^{2}+y^{2}=p$,
which is prime. Hence, Lemma \ref{lem.Z[i].prime.Nprime} (applied to
$\alpha=\pi$) shows that $\pi$ is a Gaussian prime. This completes the proof
of Theorem \ref{thm.Z[i].gauss.prime.1mod4} \textbf{(c)}.

\textbf{(b)} Assume that $p\equiv1\operatorname{mod}4$. We must prove that
there exist exactly $8$ pairs $\left(  x,y\right)  $ of integers such that
$p=x^{2}+y^{2}$.

One such pair is provided by Theorem \ref{thm.Z[i].gauss.prime.1mod4}
\textbf{(a)}. Let us call it $\left(  a,b\right)  $. To get the other $7$, we
notice that it must satisfy $a\neq0$ (since $p$ is not a perfect square) and
$b\neq0$ (for the same reason) and $a\neq b$ (since $p$ is not $2n^{2}$ for
any $n\in\mathbb{Z}$), and thus it leads to $7$ other pairs%
\begin{align*}
&  \left(  b,a\right)  ,\ \ \ \ \ \ \ \ \ \ \left(  a,-b\right)
,\ \ \ \ \ \ \ \ \ \ \left(  -b,a\right)  ,\ \ \ \ \ \ \ \ \ \ \left(
-a,b\right)  ,\\
&  \left(  b,-a\right)  ,\ \ \ \ \ \ \ \ \ \ \left(  -a,-b\right)
,\ \ \ \ \ \ \ \ \ \ \left(  -b,-a\right)  ,
\end{align*}
which are all distinct. It thus remains to prove that these altogether $8$
pairs are the \textbf{only} pairs $\left(  x,y\right)  $ of integers such that
$p=x^{2}+y^{2}$.

In other words, we need to prove that if $\left(  x,y\right)  $ is a pair of
integers such that $p=x^{2}+y^{2}$, then $\left(  x,y\right)  $ is one of the
above $8$ pairs. So let us fix a pair $\left(  x,y\right)  $ of integers such
that $p=x^{2}+y^{2}$. We must prove that $\left(  x,y\right)  $ is one of the
above $8$ pairs. In other words, we must prove that $\left(  x,y\right)  $
equals $\left(  a,b\right)  $ up to order and signs. This is equivalent to
proving that $x+yi\sim a+bi$ or $x-yi\sim a+bi$.

Set $\pi=x+yi$ and $\alpha=a+bi$. Then, $\pi$ and $\alpha$ are Gaussian
integers having norms $\operatorname*{N}\left(  \pi\right)  =x^{2}+y^{2}=p$
and $\operatorname*{N}\left(  \alpha\right)  =a^{2}+b^{2}=p$ (by the
definition of $\left(  a,b\right)  $). Thus, $\operatorname*{N}\left(
\alpha\right)  =p$ is prime. Hence, Lemma \ref{lem.Z[i].prime.Nprime} shows
that $\alpha$ is a Gaussian prime. Similarly, $\pi$ is a Gaussian prime.

We must prove that $x+yi\sim a+bi$ or $x-yi\sim a+bi$. In other words, we must
prove that $\pi\sim\alpha$ or $\overline{\pi}\sim\alpha$ (since $x+yi=\pi$ and
$x-yi=\overline{\pi}$ and $a+bi=\alpha$).

Now,
\[
\alpha=a+bi\mid\left(  a+bi\right)  \left(  a-bi\right)  =a^{2}+b^{2}%
=p=\operatorname*{N}\left(  \pi\right)  =\pi\overline{\pi}.
\]
Since $\alpha$ is a Gaussian prime, this yields that $\alpha\mid\pi$ or
$\alpha\mid\overline{\pi}$ (by Theorem \ref{thm.Z[i].prime.pab}). Thus, we are
in one of the following two Cases:

\textit{Case 1:} We have $\alpha\mid\pi$.

\textit{Case 2:} We have $\alpha\mid\overline{\pi}$.

In Case 1, we have $\alpha\mid\pi$. In other words, there exists a Gaussian
integer $\xi$ such that $\pi=\alpha\xi$. Consider this $\xi$. We have
$\pi=\alpha\xi$, thus $\operatorname*{N}\left(  \pi\right)  =\operatorname*{N}%
\left(  \alpha\xi\right)  =\operatorname*{N}\left(  \alpha\right)
\operatorname*{N}\left(  \xi\right)  $. Since both $\operatorname*{N}\left(
\pi\right)  $ and $\operatorname*{N}\left(  \alpha\right)  $ are $p$ (because
$\operatorname*{N}\left(  \pi\right)  =x^{2}+y^{2}=p$ and $\operatorname*{N}%
\left(  \alpha\right)  =a^{2}+b^{2}=p$), this rewrites as
$p=p\operatorname*{N}\left(  \xi\right)  $. We can cancel $p$ from this
equality, and obtain $\operatorname*{N}\left(  \xi\right)  =1$. Hence, $\xi$
is a unit. Therefore, $\pi=\alpha\xi$ yields $\pi\sim\alpha$. In other words,
$x+yi\sim a+bi$ (since $\pi=x+yi$ and $\alpha=a+bi$).

In Case 2, we similarly obtain $x-yi\sim a+bi$ (since $\operatorname*{N}%
\left(  \overline{\pi}\right)  =\operatorname*{N}\left(  \pi\right)
=x^{2}+y^{2}=p$ and $\overline{\pi}=x-yi$).

Hence, in both Cases, we have proven that $x+yi\sim a+bi$ or $x-yi\sim a+bi$.
This completes our proof of Theorem \ref{thm.Z[i].gauss.prime.1mod4}
\textbf{(b)}.

\textbf{(e)} Conjugation is a symmetry which preserves divisibility (by
Exercise \ref{exe.Z[i].div.conj}). Thus, since $\pi$ is a Gaussian prime, its
conjugate $\overline{\pi}$ is a Gaussian prime as well. It remains to prove
that we do not have $\pi\sim\overline{\pi}$.

Assume the contrary. Thus, $\pi\sim\overline{\pi}$. Write the Gaussian prime
$\pi$ in the form $\pi=x+yi$ for some $x,y\in\mathbb{Z}$. Thus, $\overline
{\pi}=x-yi$ and $\operatorname*{N}\left(  \pi\right)  =x^{2}+y^{2}$;
therefore, $p=\pi\overline{\pi}=\operatorname*{N}\left(  \pi\right)
=x^{2}+y^{2}$. But $\pi\sim\overline{\pi}$. Hence, there exists a unit
$\gamma$ such that $\overline{\pi}=\gamma\pi$. Consider this $\gamma$. Since
$\gamma$ is a unit, we have $\gamma\in\left\{  1,-1,i,-i\right\}  $ (by
Proposition \ref{prop.Z[i].gauss.units}). So we are in one of the following
four cases:

\textit{Case 1:} We have $\gamma=1$.

\textit{Case 2:} We have $\gamma=-1$.

\textit{Case 3:} We have $\gamma=i$.

\textit{Case 4:} We have $\gamma=-i$.

Let us first consider Case 1. In this case, we have $\gamma=1$. Now,
$x-yi=\overline{\pi}=\underbrace{\gamma}_{=1}\underbrace{\pi}_{=x+yi}=x+yi$.
Hence, $y=0$. Now, $p=x^{2}+y^{2}=x^{2}$ (since $y=0$). This contradicts the
fact that $p$ (being a prime) cannot be a square.

Let us first consider Case 2. In this case, we have $\gamma=-1$. Now,
$x-yi=\overline{\pi}=\underbrace{\gamma}_{=-1}\underbrace{\pi}_{=x+yi}%
=-\left(  x+yi\right)  =-x-yi$. Hence, $x=0$. Now, $p=x^{2}+y^{2}=y^{2}$
(since $x=0$). This contradicts the fact that $p$ (being a prime) cannot be a square.

Let us first consider Case 3. In this case, we have $\gamma=i$. Now,
$x-yi=\overline{\pi}=\underbrace{\gamma}_{=i}\underbrace{\pi}_{=x+yi}=i\left(
x+yi\right)  =-y+xi$. Hence, $x=-y$. Now, $p=x^{2}+y^{2}=2y^{2}$ (since
$x=-y$). This contradicts the fact that $p$ is odd (since $p\equiv
1\operatorname{mod}4$).

Let us first consider Case 4. In this case, we have $\gamma=-i$. Now,
$x-yi=\overline{\pi}=\underbrace{\gamma}_{=-i}\underbrace{\pi}_{=x+yi}%
=-i\left(  x+yi\right)  =y-xi$. Hence, $x=y$. Now, $p=x^{2}+y^{2}=2y^{2}$
(since $x=y$). This contradicts the fact that $p$ is odd (since $p\equiv
1\operatorname{mod}4$).

We have thus obtained a contradiction in each of our four cases. Hence, we
always get a contradiction. Thus, the proof of Theorem
\ref{thm.Z[i].gauss.prime.1mod4} \textbf{(e)} is complete.
\end{proof}

We have thus answered Question \ref{quest.intro.sum-of-2sq.2} \textbf{(b)} in
the case when $n$ is a prime: We have shown that a prime $p$ is a sum of two
perfect squares if and only if either $p=2$ or $p\equiv1\operatorname{mod}4$;
and we have shown that the number of pairs $\left(  x,y\right)  \in
\mathbb{Z}^{2}$ satisfying $p=x^{2}+y^{2}$ is $8$ when $p\equiv
1\operatorname{mod}4$ and is $4$ when $p=2$ (the latter claim is easy to check).

What about the case of arbitrary $n$?

For $n=21$, we have $n\equiv1\operatorname{mod}4$, but $n$ is not a sum of two
perfect squares. So the answer we gave for the case of prime $n$ does not
generalize to arbitrary $n$.

\begin{center}
\textbf{2019-03-13 lecture}
\end{center}

It turns out that the right answer for arbitrary $n$ will come from the
analogue of prime factorization in $\mathbb{Z}\left[  i\right]  $.

\begin{noncompile}
We begin with the following definition:

\begin{definition}
Let $\nu$ be a Gaussian integer. A \textit{Gaussian prime factor} of $\nu$
means a Gaussian prime $\pi$ such that $\pi\mid\nu$. Some say
\textquotedblleft prime divisor\textquotedblright\ instead of
\textquotedblleft prime factor\textquotedblright.
\end{definition}
\end{noncompile}

\begin{proposition}
\label{prop.Z[i].prime.ex-pri-div}Let $\nu$ be a nonzero Gaussian integer that
is not a unit. Then, there exists at least one Gaussian prime $\pi$ such that
$\pi\mid\nu$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].prime.ex-pri-div}.]This is an analogue of
Proposition \ref{prop.ent.prime.ex-pri-div}, and can be proven in the same
way. Just replace $d$ (the smallest positive divisor of $n$) by $\delta$ (a
Gaussian divisor of $\nu$ that is not a unit and has the smallest norm among
all such divisors).
\end{proof}

\begin{proposition}
\label{prop.Z[i].prime.fac-ex}Let $\nu$ be a nonzero Gaussian integer. Then,
$\nu$ is unit-equivalent to a certain product of finitely many Gaussian primes.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.Z[i].prime.fac-ex}.]This is an analogue of
Proposition \ref{prop.ent.prime.fac-ex}, and can be proven in the same way:
Strong induction on $\operatorname*{N}\left(  \nu\right)  $. The main
difference is that the case of $\operatorname*{N}\left(  \nu\right)  =1$ leads
to $\nu$ being a unit (hence unit-equivalent to an empty product of Gaussian
primes) rather than $\nu$ being $1$.
\end{proof}

\begin{definition}
Let $\nu$ be a nonzero Gaussian integer. A \textit{Gaussian prime
factorization} of $\nu$ means a tuple $\left(  \pi_{1},\pi_{2},\ldots,\pi
_{k}\right)  $ of Gaussian primes such that $\nu\sim\pi_{1}\pi_{2}\cdots
\pi_{k}$.
\end{definition}

Why did we require only $\nu\sim\pi_{1}\pi_{2}\cdots\pi_{k}$ and not $\nu
=\pi_{1}\pi_{2}\cdots\pi_{k}$ ? Because we want $-1$ to have a Gaussian prime
factorization, but there is no way to literally write $-1$ as a product of
Gaussian primes.

\begin{exercise}
\label{exe.Z[i].prime.dist=cop}Let $\pi$ and $\kappa$ be two Gaussian primes
that do not satisfy $\pi\sim\kappa$. Prove that $\pi\perp\kappa$.
\end{exercise}

\begin{proof}
[Solution sketch.]This is an analogue of Exercise \ref{exe.ent.prime.dist=cop}%
, and its solution goes accordingly.
\end{proof}

\begin{lemma}
\label{lem.Z[i].prime.vp-wd}Let $\pi$ be a Gaussian prime. Let $\alpha$ be a
nonzero Gaussian integer. Then, there exists a largest $m\in\mathbb{N}$ such
that $\pi^{m}\mid\alpha$.
\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.Z[i].prime.vp-wd}.]This is an analogue of Lemma
\ref{lem.ent.prime.vp-wd} for Gaussian integers (with $\pi$ and $\alpha$
playing the roles of $p$ and $n$), and the proof also proceeds similarly. Here
are the main differences: Instead of $p>1$, we now have $\operatorname*{N}%
\left(  \pi\right)  >1$ (which is because $\pi$ is nonzero and not a unit).
Again, let $W$ be the set of all $m\in\mathbb{N}$ satisfying $\pi^{m}%
\mid\alpha$. Then, $W$ is a nonempty set of integers (this is proven as in the
proof of Lemma \ref{lem.ent.prime.vp-wd}). Let $u=\operatorname*{N}\left(
\alpha\right)  $. Thus, $u\in\mathbb{N}$. It is easy to see that
$\operatorname*{N}\left(  \pi^{k}\right)  >k$ for each $k\in\mathbb{N}$
(indeed, Corollary \ref{cor.CC.norm.pow} \textbf{(b)} yields
$\operatorname*{N}\left(  \pi^{k}\right)  =\left(  \operatorname*{N}\left(
\pi\right)  \right)  ^{k}>k$ by Exercise \ref{exe.ent.prime.vp-lem} (applied
to $p=\operatorname*{N}\left(  \pi\right)  $)). From this point, we proceed
similarly as in the proof of Lemma \ref{lem.ent.prime.vp-wd}.
\end{proof}

Similarly to Definition \ref{def.ent.prime.vp}, we can define $\pi$-adic valuations:

\begin{definition}
\label{def.Z[i].prime.vp}Let $\pi$ be a Gaussian prime.

\textbf{(a)} Let $\alpha$ be a nonzero Gaussian integer. Then, $v_{\pi}\left(
\alpha\right)  $ shall denote the largest $m\in\mathbb{N}$ such that $\pi
^{m}\mid\alpha$. This is well-defined (by Lemma \ref{lem.Z[i].prime.vp-wd}).
This nonnegative integer $v_{\pi}\left(  \alpha\right)  $ will be called the
$\pi$\textit{-valuation} (or the $\pi$\textit{-adic valuation}) of $\alpha$.

\textbf{(b)} We extend this definition of $v_{\pi}\left(  \alpha\right)  $ to
the case of $\alpha=0$ as follows: Set $v_{\pi}\left(  0\right)  =\infty$.
\end{definition}

Definition \ref{def.Z[i].prime.vp} does not conflict with Definition
\ref{def.ent.prime.vp}. Indeed, if a prime $p$ happens to also be a Gaussian
prime, and if $n$ is an integer, then both definitions yield the same value of
$v_{p}\left(  n\right)  $ (since $p^{m}\mid a$ means the same thing whether we
treat $p$ and $a$ as integers or as Gaussian integers).

\begin{theorem}
\label{thm.Z[i].prime.vp-ring}Let $\pi$ be a Gaussian prime.

\textbf{(a)} We have $v_{\pi}\left(  \alpha\beta\right)  =v_{\pi}\left(
\alpha\right)  +v_{\pi}\left(  \beta\right)  $ for any two Gaussian integers
$\alpha$ and $\beta$.

\textbf{(b)} We have $v_{\pi}\left(  \alpha+\beta\right)  \geq\min\left\{
v_{\pi}\left(  \alpha\right)  ,v_{\pi}\left(  \beta\right)  \right\}  $ for
any two Gaussian integers $\alpha$ and $\beta$.

\textbf{(c)} We have $v_{\pi}\left(  1\right)  =0$. More generally, $v_{\pi
}\left(  \alpha\right)  =0$ for any unit $\alpha\in\mathbb{Z}\left[  i\right]
$.

\textbf{(d)} We have $v_{\pi}\left(  \kappa\right)  =%
\begin{cases}
1, & \text{if }\kappa\sim\pi;\\
0, & \text{otherwise}%
\end{cases}
$ for any Gaussian prime $\kappa$.
\end{theorem}

\begin{proof}
This is an analogue of Theorem \ref{thm.ent.prime.vp-ring}, and is proven similarly.
\end{proof}

\begin{proposition}
\label{prop.Z[i].prime.mult-in-pf}Let $\nu$ be a nonzero Gaussian integer. Let
$\left(  \alpha_{1},\alpha_{2},\ldots,\alpha_{k}\right)  $ be a Gaussian prime
factorization of $\nu$. Let $\pi$ be a Gaussian prime. Then,%
\begin{align*}
&  \left(  \text{the number of times a Gaussian integer unit-equivalent to
}\pi\right. \\
&  \ \ \ \ \ \ \ \ \ \ \left.  \text{appears in the tuple }\left(  \alpha
_{1},\alpha_{2},\ldots,\alpha_{k}\right)  \right) \\
&  =\left(  \text{the number of times }\left[  \pi\right]  _{\sim}\text{
appears in the tuple }\left(  \left[  \alpha_{1}\right]  _{\sim},\left[
\alpha_{2}\right]  _{\sim},\ldots,\left[  \alpha_{k}\right]  _{\sim}\right)
\right) \\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,k\right\}  \text{
such that }\alpha_{i}\sim\pi\right) \\
&  =\left(  \text{the number of }i\in\left\{  1,2,\ldots,k\right\}  \text{
such that }\left[  \alpha_{i}\right]  _{\sim}=\left[  \pi\right]  _{\sim
}\right) \\
&  =v_{\pi}\left(  \nu\right)  .
\end{align*}

\end{proposition}

\begin{proof}
This is an analogue of Proposition \ref{prop.ent.prime.mult-in-pf}, and is
proven similarly.
\end{proof}

\begin{theorem}
\label{thm.Z[i].prime.fac-uni}Let $\nu$ be a nonzero Gaussian integer.

\textbf{(a)} There exists a Gaussian prime factorization of $\nu$.

\textbf{(b)} Any two such factorizations differ only by reordering their
entries and multiplying them by units. More precisely: If $\left(  \alpha
_{1},\alpha_{2},\ldots,\alpha_{k}\right)  $ and $\left(  \beta_{1},\beta
_{2},\ldots,\beta_{\ell}\right)  $ are two Gaussian prime factorizations of
$\nu$, then $\left(  \left[  \alpha_{1}\right]  _{\sim},\left[  \alpha
_{2}\right]  _{\sim},\ldots,\left[  \alpha_{k}\right]  _{\sim}\right)  $ is a
permutation of $\left(  \left[  \beta_{1}\right]  _{\sim},\left[  \beta
_{2}\right]  _{\sim},\ldots,\left[  \beta_{\ell}\right]  _{\sim}\right)  $.
\end{theorem}

\begin{proof}
This is an analogue of Theorem \ref{thm.ent.prime.fac-uni}, and is proven similarly.
\end{proof}

\begin{example}
We have
\[
5=\left(  1+2i\right)  \left(  1-2i\right)  =\left(  2+i\right)  \left(
2-i\right)  .
\]
Thus, both $\left(  1+2i,1-2i\right)  $ and $\left(  2+i,2-i\right)  $ are
Gaussian prime factorizations of $5$. They may look different, but actually
you get the second one from the first by swapping the two entries and
multiplying the first entry by the unit $i$ and multiplying the second entry
by the unit $-i$. This perfectly agrees with Theorem
\ref{thm.Z[i].prime.fac-uni}.
\end{example}

In analogy to Exercise \ref{exe.ent.prime.vp-abs} (and with the same proof),
we have:

\begin{exercise}
\label{exe.Z[i].prime.vp-abs}Let $\pi$ be a Gaussian prime. Let $\alpha
,\beta\in\mathbb{Z}\left[  i\right]  $ be such that $\alpha\sim\beta$. Prove
that $v_{\pi}\left(  \alpha\right)  =v_{\pi}\left(  \beta\right)  $.
\end{exercise}

We also have the following:

\begin{exercise}
\label{exe.Z[i].prime.vp-conj}Let $\pi$ be a Gaussian prime. Let $\alpha
\in\mathbb{Z}\left[  i\right]  $. Then, $\overline{\pi}$ is a Gaussian prime
as well, and satisfies%
\[
v_{\overline{\pi}}\left(  \overline{\alpha}\right)  =v_{\pi}\left(
\alpha\right)  .
\]

\end{exercise}

\begin{proof}
[Solution sketch.]Conjugation is a symmetry, taking Gaussian integers to
Gaussian integers and preserving divisibility. Thus, any $i\in\mathbb{N}$
satisfying $\pi^{i}\mid\alpha$ must also satisfy $\overline{\pi}^{i}%
\mid\overline{\alpha}$, and vice versa. Hence, $v_{\overline{\pi}}\left(
\overline{\alpha}\right)  =v_{\pi}\left(  \alpha\right)  $ easily follows.
\end{proof}

\begin{definition}
For the rest of this section, let $\operatorname*{GP}$ be the set of all
Gaussian primes of the form $x+yi$ with $x\in\left\{  1,2,3,\ldots\right\}  $
and $y\in\left\{  0,1,2,\ldots\right\}  $.
\end{definition}

The following is easy to see:

\begin{lemma}
\label{lem.Z[i].prime.GP-reps}Let $\pi$ be a Gaussian prime. Then, there
exists \textbf{exactly one} $\sigma\in\operatorname*{GP}$ such that $\pi
\sim\sigma$.
\end{lemma}

In other words, each Gaussian prime is unit-equivalent to exactly one
$\sigma\in\operatorname*{GP}$. Thus, the set $\operatorname*{GP}$ contains
exactly one element of each unit-equivalence class of Gaussian primes. (Thus,
$\operatorname*{GP}$ is what is called a \textquotedblleft system of distinct
representatives\textquotedblright\ for the unit-equivalence classes of all
Gaussian primes.)

In analogy to Corollary \ref{cor.ent.prime.can-facZ}, we have:

\begin{corollary}
\label{cor.Z[i].prime.can-facZ}Let $\alpha$ be a nonzero Gaussian integer.
Then,
\[
\alpha\sim\prod_{\pi\in\operatorname*{GP}}\pi^{v_{\pi}\left(  \alpha\right)
}.
\]


Here, the infinite product $\prod_{\pi\in\operatorname*{GP}}\pi^{v_{\pi
}\left(  \alpha\right)  }$ is well-defined (according to the Gaussian-integer
analogue of Lemma \ref{lem.ent.prime.vpn=0} \textbf{(b)}).
\end{corollary}

In analogy to Proposition \ref{prop.ent.prime.n|m}, we have the following:

\begin{proposition}
\label{prop.Z[i].prime.n|m}Let $\alpha$ and $\beta$ be Gaussian integers.
Then, $\alpha\mid\beta$ if and only if each Gaussian prime $\pi$ satisfies
$v_{\pi}\left(  \alpha\right)  \leq v_{\pi}\left(  \beta\right)  $.
\end{proposition}

If $\alpha$ is a Gaussian integer, and $c$ is a unit-equivalence class of
Gaussian integers, then either all elements of $c$ divide $\alpha$ or none of
them does.\footnote{This is easy to check. Indeed, it boils down to the fact
that any two elements of $c$ divide each other (because they are
unit-equivalent).} Thus, we can talk of \textit{unit-equivalence classes of
Gaussian divisors of }$\alpha$ (by which we mean unit-equivalence classes of
Gaussian integers whose elements all divide $\alpha$).

Here is an analogue of Proposition \ref{prop.ent.count-divs} for Gaussian integers:

\begin{proposition}
Let $\alpha\in\mathbb{Z}\left[  i\right]  $ be a nonzero Gaussian integer. Then:

\textbf{(a)} The product $\prod_{\pi\in\operatorname*{GP}}\left(  v_{\pi
}\left(  \alpha\right)  +1\right)  $ is well-defined, since all but finitely
many of its factors are $1$.

\textbf{(b)} We have%
\begin{align*}
&  \left(  \text{the number of unit-equivalence classes of Gaussian divisors
of }\alpha\right) \\
=  &  \prod_{\pi\in\operatorname*{GP}}\left(  v_{\pi}\left(  \alpha\right)
+1\right)  .
\end{align*}


\textbf{(c)} We have%
\[
\left(  \text{the number of Gaussian divisors of }\alpha\right)  =4\cdot
\prod_{\pi\in\operatorname*{GP}}\left(  v_{\pi}\left(  \alpha\right)
+1\right)  .
\]

\end{proposition}

\begin{proof}
Same proof as for Proposition \ref{prop.ent.count-divs}, but you have to be
more careful with unit-equivalence (since in part \textbf{(b)}, you are
counting unit-equivalence classes rather than positive divisors). The analogue
of Lemma \ref{lem.ent.divs-bijs} we need to use for this proof is the
following lemma:
\end{proof}

\begin{lemma}
\label{lem.Z[i].divs-bijs}Let $\pi_{1},\pi_{2},\ldots,\pi_{u}$ be finitely
many Gaussian primes, no two of which are unit-equivalent. For each
$i\in\left\{  1,2,\ldots,u\right\}  $, let $a_{i}$ be a nonnegative integer.
Let $\alpha=\pi_{1}^{a_{1}}\pi_{2}^{a_{2}}\cdots\pi_{u}^{a_{u}}$.

Define a set $T$ by%
\begin{align*}
T  &  =\left\{  0,1,\ldots,a_{1}\right\}  \times\left\{  0,1,\ldots
,a_{2}\right\}  \times\cdots\times\left\{  0,1,\ldots,a_{u}\right\} \\
&  =\left\{  \left(  b_{1},b_{2},\ldots,b_{u}\right)  \ \mid\text{ }b_{i}%
\in\left\{  0,1,\ldots,a_{i}\right\}  \text{ for each }i\in\left\{
1,2,\ldots,u\right\}  \right\} \\
&  =\left\{  \left(  b_{1},b_{2},\ldots,b_{u}\right)  \in\mathbb{N}^{u}%
\ \mid\ b_{i}\leq a_{i}\text{ for each }i\in\left\{  1,2,\ldots,u\right\}
\right\}  .
\end{align*}
Then, the map%
\begin{align*}
\Lambda:T  &  \rightarrow\left\{  \text{unit-equivalence classes of Gaussian
divisors of }\alpha\right\}  ,\\
\left(  b_{1},b_{2},\ldots,b_{u}\right)   &  \mapsto\left[  \pi_{1}^{b_{1}}%
\pi_{2}^{b_{2}}\cdots\pi_{u}^{b_{u}}\right]  _{\sim}%
\end{align*}
is well-defined and bijective.
\end{lemma}

Now, we can finally answer Question \ref{quest.intro.sum-of-2sq.2}
\textbf{(b)} (following \cite[\S 8.3, Corollary 19]{Dummit-Foote}):

\begin{theorem}
\label{thm.Z[i].count-xx+yy}Let $n$ be a positive integer.

\textbf{(a)} If there is at least one prime $p\equiv3\operatorname{mod}4$ such
that $v_{p}\left(  n\right)  $ is odd, then there is \textbf{no} pair $\left(
x,y\right)  \in\mathbb{Z}^{2}$ such that $n=x^{2}+y^{2}$.

\textbf{(b)} Assume that for each prime $p\equiv3\operatorname{mod}4$, the
number $v_{p}\left(  n\right)  $ is even. Then,%
\begin{align*}
&  \left(  \text{the number of pairs }\left(  x,y\right)  \in\mathbb{Z}%
^{2}\text{ such that }n=x^{2}+y^{2}\right) \\
&  =4\cdot\prod_{\substack{p\text{ prime;}\\p\equiv1\operatorname{mod}%
4}}\left(  v_{p}\left(  n\right)  +1\right)  .
\end{align*}

\end{theorem}

\begin{noncompile}
In other words: If $n$ is a positive integer, then%
\begin{align*}
&  \left(  \text{the number of pairs }\left(  x,y\right)  \in\mathbb{Z}%
^{2}\text{ such that }n=x^{2}+y^{2}\right) \\
&  =\left(  \text{the number of }\delta\in\mathbb{Z}\left[  i\right]  \text{
such that }n=\delta\overline{\delta}\right) \\
&  =%
\begin{cases}
4\prod_{\substack{p\text{ prime;}\\p\equiv1\operatorname{mod}4}}\left(
v_{p}\left(  n\right)  +1\right)  , & \text{if all primes }p\equiv
3\operatorname{mod}4\text{ satisfy }v_{p}\left(  n\right)  \equiv
0\operatorname{mod}2;\\
0, & \text{if some prime }p\equiv3\operatorname{mod}4\text{ satisfies }%
v_{p}\left(  n\right)  \equiv1\operatorname{mod}2.
\end{cases}
\end{align*}

\end{noncompile}

\begin{center}
\textbf{2019-03-15 lecture}
\end{center}

\begin{example}
\textbf{(a)} Let $n=35$. Then, Theorem \ref{thm.Z[i].count-xx+yy} \textbf{(a)}
yields that there are \textbf{no} integers $x$ and $y$ such that
$n=x^{2}+y^{2}$. In fact, the prime $7\equiv3\operatorname{mod}4$ satisfies
$v_{7}\left(  n\right)  =1$.

\textbf{(b)} Let $n=45$. Then, for each prime $p\equiv3\operatorname{mod}4$,
the number $v_{p}\left(  n\right)  $ is even. Indeed, $n=45=3^{2}\cdot5$, so
$v_{3}\left(  n\right)  =2$ is even and $v_{p}\left(  n\right)  =0$ for all
other primes $p$ of Type 3. Hence, Theorem \ref{thm.Z[i].count-xx+yy}
\textbf{(b)} yields%
\begin{align*}
&  \left(  \text{the number of pairs }\left(  x,y\right)  \in\mathbb{Z}%
^{2}\text{ such that }n=x^{2}+y^{2}\right) \\
&  =4\cdot\underbrace{\prod_{\substack{p\text{ prime;}\\p\equiv
1\operatorname{mod}4}}\left(  v_{p}\left(  n\right)  +1\right)  }%
_{\substack{=v_{5}\left(  n\right)  +1\\=1+1=2}}=4\cdot2=8.
\end{align*}

\end{example}

\begin{proof}
[Proof of Theorem \ref{thm.Z[i].count-xx+yy} (sketched).]\textbf{(a)} Assume
that there is at least one prime $p\equiv3\operatorname{mod}4$ such that
$v_{p}\left(  n\right)  $ is odd. We must prove that there is \textbf{no} pair
$\left(  x,y\right)  \in\mathbb{Z}^{2}$ such that $n=x^{2}+y^{2}$.

Indeed, let $\left(  x,y\right)  \in\mathbb{Z}^{2}$ be a pair such that
$n=x^{2}+y^{2}$. We must derive a contradiction.

Let $\alpha$ be the Gaussian integer $x+yi$. Thus, $\alpha\overline{\alpha
}=x^{2}+y^{2}=n$.

We have assumed that there is at least one prime $p\equiv3\operatorname{mod}4$
such that $v_{p}\left(  n\right)  $ is odd. Consider this $p$. Note that $p$
is a Gaussian prime (by Lemma \ref{lem.Z[i].gauss.prime.3mod4}).

Thus, Exercise \ref{exe.Z[i].prime.vp-conj} (applied to $\pi=p$) yields
$v_{\overline{p}}\left(  \overline{\alpha}\right)  =v_{p}\left(
\alpha\right)  $. In view of $\overline{p}=p$, this rewrites as $v_{p}\left(
\overline{\alpha}\right)  =v_{p}\left(  \alpha\right)  $. But
\[
v_{p}\left(  \underbrace{n}_{=\alpha\overline{\alpha}}\right)  =v_{p}\left(
\alpha\overline{\alpha}\right)  =v_{p}\left(  \alpha\right)
+\underbrace{v_{p}\left(  \overline{\alpha}\right)  }_{=v_{p}\left(
\alpha\right)  }=v_{p}\left(  \alpha\right)  +v_{p}\left(  \alpha\right)
=2v_{p}\left(  \alpha\right)  .
\]
Thus, $v_{p}\left(  n\right)  $ is even. This contradicts the fact that
$v_{p}\left(  n\right)  $ is odd. Thus, we have found a contradiction for each
pair $\left(  x,y\right)  \in\mathbb{Z}^{2}$ such that $n=x^{2}+y^{2}$. Hence,
there exists no such pair. This proves Theorem \ref{thm.Z[i].count-xx+yy}
\textbf{(a)}.

\textbf{(b)} We have%
\begin{align*}
&  \left(  \text{the number of }\alpha\in\mathbb{Z}\left[  i\right]  \text{
such that }n=\alpha\overline{\alpha}\right) \\
&  =\left(  \text{the number of pairs }\left(  x,y\right)  \in\mathbb{Z}%
^{2}\text{ such that }n=x^{2}+y^{2}\right)  ,
\end{align*}
since the map%
\begin{align*}
\left\{  \left(  x,y\right)  \in\mathbb{Z}^{2}\ \mid\ n=x^{2}+y^{2}\right\}
&  \rightarrow\left\{  \alpha\in\mathbb{Z}\left[  i\right]  \ \mid
\ n=\alpha\overline{\alpha}\right\}  ,\\
\left(  x,y\right)   &  \mapsto x+yi
\end{align*}
is a bijection.

Write the canonical factorization of $n$ as
\begin{equation}
n=2^{c}\cdot p_{1}^{a_{1}}p_{2}^{a_{2}}\cdots p_{k}^{a_{k}}\cdot q_{1}^{b_{1}%
}q_{2}^{b_{2}}\cdots q_{\ell}^{b_{\ell}},
\label{pf.thm.Z[i].count-xx+yy.b.n=1}%
\end{equation}
where all the exponents $c,a_{h},b_{j}$ are $\in\mathbb{N}$, and where
$p_{1},p_{2},\ldots,p_{k}$ are distinct primes of Type 1, and where
$q_{1},q_{2},\ldots,q_{\ell}$ are distinct primes of Type 3. Note that $c=0$
if $n$ is odd.

We have assumed that for each prime $p\equiv3\operatorname{mod}4$, the number
$v_{p}\left(  n\right)  $ is even. In other words, for each prime $p$ of Type
3, the number $v_{p}\left(  n\right)  $ is even. In other words, $b_{1}%
,b_{2},\ldots,b_{\ell}$ are even (since $q_{1},q_{2},\ldots,q_{\ell}$ are
primes of Type 3, and thus the corresponding exponents $b_{j}=v_{q_{j}}\left(
n\right)  $ must be even). Hence, $b_{j}/2\in\mathbb{N}$ for each $j$.

Each $q_{j}$ is a prime of Type 3, and thus is a Gaussian prime (by Lemma
\ref{lem.Z[i].gauss.prime.3mod4}). Meanwhile, each $p_{h}$ is a prime of Type
1, and thus can be written in the form $p_{h}=\pi_{h}\overline{\pi_{h}}$ for
some Gaussian prime $\pi_{h}$ (by Theorem \ref{thm.Z[i].gauss.prime.1mod4}
\textbf{(c)}). Consider these $\pi_{h}$. For every $h$, Theorem
\ref{thm.Z[i].gauss.prime.1mod4} \textbf{(e)} shows that the conjugate
$\overline{\pi_{h}}$ is also a Gaussian prime, and that we do not have
$\pi_{h}\sim\overline{\pi_{h}}$.

Finally, let $\rho$ be the Gaussian prime $1+i$; thus $2=\rho\overline{\rho}$.
But note that $\rho\sim\overline{\rho}$ (indeed, $\overline{\rho}=1-i=\left(
-i\right)  \underbrace{\left(  1+i\right)  }_{=\rho}=\left(  -i\right)  \rho
$). Now, (\ref{pf.thm.Z[i].count-xx+yy.b.n=1}) becomes%
\begin{align}
n  &  =\underbrace{2^{c}}_{\substack{=\rho^{c}\overline{\rho}^{c}%
\\\text{(since }2=\rho\overline{\rho}\text{)}}}\cdot\left(  \prod_{h=1}%
^{k}\underbrace{p_{h}^{a_{h}}}_{\substack{=\pi_{h}^{a_{h}}\overline{\pi_{h}%
}^{a_{h}}\\\text{(since }p_{h}=\pi_{h}\overline{\pi_{h}}\text{)}}}\right)
\cdot q_{1}^{b_{1}}q_{2}^{b_{2}}\cdots q_{\ell}^{b_{\ell}}\nonumber\\
&  =\rho^{c}\overline{\rho}^{c}\cdot\left(  \prod_{h=1}^{k}\left(  \pi
_{h}^{a_{h}}\overline{\pi_{h}}^{a_{h}}\right)  \right)  \cdot q_{1}^{b_{1}%
}q_{2}^{b_{2}}\cdots q_{\ell}^{b_{\ell}},
\label{pf.thm.Z[i].count-xx+yy.b.n=2}%
\end{align}
and this is a decomposition of $n$ as a product of powers of Gaussian primes
(albeit $\rho$ and $\overline{\rho}$ are unit-equivalent).

No two of the Gaussian primes $\rho,\pi_{h},\overline{\pi_{h}},q_{j}$ are
unit-equivalent. (\textit{Proof:} Compare their norms (since unit-equivalent
Gaussian integers have equal norms). The only of these Gaussian primes that
have equal norms are $\pi_{h}$ and $\overline{\pi_{h}}$. So we merely need to
rule out $\pi_{h}\sim\overline{\pi_{h}}$. But this is clear, since we already
showed that we do not have $\pi_{h}\sim\overline{\pi_{h}}$.)

Now, define a map%
\begin{align*}
F:\left\{  1,i,-1,-i\right\}  \times\prod_{h=1}^{k}\left\{  0,1,\ldots
,a_{h}\right\}   &  \rightarrow\left\{  \alpha\in\mathbb{Z}\left[  i\right]
\ \mid\ n=\alpha\overline{\alpha}\right\}  ,\\
\left(  \gamma,\left(  d_{1},d_{2},\ldots,d_{k}\right)  \right)   &
\mapsto\gamma\cdot\rho^{c}\cdot\left(  \prod_{h=1}^{k}\left(  \pi_{h}^{d_{h}%
}\overline{\pi_{h}}^{a_{h}-d_{h}}\right)  \right)  \cdot q_{1}^{b_{1}/2}%
q_{2}^{b_{2}/2}\cdots q_{\ell}^{b_{\ell}/2}.
\end{align*}
It is easy to check that this map $F$ is well-defined\footnote{Just multiply
out $\alpha\overline{\alpha}$ for $\alpha=\gamma\cdot\rho^{c}\cdot\left(
\prod_{h=1}^{k}\left(  \pi_{h}^{d_{h}}\overline{\pi_{h}}^{a_{h}-d_{h}}\right)
\right)  \cdot q_{1}^{b_{1}/2}q_{2}^{b_{2}/2}\cdots q_{\ell}^{b_{\ell}/2}$ and
check that you obtain $n$. Corollary \ref{cor.CC.norm.pow} \textbf{(a)} needs
to be used.}. We claim that this map $F$ is a bijection.

[\textit{Proof:} To see that $F$ is injective, we must find a way to
reconstruct $\left(  \gamma,\left(  d_{1},d_{2},\ldots,d_{k}\right)  \right)
\in\left\{  1,i,-1,-i\right\}  \times\prod_{h=1}^{k}\left\{  0,1,\ldots
,a_{h}\right\}  $ from
\begin{align*}
\alpha:  &  =F\left(  \left(  \gamma,\left(  d_{1},d_{2},\ldots,d_{k}\right)
\right)  \right) \\
&  =\gamma\cdot\rho^{c}\cdot\left(  \prod_{h=1}^{k}\left(  \pi_{h}^{d_{h}%
}\overline{\pi_{h}}^{a_{h}-d_{h}}\right)  \right)  \cdot q_{1}^{b_{1}/2}%
q_{2}^{b_{2}/2}\cdots q_{\ell}^{b_{\ell}/2}.
\end{align*}


But this is easy: You first reconstruct the $k$-tuple $\left(  d_{1}%
,d_{2},\ldots,d_{k}\right)  $ by observing that $d_{h}=v_{\pi_{h}}\left(
\alpha\right)  $ for each $h$. Once you have that, you can reconstruct
$\gamma$ by%
\[
\gamma=\dfrac{\alpha}{\rho^{c}\cdot\left(  \prod_{h=1}^{k}\left(  \pi
_{h}^{d_{h}}\overline{\pi_{h}}^{a_{h}-d_{h}}\right)  \right)  \cdot
q_{1}^{b_{1}/2}q_{2}^{b_{2}/2}\cdots q_{\ell}^{b_{\ell}/2}}.
\]
So $F$ is injective.

To see that $F$ is surjective, we must prove that each $\alpha\in
\mathbb{Z}\left[  i\right]  $ satisfying $n=\alpha\overline{\alpha}$ has the
form
\[
\alpha=\gamma\cdot\rho^{c}\cdot\left(  \prod_{h=1}^{k}\left(  \pi_{h}^{d_{h}%
}\overline{\pi_{h}}^{a_{h}-d_{h}}\right)  \right)  \cdot q_{1}^{b_{1}/2}%
q_{2}^{b_{2}/2}\cdots q_{\ell}^{b_{\ell}/2}%
\]
for some $\left(  \gamma,\left(  d_{1},d_{2},\ldots,d_{k}\right)  \right)  $.
To prove this, use canonical factorization of $\alpha$ inside $\mathbb{Z}%
\left[  i\right]  $ to see that%
\begin{equation}
\alpha=\gamma\cdot\rho^{c^{\prime}}\cdot\left(  \prod_{h=1}^{k}\left(  \pi
_{h}^{d_{h}^{\prime}}\overline{\pi_{h}}^{e_{h}^{\prime}}\right)  \right)
\cdot q_{1}^{b_{1}^{\prime}}q_{2}^{b_{2}^{\prime}}\cdots q_{\ell}^{b_{\ell
}^{\prime}} \label{pf.thm.Z[i].count-xx+yy.b.al=2}%
\end{equation}
for some $c^{\prime},d_{h}^{\prime},e_{h}^{\prime},b_{j}^{\prime}\in
\mathbb{N}$. Consider these $c^{\prime},d_{h}^{\prime},e_{h}^{\prime}%
,b_{j}^{\prime}\in\mathbb{N}$. From (\ref{pf.thm.Z[i].count-xx+yy.b.al=2}), we
obtain
\begin{align*}
\alpha\overline{\alpha}  &  =\gamma\cdot\rho^{c^{\prime}}\cdot\left(
\prod_{h=1}^{k}\left(  \pi_{h}^{d_{h}^{\prime}}\overline{\pi_{h}}%
^{e_{h}^{\prime}}\right)  \right)  \cdot q_{1}^{b_{1}^{\prime}}q_{2}%
^{b_{2}^{\prime}}\cdots q_{\ell}^{b_{\ell}^{\prime}}\\
&  \ \ \ \ \ \ \ \ \ \ \cdot\overline{\gamma\cdot\rho^{c^{\prime}}\cdot\left(
\prod_{h=1}^{k}\left(  \pi_{h}^{d_{h}^{\prime}}\overline{\pi_{h}}%
^{e_{h}^{\prime}}\right)  \right)  \cdot q_{1}^{b_{1}^{\prime}}q_{2}%
^{b_{2}^{\prime}}\cdots q_{\ell}^{b_{\ell}^{\prime}}}\\
&  =\underbrace{\gamma\overline{\gamma}}_{\substack{=\operatorname*{N}\left(
\gamma\right)  =1\\\text{(since }\gamma\text{ is a unit)}}}\cdot
\underbrace{\rho^{c^{\prime}}\overline{\rho}^{c^{\prime}}}_{\substack{=\left(
\rho\overline{\rho}\right)  ^{c^{\prime}}=2^{c^{\prime}}\\\text{(since }%
\rho\overline{\rho}=2\text{)}}}\cdot\left(  \prod_{h=1}^{k}\left(  \pi
_{h}^{d_{h}^{\prime}}\overline{\pi_{h}}^{e_{h}^{\prime}}\overline{\pi
_{h}^{d_{h}^{\prime}}\overline{\pi_{h}}^{e_{h}^{\prime}}}\right)  \right)
\cdot q_{1}^{b_{1}^{\prime}}q_{2}^{b_{2}^{\prime}}\cdots q_{\ell}^{b_{\ell
}^{\prime}}\cdot\underbrace{\overline{q_{1}^{b_{1}^{\prime}}q_{2}%
^{b_{2}^{\prime}}\cdots q_{\ell}^{b_{\ell}^{\prime}}}}_{\substack{=q_{1}%
^{b_{1}^{\prime}}q_{2}^{b_{2}^{\prime}}\cdots q_{\ell}^{b_{\ell}^{\prime}%
}\\\text{(since }q_{1},q_{2},\ldots,q_{\ell}\\\text{are reals)}}}\\
&  =2^{c^{\prime}}\cdot\left(  \prod_{h=1}^{k}\underbrace{\left(  \pi
_{h}^{d_{h}^{\prime}}\overline{\pi_{h}}^{e_{h}^{\prime}}\overline{\pi
_{h}^{d_{h}^{\prime}}\overline{\pi_{h}}^{e_{h}^{\prime}}}\right)  }_{=\left(
\pi_{h}\overline{\pi_{h}}\right)  ^{d_{h}^{\prime}+e_{h}^{\prime}}}\right)
\cdot\underbrace{q_{1}^{b_{1}^{\prime}}q_{2}^{b_{2}^{\prime}}\cdots q_{\ell
}^{b_{\ell}^{\prime}}\cdot q_{1}^{b_{1}^{\prime}}q_{2}^{b_{2}^{\prime}}\cdots
q_{\ell}^{b_{\ell}^{\prime}}}_{=q_{1}^{2b_{1}^{\prime}}q_{2}^{2b_{2}^{\prime}%
}\cdots q_{\ell}^{2b_{\ell}^{\prime}}}\\
&  =2^{c^{\prime}}\cdot\left(  \prod_{h=1}^{k}\left(  \underbrace{\pi
_{h}\overline{\pi_{h}}}_{=p_{h}}\right)  ^{d_{h}^{\prime}+e_{h}^{\prime}%
}\right)  \cdot q_{1}^{2b_{1}^{\prime}}q_{2}^{2b_{2}^{\prime}}\cdots q_{\ell
}^{2b_{\ell}^{\prime}}=2^{c^{\prime}}\cdot\left(  \prod_{h=1}^{k}p_{h}%
^{d_{h}^{\prime}+e_{h}^{\prime}}\right)  \cdot q_{1}^{2b_{1}^{\prime}}%
q_{2}^{2b_{2}^{\prime}}\cdots q_{\ell}^{2b_{\ell}^{\prime}}.
\end{align*}
Thus,%
\begin{equation}
n=\alpha\overline{\alpha}=2^{c^{\prime}}\cdot\left(  \prod_{h=1}^{k}%
p_{h}^{d_{h}^{\prime}+e_{h}^{\prime}}\right)  \cdot q_{1}^{2b_{1}^{\prime}%
}q_{2}^{2b_{2}^{\prime}}\cdots q_{\ell}^{2b_{\ell}^{\prime}}.
\label{pf.thm.Z[i].count-xx+yy.b.n=5}%
\end{equation}
This is a prime factorization of $n$ as an integer. But so is
(\ref{pf.thm.Z[i].count-xx+yy.b.n=1}). Since the prime factorization of an
integer is unique (or by comparing $p$-valuations of the right hand sides on
(\ref{pf.thm.Z[i].count-xx+yy.b.n=5}) and (\ref{pf.thm.Z[i].count-xx+yy.b.n=1}%
)), we thus conclude%
\begin{align*}
c^{\prime}  &  =c;\ \ \ \ \ \ \ \ \ \ d_{h}^{\prime}+e_{h}^{\prime}%
=a_{h}\ \ \ \ \ \ \ \ \ \ \text{for all }h;\\
2b_{j}^{\prime}  &  =b_{j}\ \ \ \ \ \ \ \ \ \ \text{for all }j.
\end{align*}
In other words,%
\begin{align*}
c^{\prime}  &  =c;\ \ \ \ \ \ \ \ \ \ e_{h}^{\prime}=a_{h}-d_{h}^{\prime
}\ \ \ \ \ \ \ \ \ \ \text{for all }h;\\
b_{j}^{\prime}  &  =b_{j}/2\ \ \ \ \ \ \ \ \ \ \text{for all }j.
\end{align*}
Hence, (\ref{pf.thm.Z[i].count-xx+yy.b.al=2}) rewrites as%
\begin{align*}
\alpha &  =\gamma\cdot\rho^{c}\cdot\left(  \prod_{h=1}^{k}\left(  \pi
_{h}^{d_{h}^{\prime}}\overline{\pi_{h}}^{a_{h}-d_{h}^{\prime}}\right)
\right)  \cdot q_{1}^{b_{1}/2}q_{2}^{b_{2}/2}\cdots q_{\ell}^{b_{\ell}/2}\\
&  =F\left(  \left(  \gamma,\left(  d_{1}^{\prime},d_{2}^{\prime},\ldots
,d_{k}^{\prime}\right)  \right)  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
the definition of }F\right)  .
\end{align*}
Thus, we have shown that $\alpha$ is a value of $F$. This proves that $F$ is surjective.

Now, $F$ is injective and surjective, hence bijective.]

So $F$ is a bijection. Thus,%
\begin{align*}
&  \left\vert \left\{  1,i,-1,-i\right\}  \times\prod_{h=1}^{k}\left\{
0,1,\ldots,a_{h}\right\}  \right\vert \\
&  =\left\vert \left\{  \alpha\in\mathbb{Z}\left[  i\right]  \ \mid
\ n=\alpha\overline{\alpha}\right\}  \right\vert \\
&  =\left(  \text{the number of }\alpha\in\mathbb{Z}\left[  i\right]  \text{
such that }n=\alpha\overline{\alpha}\right) \\
&  =\left(  \text{the number of pairs }\left(  x,y\right)  \in\mathbb{Z}%
^{2}\text{ such that }n=x^{2}+y^{2}\right)  ,
\end{align*}
so that%
\begin{align*}
&  \left(  \text{the number of pairs }\left(  x,y\right)  \in\mathbb{Z}%
^{2}\text{ such that }n=x^{2}+y^{2}\right) \\
&  =\left\vert \left\{  1,i,-1,-i\right\}  \times\prod_{h=1}^{k}\left\{
0,1,\ldots,a_{h}\right\}  \right\vert =\underbrace{\left\vert \left\{
1,i,-1,-i\right\}  \right\vert }_{=4}\cdot\prod_{h=1}^{k}%
\underbrace{\left\vert \left\{  0,1,\ldots,a_{h}\right\}  \right\vert
}_{=a_{h}+1}\\
&  =4\cdot\prod_{h=1}^{k}\left(  \underbrace{a_{h}}_{=v_{p_{h}}\left(
n\right)  }+1\right)  =4\cdot\prod_{h=1}^{k}\left(  v_{p_{h}}\left(  n\right)
+1\right)  =4\cdot\prod_{\substack{p\text{ prime;}\\p\equiv1\operatorname{mod}%
4}}\left(  v_{p}\left(  n\right)  +1\right)  .
\end{align*}
(The last equality sign is a consequence of the fact that $p_{1},p_{2}%
,\ldots,p_{h}$ are distinct primes of Type 1, and that all other primes
$p\notin\left\{  p_{1},p_{2},\ldots,p_{h}\right\}  $ of Type 1 satisfy
$v_{p}\left(  n\right)  =0$.) This proves Theorem \ref{thm.Z[i].count-xx+yy}
\textbf{(b)}.
\end{proof}

One consequence of Theorem \ref{thm.Z[i].count-xx+yy} is that a positive
integer $n$ can be written in the form $x^{2}+y^{2}$ with $x,y\in\mathbb{Z}$
if and only if it has the property that for each prime $p\equiv
3\operatorname{mod}4$, the number $v_{p}\left(  n\right)  $ is even. A
different proof of this fact appears in \cite[Theorem in Chapter 4]{AigZie}.

\subsubsection{What are the Gaussian primes?}

We have so far seen the following Gaussian primes:

\begin{itemize}
\item Each prime of Type 3 is a Gaussian prime.

\item $1+i$ is a Gaussian prime.

\item For each prime $p$ of Type 1, we have a Gaussian prime $\pi$ such that
$p=\pi\overline{\pi}$, and then $\overline{\pi}$ is also a Gaussian prime.
\end{itemize}

\begin{theorem}
Each Gaussian prime is unit-equivalent to one of the Gaussian primes in this list.
\end{theorem}

\begin{proof}
See \href{http://www-users.math.umn.edu/~dgrinber/19s/hw5s.pdf}{homework set
\#5} exercise 3.
\end{proof}

\subsection{Brief survey of similar number systems}

\begin{itemize}
\item Let us now see when a prime $p$ can be written as $x^{2}+2y^{2}$ with
$x,y\in\mathbb{Z}$.

The set
\[
\mathbb{Z}\left[  \sqrt{-2}\right]  =\mathbb{Z}\left[  \sqrt{2}i\right]
\]
is defined as the set of all complex numbers of the form $a+b\sqrt{2}i$ with
$a,b\in\mathbb{Z}$. It is perhaps easier to regard it as its own variant of
Gaussian integers, which I will call the \textquotedblleft$2$-Gaussian
integers\textquotedblright. These \textquotedblleft$2$-Gaussian
integers\textquotedblright\ can be defined as pairs $\left(  a,b\right)
\in\mathbb{Z}^{2}$ with addition and subtraction defined entrywise and
multiplication defined by%
\[
\left(  a,b\right)  \left(  c,d\right)  =\left(  ac-2bd,ad+bc\right)  .
\]
You can then write such pairs $\left(  a,b\right)  $ as $a+b\sqrt{2}i$, where
$\sqrt{2}i$ is simply a symbol for the $2$-Gaussian integer $\left(
0,1\right)  $. Each $2$-Gaussian integer $\left(  a,b\right)  $ has a norm,
defined by $\operatorname*{N}\left(  \left(  a,b\right)  \right)
=a^{2}+2b^{2}$.

Much of the theory of Gaussian integers still applies verbatim to $2$-Gaussian
integers. In particular, division with remainder still works for $2$-Gaussian
integers (like it does for Gaussian integers, i.e., non-uniquely), and the
proof uses the same argument, but this time we have $\operatorname*{N}\left(
\rho\right)  \leq3\operatorname*{N}\left(  \beta\right)  /4$ instead of
$\operatorname*{N}\left(  \rho\right)  \leq\operatorname*{N}\left(
\beta\right)  /2$. Hence, $2$-Gaussian integers have unique factorizations
into \textquotedblleft$2$-Gaussian primes\textquotedblright.

This can be used to show that a prime $p$ can be written as $x^{2}+2y^{2}$ if
and only if there is an integer $u$ satisfying $u^{2}\equiv
-2\operatorname{mod}p$. It can furthermore be shown that such an integer $u$
exists if and only if $p=2$ or $p\equiv1,3\operatorname{mod}8$ (where
\textquotedblleft$p\equiv1,3\operatorname{mod}8$\textquotedblright\ is
shorthand for \textquotedblleft$p\equiv1\operatorname{mod}8$ or $p\equiv
3\operatorname{mod}8$\textquotedblright). The proof uses a fact called
\textit{quadratic reciprocity}, which we \textbf{may} see later in this course.

\item When can a prime $p$ be written as $x^{2}+3y^{2}$ with $x,y\in
\mathbb{Z}$ ?

The logical continuation of the above pattern would be \textquotedblleft when
$p=3$ or $p\equiv1\operatorname{mod}3$\textquotedblright, since these are the
cases when there is an integer $u$ satisfying $u^{2}\equiv-3\operatorname{mod}%
p$. And that is indeed true, but the proof is more complicated. Indeed, the
\textquotedblleft$3$-Gaussian integers\textquotedblright\ no longer have
division with remainder, as $\operatorname*{N}\left(  \rho\right)
\leq\operatorname*{N}\left(  \beta\right)  /2$ turns into $\operatorname*{N}%
\left(  \rho\right)  \leq\operatorname*{N}\left(  \beta\right)  $ which is not
a strict inequality. Nevertheless we can prove our guess with more complicated
reasoning: We need to use not $\mathbb{Z}\left[  \sqrt{-3}\right]  $ but
rather \href{https://en.wikipedia.org/wiki/Eisenstein_integer}{the
\textit{Eisenstein integers}} $a+b\omega$ with $a,b\in\mathbb{Z}$ and
$\omega=\dfrac{-1+i\sqrt{3}}{2}$. These are best understood as pairs $\left(
a,b\right)  \in\mathbb{Z}^{2}$ with addition and subtraction defined entrywise
and multiplication defined by%
\[
\left(  a,b\right)  \left(  c,d\right)  =\left(  ac-bd,ad+bc-bd\right)  .
\]
Their norm is $\operatorname*{N}\left(  \left(  a,b\right)  \right)
=a^{2}-ab+b^{2}$. They form a triangular lattice, not a rectangular one, and
they do have division with remainder. Note that $\operatorname*{N}\left(
a+b\omega\right)  =a^{2}-ab+b^{2}$, so some more work is needed to turn them
into $x^{2}+3y^{2}$ solutions, but it's doable.

\item When can a prime $p$ be written as $x^{2}+4y^{2}$ with $x,y\in
\mathbb{Z}$ ?

This is easy: $4y^{2}=\left(  2y\right)  ^{2}$, so we are looking for a way of
writing $p$ as $x^{2}+y^{2}$ with $y$ even.

I claim that the answer is \textquotedblleft when $p\equiv1\operatorname{mod}%
4$\textquotedblright. Do you see why?

\item When can a prime $p$ be written as $x^{2}+5y^{2}$ with $x,y\in
\mathbb{Z}$ ?

Our guess, by following the above pattern, would be \textquotedblleft when
$p=2$ or $p=5$ or $p\equiv1,3,7,9\operatorname{mod}20$\textquotedblright,
since these are the cases when there is an integer $u$ satisfying $u^{2}%
\equiv-5\operatorname{mod}p$. But this is not true anymore. The right answer
is \textquotedblleft when $p=2$ or $p=5$ or $p\equiv1,9\operatorname{mod}%
20$\textquotedblright. And unsurprisingly, $\mathbb{Z}\left[  \sqrt
{-5}\right]  $ does not have division with remainder.

\item More generally, you can fix $n\in\mathbb{N}$ and ask when a prime can be
written in the form $x^{2}+ny^{2}$. There is a whole book \cite{Cox13} devoted
to this question! The answer becomes more complicated with $n$ getting large,
and touches on a surprising number of different fields of mathematics
(geometry, complex analysis, elliptic functions and elliptic curves).

\item We can also ask when a prime $p$ can be written as $x^{2}-ny^{2}$. The
appropriate analogue of $\mathbb{Z}\left[  i\right]  $ tailored to this
question is $\mathbb{Z}\left[  \sqrt{n}\right]  $, which however behaves much
differently, since $\sqrt{n}$ is real. For example, as you saw on
\href{http://www-users.math.umn.edu/~dgrinber/19s/hw4s.pdf}{homework set \#4}
(in the Remark after Exercise 4), there are infinitely many units in
$\mathbb{Z}\left[  \sqrt{2}\right]  $; the same is true for each
$\mathbb{Z}\left[  \sqrt{n}\right]  $ with $n>1$ and $n$ not being a perfect
square (but this is much harder to prove).

\item When can $n\in\mathbb{N}$ be written as a sum of three squares?
Legendre's three-squares theorem: iff $n$ is not of the form $n=4^{a}\left(
8b+7\right)  $ for integers $a,b$. Very hard to prove (\cite[Chapter
XIII]{Uspensky-Heaslet} might have the only elementary proof).

\item When can $n\in\mathbb{N}$ be written as a sum of four squares?
Lagrange's four-squares theorem: always!\footnote{An application (fortunately,
no longer relevant):
\par
\textquotedblleft\texttt{Warning: Due to a known bug, the default Linux
document viewer evince prints N*N copies of a PDF file when N copies
requested. As a workaround, use Adobe Reader acroread for printing multiple
copies of PDF documents, or use the fact that every natural number is a sum of
at most four squares.}\textquotedblright} This is easier to show, and there is
even a formula for the number of representations: it is $8\sum
_{\substack{d\mid n;\\4\nmid d}}d$. The existence part can be proven using
\textquotedblleft Hurwitz integers\textquotedblright, which are certain quaternions.
\end{itemize}

\begin{center}
\textbf{2019-03-25 lecture}
\end{center}

\section{\label{chp.ring}Rings and fields}

\subsection{\label{sect.ring.ring}Definition of a ring}

We have seen several \textquotedblleft number systems\textquotedblright\ in
the above chapters:

\begin{itemize}
\item $\mathbb{N}$ (the nonnegative integers);

\item $\mathbb{Z}$ (the integers);

\item $\mathbb{R}$ (the real numbers);

\item $\mathbb{Z}/n$ for a positive integer $n$;

\item $\mathbb{C}$ (the complex numbers);

\item $\mathbb{D}$ (the dual numbers -- see homework set \#4 exercise 3);

\item $\mathbb{Z}\left[  \sqrt{2}\right]  =\left\{  a+b\sqrt{2}\ \mid
\ a,b\in\mathbb{Z}\right\}  $ (see homework set \#4 exercise 4);

\item $\mathbb{Z}\left[  \omega\right]  =\left\{  a+b\omega\ \mid
\ a,b\in\mathbb{Z}\right\}  $ (the Eisenstein integers);

\item $\mathbb{Z}\left[  \sqrt{-3}\right]  $ (see homework set \#5 exercise 6).
\end{itemize}

It may be a stretch to call the elements of some of these \textquotedblleft
numbers\textquotedblright, but it is not taboo (the word \textquotedblleft
number\textquotedblright\ has no precise meaning in mathematics), and these
sets have a lot in common: We can add, subtract and multiply their elements
(except for $\mathbb{N}$, which does not allow subtraction); these operations
satisfy the usual rules (e.g., associativity of multiplication,
distributivity, etc.); these sets contain some element \textquotedblleft
behaving like $0$\textquotedblright\ (that is, an element $\mathbf{0}$ such
that $a+\mathbf{0}=\mathbf{0}+a=a$ and $a\cdot\mathbf{0}=\mathbf{0}\cdot
a=\mathbf{0}$ for all $a$) and some element \textquotedblleft behaving like
$1$\textquotedblright\ (that is, an element $\mathbf{1}$ such that
$a\cdot\mathbf{1}=\mathbf{1}\cdot a=a$ for all $a$). It turns out that just a
few of these rules are sufficient to make \textquotedblleft all the other
rules\textquotedblright\ (in a certain appropriate sense) follow from them.
Thus, it is reasonable to crystallize these few rules into a common, general
notion (of which the above examples -- excluding $\mathbb{N}$ -- will be
particular cases); this notion will be called a \textquotedblleft%
\textbf{ring}\textquotedblright. Hence, we shall define a \textbf{ring} to be
(roughly speaking) a set with operations $+$ and $\cdot$ and elements $0$ and
$1$ that satisfies these few rules. Let us be specific about what these rules
are:\footnote{Recall the definition of a \textquotedblleft binary
operation\textquotedblright\ (Definition \ref{def.intro.binop}). In
particular, a binary operation on a set $S$ must have all its values in $S$.}

\begin{definition}
\label{def.rings.ring}\textbf{(a)} A \textit{ring} means a set $\mathbb{K}$
endowed with

\begin{itemize}
\item two binary operations called \textquotedblleft\textit{addition}%
\textquotedblright\ and \textquotedblleft\textit{multiplication}%
\textquotedblright, and denoted by $+_{\mathbb{K}}$ and $\cdot_{\mathbb{K}}$,
respectively, and

\item two elements called \textquotedblleft\textit{zero}\textquotedblright%
\ (or \textquotedblleft\textit{origin}\textquotedblright) and
\textquotedblleft\textit{unity}\textquotedblright\ (or \textquotedblleft%
\textit{one}\textquotedblright), and denoted by $0_{\mathbb{K}}$ and
$1_{\mathbb{K}}$, respectively
\end{itemize}

\noindent such that the following axioms are satisfied:

\begin{itemize}
\item \textbf{Commutativity of addition:} We have $a+_{\mathbb{K}%
}b=b+_{\mathbb{K}}a$ for all $a,b\in\mathbb{K}$.

\item \textbf{Associativity of addition:} We have $a+_{\mathbb{K}}\left(
b+_{\mathbb{K}}c\right)  =\left(  a+_{\mathbb{K}}b\right)  +_{\mathbb{K}}c$
for all $a,b,c\in\mathbb{K}$.

\item \textbf{Neutrality of zero:} We have $a+_{\mathbb{K}}0_{\mathbb{K}%
}=0_{\mathbb{K}}+_{\mathbb{K}}a=a$ for all $a\in\mathbb{K}$.

\item \textbf{Existence of additive inverses:} For any $a\in\mathbb{K}$, there
exists an element $a^{\prime}\in\mathbb{K}$ such that $a+_{\mathbb{K}%
}a^{\prime}=a^{\prime}+_{\mathbb{K}}a=0_{\mathbb{K}}$. (It is not
\textbf{immediately} obvious, but will be shown later, that such an
$a^{\prime}$ is unique. Thus, $a^{\prime}$ is called the \textit{additive
inverse} of $a$, and is denoted by $-a$.)

\item \textbf{Associativity of multiplication:} We have $a\left(  bc\right)
=\left(  ab\right)  c$ for all $a,b,c\in\mathbb{K}$. Here and in the
following, we use \textquotedblleft$xy$\textquotedblright\ as an abbreviation
for \textquotedblleft$x\cdot_{\mathbb{K}}y$\textquotedblright.

\item \textbf{Neutrality of one:} We have $a1_{\mathbb{K}}=1_{\mathbb{K}}a=a$
for all $a\in\mathbb{K}$.

\item \textbf{Annihilation:} We have $a0_{\mathbb{K}}=0_{\mathbb{K}%
}a=0_{\mathbb{K}}$ for all $a\in\mathbb{K}$.

\item \textbf{Distributivity:} We have%
\begin{align*}
a\left(  b+_{\mathbb{K}}c\right)   &  =ab+_{\mathbb{K}}%
ac\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  a+_{\mathbb{K}}b\right)  c  &  =ac+_{\mathbb{K}}bc
\end{align*}
for all $a,b,c\in\mathbb{K}$. Here and in the following, we are using the
PEMDAS convention for order of operations; thus, for example,
\textquotedblleft$ab+_{\mathbb{K}}ac$\textquotedblright\ must be understood as
\textquotedblleft$\left(  ab\right)  +_{\mathbb{K}}\left(  ac\right)
$\textquotedblright.
\end{itemize}

\noindent These eight axioms will be called the \textit{ring axioms}.

(Note that we do not require the existence of a \textquotedblleft
subtraction\textquotedblright\ operation $-_{\mathbb{K}}$. But we will later
construct such an operation out of the existing operations and axioms; it is
thus unnecessary to require it. We also do not require the existence of
multiplicative inverses; nor do we require commutativity of multiplication yet.)

\textbf{(b)} A ring $\mathbb{K}$ (with operations $+_{\mathbb{K}}$ and
$\cdot_{\mathbb{K}}$) is called \textit{commutative} if it satisfies the
following extra axiom:

\begin{itemize}
\item \textbf{Commutativity of multiplication:} We have $ab=ba$ for all
$a,b\in\mathbb{K}$.
\end{itemize}
\end{definition}

Note a few things:

\begin{itemize}
\item We shall abbreviate $+_{\mathbb{K}}$, $\cdot_{\mathbb{K}}$,
$0_{\mathbb{K}}$ and $1_{\mathbb{K}}$ as $+$, $\cdot$, $0$ and $1$ unless
there is a chance of confusion with the \textquotedblleft
usual\textquotedblright\ notions of addition, multiplication, zero and one.
(The example of the ring $\mathbb{Z}^{\prime}$ shown below is a case where
such confusion is possible; but most of the time, it is not.)

\item We have not required our rings to be endowed with a \textquotedblleft
subtraction\textquotedblright\ operation. Nevertheless, each ring $\mathbb{K}$
automatically has a subtraction operation: Namely, for any $a,b\in\mathbb{K}$,
we can define $a-b$ to be $a+b^{\prime}$, where $b^{\prime}$ is the additive
inverse of $b$. (We will later see that this operation is well-defined
(Definition \ref{def.rings.inv-add-a}) and satisfies the rules you would
expect (Definition \ref{prop.rings.inv-add.rules}).)

\item Some of the ring axioms we required in Definition \ref{def.rings.ring}
are redundant, i.e., they follow from other ring axioms. (For example,
Annihilation follows from the other axioms.) We don't mind this, as long as
these axioms are natural and easy to check in real examples.

\item We have required commutativity of addition to hold for all rings, but
commutativity of multiplication only to hold for commutative rings. You may
wonder what happens if we also omit the commutativity of addition. The answer
is \textquotedblleft nothing new\textquotedblright: Commutativity of addition
follows from the other axioms! (Proving this is a fun, although
inconsequential, puzzle.)

\item By our definition, a ring consists of a set $\mathbb{K}$, two operations
$+$ and $\cdot$ and two elements $0$ and $1$. Thus, strictly speaking, a ring
is a $5$-tuple $\left(  \mathbb{K},+,\cdot,0,1\right)  $. In reality, we will
often just speak of the \textquotedblleft ring $\mathbb{K}$\textquotedblright%
\ (so we will mention only the set and not the other four pieces of data) and
assume that the reader can figure out the rest of the $5$-tuple. This is okay
as long as the rest of the $5$-tuple can be inferred from the context. For
example, when we say \textquotedblleft the ring $\mathbb{Z}$\textquotedblright%
, it is clear that we mean the ring $\left(  \mathbb{Z},+,\cdot,0,1\right)  $
with the usual addition and multiplication operations and the usual numbers
$0$ and $1$. The same applies when we speak of \textquotedblleft the ring
$\mathbb{R}$\textquotedblright\ or \textquotedblleft the ring $\mathbb{C}%
$\textquotedblright\ or \textquotedblleft the ring $\mathbb{Z}\left[
i\right]  $\textquotedblright. In general, whenever a set $S$ is equipped with
two operations that are called $+$ and $\cdot$ and two elements that are
called $0$ and $1$ (even if these elements are not literally the numbers $0$
and $1$), we automatically understand \textquotedblleft the ring
$S$\textquotedblright\ to be the ring $\left(  S,+,\cdot,0,1\right)  $ that is
defined using these operations and elements. If we want to make a different
ring out of the set $S$, then we have to say this explicitly.

\item Some authors do not require the element $1$ as part of what it means to
be a ring. But we do. Be careful when reading the literature, as the truth or
falsehood of many results depends on whether the $1$ is included in the
definition of a ring or not. (When authors do not require the element $1$ in
the definition of a ring, they reserve the notion of a \textquotedblleft
unital ring\textquotedblright\ for a ring that does come equipped with a $1$
that satisfies the \textquotedblleft Neutrality of one\textquotedblright%
\ axiom; i.e., they call \textquotedblleft unital ring\textquotedblright\ what
we call \textquotedblleft ring\textquotedblright.)
\end{itemize}

\subsection{\label{sect.ring.exa}Examples of rings}

Many of the \textquotedblleft number systems\textquotedblright\ seen above,
and several others, are examples of rings:

\begin{itemize}
\item The sets $\mathbb{Z}$, $\mathbb{Q}$, $\mathbb{R}$ and $\mathbb{C}$
(endowed with the usual addition, multiplication, $0$ and $1$) are commutative
rings. In each case, the additive inverse of an element $a$ is what we know as
$-a$ from high school (or undergraduate mathematics, in the case of
$\mathbb{C}$).

\item The set $\mathbb{N}$ (again endowed with the usual addition,
multiplication, $0$ and $1$) is not a ring. Indeed, the \textquotedblleft
existence of additive inverses\textquotedblright\ axiom fails for $a=1$,
because the element $1$ has no additive inverse in $\mathbb{N}$ (that is,
there is no $1^{\prime}\in\mathbb{N}$ such that $1+1^{\prime}=1^{\prime}+1=0$).

\item The sets $\mathbb{C}$, $\mathbb{Z}\left[  i\right]  $, $\mathbb{D}$,
$\mathbb{Z}\left[  \sqrt{2}\right]  $, $\mathbb{Z}\left[  \omega\right]  $ and
$\mathbb{Z}\left[  \sqrt{-3}\right]  $ (from the previous chapter and from the
homework sets) are commutative rings. All of the axioms are easy to check, and
some of them we have checked. In each case, the element $a^{\prime}$ in the
\textquotedblleft existence of additive inverses\textquotedblright\ axiom is
$-a$.

\item If you have seen polynomials: The set $\mathbb{Z}\left[  x\right]  $ of
all polynomials in a single variable $x$ with integer coefficients is a
commutative ring. Similarly for other kinds of coefficients, and several
variables. But we will come back later to this, once we have rigorously
defined polynomials.

\item We can define a commutative ring $\mathbb{Z}^{\prime}$ as follows:

We define a binary operation $\widetilde{\times}$ on $\mathbb{Z}$ by%
\[
\left(  a\widetilde{\times}b=-ab\ \ \ \ \ \ \ \ \ \ \text{for all }%
a,b\in\mathbb{Z}\right)  .
\]
Now, let $\mathbb{Z}^{\prime}$ be the \textbf{set} $\mathbb{Z}$, endowed with
the usual addition $+$ and the unusual multiplication $\widetilde{\times}$ and
the elements $0_{\mathbb{Z}^{\prime}}=0$ and $1_{\mathbb{Z}^{\prime}}=-1$.

Is this $\mathbb{Z}^{\prime}$ a commutative ring? Let us check the axioms:

\begin{itemize}
\item The first four axioms involve only addition and $0$ (but not
multiplication and $1$), and therefore still hold for $\mathbb{Z}^{\prime}$
(because $\mathbb{Z}^{\prime}$ has the same addition and $0$ as $\mathbb{Z}$).

\item Associativity of multiplication: We must check that%
\[
a\widetilde{\times}\left(  b\widetilde{\times}c\right)  =\left(
a\widetilde{\times}b\right)  \widetilde{\times}c\ \ \ \ \ \ \ \ \ \ \text{for
all }a,b,c\in\mathbb{Z}^{\prime}.
\]
(Note that we cannot omit the \textquotedblleft multiplication
sign\textquotedblright\ $\widetilde{\times}$ here and simply write
\textquotedblleft$bc$\textquotedblright\ for \textquotedblleft%
$b\widetilde{\times}c$\textquotedblright, because \textquotedblleft%
$bc$\textquotedblright\ already means something different. Note also that
\textquotedblleft$a,b,c\in\mathbb{Z}^{\prime}$\textquotedblright\ means the
same as \textquotedblleft$a,b,c\in\mathbb{Z}$\textquotedblright, because
$\mathbb{Z}^{\prime}=\mathbb{Z}$ as sets.)

Checking this is straightforward: Let $a,b,c\in\mathbb{Z}^{\prime}$. Then,
comparing
\begin{align*}
a\widetilde{\times}\underbrace{\left(  b\widetilde{\times}c\right)  }_{=-bc}
&  =a\widetilde{\times}\left(  -bc\right)  =-a\left(  -bc\right)
=abc\ \ \ \ \ \ \ \ \ \ \text{with}\\
\underbrace{\left(  a\widetilde{\times}b\right)  }_{=-ab}\widetilde{\times}c
&  =\left(  -ab\right)  \widetilde{\times}c=-\left(  -ab\right)  c=abc,
\end{align*}
we obtain $a\widetilde{\times}\left(  b\widetilde{\times}c\right)  =\left(
a\widetilde{\times}b\right)  \widetilde{\times}c$. Thus, associativity of
multiplication holds for $\mathbb{Z}^{\prime}$.

\item Neutrality of one in $\mathbb{Z}^{\prime}$: We must check that%
\[
a\widetilde{\times}1_{\mathbb{Z}^{\prime}}=1_{\mathbb{Z}^{\prime}%
}\widetilde{\times}a=a\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathbb{Z}%
^{\prime}.
\]


This, too, is straightforward: If $a\in\mathbb{Z}^{\prime}$, then
$a\widetilde{\times}\underbrace{1_{\mathbb{Z}^{\prime}}}_{=-1}%
=a\widetilde{\times}\left(  -1\right)  =-a\left(  -1\right)  =a$ and similarly
$1_{\mathbb{Z}^{\prime}}\widetilde{\times}a=a$.

\item Annihilation and commutativity of multiplication are just as easy to check.

\item Distributivity for $\mathbb{Z}^{\prime}$: We must check that%
\begin{align*}
a\widetilde{\times}\left(  b+c\right)   &  =a\widetilde{\times}%
b+a\widetilde{\times}c\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  a+b\right)  \widetilde{\times}c  &  =a\widetilde{\times}%
c+b\widetilde{\times}c
\end{align*}
for all $a,b,c\in\mathbb{Z}^{\prime}$.

So let $a,b,c\in\mathbb{Z}^{\prime}$. In order to verify $a\widetilde{\times
}\left(  b+c\right)  =a\widetilde{\times}b+a\widetilde{\times}c$, we compare%
\[
a\widetilde{\times}\left(  b+c\right)  =-a\left(  b+c\right)  =-ab-ac
\]
with%
\[
a\widetilde{\times}b+a\widetilde{\times}c=\left(  -ab\right)  +\left(
-ac\right)  =-ab-ac.
\]
Similarly we can check $\left(  a+b\right)  \widetilde{\times}%
c=a\widetilde{\times}c+b\widetilde{\times}c$.
\end{itemize}

So $\mathbb{Z}^{\prime}$ is a ring.

(Note that $\left(  \mathbb{Z},+,\widetilde{\times},0,1\right)  $ is not a ring.)

However, $\mathbb{Z}^{\prime}$ is not a \textbf{new} ring. It is just
$\mathbb{Z}$ with its elements renamed. Namely, if we rename each integer $a$
as $-a$, then the operations of $+$ and $\cdot$ and the elements $0$ and $1$
of $\mathbb{Z}$ turn into the operations $+$ and $\widetilde{\times}$ and the
elements $0$ and $1_{\mathbb{Z}^{\prime}}$ of $\mathbb{Z}^{\prime}$. This is a
confusing thing to say (please don't actually rename numbers as other
numbers!); the rigorous (and hopefully not confusing) way to say this is as
follows: The bijection%
\[
\varphi:\mathbb{Z}\rightarrow\mathbb{Z}^{\prime},\ \ \ \ \ \ \ \ \ \ a\mapsto
-a
\]
satisfies%
\begin{align*}
\varphi\left(  a+b\right)   &  =\varphi\left(  a\right)  +\varphi\left(
b\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in\mathbb{Z};\\
\varphi\left(  ab\right)   &  =\varphi\left(  a\right)  \widetilde{\times
}\varphi\left(  b\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in
\mathbb{Z};\\
\varphi\left(  0\right)   &  =0;\\
\varphi\left(  1\right)   &  =-1=1_{\mathbb{Z}^{\prime}}.
\end{align*}
Thus, we can view $\varphi$ as a way of relabelling the integers so that data
$+,\cdot,0,1$ of $\mathbb{Z}$ become the data $+,\widetilde{\times
},0,1_{\mathbb{Z}^{\prime}}$ of $\mathbb{Z}^{\prime}$. We will later call
bijections like $\varphi$ \textquotedblleft ring
isomorphisms\textquotedblright. (See Definition \ref{def.riiso.riiso} for the
definition of a ring homomorphism.)

\item Recall: If $A$ and $B$ are two sets, then
\[
B^{A}:=\left\{  \text{maps }A\rightarrow B\right\}  .
\]
(This notation is not wantonly chosen to annoy you with its seeming
backwardness; instead, it harkens back to the fact that $\left\vert
B^{A}\right\vert =\left\vert B\right\vert ^{\left\vert A\right\vert }$.)

The set $\mathbb{Q}^{\mathbb{Q}}$ of all the maps from $\mathbb{Q}$ to
$\mathbb{Q}$ is a commutative ring, where

\begin{itemize}
\item addition and multiplication are defined pointwise: i.e., if
$f,g\in\mathbb{Q}^{\mathbb{Q}}$ are two maps, then the maps $f+g$ and $f\cdot
g$ are defined by
\begin{align*}
\left(  f+g\right)  \left(  x\right)   &  =f\left(  x\right)  +g\left(
x\right)  \ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  f\cdot g\right)  \left(  x\right)   &  =f\left(  x\right)  \cdot
g\left(  x\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }x\in\mathbb{Q};
\end{align*}


\item $0$ means the \textquotedblleft constant $0$\textquotedblright\ function
(i.e., the map $\mathbb{Q}\rightarrow\mathbb{Q},\ x\mapsto0$);

\item $1$ means the \textquotedblleft constant $1$\textquotedblright\ function
(i.e., the map $\mathbb{Q}\rightarrow\mathbb{Q},\ x\mapsto1$).
\end{itemize}

All the ring axioms are easy to check. For example, each $f\in\mathbb{Q}%
^{\mathbb{Q}}$ has an additive inverse (namely, the map $-f\in\mathbb{Q}%
^{\mathbb{Q}}$ that sends each $x\in\mathbb{Q}$ to $-f\left(  x\right)  $).

Similarly, the sets $\mathbb{Q}^{\mathbb{C}}$ or $\mathbb{Q}^{\mathbb{N}}$ or
$\mathbb{R}^{\mathbb{R}}$ (the set of \textquotedblleft
functions\textquotedblright\ you know from calculus) or $\mathbb{C}%
^{\mathbb{C}}$ (or, more generally, for $\mathbb{K}^{S}$, where $\mathbb{K}$
is any commutative ring and $S$ is any set) can be made into commutative
rings; but the set $\mathbb{N}^{\mathbb{Q}}$ cannot. The problem with
$\mathbb{N}^{\mathbb{Q}}$ is that \textquotedblleft existence of additive
inverses\textquotedblright\ is not satisfied, since $-a\notin\mathbb{N}$ for
positive $a\in\mathbb{N}$.

\item Recall that%
\[
\mathbb{Z}\left[  \sqrt{2}\right]  =\left\{  a+b\sqrt{2}\ \mid\ a,b\in
\mathbb{Z}\right\}  \text{ is a ring.}%
\]
But the set $\left\{  a+b\sqrt[3]{2}\ \mid\ a,b\in\mathbb{Z}\right\}  $ (with
the usual addition and multiplication) is \textbf{not} a ring. The reason is
that multiplication is not a binary operation on this set, since it is
possible that two numbers $\alpha$ and $\beta$ lie in this set but their
product $\alpha\beta$ does not. For example, $1+\sqrt[3]{2}$ lies in this set,
but%
\[
\left(  1+\sqrt[3]{2}\right)  \left(  1+\sqrt[3]{2}\right)  =1+2\sqrt[3]%
{2}+\sqrt[3]{4}%
\]
does not. (That said, this set does satisfy all the eight ring axioms.)
\end{itemize}

\begin{center}
\textbf{2019-03-27 lecture}
\end{center}

\begin{itemize}
\item The set of $2\times2$-matrices with rational entries (endowed with
matrix addition as $+$, matrix multiplication as $\cdot$, the zero matrix
$\left(
\begin{array}
[c]{cc}%
0 & 0\\
0 & 0
\end{array}
\right)  $ as $0$, and $\left(
\begin{array}
[c]{cc}%
1 & 0\\
0 & 1
\end{array}
\right)  $ as $1$) is a ring, but \textbf{not} a commutative ring. Indeed, the
ring axioms are true (this is known from linear algebra), but commutativity of
multiplication is not (the product $AB$ of two $2\times2$-matrices $A$ and $B$
is not always equal to $BA$). The same applies to $n\times n$-matrices for
arbitrary $n\in\mathbb{N}$. (We will see this in Corollary
\ref{cor.matrix.ring} below, in greater generality.)

\item If you like the empty set, you will enjoy the \textit{zero ring}. This
is the one-element set $\left\{  0\right\}  $, endowed with the only possible
addition (given by $0+0=0$), the only possible multiplication (given by
$0\cdot0=0$), the only possible zero (namely, $0$) and the only possible unity
(also $0$). This is a commutative ring, and is known as the \textit{zero
ring}. Resist the temptation of denoting its unity by $1$, as this will
quickly lead to painful confusion.

(Some authors choose to forbid this ring, usually for no good reasons.)

\item If $n$ is an integer, then $\mathbb{Z}/n$ is a ring (with the operations
$+$ and $\cdot$ that we defined, with the zero $\left[  0\right]  _{n}$ and
the unity $\left[  1\right]  _{n}$). When the integer $n$ is positive, this
ring $\mathbb{Z}/n$ has $n$ elements. (When $n$ is prime, it can be shown that
$\mathbb{Z}/n$ is the only ring with exactly $n$ elements, up to relabeling
its elements. In general, however, there can be several rings with $n$ elements.)

\item In set theory, the
\textit{\href{https://en.wikipedia.org/wiki/Symmetric_difference}{\textit{symmetric
difference}}} $A\bigtriangleup B$ of two sets $A$ and $B$ is defined to be the
set%
\begin{align*}
\left(  A\cup B\right)  \setminus\left(  A\cap B\right)   &  =\left(
A\setminus B\right)  \cup\left(  B\setminus A\right) \\
&  =\left\{  x\ \mid\ x\text{ belongs to \textbf{exactly one} of }A\text{ and
}B\right\}  .
\end{align*}


Now, let $S$ be any set. Let $\mathcal{P}\left(  S\right)  $ denote the power
set of $S$ (that is, the set of all subsets of $S$). Then, it is easy to check
that the following properties hold:%
\begin{align*}
A\bigtriangleup B  &  =B\bigtriangleup A\ \ \ \ \ \ \ \ \ \ \text{for any sets
}A\text{ and }B;\\
A\cap B  &  =B\cap A\ \ \ \ \ \ \ \ \ \ \text{for any sets }A\text{ and }B;\\
\left(  A\bigtriangleup B\right)  \bigtriangleup C  &  =A\bigtriangleup\left(
B\bigtriangleup C\right)  \ \ \ \ \ \ \ \ \ \ \text{for any sets }A,B,C;\\
\left(  A\cap B\right)  \cap C  &  =A\cap\left(  B\cap C\right)
\ \ \ \ \ \ \ \ \ \ \text{for any sets }A,B,C;\\
A\bigtriangleup\varnothing &  =\varnothing\bigtriangleup
A=A\ \ \ \ \ \ \ \ \ \ \text{for any set }A;\\
A\cap S  &  =S\cap A=A\ \ \ \ \ \ \ \ \ \ \text{for any subset }A\text{ of
}S;\\
A\bigtriangleup A  &  =\varnothing\ \ \ \ \ \ \ \ \ \ \text{for any set }A;\\
\varnothing\cap A  &  =A\cap\varnothing=\varnothing
\ \ \ \ \ \ \ \ \ \ \text{for any set }A;\\
A\cap\left(  B\bigtriangleup C\right)   &  =\left(  A\cap B\right)
\bigtriangleup\left(  A\cap C\right)  \ \ \ \ \ \ \ \ \ \ \text{for any sets
}A,B,C;\\
\left(  A\bigtriangleup B\right)  \cap C  &  =\left(  A\cap C\right)
\bigtriangleup\left(  B\cap C\right)  \ \ \ \ \ \ \ \ \ \ \text{for any sets
}A,B,C.
\end{align*}
Therefore, the set $\mathcal{P}\left(  S\right)  $, endowed with the addition
$\bigtriangleup$, the multiplication $\cap$, the zero $\varnothing$ and the
unity $S$ is a commutative ring. Furthermore, the additive inverse of any
$A\in\mathcal{P}\left(  S\right)  $ is $A$ itself (since $A\bigtriangleup
A=\varnothing$). Moreover, each $A\in\mathcal{P}\left(  S\right)  $ satisfies
$A\cap A=A$, which means (in the language of ring operations) that its square
is itself. Thus, $\mathcal{P}\left(  S\right)  $ is what is called a
\textit{\href{https://en.wikipedia.org/wiki/Boolean_ring}{\textit{Boolean
ring}}}. (See Exercise 2 on
\href{http://www-users.math.umn.edu/~dgrinber/19s/mt2s.pdf}{midterm \#2} for
the precise definition and a few properties of Boolean rings.)
\end{itemize}

Let us now see some non-examples -- i.e., examples of things that are not rings:

\begin{itemize}
\item You probably remember the
\textit{\href{https://en.wikipedia.org/wiki/Cross_product}{\textit{cross
product}}} from analytic geometry. In a nutshell: The set $\mathbb{R}^{3}$ of
vectors in $3$-dimensional space has a binary operation $\times$ defined on
it, which is given by%
\[
\left(  a_{1},a_{2},a_{3}\right)  \times\left(  b_{1},b_{2},b_{3}\right)
=\left(  a_{2}b_{3}-a_{3}b_{2},a_{3}b_{1}-a_{1}b_{3},a_{1}b_{2}-a_{2}%
b_{1}\right)  .
\]
Is the set $\mathbb{R}^{3}$, equipped with the addition $+$ and the
multiplication $\times$ (and some elements playing the roles of zero and
unity) a ring?

The answer is \textquotedblleft no\textquotedblright, no matter which elements
you want to play the roles of zero and unity. Indeed, the \textquotedblleft
Associativity of multiplication\textquotedblright\ axiom does not hold,
because three vectors $\mathbf{a},\mathbf{b},\mathbf{c}\in\mathbb{R}^{3}$
usually do \textbf{not} satisfy $\mathbf{a}\times\left(  \mathbf{b}%
\times\mathbf{c}\right)  =\left(  \mathbf{a}\times\mathbf{b}\right)
\times\mathbf{c}$.

Nevertheless, not all is lost; for example, the \textquotedblleft
Distributivity\textquotedblright\ axiom holds. The structure formed by the set
$\mathbb{R}^{3}$, its addition $+$ and its cross product $\times$ is an
instance of a different concept -- namely, of a
\href{https://en.wikipedia.org/wiki/Lie_algebra}{Lie algebra}.

\item So the cross product does not work; what about the dot product? The dot
product of two vectors $\left(  a_{1},a_{2},a_{3}\right)  $ and $\left(
b_{1},b_{2},b_{3}\right)  $ in $\mathbb{R}^{3}$ is a real number given by%
\[
\left(  a_{1},a_{2},a_{3}\right)  \cdot\left(  b_{1},b_{2},b_{3}\right)
=a_{1}b_{1}+a_{2}b_{2}+a_{3}b_{3}.
\]
Can this be used to make $\mathbb{R}^{3}$ into a ring?

No, because the dot product is not even a binary operation on $\mathbb{R}^{3}%
$. Indeed, our definition of a binary operation requires that its output
belongs to the same domain as its two inputs; this is clearly not true of the
dot product (since its output is a real number, while its two inputs are vectors).

\item For each $a,b\in\mathbb{R}$, we let $A_{a,b}$ be the function%
\[
\mathbb{R}\rightarrow\mathbb{R},\ \ \ \ \ \ \ \ \ \ x\mapsto ax+b.
\]
This sort of function is called \textquotedblleft linear
function\textquotedblright\ in high school; research mathematicians prefer to
call it \textquotedblleft affine-linear function\textquotedblright\ instead
(while reserving the word \textquotedblleft linear\textquotedblright\ for a
more restrictive class of functions). Let $\operatorname*{ALF}$ be the set of
these affine-linear functions $A_{a,b}$ for all $a,b\in\mathbb{R}$.

We can define a pointwise addition $+$ on $\operatorname*{ALF}$; that is, for
any $f,g\in A_{a,b}$, we define a function $f+g\in A_{a,b}$ by%
\[
\left(  f+g\right)  \left(  x\right)  =f\left(  x\right)  +g\left(  x\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }x\in\mathbb{R}.
\]
We can also try to define a multiplication $\cdot$ on $\operatorname*{ALF}$.
One obvious choice would be to define multiplication to be composition (that
is, $f\cdot g=f\circ g$); another would be pointwise multiplication (that is,
$\left(  f\cdot g\right)  \left(  x\right)  =f\left(  x\right)  \cdot g\left(
x\right)  $ for all $x\in\mathbb{R}$). Does any of these lead to a ring?

No. If we define multiplication to be composition, then the \textquotedblleft
Distributivity\textquotedblright\ axiom is violated, since affine-linear
functions $f,g,h$ do not always satisfy $f\circ\left(  g+h\right)  =f\circ
g+f\circ h$. If we define multiplication to be pointwise multiplication, then
it is not a binary operation on $\operatorname*{ALF}$, since the pointwise
product of two affine-linear functions is not an affine-linear function in general.

\item How comes we cannot divide by $0$?

Let us make the question precise. Of course, we cannot find an integer $a$
that satisfies $0\cdot a=1$, or a real, or a complex number, etc. But could we
perhaps find such a number $a$ in some larger \textquotedblleft number
system\textquotedblright?

The answer, of course, depends on what \textquotedblleft number
system\textquotedblright\ means for you. If it means a ring, then we cannot
find such an $a$ in any ring.

Indeed, assume that we can. In other words, assume that there is a ring
$\mathbb{K}$ that contains the usual set $\mathbb{Z}$ of integers as well as a
new element $\infty$ such that $0\cdot\infty=1$. And assume (this is a very
reasonable assumption) that the numbers $0$ and $1$ are indeed the zero and
the unity of this ring. Then, the Annihilation axiom yields $0\cdot\infty=0$,
so that $0=0\cdot\infty=1$, which is absurd. So such a ring $\mathbb{K}$
cannot exist. Thus, we cannot divide by $0$, even if we extend our
\textquotedblleft number system\textquotedblright.

\item Here is an \textquotedblleft almost-ring\textquotedblright\ beloved to
combinatorialists: the \textit{max-plus semiring} $\mathbb{T}$ (also known as
the \textit{tropical semiring}\footnote{To be pedantic: The name
\textquotedblleft tropical semiring\textquotedblright\ refers to several
different objects, of which $\mathbb{T}$ is but one.}).

We introduce a new symbol $-\infty$, and we set $\mathbb{T}=\mathbb{Z}%
\cup\left\{  -\infty\right\}  $ as sets. But we do \textbf{not}
\textquotedblleft inherit\textquotedblright\ the addition and multiplication
from $\mathbb{Z}$. Instead, let us define two new \textquotedblleft
addition\textquotedblright\ and \textquotedblleft
multiplication\textquotedblright\ operations $+_{\mathbb{T}}$ and
$\cdot_{\mathbb{T}}$ (not to be mistaken for the original addition $+$ and
multiplication $\cdot$ of integers) as follows:%
\begin{align*}
a+_{\mathbb{T}}b  &  =\max\left\{  a,b\right\}  ;\\
a\cdot_{\mathbb{T}}b  &  =a+b\ \ \ \ \ \ \ \ \ \ \left(  \text{usual addition
of integers}\right)  ,
\end{align*}
where we set%
\begin{align*}
\max\left\{  -\infty,n\right\}   &  =\max\left\{  n,-\infty\right\}
=n\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  -\infty\right)  +n  &  =n+\left(  -\infty\right)  =-\infty
\ \ \ \ \ \ \ \ \ \ \text{for any }n\in\mathbb{Z}\cup\left\{  -\infty\right\}
.
\end{align*}


This set $\mathbb{T}$ endowed with the \textquotedblleft
addition\textquotedblright\ $+_{\mathbb{T}}$, \textquotedblleft
multiplication\textquotedblright\ $\cdot_{\mathbb{T}}$, \textquotedblleft
zero\textquotedblright\ $-\infty$ and \textquotedblleft
unity\textquotedblright\ $0$ satisfies all but one of the ring
axioms.\footnote{For example, the distributivity axiom for $\mathbb{T}$ boils
down to the two identities%
\begin{align*}
a+\max\left\{  b,c\right\}   &  =\max\left\{  a+b,a+c\right\}
\ \ \ \ \ \ \ \ \ \ \text{and}\\
\max\left\{  a,b\right\}  +c  &  =\max\left\{  a+c,b+c\right\}  .
\end{align*}
} The only one that it does not satisfy is the existence of additive inverses.
Such a structure is called a \textit{semiring}.

\item Consider the set
\[
2\mathbb{Z}:=\left\{  2a\ \mid\ a\in\mathbb{Z}\right\}  =\left\{
\ldots,-4,-2,0,2,4,\ldots\right\}  =\left\{  \text{all even integers}\right\}
.
\]
Endowing this set with the usual addition and multiplication (and $0$), we
obtain a structure that is like a ring but has no unity. This is called a
\textit{nonunital ring}. There is no way to find a unity for it, because (for
example) $2$ is not a product of any two elements of $2\mathbb{Z}$.
\end{itemize}

\subsection{\label{sect.ring.subring}Subrings}

Looking back at the examples of rings listed above, you might notice that a
lot of them are \textquotedblleft nested\textquotedblright\ inside one
another: For example, the rings $\mathbb{Z}$, $\mathbb{Q}$, $\mathbb{R}$ and
$\mathbb{C}$ form a chain $\mathbb{Z}\subseteq\mathbb{Q}\subseteq
\mathbb{R}\subseteq\mathbb{C}$ in which each ring not only is a subset of the
subsequent one\footnote{To be fully honest, we are relying on Convention
\ref{conv.CC.RRtoCC.embed} in order to make $\mathbb{R}$ a subset of
$\mathbb{C}$. And if you look closely at the definitions of $\mathbb{Q}$ and
$\mathbb{R}$, the relations $\mathbb{Z}\subseteq\mathbb{Q}$ and $\mathbb{Q}%
\subseteq\mathbb{R}$ are also not immediately satisfied but rather rely on
similar conventions. For example, rational numbers are defined as equivalence
classes of pairs of integers; an integer is not an equivalence class of such
pairs. Thus, we need a convention which identifies each integer $z$ with an
appropriate rational number in order to turn $\mathbb{Z}$ into a subset of
$\mathbb{Q}$. Similarly for turning $\mathbb{Q}$ into a subset of $\mathbb{R}%
$. But let us not worry about this issue for now.}, but also has
\textquotedblleft the same\textquotedblright\ addition, multiplication, zero
and unity as the subsequent one. Of course, when we are saying
\textquotedblleft the same\textquotedblright\ here, we do not literally mean
\textquotedblleft the same\textquotedblright; we mean that, e.g., if we add
two integers in $\mathbb{Z}$, we get the same result as if we add the same two
integers as elements of $\mathbb{Q}$, or as elements of $\mathbb{R}$, or as
elements of $\mathbb{C}$. In other words, the addition operation of the ring
$\mathbb{Z}$ is a \textbf{restriction} of the addition operation of the ring
$\mathbb{Q}$, which in turn is a restriction of the addition operation of the
ring $\mathbb{R}$, etc.. The same holds for multiplication. The zeroes of the
rings $\mathbb{Z}$, $\mathbb{Q}$, $\mathbb{R}$ and $\mathbb{C}$ are literally
identical, as are the unities of these rings.

It is worth introducing a name for this situation:

\begin{definition}
\label{def.ring.subring}Let $\mathbb{K}$ and $\mathbb{L}$ be two rings. We say
that $\mathbb{K}$ is a \textit{subring} of $\mathbb{L}$ if and only if it
satisfies the following five requirements:

\begin{itemize}
\item the set $\mathbb{K}$ is a subset of $\mathbb{L}$;

\item the addition of $\mathbb{K}$ is a restriction of the addition of
$\mathbb{L}$ (that is, we have $a_{1}+_{\mathbb{K}}a_{2}=a_{1}+_{\mathbb{L}%
}a_{2}$ for all $a_{1},a_{2}\in\mathbb{K}$);

\item the multiplication of $\mathbb{K}$ is a restriction of the
multiplication of $\mathbb{L}$ (that is, we have $a_{1}\cdot_{\mathbb{K}}%
a_{2}=a_{1}\cdot_{\mathbb{L}}a_{2}$ for all $a_{1},a_{2}\in\mathbb{K}$);

\item the zero of $\mathbb{K}$ is the zero of $\mathbb{L}$ (that is, we have
$0_{\mathbb{K}}=0_{\mathbb{L}}$);

\item the unity of $\mathbb{K}$ is the unity of $\mathbb{L}$ (that is, we have
$1_{\mathbb{K}}=1_{\mathbb{L}}$).
\end{itemize}
\end{definition}

Thus, according to this definition:

\begin{itemize}
\item the ring $\mathbb{Z}$ is a subring of $\mathbb{Q}$;

\item the ring $\mathbb{Q}$ is a subring of $\mathbb{R}$;

\item the ring $\mathbb{R}$ is a subring of $\mathbb{C}$;

\item the ring $\mathbb{Z}\left[  i\right]  $ (of Gaussian integers) is a
subring of $\mathbb{C}$;

\item every ring $\mathbb{K}$ is a subring of itself.
\end{itemize}

What is an example of two rings $\mathbb{K}$ and $\mathbb{L}$ for which the
set $\mathbb{K}$ is a \textbf{subset} of $\mathbb{L}$ yet the ring
$\mathbb{K}$ is \textbf{not a subring} of $\mathbb{L}$ ? Here is one example
of an \textquotedblleft almost-subring\textquotedblright:

\begin{example}
One of our above examples of rings (in Section \ref{sect.ring.exa}) is the
power set of any set $S$. Namely, if $S$ is any set, then we have observed
that its power set $\mathcal{P}\left(  S\right)  $, endowed with the addition
$\bigtriangleup$, the multiplication $\cap$, the zero $\varnothing$ and the
unity $S$ is a commutative ring. We shall refer to this ring by $\mathcal{P}%
\left(  S\right)  $ (omitting mention of its addition, multiplication, zero
and unity).

Now, let $T$ be a subset of a set $S$. Is $\mathcal{P}\left(  T\right)  $ a
subring of the ring $\mathcal{P}\left(  S\right)  $ ? The first four
requirements of Definition \ref{def.ring.subring} are satisfied: The set
$\mathcal{P}\left(  T\right)  $ is a subset of $\mathcal{P}\left(  S\right)
$; its addition is a restriction of the addition of $\mathcal{P}\left(
S\right)  $ (indeed, both of these additions turn two sets $A$ and $B$ into
$A\bigtriangleup B$); its multiplication is a restriction of the
multiplication of $\mathcal{P}\left(  S\right)  $, its zero is the zero of
$\mathcal{P}\left(  S\right)  $. But its unity is not the unity of
$\mathcal{P}\left(  S\right)  $ (unless $T=S$); indeed, the former unity is
$T$, while the latter unity is $S$. Thus, $\mathcal{P}\left(  T\right)  $ is
not a subring of $\mathcal{P}\left(  S\right)  $ (unless $T=S$). It fails the
fifth requirement of Definition \ref{def.ring.subring}.

(As we have remarked, some authors do not require rings to have a unity.
Correspondingly, these authors do not pose the fifth requirement in Definition
\ref{def.ring.subring}. Thus, for these authors, $\mathcal{P}\left(  T\right)
$ is a subring of $\mathcal{P}\left(  S\right)  $.)
\end{example}

For a less subtle example, recall the ring $\mathbb{Z}^{\prime}$ constructed
in Section \ref{sect.ring.exa}. The sets $\mathbb{Z}^{\prime}$ and
$\mathbb{Z}$ are identical, but the rings $\mathbb{Z}^{\prime}$ and
$\mathbb{Z}$ are not, so the ring $\mathbb{Z}^{\prime}$ is not a subring of
$\mathbb{Z}$ despite being a subset of $\mathbb{Z}$.

When we have two rings $\mathbb{K}$ and $\mathbb{L}$ such that $\mathbb{K}%
\subseteq\mathbb{L}$ as sets (or, more generally, such that $\mathbb{K}$ and
$\mathbb{L}$ have elements in common), we generally need to be careful using
the symbol \textquotedblleft$+$\textquotedblright: This symbol may mean both
the addition of $\mathbb{K}$ and the addition of $\mathbb{L}$, and these
additions might not be the same. Thus it is prudent to disambiguate its
meaning by attaching a subscript \textquotedblleft$_{\mathbb{K}}%
$\textquotedblright\ or \textquotedblleft$_{\mathbb{L}}$\textquotedblright\ to
it. The same applies to the symbols \textquotedblleft$\cdot$\textquotedblright%
, \textquotedblleft$0$\textquotedblright\ and \textquotedblleft$1$%
\textquotedblright\ and expressions like \textquotedblleft$ab$%
\textquotedblright\ (which have an implicit multiplication sign). However,
when $\mathbb{K}$ is a subring of $\mathbb{L}$, we do not need to take this
precaution; in this case, the meaning of expressions like \textquotedblleft%
$a+b$\textquotedblright\ does not depend on whether you read \textquotedblleft%
$+$\textquotedblright\ as the addition of $\mathbb{K}$ or as the addition of
$\mathbb{L}$.

The following facts are essentially obvious:

\begin{proposition}
\label{prop.ring.subring.comm}A subring of a commutative ring is always commutative.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ring.subring.comm}.]Let $\mathbb{K}$ be a
subring of a commutative ring $\mathbb{L}$. We must prove that $\mathbb{K}$ is commutative.

We have $ab=ba$ for all $a,b\in\mathbb{L}$ (since $\mathbb{L}$ is
commutative). Thus, $ab=ba$ for all $a,b\in\mathbb{K}$ (since $\mathbb{K}$ is
a subring of $\mathbb{L}$). In other words, $\mathbb{K}$ is commutative. This
completes our proof.

Note how we were able to write expressions like \textquotedblleft%
$ab$\textquotedblright\ and \textquotedblleft$ba$\textquotedblright\ without
specifying whether we were using the multiplication of $\mathbb{K}$ or the
multiplication of $\mathbb{L}$. This was legitimate because $\mathbb{K}$ is a
subring (not just a subset) of $\mathbb{L}$.
\end{proof}

\begin{proposition}
\label{prop.ring.subring.as-subset}Let $\mathbb{L}$ be a ring. Let $S$ be a
subset of $\mathbb{L}$ that satisfies the following four conditions:\footnotemark

\begin{itemize}
\item We have $0\in S$ and $1\in S$.

\item The subset $S$ is \textit{closed under addition}. (This means that all
$a,b\in S$ satisfy $a+b\in S$.)

\item The subset $S$ is \textit{closed under additive inverses}. (This means
that all $a\in S$ satisfy $-a\in S$.)

\item The subset $S$ is \textit{closed under multiplication}. (This means that
all $a,b\in S$ satisfy $ab\in S$.)
\end{itemize}

Then, the set $S$ itself becomes a ring if we endow it with the following two operations:

\begin{itemize}
\item an addition operation $+$ which is defined as the restriction of the
addition operation of the ring $\mathbb{L}$;

\item a multiplication operation $\cdot$ which is defined as the restriction
of the multiplication operation of the ring $\mathbb{L}$,
\end{itemize}

\noindent and the zero $0$ and the unity $1$. Furthermore, this ring $S$ is a
subring of $\mathbb{L}$.
\end{proposition}

\footnotetext{In this proposition, the symbols \textquotedblleft%
$+$\textquotedblright, \textquotedblleft$\cdot$\textquotedblright,
\textquotedblleft$0$\textquotedblright\ and \textquotedblleft$1$%
\textquotedblright\ mean the addition, the multiplication, the zero and the
unity of $\mathbb{L}$.}

\begin{proof}
[Proof of Proposition \ref{prop.ring.subring.as-subset}.]The addition
operation $+$ that we are trying to define on $S$ is indeed a well-defined
binary operation on $S$, because $S$ is closed under addition. Ditto for the
multiplication operation $\cdot$. Also, $0$ and $1$ are elements of $S$ (by
the first of our four conditions). Thus, in order to prove that the subset $S$
becomes a ring (when endowed with these two operations and two elements), we
just need to check that it satisfies the ring axioms. This is easy: The
\textquotedblleft Existence of additive inverses\textquotedblright\ axiom
follows from the fact that $S$ is closed under additive inverses; all the
remaining axioms follow from the fact that $\mathbb{L}$ is a ring. Finally,
this ring $S$ is a subring of $\mathbb{L}$, because of how we defined it.
Thus, Proposition \ref{prop.ring.subring.as-subset} is proven.
\end{proof}

\begin{definition}
Let $\mathbb{L}$ be a ring. Let $S$ be a subset of $\mathbb{L}$ that satisfies
the four conditions of Proposition \ref{prop.ring.subring.as-subset}. Then, we
shall say that \textquotedblleft$S$ is a subring of $\mathbb{L}$%
\textquotedblright. Technically speaking, this is premature, since $S$ is so
far just a subset of $\mathbb{L}$ without the structure of a ring; however,
Proposition \ref{prop.ring.subring.as-subset} shows that there is an obvious
way of turning $S$ into a ring (viz.: define two operations $+$ and $\cdot$ by
restricting the corresponding operations of $\mathbb{L}$, and steal the zero
and the unity from $\mathbb{L}$), and we shall automatically regard $S$ as
becoming a ring in this way (unless we say otherwise). We say that the
operations $+$ and $\cdot$ on $S$ (obtained by restricting the corresponding
operations on $\mathbb{L}$) and the zero and the unity of $S$ (which are
exactly those of $\mathbb{L}$) are \textit{inherited from }$\mathbb{L}$.
\end{definition}

Thus, finding subrings of a ring $\mathbb{L}$ boils down to finding subsets
that contain its $0$ and $1$ and are closed under addition, under additive
inverses and under multiplication; the ring axioms don't need to be
re-checked. This offers an easy way to discover subrings:

\begin{example}
Let us define a few subsets of the ring $\mathbb{Z}\left[  i\right]  $ and see
whether they are subrings.

\textbf{(a)} Let
\[
S_{1}=\left\{  a+bi\ \mid\ a,b\in\mathbb{Z}\text{, and }b\text{ is
even}\right\}  =\left\{  a+2ci\ \mid\ a,c\in\mathbb{Z}\right\}  .
\]
Is $S_{1}$ a subring of $\mathbb{Z}\left[  i\right]  $ ?

It is easy to check that $0\in S_{1}$ and $1\in S_{1}$. Let us now check that
$S_{1}$ is closed under multiplication: Let $\alpha,\beta\in S_{1}$; we need
to show that $\alpha\beta\in S_{1}$. We have $\alpha\in S_{1}=\left\{
a+2ci\ \mid\ a,c\in\mathbb{Z}\right\}  $; in other words, we can write
$\alpha$ in the form $\alpha=x+2yi$ for some $x,y\in\mathbb{Z}$. Similarly, we
can write $\beta$ in the form $\beta=z+2wi$ for some $z,w\in\mathbb{Z}$. Now,
multiplying the two equalities $\alpha=x+2yi$ and $\beta=z+2wi$, we obtain%
\begin{align*}
\alpha\beta &  =\left(  x+2yi\right)  \left(  z+2wi\right)
=xz+2xwi+2yzi+4yw\underbrace{i^{2}}_{=-1}\\
&  =\left(  xz-4yw\right)  +2\left(  xw+yz\right)  i.
\end{align*}
Thus, $\alpha\beta$ can be written in the form $a+2ci$ for some $a,c\in
\mathbb{Z}$ (namely, for $a=xz-4yw$ and $c=xw+yz$). Thus, $\alpha\beta\in
S_{1}$. Now, forget that we fixed $\alpha,\beta$. We thus have shown that all
$\alpha,\beta\in S_{1}$ satisfy $\alpha\beta\in S_{1}$. In other words,
$S_{1}$ is closed under multiplication. Similar arguments show that $S_{1}$ is
closed under addition and under additive inverses. Thus, $S_{1}$ is a subring
of $\mathbb{Z}\left[  i\right]  $.

This subring $S_{1}$ is only \textquotedblleft half as large\textquotedblright%
\ as $\mathbb{Z}\left[  i\right]  $ (in a vague sense that can be made
precise), but it has rather different properties. For example, $\mathbb{Z}%
\left[  i\right]  $ has greatest common divisors and unique factorization into
primes; the subring $S_{1}$
\href{https://math.stackexchange.com/questions/657058}{does not}.

There is nothing special about the number $2$; we could have just as easily
shown that $\left\{  a+kci\ \mid\ a,c\in\mathbb{Z}\right\}  $ is a subring of
$\mathbb{Z}\left[  i\right]  $ for each $k\in\mathbb{Z}$.

\textbf{(b)} Let
\[
S_{2}=\left\{  a+bi\ \mid\ a,b\in\mathbb{Z}\text{, and }a\text{ is
even}\right\}  =\left\{  2c+bi\ \mid\ c,b\in\mathbb{Z}\right\}  .
\]
Is $S_{2}$ a subring of $\mathbb{Z}\left[  i\right]  $ ? No, since $1\notin
S_{2}$.

\textbf{(c)} Let
\[
S_{3}=\left\{  a+bi\ \mid\ a,b\in\mathbb{Z}\text{, and }b\text{ is a multiple
of }a\right\}  =\left\{  a+aci\ \mid\ a,c\in\mathbb{Z}\right\}  .
\]
Is $S_{3}$ a subring of $\mathbb{Z}\left[  i\right]  $ ? The subset $S_{3}$
does contain both $0$ and $1$ and is closed under additive inverses; but
$S_{3}$ is not closed under addition (nor under multiplication). Thus, $S_{3}$
is not a subring of $\mathbb{Z}\left[  i\right]  $. (For a concrete example:
The numbers $1+2i$ and $1+3i$ both belong to $S_{3}$, but their sum $2+5i$
does not.)

\textbf{(d)} Let%
\[
S_{4}=\left\{  a+bi\ \mid\ a,b\in\mathbb{N}\right\}  .
\]
Is $S_{4}$ a subring of $\mathbb{Z}\left[  i\right]  $ ? No, because $S_{4}$
is not closed under additive inverses (although $S_{4}$ satisfies all the
other three conditions of Proposition \ref{prop.ring.subring.as-subset}.)

\textbf{(e)} A pattern emerges: It appears that the only subrings of
$\mathbb{Z}\left[  i\right]  $ are the ones of the form $\left\{
a+kci\ \mid\ a,c\in\mathbb{Z}\right\}  $ for $k\in\mathbb{Z}$. This is indeed
true. (It is not hard to prove, if you are so inclined! \textbf{Hint:} Let $S$
be any subring of $\mathbb{Z}\left[  i\right]  $. Clearly, $S$ contains $1$
and therefore all the integer multiples of $1$; in other words, $\mathbb{Z}%
\subseteq S$. Hence, if $S\subseteq\mathbb{Z}$, then clearly $S=\mathbb{Z}$,
which means that $S=\left\{  a+kci\ \mid\ a,c\in\mathbb{Z}\right\}  $ for
$k=0$. Thus, we can WLOG assume that $S\not \subseteq \mathbb{Z}$. Hence,
there exists at least one $a+bi\in S$ with $b\neq0$. Thus, there exists at
least one $a+bi\in S$ with $b>0$ (indeed, if $b<0$, then we replace this
element by its additive inverse). Pick the one with the \textbf{smallest} $b$.
Then, from $a+bi\in S$ and $a\in\mathbb{Z}\subseteq S$, we obtain $\left(
a+bi\right)  -a\in S$ (since $S$ is a ring), which means that $bi\in S$. Next,
argue that $S=\left\{  a+kci\ \mid\ a,c\in\mathbb{Z}\right\}  $ for $k=b$.)
\end{example}

\subsection{\label{sect.ring.rules}Additive inverses, sums, powers and their
properties}

What can you do when you have a ring?

\begin{convention}
\label{conv.rings.K}For the rest of this section, we fix a ring $\mathbb{K}$,
and we denote its addition, multiplication, zero and unity by $+$, $\cdot$,
$0$ and $1$.
\end{convention}

One thing you can do is subtraction. This relies on the following fact:

\begin{theorem}
\label{thm.rings.inv-add.uni}Let $a\in\mathbb{K}$. Then, $a$ has exactly one
additive inverse.
\end{theorem}

Before we prove this, let us recall how additive inverses are defined:

\begin{definition}
\label{def.rings.inv-add}Let $a\in\mathbb{K}$. An \textit{additive inverse} of
$a$ means an element $a^{\prime}$ of $\mathbb{K}$ such that $a+a^{\prime
}=a^{\prime}+a=0$.
\end{definition}

\begin{proof}
[Proof of Theorem \ref{thm.rings.inv-add.uni}.]By the ring axioms, $a$ has
\textbf{at least one} additive inverse. We must thus only show that $a$ has
\textbf{at most one} additive inverse.

This can be done by the same argument that we used previously to prove that a
residue class in $\mathbb{Z}/n$ has at most one inverse (in the proof of
Proposition \ref{prop.equiv.modinv.uni}), but now we need to replace
$\mathbb{Z}/n$, multiplication and $\left[  1\right]  _{n}$ by $\mathbb{K}$,
addition and $0$, respectively.

In detail: Let $b$ and $c$ be two additive inverses of $a$. We must prove that
$b=c$. We have $a+b=0$ (since $b$ is an additive inverse of $a$) and $c+a=0$
(since $c$ is an additive inverse of $a$). Hence, the associativity of
addition yields%
\[
\left(  c+a\right)  +b=c+\underbrace{\left(  a+b\right)  }_{=0}=c+0=c
\]
(by the neutrality of zero). Comparing this with%
\[
\underbrace{\left(  c+a\right)  }_{=0}+b=0+b=b\qquad\left(  \text{by the
neutrality of zero}\right)  ,
\]
we obtain $b=c$, so our two additive inverses are equal. This shows that the
additive inverse is unique. Thus, Theorem \ref{thm.rings.inv-add.uni} is proven.
\end{proof}

\begin{definition}
\label{def.rings.inv-add-a}\textbf{(a)} If $a\in\mathbb{K}$, then the additive
inverse of $a$ will be called $-a$. (This is well-defined, since Theorem
\ref{thm.rings.inv-add.uni} shows that this additive inverse is unique.)

\textbf{(b)} If $a\in\mathbb{K}$ and $b\in\mathbb{K}$, then we define the
\textit{difference} $a-b$ to be the element $a+\left(  -b\right)  $ of
$\mathbb{K}$. This new binary operation $-$ on $\mathbb{K}$ is called
\textquotedblleft\textit{subtraction}\textquotedblright.
\end{definition}

Additive inverses and subtraction satisfy certain rules that should not
surprise you:

\begin{proposition}
\label{prop.rings.inv-add.rules}Let $a,b,c\in\mathbb{K}$.

\textbf{(a)} We have $a-b=c$ if and only if $a=b+c$. (Roughly speaking, this
means that subtraction undoes addition.)

\textbf{(b)} We have $-\left(  a+b\right)  =\left(  -a\right)  +\left(
-b\right)  $.

\textbf{(c)} We have $-0=0$.

\textbf{(d)} We have $0-a=-a$.

\textbf{(e)} We have $-\left(  -a\right)  =a$.

\textbf{(f)} We have $-\left(  ab\right)  =\left(  -a\right)  b=a\left(
-b\right)  $.

\textbf{(g)} We have $a-b-c=a-\left(  b+c\right)  $. (Here and in the
following, \textquotedblleft$a-b-c$\textquotedblright\ should be read as
\textquotedblleft$\left(  a-b\right)  -c$\textquotedblright.)
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.rings.inv-add.rules}.]All of this is fairly
straightforward to prove:

\textbf{(a)} $\Longrightarrow:$ Assume $a-b=c$. Thus, $c=a-b=a+\left(
-b\right)  $ (by the definition of $a-b$). Adding $b$ on both sides of this
equation, we get%
\begin{align*}
c+b  &  =\left(  a+\left(  -b\right)  \right)  +b=a+\underbrace{\left(
\left(  -b\right)  +b\right)  }_{\substack{=0\\\text{(since }-b\text{ is
the}\\\text{additive inverse of }b\text{)}}}\ \ \ \ \ \ \ \ \ \ \left(
\text{by associativity of addition}\right) \\
&  =a+0=a
\end{align*}
(by the neutrality of zero), so that $a=c+b=b+c$.

$\Longleftarrow:$ Assume $a=b+c$. Adding $-b$ to both sides of this equation,
we get%
\begin{align*}
a+\left(  -b\right)   &  =\underbrace{\left(  b+c\right)  }%
_{\substack{=c+b\\\text{(by commutativity}\\\text{of addition)}}}+\left(
-b\right)  =\left(  c+b\right)  +\left(  -b\right)  =c+\underbrace{\left(
b+\left(  -b\right)  \right)  }_{\substack{=0\\\text{(since }-b\text{ is
the}\\\text{additive inverse of }b\text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by associativity of addition}\right) \\
&  =c+0=c
\end{align*}
(by the neutrality of zero), so that $c=a+\left(  -b\right)  =a-b$. Thus,
Proposition \ref{prop.rings.inv-add.rules} \textbf{(a)} is proven.

\textbf{(b)} We need to prove that $\left(  -a\right)  +\left(  -b\right)
=-\left(  a+b\right)  $. In other words, we need to prove that $\left(
-a\right)  +\left(  -b\right)  $ is the additive inverse of $a+b$ (because
that's what $-\left(  a+b\right)  $ is). In other words, we need to prove
that
\[
\left(  a+b\right)  +\left(  \left(  -a\right)  +\left(  -b\right)  \right)
=\left(  \left(  -a\right)  +\left(  -b\right)  \right)  +\left(  a+b\right)
=0.
\]


Associativity of addition yields%
\begin{align*}
\left(  a+b\right)  +\left(  \left(  -a\right)  +\left(  -b\right)  \right)
&  =a+\left(  b+\underbrace{\left(  \left(  -a\right)  +\left(  -b\right)
\right)  }_{=\left(  -b\right)  +\left(  -a\right)  }\right)
=a+\underbrace{\left(  b+\left(  \left(  -b\right)  +\left(  -a\right)
\right)  \right)  }_{\substack{=\left(  b+\left(  -b\right)  \right)  +\left(
-a\right)  \\\text{(by associativity}\\\text{of addition)}}}\\
&  =a+\left(  \underbrace{\left(  b+\left(  -b\right)  \right)  }%
_{\substack{=0\\\text{(since }-b\text{ is the}\\\text{additive inverse of
}b\text{)}}}+\left(  -a\right)  \right)  =a+\underbrace{\left(  0+\left(
-a\right)  \right)  }_{=-a}\\
&  =a+\left(  -a\right)  =0
\end{align*}
(since $-a$ is the additive inverse of $a$). Also, $\left(  a+b\right)
+\left(  \left(  -a\right)  +\left(  -b\right)  \right)  =\left(  \left(
-a\right)  +\left(  -b\right)  \right)  +\left(  a+b\right)  $ (by
commutativity of addition). Combining these two equalities, we obtain%
\[
\left(  a+b\right)  +\left(  \left(  -a\right)  +\left(  -b\right)  \right)
=\left(  \left(  -a\right)  +\left(  -b\right)  \right)  +\left(  a+b\right)
=0.
\]
This completes the proof of Proposition \ref{prop.rings.inv-add.rules}
\textbf{(b)}.

\textbf{(c)} We have $0+0=0$ (by the neutrality of $0$). But this shows
precisely that $0$ is an additive inverse of $0$. In other words, $0=-0$. This
proves Proposition \ref{prop.rings.inv-add.rules} \textbf{(c)}.

\textbf{(d)} The definition of subtraction yields $0-a=0+\left(  -a\right)
=-a$ (by the neutrality of $0$). This proves Proposition
\ref{prop.rings.inv-add.rules} \textbf{(d)}.

\textbf{(e)} Since $-a$ is an additive inverse of $a$, we have $\left(
-a\right)  +a=0$ and $a+\left(  -a\right)  =0$. But the same two equations say
that $a$ is an additive inverse of $-a$. In other words, $a=-\left(
-a\right)  $. This proves Proposition \ref{prop.rings.inv-add.rules}
\textbf{(e)}.

\textbf{(f)} We have $\left(  -a\right)  +a=0$ (since $-a$ is an additive
inverse of $a$). But distributivity yields $\left(  -a\right)
b+ab=\underbrace{\left(  \left(  -a\right)  +a\right)  }_{=0}b=0b=0$ (by
annihilation). Likewise, $ab+\left(  -a\right)  b=0$. Hence, $\left(
-a\right)  b$ is an additive inverse of $ab$. In other words, $\left(
-a\right)  b=-\left(  ab\right)  $.

We have $b+\left(  -b\right)  =0$ (since $-b$ is an additive inverse of $b$).
But distributivity yields $ab+a\left(  -b\right)  =a\underbrace{\left(
b+\left(  -b\right)  \right)  }_{=0}=a0=0$ (by annihilation). Likewise,
$a\left(  -b\right)  +ab=0$. Hence, $a\left(  -b\right)  $ is an additive
inverse of $ab$. In other words, $a\left(  -b\right)  =-\left(  ab\right)  $.
Combining this with $\left(  -a\right)  b=-\left(  ab\right)  $, we obtain
$-\left(  ab\right)  =\left(  -a\right)  b=a\left(  -b\right)  $. This proves
Proposition \ref{prop.rings.inv-add.rules} \textbf{(f)}.

\textbf{(g)} The definition of subtraction yields%
\[
a-b-c=\underbrace{\left(  a-b\right)  }_{\substack{=a+\left(  -b\right)
\\\text{(by the definition of}\\\text{subtraction)}}}+\left(  -c\right)
=\left(  a+\left(  -b\right)  \right)  +\left(  -c\right)  =a+\left(  \left(
-b\right)  +\left(  -c\right)  \right)
\]
(by associativity of addition). But Proposition \ref{prop.rings.inv-add.rules}
\textbf{(b)} (applied to $b$ and $c$ instead of $a$ and $b$) yields $-\left(
b+c\right)  =\left(  -b\right)  +\left(  -c\right)  $. The definition of
subtraction yields%
\[
a-\left(  b+c\right)  =a+\underbrace{\left(  -\left(  b+c\right)  \right)
}_{=\left(  -b\right)  +\left(  -c\right)  }=a+\left(  \left(  -b\right)
+\left(  -c\right)  \right)  .
\]
Comparing this with $a-b-c=a+\left(  \left(  -b\right)  +\left(  -c\right)
\right)  $, we obtain $a-b-c=a-\left(  b+c\right)  $. This proves Proposition
\ref{prop.rings.inv-add.rules} \textbf{(g)}.
\end{proof}

If $a,b\in\mathbb{K}$, then the expression \textquotedblleft$-ab$%
\textquotedblright\ can be considered ambiguous, since it can be read either
as \textquotedblleft$\left(  -a\right)  b$\textquotedblright\ or as
\textquotedblleft$-\left(  ab\right)  $\textquotedblright. But Proposition
\ref{prop.rings.inv-add.rules} \textbf{(f)} shows that these two readings
yield the same result; therefore, you need not fear this ambiguity.

Furthermore, we don't need to parenthesize expressions like $a+b+c$ or $abc$. Indeed:

\begin{theorem}
\label{thm.rings.sum.wd}Finite sums of elements of $\mathbb{K}$ can be defined
in the same way as finite sums of usual (i.e., real or rational) numbers (with
the empty sum defined to be $0$). That is, if $S$ is a finite set, and if
$a_{s}\in\mathbb{K}$ for each $s\in S$, then $\sum\limits_{s\in S}a_{s}$ is
well-defined and satisfies the usual rules, such as%
\[
\sum\limits_{s\in S}\left(  a_{s}+b_{s}\right)  =\sum\limits_{s\in S}%
a_{s}+\sum\limits_{s\in S}b_{s}.
\]


Thus, in particular, sums like $\sum_{i=p}^{q}a_{i}$ or $a_{1}+a_{2}%
+\cdots+a_{k}$ are well-defined. We don't need to put parentheses or specify
the order of summation in order to make them non-ambiguous.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.rings.sum.wd}.]This is proven just as for numbers.
(See \cite[\S 2.14 and \S 1.4]{detnotes} for how it is proven for numbers.)
\end{proof}

What about finite products? Is $\prod_{s\in S}a_{s}$ well-defined? Not always,
but only for commutative rings. Indeed, a product like $\prod_{s\in S}a_{s}$
has no pre-defined order of multiplication (in general), so for it to be
well-defined, it would have to be independent of the order; but this would
require the commutativity of multiplication.

\begin{theorem}
\label{thm.rings.prod.wd}\textbf{(a)} Finite products of elements of
$\mathbb{K}$ can be defined in the same way as finite products of usual (i.e.,
real or rational) numbers (with the empty product defined to be $1$)
\textbf{as long as the ring }$\mathbb{K}$ \textbf{is commutative}.

\textbf{(b)} For general (not necessarily commutative) rings $\mathbb{K}$, we
can still define products with a pre-determined order, such as $a_{1}%
a_{2}\cdots a_{k}$ (where $a_{1},a_{2},\ldots,a_{k}\in\mathbb{K}$). These
products can be defined recursively as follows:%
\[
a_{1}a_{2}\cdots a_{k}=1\ \ \ \ \ \ \ \ \ \ \text{if }k=0;
\]
otherwise,%
\[
a_{1}a_{2}\cdots a_{k}=\left(  a_{1}a_{2}\cdots a_{k-1}\right)  a_{k}.
\]


These products still satisfy reasonable rules, such as%
\[
a_{1}a_{2}\cdots a_{k}=\left(  a_{1}a_{2}\cdots a_{i}\right)  \left(
a_{i+1}a_{i+2}\cdots a_{k}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }%
i\in\left\{  0,1,\ldots,k\right\}  .
\]

\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.rings.prod.wd}.]\textbf{(a)} This is proven just as
for numbers. (See \cite[\S 2.14 and \S 1.4]{detnotes} for how it is proven for numbers.)

\textbf{(b)} This will be proven on HW0. (For now, you can find proofs in
various texts on algebra, or at
\url{https://groupprops.subwiki.org/wiki/Associative_implies_generalized_associative}
.)
\end{proof}

Theorem \ref{thm.rings.prod.wd} \textbf{(b)} is called the \textit{general
associativity theorem for rings}. Note that Theorem \ref{thm.rings.prod.wd}
\textbf{(b)} entails that if we have $k$ elements $a_{1},a_{2},\ldots,a_{k}$
of a ring $\mathbb{K}$, then any two ways of parenthesizing the product
$a_{1}a_{2}\cdots a_{k}$ yield the same result. For example, for $k=4$, we
have%
\[
\left(  \left(  a_{1}a_{2}\right)  a_{3}\right)  a_{4}=\left(  a_{1}\left(
a_{2}a_{3}\right)  \right)  a_{4}=\left(  a_{1}a_{2}\right)  \left(
a_{3}a_{4}\right)  =a_{1}\left(  \left(  a_{2}a_{3}\right)  a_{4}\right)
=a_{1}\left(  a_{2}\left(  a_{3}a_{4}\right)  \right)  .
\]
(It is not hard to prove this particular chain of identities by applying the
associativity of multiplication in the appropriate places; but for higher
values of $k$, such a manual approach becomes more and more cumbersome.)

What else can we do with our ring $\mathbb{K}$ ?

By definition, we know how to multiply two elements of $\mathbb{K}$. But there
is also a natural way to multiply an element of $\mathbb{K}$ with an integer.
This is defined as follows:

\begin{definition}
\label{def.rings.na}Let $a\in\mathbb{K}$ and $n\in\mathbb{Z}$. Then, we define
an element $na$ of $\mathbb{K}$ by%
\[
na=%
\begin{cases}
\underbrace{a+a+\cdots+a}_{n\text{ times}}, & \text{if }n\geq0;\\
-\left(  \underbrace{a+a+\cdots+a}_{-n\text{ times}}\right)  , & \text{if }n<0
\end{cases}
.
\]

\end{definition}

The \textquotedblleft$na$\textquotedblright\ that we have just defined has
nothing to do with the multiplication $\cdot$ of $\mathbb{K}$, since $n$ is
not (generally) an element of $\mathbb{K}$. However, when $\mathbb{K}$ is one
of the usual rings of numbers (like $\mathbb{Z}$, $\mathbb{Q}$, $\mathbb{R}$,
$\mathbb{C}$), then this kind of multiplication coincides with the
multiplication $\cdot$ of $\mathbb{K}$ (that is, $na$ means the same thing).
Indeed, Definition \ref{def.rings.na} clearly generalizes the definition of
$na$ for rational numbers $a$. Furthermore, when $\mathbb{K}=\mathbb{Z}/n$ for
some integer $n$, Definition \ref{def.rings.na} agrees with Definition
\ref{def.eqrel.Z/n.scaling} (in the sense that both definitions yield the same
result for $r\alpha$ when $r\in\mathbb{Z}$ and $\alpha\in\mathbb{Z}/n$). (This
is easy to prove by induction.)

\begin{center}
\textbf{2019-03-29 lecture}
\end{center}

We can also define powers of elements of a commutative ring:

\begin{definition}
\label{def.rings.pow}Let $a\in\mathbb{K}$ and $n\in\mathbb{N}$. Then, we
define an element $a^{n}$ of $\mathbb{K}$ by%
\[
a^{n}=\underbrace{a\cdot a\cdot\cdots\cdot a}_{n\text{ times}}.
\]

\end{definition}

This definition clearly generalizes the definition of $a^{n}$ for rational
numbers $a$. Furthermore, when $\mathbb{K}=\mathbb{Z}/n$ for some integer $n$,
Definition \ref{def.rings.pow} agrees with Definition
\ref{def.eqrel.Z/n.kpower} (in the sense that both definitions yield the same
result for $\alpha^{k}$ when $\alpha\in\mathbb{Z}/n$ and $k\in\mathbb{N}$).
(This follows from Theorem \ref{thm.eqrel.Z/n.rules-exp} \textbf{(c)}.)
Furthermore, when $\mathbb{K}=\mathbb{C}$, Definition \ref{def.rings.pow}
agrees with Definition \ref{def.CC.CC.power}.

Standard rules for addition, subtraction, multiplication and taking powers
hold in every ring:

\begin{proposition}
\label{prop.rings.pow.rules}\textbf{(a)} We have%
\begin{align}
\left(  n+m\right)  a  &  =na+ma\ \ \ \ \ \ \ \ \ \ \text{for all }%
a\in\mathbb{K}\text{ and }n,m\in\mathbb{Z}; \label{eq.prop.rings.pow.rules.d1}%
\\
n\left(  a+b\right)   &  =na+nb\ \ \ \ \ \ \ \ \ \ \text{for all }%
a,b\in\mathbb{K}\text{ and }n\in\mathbb{Z}; \label{eq.prop.rings.pow.rules.d2}%
\\
-\left(  na\right)   &  =\left(  -n\right)  a=n\left(  -a\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathbb{K}\text{ and }n\in
\mathbb{Z};\label{eq.prop.rings.pow.rules.d3}\\
\left(  nm\right)  a  &  =n\left(  ma\right)  \ \ \ \ \ \ \ \ \ \ \text{for
all }a\in\mathbb{K}\text{ and }n,m\in\mathbb{Z}%
;\label{eq.prop.rings.pow.rules.2}\\
n\left(  ab\right)   &  =\left(  na\right)  b=a\left(  nb\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in\mathbb{K}\text{ and }n\in
\mathbb{Z};\label{eq.prop.rings.pow.rules.3}\\
1a  &  =a\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathbb{K};\\
\left(  -1\right)  a  &  =-a\ \ \ \ \ \ \ \ \ \ \text{for all }a\in
\mathbb{K};\label{eq.prop.rings.pow.rules.4}\\
1^{n}  &  =1\ \ \ \ \ \ \ \ \ \ \text{for all }n\in\mathbb{N}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, the \textquotedblleft%
}1\text{\textquotedblright\ means the unity of }\mathbb{K}\right)
;\nonumber\\
0^{n}  &  =%
\begin{cases}
0, & \text{if }n>0\\
1, & \text{if }n=0
\end{cases}
\ \ \ \ \ \ \ \ \ \ \text{for all }n\in\mathbb{N}%
\label{eq.prop.rings.pow.rules.5}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, the \textquotedblleft%
}0\text{\textquotedblright\ in \textquotedblleft}0^{n}\text{\textquotedblright%
\ means the zero of }\mathbb{K}\right)  ;\nonumber\\
a^{n+m}  &  =a^{n}a^{m}\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathbb{K}\text{
and }n,m\in\mathbb{N};\label{eq.prop.rings.pow.rules.7}\\
\left(  a^{n}\right)  ^{m}  &  =a^{nm}\ \ \ \ \ \ \ \ \ \ \text{for all }%
a\in\mathbb{K}\text{ and }n,m\in\mathbb{N};\label{eq.prop.rings.pow.rules.8}\\
a^{0}  &  =1\ \ \ \ \ \ \ \ \ \ \text{for all }a\in\mathbb{K}.
\end{align}
In particular:

\begin{itemize}
\item The equality (\ref{eq.prop.rings.pow.rules.d3}) shows that the
expression \textquotedblleft$-na$\textquotedblright\ (with $a\in\mathbb{K}$
and $n\in\mathbb{Z}$) is unambiguous (since its two possible interpretations,
namely $-\left(  na\right)  $ and $\left(  -n\right)  a$, yield equal results).

\item The equality (\ref{eq.prop.rings.pow.rules.2}) shows that the expression
\textquotedblleft$nma$\textquotedblright\ (with $a\in\mathbb{K}$ and
$n,m\in\mathbb{Z}$) is unambiguous.

\item The equality (\ref{eq.prop.rings.pow.rules.3}) shows that the expression
\textquotedblleft$nab$\textquotedblright\ (with $a,b\in\mathbb{K}$ and
$n\in\mathbb{Z}$) is unambiguous.
\end{itemize}

\textbf{(b)} For any $a,b\in\mathbb{K}$, we have
\begin{align*}
\left(  a+b\right)  ^{2}  &  =\left(  a+b\right)  \left(  a+b\right)
=a\left(  a+b\right)  +b\left(  a+b\right) \\
&  =aa+ab+ba+bb=a^{2}+ab+ba+b^{2}.
\end{align*}
This further equals $a^{2}+2ab+b^{2}$ if $\mathbb{K}$ is commutative.

\textbf{(c)} Let $a,b\in\mathbb{K}$ satisfy $ab=ba$. (This holds automatically
when $\mathbb{K}$ is commutative.) Then:%
\begin{align*}
ab^{n}  &  =b^{n}a\ \ \ \ \ \ \ \ \ \ \text{for all }n\in\mathbb{N};\\
a^{i}b^{j}  &  =b^{j}a^{i}\ \ \ \ \ \ \ \ \ \ \text{for all }i,j\in
\mathbb{N};\\
\left(  ab\right)  ^{n}  &  =a^{n}b^{n}\ \ \ \ \ \ \ \ \ \ \text{for all }%
n\in\mathbb{N};\\
\left(  a+b\right)  ^{n}  &  =\sum_{k=0}^{n}\dbinom{n}{k}a^{k}b^{n-k}%
\ \ \ \ \ \ \ \ \ \ \text{for all }n\in\mathbb{N}.
\end{align*}


\textbf{(d)} Let $a,b\in\mathbb{K}$ satisfy $ab=ba$. Then,%
\[
a^{n}-b^{n}=\left(  a-b\right)  \left(  a^{n-1}+a^{n-2}b+\cdots+ab^{n-2}%
+b^{n-1}\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }n\in\mathbb{N}.
\]

\end{proposition}

\begin{proof}
\textbf{(a)} Analogous to the proofs for rationals (at least if you know the
right proofs). For example, to prove (\ref{eq.prop.rings.pow.rules.d1}),
consider six cases corresponding to the six possible constellations of signs
of $n,m,n+m$.

\textbf{(b)} Expand using distributivity.

\textbf{(c)} Induction.

\textbf{(d)} Analogous to the proof for rationals.
\end{proof}

\subsection{\label{sect.ring.inv}Multiplicative inverses and fields}

\begin{convention}
For the rest of this section, we fix a ring $\mathbb{K}$, and we denote its
addition, multiplication, zero and unity by $+$, $\cdot$, $0$ and $1$.
\end{convention}

Each element $a$ of the ring $\mathbb{K}$ has an additive inverse $-a$, which
satisfies $\left(  -a\right)  +a=a+\left(  -a\right)  =0$. What about a
\textquotedblleft multiplicative inverse\textquotedblright?

\begin{definition}
\label{def.rings.inv-mul}Let $a\in\mathbb{K}$. A \textit{multiplicative
inverse} of $a$ means an element $a^{\prime}$ of $\mathbb{K}$ such that
$aa^{\prime}=a^{\prime}a=1$.
\end{definition}

Of course, multiplicative inverses don't always exist. In $\mathbb{Q}$, the
number $0$ has none. In $\mathbb{Z}$, the number $2$ has none. But when they
do exist, they are unique:

\begin{theorem}
\label{thm.rings.inv-mul.uni}Let $a\in\mathbb{K}$. Then, $a$ has \textbf{at
most one} multiplicative inverse.
\end{theorem}

\begin{proof}
This is analogous to Theorem \ref{thm.rings.inv-add.uni}, but we have to
replace $+$ and $0$ by $\cdot$ and $1$.
\end{proof}

\textbf{Warning:} In Definition \ref{def.rings.inv-add}, we could have
replaced \textquotedblleft$a+a^{\prime}=a^{\prime}+a=0$\textquotedblright\ by
\textquotedblleft$a+a^{\prime}=0$\textquotedblright, since $a+a^{\prime
}=a^{\prime}+a$ already follows from commutativity of addition. But in
Definition \ref{def.rings.inv-mul}, we cannot replace \textquotedblleft%
$aa^{\prime}=a^{\prime}a=1$\textquotedblright\ by \textquotedblleft%
$aa^{\prime}=1$\textquotedblright, since $\mathbb{K}$ need not be commutative.
If we require $aa^{\prime}=1$ only, then $a^{\prime}$ is just a \textit{right
inverse} of $a$; such a right inverse is not necessarily unique.

\begin{definition}
\label{def.rings.inv-mul-a}\textbf{(a)} An element $a\in\mathbb{K}$ is said to
be \textit{invertible} if it has a multiplicative inverse. An invertible
element is also called a \textit{unit}.

\textbf{(b)} If $a\in\mathbb{K}$ is invertible, then the multiplicative
inverse of $a$ will be called $a^{-1}$. (This is well-defined, since Theorem
\ref{thm.rings.inv-mul.uni} shows that this multiplicative inverse is unique.)

\textbf{(c)} Assume that $\mathbb{K}$ is commutative. If $a\in\mathbb{K}$ and
$b\in\mathbb{K}$ are such that $b$ is invertible, then we define the
\textit{quotient }$a/b$ (also called $\dfrac{a}{b}$) to be the element
$ab^{-1}$ of $\mathbb{K}$. This new binary partial operation $/$ on
$\mathbb{K}$ is called \textquotedblleft\textit{division}\textquotedblright.
\end{definition}

The word \textquotedblleft partial\textquotedblright\ in \textquotedblleft
partial operation\textquotedblright\ means that it is not always defined. We
already have seen this for rational numbers: We cannot divide by $0$.

Again, we follow PEMDAS rules as far as division is concerned. Do not use the
ambiguous expression \textquotedblleft$a/bc$\textquotedblright; it can mean
either $a/\left(  bc\right)  $ or $\left(  a/b\right)  c$, depending on whom
you ask, and thus should always be parenthesized.

The notion of \textquotedblleft unit\textquotedblright\ we have just defined
generalizes the units of $\mathbb{Z}\left[  i\right]  $. Don't confuse
\textquotedblleft unit\textquotedblright\ (= invertible element) with
\textquotedblleft unity\textquotedblright\ (= $1_{\mathbb{K}}$). The unity is
always a unit (by Exercise \ref{exe.rings.inv-mul.rules} \textbf{(a)} further
below), but often not the only unit.

Definition \ref{def.rings.inv-mul-a} \textbf{(c)} generalizes the usual
meaning of $a/b$ in $\mathbb{Q}$, $\mathbb{R}$ and $\mathbb{C}$.

Please do not use Definition \ref{def.rings.inv-mul-a} \textbf{(c)} when
$\mathbb{K}$ is not commutative; that would cause confusion, since $ab^{-1}$
and $b^{-1}a$ would have equal rights to the name \textquotedblleft$\dfrac
{a}{b}$\textquotedblright.

If $\mathbb{K}=\mathbb{Z}/n$ for a positive integer $n$, and if $\alpha
\in\mathbb{K}$, then the multiplicative inverse of $\alpha$ is the same as an
inverse of $\alpha$ (as defined in Definition \ref{def.equiv.modinv.inverse}).
Thus, multiplicative inverses in arbitrary rings generalize the concept of
inverses in $\mathbb{Z}/n$. Likewise, they generalize inverses in $\mathbb{C}%
$; that is, an inverse of a complex number $\alpha\in\mathbb{C}$ (as defined
in Definition \ref{def.CC.CC.inverse.inverse}) is the same as a multiplicative
inverse of $\alpha$.

Again, it is not hard to check that multiplicative inverses and division have
the properties you would hope them to have:

\begin{exercise}
\label{exe.rings.inv-mul.rules}Prove the following:

\textbf{(a)} The element $1_{\mathbb{K}}$ of $\mathbb{K}$ is always invertible.

\textbf{(b)} The element $-1_{\mathbb{K}}$ of $\mathbb{K}$ is always
invertible. (Note that $-1_{\mathbb{K}}$ is not always distinct from
$1_{\mathbb{K}}$.)

\textbf{(c)} Let $a\in\mathbb{K}$ be invertible. Then, its inverse $a^{-1}$ is
invertible as well, and its inverse is $\left(  a^{-1}\right)  ^{-1}=a$.

\textbf{(d)} Let $a,b\in\mathbb{K}$ be invertible. Then, their product $ab$ is
invertible as well, and its inverse is $\left(  ab\right)  ^{-1}=b^{-1}a^{-1}%
$. (Mind the order of multiplication: it is $b^{-1}a^{-1}$, not $a^{-1}b^{-1}$.)

\textbf{(e)} Assume that $\mathbb{K}$ is commutative. Let $a,b,c,d\in
\mathbb{K}$ be such that $b$ and $d$ are invertible. Then,
\[
a/b+c/d=\left(  ad+bc\right)  /\left(  bd\right)
\ \ \ \ \ \ \ \ \ \ \text{and}\ \ \ \ \ \ \ \ \ \ \left(  a/b\right)  \left(
c/d\right)  =\left(  ac\right)  /\left(  bd\right)  .
\]

\end{exercise}

Some rings have many invertible elements (such as $\mathbb{Q}$, where each
nonzero element is invertible), while others have few (such as $\mathbb{Z}$,
whose only invertible elements are $1$ and $-1$). The extreme case on the
former end is called a \textit{skew field} or a \textit{field}, depending on
its commutativity:

\begin{definition}
\label{def.field.field}\textbf{(a)} An element $a\in\mathbb{K}$ is said to be
\textit{nonzero} if $a\neq0$. (Here, of course, $0$ means the zero of
$\mathbb{K}$.)

\textbf{(b)} We say that $\mathbb{K}$ is a \textit{skew field} if $0\neq1$ in
$\mathbb{K}$ and if every nonzero $a\in\mathbb{K}$ is invertible. (Here,
\textquotedblleft$0\neq1$ in $\mathbb{K}$\textquotedblright\ means
\textquotedblleft$0_{\mathbb{K}}\neq1_{\mathbb{K}}$\textquotedblright; we are
clearly not requiring the \textbf{integers} $0$ and $1$ to be distinct.)

\textbf{(c)} We say that $\mathbb{K}$ is a \textit{field} if $\mathbb{K}$ is a
commutative skew field.
\end{definition}

The condition \textquotedblleft$0\neq1$ in $\mathbb{K}$\textquotedblright\ is
technical. It is easy to see that if a ring $\mathbb{K}$ satisfies $0=1$ in
$\mathbb{K}$, then it has only one element (to wit: any $a\in\mathbb{K}$ must
satisfy $a=\underbrace{1}_{=0}\cdot a=0\cdot a=0$), which entails that
$\mathbb{K}$ is the zero ring (up to relabeling of its element $0$). We do not
want the zero ring to count as a skew field; thus we require $0\neq1$ in
$\mathbb{K}$.

Some authors call skew fields \textit{division rings}.

\begin{example}
\textbf{(a)} The rings $\mathbb{Q}$, $\mathbb{R}$ and $\mathbb{C}$ are fields.

\textbf{(b)} The rings $\mathbb{Z}$, $\mathbb{Z}\left[  i\right]  $ and
$\mathbb{Z}\left[  \sqrt{2}\right]  $ are not fields (since, for example, $2$
is not invertible in any of these rings). However, $\mathbb{Z}\left[
i\right]  $ and $\mathbb{Z}\left[  \sqrt{2}\right]  $ would become fields if
we had used $\mathbb{Q}$ instead of $\mathbb{Z}$ in their definitions.

\textbf{(c)} The polynomial ring $\mathbb{Z}\left[  x\right]  $ is not a field
(since, for example, $x$ is not invertible in it). There is a way to get a
field out of it, similarly to how $\mathbb{Q}$ is obtained from $\mathbb{Z}$.
(This leads to the so-called
\textit{\href{https://en.wikipedia.org/wiki/Rational_function}{\textit{rational
functions}}}.)

\textbf{(d)} Recall the commutative ring $\mathbb{Q}^{\mathbb{Q}}$; the
elements of this ring are functions from $\mathbb{Q}$ to $\mathbb{Q}$, and the
operations $+$ and $\cdot$ are defined pointwise. Is this ring a field?

Let us see what the multiplicative inverse of a function $f\in\mathbb{Q}%
^{\mathbb{Q}}$ is. If $f,g\in\mathbb{Q}^{\mathbb{Q}}$ are two functions, then
we have the following chain of equivalences:%
\begin{align*}
&  \ \left(  g\text{ is the multiplicative inverse of }f\right) \\
&  \Longleftrightarrow\ \left(  fg=gf=1_{\mathbb{Q}^{\mathbb{Q}}}\right) \\
&  \Longleftrightarrow\ \left(  \left(  fg\right)  \left(  x\right)  =\left(
gf\right)  \left(  x\right)  =1_{\mathbb{Q}^{\mathbb{Q}}}\left(  x\right)
\text{ for all }x\in\mathbb{Q}\right) \\
&  \Longleftrightarrow\ \left(  f\left(  x\right)  \cdot g\left(  x\right)
=g\left(  x\right)  \cdot f\left(  x\right)  =1\text{ for all }x\in
\mathbb{Q}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since each }x\in\mathbb{Q}\text{ satisfies }\left(  fg\right)  \left(
x\right)  =f\left(  x\right)  \cdot g\left(  x\right) \\
\text{and }\left(  gf\right)  \left(  x\right)  =g\left(  x\right)  \cdot
f\left(  x\right)  \text{ and }1_{\mathbb{Q}^{\mathbb{Q}}}\left(  x\right)  =1
\end{array}
\right) \\
&  \Longleftrightarrow\ \left(  g\left(  x\right)  =\dfrac{1}{f\left(
x\right)  }\text{ for all }x\in\mathbb{Q}\right)  .
\end{align*}
(Note that this is \textbf{not} the same as saying that $f$ and $g$ are
inverse maps! The multiplication of $\mathbb{Q}^{\mathbb{Q}}$ is not given by
composition of maps.)

This shows that a function $f\in\mathbb{Q}^{\mathbb{Q}}$ is invertible in
$\mathbb{Q}^{\mathbb{Q}}$ if and only if it never takes the value $0$ (because
its multiplicative inverse $g$ would have to satisfy $g\left(  x\right)
=\dfrac{1}{f\left(  x\right)  }$ for all $x\in\mathbb{Q}$). But a function
$f\in\mathbb{Q}^{\mathbb{Q}}$ can be $0$ at some point and $\neq0$ at another.
Then, it is not invertible (since it is $0$ at some point) yet nonzero (since
it is $\neq0$ at another). For example, the function $\operatorname*{id}%
\in\mathbb{Q}^{\mathbb{Q}}$ is not invertible yet nonzero. Thus,
$\mathbb{Q}^{\mathbb{Q}}$ is not a field.

\textbf{(e)} The ring $\mathbb{Q}^{2\times2}$ of $2\times2$-matrices with
rational entries is not a skew field. Indeed, the $2\times2$-matrix $\left(
\begin{array}
[c]{cc}%
1 & 0\\
1 & 0
\end{array}
\right)  $ is nonzero but not invertible. (More generally: For each
$n\in\mathbb{N}$, the $n\times n$-matrices over $\mathbb{Q}$ form a ring,
which we will study later. Our notion of \textquotedblleft
invertible\textquotedblright\ for elements of this ring coincides with the
usual notion of \textquotedblleft invertible\textquotedblright\ for $n\times
n$-matrices in linear algebra.)
\end{example}

What about $\mathbb{Z}/n$ ?

\begin{theorem}
\label{thm.field.Z/n}Let $n$ be a positive integer. The ring $\mathbb{Z}/n$ is
a field if and only if $n$ is prime.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.field.Z/n}.]$\Longleftarrow:$ Assume that $n$ is
prime. We must prove that $\mathbb{Z}/n$ is a field.

First of all, $n>1$ (since $n$ is prime). Thus, $n\nmid1$, so that
$1\not \equiv 0\operatorname{mod}n$, so that $0\not \equiv 1\operatorname{mod}%
n$. In other words, $\left[  0\right]  _{n}\neq\left[  1\right]  _{n}$. In
other words, $0\neq1$ in $\mathbb{Z}/n$ (since $0_{\mathbb{Z}/n}=\left[
0\right]  _{n}$ and $1_{\mathbb{Z}/n}=\left[  1\right]  _{n}$).

Also, the ring $\mathbb{Z}/n$ is commutative.

So it remains to prove that every nonzero $\alpha\in\mathbb{Z}/n$ is
invertible (because then, we will immediately conclude that $\mathbb{Z}/n$ is
a skew field and therefore a field).

Indeed, let $\alpha\in\mathbb{Z}/n$ be nonzero. We must prove that $\alpha$ is invertible.

Proposition \ref{prop.eqrel.Z/n.PR} \textbf{(b)} shows that there exists a
unique $a\in\left\{  0,1,\ldots,n-1\right\}  $ satisfying $\alpha=\left[
a\right]  _{n}$. Consider this $a$. If we had $a=0$, then $\alpha=\left[
a\right]  _{n}$ would become $\alpha=\left[  0\right]  _{n}=0_{\mathbb{Z}/n}$,
which would contradict the assumption that $\alpha$ is nonzero. So $a\neq0$.
Thus, $a\in\left\{  1,2,\ldots,n-1\right\}  $ (since $a\in\left\{
0,1,\ldots,n-1\right\}  $). Hence, Proposition
\ref{prop.ent.prime.each-i-coprime} (applied to $i=a$ and $p=n$) shows that
$a$ is coprime to $n$. In other words, $a\perp n$.

Now, define a set $U_{n}$ as in Corollary \ref{cor.equiv.modinv.Unphi}. Then,
Corollary \ref{cor.equiv.modinv.Unphi} \textbf{(a)} yields $\left[  a\right]
_{n}\in U_{n}$ (since $a\perp n$). In other words, $\left[  a\right]  _{n}$
has an inverse (by the definition of $U_{n}$). In other words, $\alpha$ has an
inverse (since $\alpha=\left[  a\right]  _{n}$). In other words, $\alpha$ has
a multiplicative inverse (because inverses in $\mathbb{Z}/n$ are precisely
what we now call multiplicative inverses). In other words, $\alpha$ is
invertible. So we have proven the \textquotedblleft$\Longleftarrow
$\textquotedblright\ direction of Theorem \ref{thm.field.Z/n}.

$\Longrightarrow:$ Rough idea: Assume that $\mathbb{Z}/n$ is a field. We must
prove that $n$ is a prime. Assume the contrary.

We have $0\neq1$ in $\mathbb{Z}/n$ (since $\mathbb{Z}/n$ is a field); in other
words, $0\not \equiv 1\operatorname{mod}n$. This quickly yields $n>1$. Hence,
there must exist two elements $d,e\in\left\{  1,2,\ldots,n-1\right\}  $ such
that $n=de$ (since $n$ is not a prime). Consider these $d$ and $e$. Theorem
\ref{thm.eqrel.Z/n.explicit} shows that the $n$ residue classes $\left[
0\right]  _{n},\left[  1\right]  _{n},\ldots,\left[  n-1\right]  _{n}$ are
distinct. Hence, the residue classes $\left[  d\right]  _{n}$ and $\left[
e\right]  _{n}$ are nonzero (since $d,e\in\left\{  1,2,\ldots,n-1\right\}  $
are distinct from $0$). Thus, these two residue classes are invertible (since
$\mathbb{Z}/n$ is a field). Thus, by Exercise \ref{exe.rings.inv-mul.rules}
\textbf{(d)}, their product $\left[  d\right]  _{n}\left[  e\right]  _{n}$ is
invertible as well. But this product is $\left[  d\right]  _{n}\left[
e\right]  _{n}=\left[  de\right]  _{n}=\left[  n\right]  _{n}=\left[
0\right]  _{n}=0_{\mathbb{Z}/n}$, which is not invertible. Contradiction.
Thus, the \textquotedblleft$\Longrightarrow$\textquotedblright\ direction of
Theorem \ref{thm.field.Z/n} is proven.
\end{proof}

\begin{center}
\textbf{2019-04-01 lecture}
\end{center}

Now, for an example of a skew field that is not a field.

\begin{example}
\label{exa.ring.H}Informally, we have obtained $\mathbb{C}$ from $\mathbb{R}$
by throwing in a new number $i$ that satisfies $i^{2}=-1$. In order for $i$
not to feel alone, let us introduce yet another new \textquotedblleft
number\textquotedblright\ $j$ such that $j^{2}=-1$ and $ji=-ij$. Now we try to
calculate with these $i$ and $j$. Of course, $i$ and $j$ cannot belong to a
commutative ring together, but let us assume that they (and the further
numbers we obtain from them) at least satisfy the ring axioms.

We have%
\begin{align*}
i\cdot ij  &  =\underbrace{ii}_{=i^{2}=-1}j=\left(  -1\right)
j=-j\ \ \ \ \ \ \ \ \ \ \text{and}\\
j\cdot ij  &  =\underbrace{ji}_{=-ij}j=-i\underbrace{jj}_{=j^{2}=-1}=-i\left(
-1\right)  =i\ \ \ \ \ \ \ \ \ \ \text{and}\\
ij\cdot ij  &  =i\underbrace{ji}_{=-ij}j=-\underbrace{ii}_{=i^{2}%
=-1}\underbrace{jj}_{=j^{2}=-1}=-\left(  -1\right)  \left(  -1\right)  =-1
\end{align*}
and (using the distributivity laws)%
\begin{align*}
\left(  1+2i+3ij\right)  \left(  2-3j\right)   &
=2+4i+6ij-3j-6ij-9i\underbrace{j^{2}}_{=-1}\\
&  =2+4i-3j+9i=2+13i-3j.
\end{align*}
Similarly, any of these new \textquotedblleft numbers\textquotedblright\ can
be written in the form $a+bi+cj+dij$ for reals $a,b,c,d$.

Blithely introducing new \textquotedblleft numbers\textquotedblright\ like
this can be risky. It could happen that (just as with defining $\infty$ to be
$\dfrac{1}{0}$) our new numbers would lead to contradictions. For example,
what if we have some expression that involves $i$ and $j$ and that can be
simplified to $0$ in one way and simplified to $1$ in another; would that mean
that $0=1$ ? No; it would simply mean that the new \textquotedblleft
numbers\textquotedblright\ we have introduced do not actually exist. (Or,
speaking more abstractly: that the new numbers are just the zero ring in a
complicated disguise.)

So it makes sense to look for a rigorous definition of our new numbers. There
is a direct (though rather painful) way of doing this: We can rigorously
define our new numbers as $4$-tuples $\left(  a,b,c,d\right)  $ of real
numbers, with addition and subtraction defined entrywise, and with
multiplication given by%
\begin{align*}
&  \left(  x_{1},x_{2},x_{3},x_{4}\right)  \cdot\left(  y_{1},y_{2}%
,y_{3},y_{4}\right) \\
&  =\left(  x_{1}y_{1}-x_{2}y_{2}-x_{3}y_{3}-x_{4}y_{4},x_{1}y_{2}+x_{2}%
y_{1}+x_{3}y_{4}-x_{4}y_{3},\right. \\
&  \ \ \ \ \ \ \ \ \ \ \left.  x_{1}y_{3}-x_{2}y_{4}+x_{3}y_{1}+x_{4}%
y_{2},x_{1}y_{4}+x_{2}y_{3}-x_{3}y_{2}+x_{4}y_{1}\right)  .
\end{align*}


These new numbers are \href{https://en.wikipedia.org/wiki/Quaternion}{the
\textit{quaternions}}. It turns out that they form a skew field, albeit not a
field (since commutativity is lacking). They have several properties that make
them useful in physics and space geometry. For one, they encode both the
scalar product and the cross product of two vectors in $\mathbb{R}^{3}$:
Namely, if $\mathbf{a}=\left(
\begin{array}
[c]{c}%
a_{1}\\
a_{2}\\
a_{3}%
\end{array}
\right)  \in\mathbb{R}^{3}$ and $\mathbf{b}=\left(
\begin{array}
[c]{c}%
b_{1}\\
b_{2}\\
b_{3}%
\end{array}
\right)  \in\mathbb{R}^{3}$ are two vectors, then the quaternion%
\begin{align*}
&  \left(  0,a_{1},a_{2},a_{3}\right)  \cdot\left(  0,b_{1},b_{2},b_{3}\right)
\\
&  =\left(  \underbrace{-a_{1}b_{1}-a_{2}b_{2}-a_{3}b_{3}}%
_{\substack{=-\mathbf{a}\cdot\mathbf{b}\\\text{(where }\cdot\text{ stands
for}\\\text{the scalar product)}}},\underbrace{a_{2}b_{3}-a_{3}b_{2}%
,a_{3}b_{1}-a_{1}b_{3},a_{1}b_{2}-a_{2}b_{1}}_{\substack{\text{the three
coordinates}\\\text{of the cross product }\mathbf{a}\times\mathbf{b}}}\right)
.
\end{align*}
Also,
\href{https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation}{the
quaternions can be used to encode rotations in 3-dimensional space}.
\end{example}

\subsection{\label{sect.ring.hunting1}Hunting for finite fields I}

\begin{definition}
\label{def.ring.size}\textbf{(a)} The \textit{ground set} of a ring $\left(
\mathbb{K},+,\cdot,0,1\right)  $ is defined to be the set $\mathbb{K}$.

\textbf{(b)} The \textit{elements} of a ring are defined to be the elements of
its ground set.

\textbf{(c)} The \textit{size} (or \textit{cardinality}) of a ring is defined
to be the size of its ground set.

\textbf{(d)} A ring is said to be \textit{finite} if its size is finite (i.e.,
if it has only finitely many elements).
\end{definition}

We have seen a bunch of finite rings. For example, if $S$ is a finite set,
then the commutative ring $\left(  \mathcal{P}\left(  S\right)
,\bigtriangleup,\cap,\varnothing,S\right)  $ (see one of the examples above)
has size $\left\vert \mathcal{P}\left(  S\right)  \right\vert =2^{\left\vert
S\right\vert }$, and thus is finite.

We also have seen infinitely many finite fields:%
\[
\mathbb{Z}/2,\ \ \ \ \ \ \ \ \ \ \mathbb{Z}/3,\ \ \ \ \ \ \ \ \ \ \mathbb{Z}%
/5,\ \ \ \ \ \ \ \ \ \ \mathbb{Z}/7,\ \ \ \ \ \ \ \ \ \ \mathbb{Z}%
/11,\ \ \ \ \ \ \ \ \ \ \ldots
\]
Indeed, Theorem \ref{thm.field.Z/n} yields that $\mathbb{Z}/p$ is a finite
field whenever $p$ is a prime.

\begin{question}
\label{quest.finfield.nonprime}Are there any further finite fields?
\end{question}

\begin{remark}
Recall Shamir's Secret Sharing Scheme, which we introduced in Subsection
\ref{subsect.intro.shamir.k=3}. The way we defined the Scheme, it had a
problem: It relied on a spurious notion of a \textquotedblleft uniformly
random rational number\textquotedblright, which does not exist in nature. Now
we can fix this problem: Replace rational numbers by elements of a finite
field. More precisely, let $N$ again be the length of the bitstring that we
want to encrypt. Pick a prime $p$ that satisfies $p>N$; this exists due to
Theorem \ref{thm.ent.prime.infin}. Then, the finite field $\mathbb{Z}/p$ has
more than $p$ elements. Now, use elements of $\mathbb{Z}/p$ instead of
integers. (Thus, a bitstring $a_{N-1}a_{N-2}\cdots a_{0}$ will be encoded as
the residue class $\left[  a_{N-1}a_{N-2}\cdots a_{0}\right]  _{p}%
\in\mathbb{Z}/p$ rather than as the number $a_{N-1}a_{N-2}\cdots a_{0}%
\in\mathbb{Z}$.) Instead of picking two uniformly random bitstrings
$\mathbf{c}$ and $\mathbf{b}$ and transforming them into numbers $c$ and $b$,
just pick two uniformly random residue classes $c,b\in\mathbb{Z}/p$. (This is
possible, since $\mathbb{Z}/p$ is a finite set.)

This relies on having a well-behaved notion of polynomials over $\mathbb{Z}%
/p$. We will later give a rigorous definition of this notion.

Finite fields have many uses -- not just in making Shamir's Secret Sharing
Scheme work. One great source of applications is \textit{coding theory}, which
we might see later.
\end{remark}

Let us take some first steps towards addressing Question
\ref{quest.finfield.nonprime}. We have found a field of size $p$ for each
prime $p$. Are there fields of other sizes?

\textbf{First idea:} Let us try to get such a field by \textquotedblleft
duplicating\textquotedblright\ the known field $\mathbb{Z}/p$. Thus, we fix a
prime $p$, and consider the Cartesian product $\left(  \mathbb{Z}/p\right)
\times\left(  \mathbb{Z}/p\right)  $. Define addition, subtraction and
multiplication on this Cartesian product entrywise (so, e.g., $\left(
a,b\right)  \left(  c,d\right)  =\left(  ac,bd\right)  $). This will yield a
commutative ring with zero $\left(  \left[  0\right]  _{p},\left[  0\right]
_{p}\right)  $ and unity $\left(  \left[  1\right]  _{p},\left[  1\right]
_{p}\right)  $.

However, the element $\left(  \left[  0\right]  _{p},\left[  1\right]
_{p}\right)  $ of this ring is nonzero (because it is not $\left(  \left[
0\right]  _{p},\left[  0\right]  _{p}\right)  $) but has no inverse (since
multiplying it by anything will never make its first entry anything other than
$\left[  0\right]  _{p}$). So this ring is not a field.

\textbf{Second idea:} We obtained $\mathbb{C}$ from $\mathbb{R}$ by
\textquotedblleft adjoining\textquotedblright\ a square root of $-1$. (In
abstract algebra, the verb \textquotedblleft adjoin\textquotedblright\ means
\textquotedblleft insert\textquotedblright\ or \textquotedblleft
add\textquotedblright\ -- not in the sense of the addition operation $+$, but
in the sense of throwing in something new into an existing collection.)

Let's try to do this with $\mathbb{Z}/p$ instead of $\mathbb{R}$.

More generally, let us start with an arbitrary commutative ring $\mathbb{K}$,
and try to \textquotedblleft adjoin\textquotedblright\ a square root of $-1$
to it. We are bold and don't care whether there might already be such a square
root in $\mathbb{K}$; if there is, then we will get a second one!

Let $0$ and $1$ stand for the zero and the unity of $\mathbb{K}$. If
$\mathbb{K}=\mathbb{Z}/n$ for some integer $n$, then these are the residue
classes $\left[  0\right]  _{n}$ and $\left[  1\right]  _{n}$.

Now, we want to define a new commutative ring $\mathbb{K}^{\prime}$ by
\textquotedblleft adjoining\textquotedblright\ a square root of $-1$ to
$\mathbb{K}$. A way to make this rigorous is as follows (just as we defined
$\mathbb{C}$ rigorously in Definition \ref{def.CC.CC}):

\begin{definition}
\label{def.finfield.K'}Let $\mathbb{K}$ be a commutative ring.

\textbf{(a)} Let $\mathbb{K}^{\prime}$ be the set of all pairs $\left(
a,b\right)  \in\mathbb{K}\times\mathbb{K}$.

\textbf{(b)} For each $r\in\mathbb{K}$, we denote the pair $\left(
r,0\right)  \in\mathbb{K}^{\prime}$ by $r_{\mathbb{K}^{\prime}}$. We identify
$r\in\mathbb{K}$ with $r_{\mathbb{K}^{\prime}}=\left(  r,0\right)
\in\mathbb{K}^{\prime}$, so that $\mathbb{K}$ becomes a subset of
$\mathbb{K}^{\prime}$.

\textbf{(c)} We let $i$ be the pair $\left(  0,1\right)  \in\mathbb{K}%
^{\prime}$.

\textbf{(d)} We define three binary operations $+$, $-$ and $\cdot$ on
$\mathbb{K}^{\prime}$ by setting%
\begin{align*}
\left(  a,b\right)  +\left(  c,d\right)   &  =\left(  a+c,b+d\right)  ,\\
\left(  a,b\right)  -\left(  c,d\right)   &  =\left(  a-c,b-d\right)
,\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  a,b\right)  \cdot\left(  c,d\right)   &  =\left(  ac-bd,ad+bc\right)
\end{align*}
for all $\left(  a,b\right)  \in\mathbb{K}^{\prime}$ and $\left(  c,d\right)
\in\mathbb{K}^{\prime}$.

\textbf{(e)} If $\alpha,\beta\in\mathbb{K}^{\prime}$, then we write
$\alpha\beta$ for $\alpha\cdot\beta$.
\end{definition}

You will, of course, recognize this definition to be a calque of Definition
\ref{def.CC.CC} with $\mathbb{R}$ and $\mathbb{C}$ replaced by $\mathbb{K}$
and $\mathbb{K}^{\prime}$. The elements of $\mathbb{K}^{\prime}$ are like
complex numbers, but built upon $\mathbb{K}$ instead of $\mathbb{R}$.

\begin{proposition}
\label{prop.finfield.K'.cring}\textbf{(a)} The set $\mathbb{K}^{\prime}$
defined in Definition \ref{def.finfield.K'} (equipped with the operations $+$
and $\cdot$ and the elements $0_{\mathbb{K}^{\prime}}$ and $1_{\mathbb{K}%
^{\prime}}$) is a commutative ring.

\textbf{(b)} Furthermore, the ring $\mathbb{K}$ is a subring of $\mathbb{K}%
^{\prime}$ (where we regard $\mathbb{K}$ as a subset of $\mathbb{K}^{\prime}$
as explained in Definition \ref{def.finfield.K'} \textbf{(b)}).
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.finfield.K'.cring}.]\textbf{(a)} Same argument
as we did for $\mathbb{C}$ in the proof of Theorem \ref{thm.CC.CC.rules}.

\textbf{(b)} This is straightforward to check.
\end{proof}

\begin{convention}
For the rest of this section, we let $\mathbb{K}^{\prime}$ be the commutative
ring constructed in Proposition \ref{prop.finfield.K'.cring} (i.e., the set
$\mathbb{K}^{\prime}$ equipped with the operations $+$ and $\cdot$ and the
elements $0_{\mathbb{K}^{\prime}}$ and $1_{\mathbb{K}^{\prime}}$).
\end{convention}

Thus, if $\mathbb{K}=\mathbb{Z}/p$, then $\mathbb{K}^{\prime}$ is a
commutative ring with $p^{2}$ elements.

\begin{question}
When is $\mathbb{K}^{\prime}$ is a field?
\end{question}

Assume that $0\neq1$ in $\mathbb{K}$; thus, $0\neq1$ in $\mathbb{K}^{\prime}$
as well (since $0_{\mathbb{K}^{\prime}}=\left(  0,0\right)  \neq\left(
1,0\right)  =1_{\mathbb{K}^{\prime}}$). Hence, in order for $\mathbb{K}%
^{\prime}$ to be a field, every nonzero $\xi\in\mathbb{K}^{\prime}$ needs to
have a multiplicative inverse. Thus, in particular, every nonzero element of
$\mathbb{K}$ must have a multiplicative inverse in $\mathbb{K}^{\prime}$. It
is easy to see that such an inverse, if it exists, must belong to $\mathbb{K}$
as well (i.e., it must have the form $r_{\mathbb{K}^{\prime}}$ for some
$r\in\mathbb{K}$); thus, this means that every nonzero element of $\mathbb{K}$
must have a multiplicative inverse in $\mathbb{K}$. In other words,
$\mathbb{K}$ itself must be a field.

Thus, we assume from now on that $\mathbb{K}$ is a field. But we are not done
yet. It is definitely not always true that $\mathbb{K}^{\prime}$ is a field.
For example, if $\mathbb{K}=\mathbb{Z}/2$, then the element $\left(
1,1\right)  $ of $\mathbb{K}^{\prime}$ has no inverse (check this!), and so
$\mathbb{K}^{\prime}$ is not a field in this case. What must $\mathbb{K}$
satisfy in order for $\mathbb{K}^{\prime}$ to be a field?

We know what it must satisfy: The condition is that every nonzero $\xi
\in\mathbb{K}^{\prime}$ has a multiplicative inverse. We just need to see when
this condition holds.

So let $\xi=\left(  x,y\right)  \in\mathbb{K}^{\prime}$ (with $x,y\in
\mathbb{K}$) be nonzero. Thus, $\left(  x,y\right)  \neq\left(  0,0\right)  $.

How to find $\xi^{-1}$ ? Notice that $\xi=\left(  x,y\right)  =x+yi$ (this is
proven just as for complex numbers). Thus, you can try to compute $\xi^{-1}$
by rationalizing the denominator (just as we learned to divide complex
numbers):%
\[
\dfrac{1}{\xi}=\dfrac{1}{x+yi}=\dfrac{x-yi}{\left(  x+yi\right)  \left(
x-yi\right)  }=\dfrac{x-yi}{x^{2}+y^{2}}%
\]
(since $\left(  x+yi\right)  \left(  x-yi\right)  =\left(  x,y\right)  \left(
x,-y\right)  =\left(  x^{2}+y^{2},0\right)  $, as you can easily see using the
definition of $\cdot$ on $\mathbb{K}^{\prime}$).

We need $x^{2}+y^{2}\neq0$ in $\mathbb{K}$ for this to work. In other words,
we need the following condition to hold:

\begin{statement}
\textit{Condition 1:} For every pair $\left(  x,y\right)  \in\mathbb{K}%
\times\mathbb{K}$ satisfying $\left(  x,y\right)  \neq\left(  0,0\right)  $,
we have $x^{2}+y^{2}\neq0$ in $\mathbb{K}$.
\end{statement}

Thus, $\mathbb{K}^{\prime}$ is a field if Condition 1 holds. Conversely, if
$\mathbb{K}^{\prime}$ is a field, then Condition 1 holds (because if $\left(
x,y\right)  \in\mathbb{K}\times\mathbb{K}$ satisfies $\left(  x,y\right)
\neq\left(  0,0\right)  $, then $\left(  x,y\right)  \left(  x,-y\right)
=\left(  x^{2}+y^{2},0\right)  $ would have to be $\neq\left(  0,0\right)  $
in order for $\mathbb{K}^{\prime}$ to be a field). So $\mathbb{K}^{\prime}$ is
a field if and only if Condition 1 holds.

If $\mathbb{K}=\mathbb{Z}/p$ for some prime $p$, then Condition 1 can be
restated as follows:

\begin{statement}
\textit{Condition 1':} For every pair $\left(  x,y\right)  \in\left(
\mathbb{Z}/p\right)  \times\left(  \mathbb{Z}/p\right)  $ satisfying $\left(
x,y\right)  \neq\left(  0,0\right)  $, we have $x^{2}+y^{2}\neq0$ in
$\mathbb{Z}/p$.
\end{statement}

We can further restate Condition 1' in terms of integers by replacing the
residue classes $x$ and $y$ with their representatives $a$ and $b$:

\begin{statement}
\textit{Condition 2:} For every pair $\left(  a,b\right)  \in\mathbb{Z}%
\times\mathbb{Z}$ such that \textbf{not both} $a$ and $b$ are divisible by
$p$, the sum $a^{2}+b^{2}$ is not divisible by $p$.
\end{statement}

So the ring $\mathbb{K}^{\prime}$ constructed from $\mathbb{K}=\mathbb{Z}/p$
is a field if and only if Condition 2 holds. When does Condition 2 hold?

\begin{example}
Let $\mathbb{K}=\mathbb{Z}/p$.

\textbf{(a)} If $p=2$, then Condition 2 fails for $\left(  a,b\right)
=\left(  1,1\right)  $. So $\mathbb{K}^{\prime}$ is not a field for $p=2$.

\textbf{(b)} If $p=3$, then Condition 2 holds. So $\mathbb{K}^{\prime}$ is a
field for $p=3$. Thus we have found a field with $3^{2}=9$ elements.

\textbf{(c)} If $p=5$, then Condition 2 fails for $\left(  a,b\right)
=\left(  1,2\right)  $. So $\mathbb{K}^{\prime}$ is not a field for $p=5$.
\end{example}

This suggests that the following:

\begin{proposition}
A prime $p$ satisfies Condition 2 if and only if $p\equiv3\operatorname{mod}4$.
\end{proposition}

\begin{proof}
$\Longrightarrow:$ Assume that a prime $p$ satisfies Condition 2. Assume (for
contradiction) that $p\not \equiv 3\operatorname{mod}4$. So $p$ is a prime of
Type 1 or 2. Thus, $p=x^{2}+y^{2}$ for two integers $x,y$ (by Theorem
\ref{thm.Z[i].gauss.prime.1mod4} \textbf{(a)}). Now, $\left(  x,y\right)  $ is
a pair in $\mathbb{Z}\times\mathbb{Z}$ such that \textbf{not both} $x$ and $y$
are divisible by $p$ (why not?), but the sum $x^{2}+y^{2}=p$ is divisible by
$p$. So Condition 2 fails for $\left(  a,b\right)  =\left(  x,y\right)  $.

$\Longleftarrow:$ Assume that a prime $p$ satisfies $p\equiv
3\operatorname{mod}4$. Thus, $\left(  p-1\right)  /2$ is an odd nonnegative integer.

We must prove that Condition 2 holds. In other words, we must prove that for
every pair $\left(  a,b\right)  \in\mathbb{Z}\times\mathbb{Z}$ such that
\textbf{not both} $a$ and $b$ are divisible by $p$, the sum $a^{2}+b^{2}$ is
not divisible by $p$.

Let $\left(  a,b\right)  \in\mathbb{Z}\times\mathbb{Z}$ be a pair such that
\textbf{not both} $a$ and $b$ are divisible by $p$. We must prove that the sum
$a^{2}+b^{2}$ is not divisible by $p$.

Assume the contrary. Thus, $a^{2}+b^{2}\equiv0\operatorname{mod}p$.

If we had $p\mid a$, then we would have $a\equiv0\operatorname{mod}p$ and thus
$a^{2}+b^{2}\equiv0^{2}+b^{2}=b^{2}\operatorname{mod}p$, so that $b^{2}\equiv
a^{2}+b^{2}\equiv0\operatorname{mod}p$ and thus $p\mid b^{2}$ and therefore
$p\mid b$; but this would contradict our assumption that \textbf{not both} $a$
and $b$ are divisible by $p$. Hence, we cannot have $p\mid a$. Thus, we have
$p\nmid a$. Hence, Fermat's little theorem yields $a^{p-1}\equiv
1\operatorname{mod}p$. Similarly, $b^{p-1}\equiv1\operatorname{mod}p$.

From $a^{2}+b^{2}\equiv0\operatorname{mod}p$, we get $a^{2}\equiv
-b^{2}\operatorname{mod}p$. Taking this congruence to the $\left(  p-1\right)
/2$-th power\footnote{We can do this, since $\left(  p-1\right)  /2$ is a
nonnegative integer.}, we find%
\[
\left(  a^{2}\right)  ^{\left(  p-1\right)  /2}\equiv\left(  -b^{2}\right)
^{\left(  p-1\right)  /2}=\underbrace{\left(  -1\right)  ^{\left(  p-1\right)
/2}}_{\substack{=-1\\\text{(since }\left(  p-1\right)  /2\text{ is odd)}%
}}\underbrace{\left(  b^{2}\right)  ^{\left(  p-1\right)  /2}}%
_{\substack{=b^{p-1}\\\equiv1\operatorname{mod}p}}\equiv-1\operatorname{mod}%
p.
\]
Hence,%
\[
-1\equiv\left(  a^{2}\right)  ^{\left(  p-1\right)  /2}=a^{p-1}\equiv
1\operatorname{mod}p.
\]
Hence, $p\mid\left(  -1\right)  -1=-2\mid2$, so $p=2$ (since $p$ is prime).
This contradicts $p\equiv3\operatorname{mod}4$. This contradiction shows that
our assumption was false; thus, Condition 2 holds.
\end{proof}

Thus, if we set $\mathbb{K}=\mathbb{Z}/p$ where $p$ is a prime of Type 3, then
$\mathbb{K}^{\prime}$ will be a field. So we have found a field $\mathbb{K}%
^{\prime}$ with $p^{2}$ elements for any prime $p$ of Type 3. What about the
other primes?

We can try to vary the construction above: Instead of adjoining a square root
of $-1$, we adjoin a square root of some other element $\eta\in\mathbb{Z}/p$.

\begin{definition}
Let $\mathbb{K}$ be a ring. A \textit{square} (in $\mathbb{K}$) means an
element of the form $a^{2}$ for some $a\in\mathbb{K}$.
\end{definition}

Now, we generalize Definition \ref{def.finfield.K'} as follows:

\begin{definition}
\label{def.finfield.K'eta}Let $\mathbb{K}$ be a commutative ring. Let $\eta
\in\mathbb{K}$.

\textbf{(a)} Let $\mathbb{K}_{\eta}^{\prime}$ be the set of all pairs $\left(
a,b\right)  \in\mathbb{K}\times\mathbb{K}$.

\textbf{(b)} For each $r\in\mathbb{K}$, we denote the pair $\left(
r,0\right)  \in\mathbb{K}_{\eta}^{\prime}$ by $r_{\mathbb{K}_{\eta}^{\prime}}%
$. We identify $r\in\mathbb{K}$ with $r_{\mathbb{K}_{\eta}^{\prime}}=\left(
r,0\right)  \in\mathbb{K}_{\eta}^{\prime}$, so that $\mathbb{K}$ becomes a
subset of $\mathbb{K}_{\eta}^{\prime}$.

\textbf{(c)} We let $i_{\eta}$ be the pair $\left(  0,1\right)  \in
\mathbb{K}_{\eta}^{\prime}$.

\textbf{(d)} We define three binary operations $+$, $-$ and $\cdot$ on
$\mathbb{K}_{\eta}^{\prime}$ by setting%
\begin{align*}
\left(  a,b\right)  +\left(  c,d\right)   &  =\left(  a+c,b+d\right)  ,\\
\left(  a,b\right)  -\left(  c,d\right)   &  =\left(  a-c,b-d\right)
,\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  a,b\right)  \cdot\left(  c,d\right)   &  =\left(  ac+\eta
bd,ad+bc\right)
\end{align*}
for all $\left(  a,b\right)  \in\mathbb{K}_{\eta}^{\prime}$ and $\left(
c,d\right)  \in\mathbb{K}_{\eta}^{\prime}$.

\textbf{(e)} If $\alpha,\beta\in\mathbb{K}_{\eta}^{\prime}$, then we write
$\alpha\beta$ for $\alpha\cdot\beta$.
\end{definition}

Note that $\mathbb{K}_{\eta}^{\prime}$ differs from $\mathbb{K}^{\prime}$ only
in how the multiplication is defined.

\begin{theorem}
\textbf{(a)} The set $\mathbb{K}_{\eta}^{\prime}$ defined in Definition
\ref{def.finfield.K'eta} (equipped with the operations $+$ and $\cdot$ and the
elements $0_{\mathbb{K}_{\eta}^{\prime}}$ and $1_{\mathbb{K}_{\eta}^{\prime}}%
$) is a commutative ring.

\textbf{(b)} If $\mathbb{K}$ is a field and $\eta$ is not a square in
$\mathbb{K}$, then $\mathbb{K}_{\eta}^{\prime}$ is a field.

\textbf{(c)} Let $p$ be a prime. There always exists an element $\eta
\in\mathbb{Z}/p$ that is not a square, \textbf{unless} $p=2$.
\end{theorem}

\begin{proof}
\textbf{(a)} Similar to the proof for $\mathbb{C}$.

\textbf{(b)} Assume that $\mathbb{K}$ is a field and that $\eta$ is not a
square in $\mathbb{K}$. We need to prove that $\mathbb{K}_{\eta}^{\prime}$ is
a field. In other words, we need to prove that each nonzero $\xi\in
\mathbb{K}_{\eta}^{\prime}$ is invertible.

So let $\xi\in\mathbb{K}_{\eta}^{\prime}$ be nonzero, and write $\xi$ as
$\xi=\left(  x,y\right)  $ with $x,y\in\mathbb{K}$. We must show that $\xi$ is invertible.

We have $\left(  x,y\right)  \left(  x,-y\right)  =\left(  x^{2}-\eta
y^{2},0\right)  $ (by the definition of the operation $\cdot$ on
$\mathbb{K}_{\eta}^{\prime}$). If $x^{2}-\eta y^{2}$ is nonzero, then this
shows quickly that $\left(  \dfrac{x}{x^{2}-\eta y^{2}},\dfrac{-y}{x^{2}-\eta
y^{2}}\right)  $ is an inverse of $\left(  x,y\right)  =\xi$, and thus $\xi$
is invertible. So we need to prove that $x^{2}-\eta y^{2}$ is nonzero.

Assume the contrary. Thus, $x^{2}-\eta y^{2}=0$, so that $x^{2}=\eta y^{2}$.
If $y$ is nonzero, then this can be rewritten as $\dfrac{x^{2}}{y^{2}}=\eta$,
whence $\eta=\dfrac{x^{2}}{y^{2}}=\left(  \dfrac{x}{y}\right)  ^{2}$, which
contradicts the fact that $\eta$ is not a square. So $y$ cannot be nonzero.
Thus, $y=0$. Hence, $x^{2}=\eta\underbrace{y^{2}}_{=0^{2}}=0$. Since
$\xi=\left(  x,\underbrace{y}_{=0}\right)  =\left(  x,0\right)  $, we know
that $x$ is nonzero (since $\xi$ is nonzero). Hence, $x$ has a multiplicative
inverse (since $\mathbb{K}$ is a field). Hence, multiplying $x^{2}=0$ by
$x^{-1}$, we obtain $x=0$, which contradicts $x$ being nonzero. So our
assumption was wrong. Part \textbf{(b)} is proven.

\textbf{(c)} Assume that $p\neq2$. Thus, $p>2$.

Consider the map%
\[
\mathbb{Z}/p\rightarrow\mathbb{Z}/p,\ \ \ \ \ \ \ \ \ \ \alpha\mapsto
\alpha^{2}.
\]
This map is \textbf{not} injective (since it sends the two distinct residue
classes $\left[  1\right]  _{p}$ and $\left[  p-1\right]  _{p}$ both to
$\left[  1\right]  _{p}$). Hence, it cannot be surjective either (since
otherwise, the Pigeonhole Principle for Surjections would entail that it is
bijective, hence injective). In other words, there exists some $\eta
\in\mathbb{Z}/p$ that is not in its image. In other words, there exists an
element $\eta\in\mathbb{Z}/p$ that is not a square.
\end{proof}

Now, if $p$ is a prime with $p>2$, then part \textbf{(c)} of the above Theorem
yields that there exists an element $\eta\in\mathbb{Z}/p$ that is not a
square; therefore, part \textbf{(b)} of the above Theorem shows that
$\mathbb{K}_{\eta}^{\prime}$ is a field where $\mathbb{K}=\mathbb{Z}/p$. This
is a field with $p^{2}$ elements.

Is there a field of size $4$, too?

We cannot get such a field by adjoining a square root to $\mathbb{Z}/2$. So
let us instead try to adjoin an element $j$ such that $j^{2}=j+1$. So we
define $\mathbb{K}^{\prime\prime}$ as the set of all pairs $\left(
a,b\right)  \in\left(  \mathbb{Z}/2\right)  \times\left(  \mathbb{Z}/2\right)
$, and we define $+,-,\cdot$ on $\mathbb{K}^{\prime\prime}$ by%
\begin{align*}
\left(  a,b\right)  +\left(  c,d\right)   &  =\left(  a+c,b+d\right)  ,\\
\left(  a,b\right)  -\left(  c,d\right)   &  =\left(  a-c,b-d\right)
,\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  a,b\right)  \cdot\left(  c,d\right)   &  =\left(
ac+bd,ad+bc+bd\right)  .
\end{align*}
You can check that this is a field with $4$ elements.

Thus, for each prime $p$, we have found a field with $p^{2}$ elements.

For the sake of completeness, let me mention a \textbf{third idea} for
constructing fields of size $p^{2}$: Recall that our field $\mathbb{Z}/p$ of
size $p$ consisted of residue classes of integers modulo $p$. What happens if
we take the residue classes of Gaussian integers modulo a Gaussian prime $\pi$ ?

I will not go into details, but here is a summary:

\begin{itemize}
\item The result is always a field of size $\operatorname*{N}\left(
\pi\right)  $.

\item If $\pi$ is not unit-equivalent to an integer, then this is a field that
we already know (namely, $\mathbb{Z}/p$ for $p=\operatorname*{N}\left(
\pi\right)  $) with its elements relabelled.

\item If $\pi$ is unit-equivalent to an integer, then $\pi$ is unit-equivalent
to a prime $p$ of Type 3, and the field of residue classes modulo $\pi$ will
be a field with $p^{2}$ elements. Namely, it will be the field $\mathbb{K}%
^{\prime}$ we constructed above (for $\mathbb{K}=\mathbb{Z}/p$), with its
elements relabelled.
\end{itemize}

So this approach only gets us fields of size $p^{2}$ when $p$ is a prime of
Type 3; it is thus inferior to the second idea above. Nevertheless, it
illustrates a general idea: that residue classes make sense not only for integers.

\begin{center}
\textbf{2019-04-03 lecture}
\end{center}

\textbf{Warning:} When $p$ is a prime, $\mathbb{Z}/p^{2}$ is \textbf{not} a
field; thus, the field with $p^{2}$ elements that we constructed is not
$\mathbb{Z}/p^{2}$.

Now, what about finite fields of size $p^{3},p^{4},\ldots$ ? What about finite
fields of size $6$ ?

\textbf{Spoiler:} It turns out that the former exist, while the latter do not.
We will hopefully prove this later. More generally, for an integer $n>1$,
there exists a field of size $n$ if and only if $n$ is a prime power (= power
of a prime). Even better, if $n$ is a prime power, then a field of size $n$ is
unique up to relabeling. We hope to see a proof of this (at least of the
existence part) further on in this class.

\subsection{\label{sect.ring.cart-prod}Cartesian products}

Next comes a basic and unimaginative way of constructing new rings from old:

\begin{definition}
\label{def.ring.dirprod1}Let $\mathbb{K}_{1},\mathbb{K}_{2},\ldots
,\mathbb{K}_{n}$ be $n$ rings. Consider the set $\mathbb{K}_{1}\times
\mathbb{K}_{2}\times\cdots\times\mathbb{K}_{n}$, whose elements are $n$-tuples
$\left(  k_{1},k_{2},\ldots,k_{n}\right)  $ with $k_{i}\in\mathbb{K}_{i}$.

We define operations $+$ and $\cdot$ on $\mathbb{K}_{1}\times\mathbb{K}%
_{2}\times\cdots\times\mathbb{K}_{n}$ by%
\begin{align*}
\left(  a_{1},a_{2},\ldots,a_{n}\right)  +\left(  b_{1},b_{2},\ldots
,b_{n}\right)   &  =\left(  a_{1}+b_{1},a_{2}+b_{2},\ldots,a_{n}+b_{n}\right)
\ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  a_{1},a_{2},\ldots,a_{n}\right)  \cdot\left(  b_{1},b_{2},\ldots
,b_{n}\right)   &  =\left(  a_{1}b_{1},a_{2}b_{2},\ldots,a_{n}b_{n}\right)  .
\end{align*}

\end{definition}

\begin{proposition}
\label{prop.ring.dirprod.ring}Let $\mathbb{K}_{1},\mathbb{K}_{2}%
,\ldots,\mathbb{K}_{n}$ be $n$ rings.

\textbf{(a)} The set $\mathbb{K}_{1}\times\mathbb{K}_{2}\times\cdots
\times\mathbb{K}_{n}$, endowed with the operations $+$ and $\cdot$ we just
defined and with the zero $\left(  0,0,\ldots,0\right)  $ and the unity
$\left(  1,1,\ldots,1\right)  $, is a ring.

\textbf{(b)} If the rings $\mathbb{K}_{1},\mathbb{K}_{2},\ldots,\mathbb{K}%
_{n}$ are commutative, then so is the ring $\mathbb{K}_{1}\times\mathbb{K}%
_{2}\times\cdots\times\mathbb{K}_{n}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.ring.dirprod.ring}.]All axioms are checked
entrywise: For example, associativity of multiplication follows from comparing%
\begin{align*}
&  \underbrace{\left(  \left(  a_{1},a_{2},\ldots,a_{n}\right)  \cdot\left(
b_{1},b_{2},\ldots,b_{n}\right)  \right)  }_{=\left(  a_{1}b_{1},a_{2}%
b_{2},\ldots,a_{n}b_{n}\right)  }\cdot\left(  c_{1},c_{2},\ldots,c_{n}\right)
\\
&  =\left(  a_{1}b_{1},a_{2}b_{2},\ldots,a_{n}b_{n}\right)  \cdot\left(
c_{1},c_{2},\ldots,c_{n}\right) \\
&  =\left(  \left(  a_{1}b_{1}\right)  c_{1},\left(  a_{2}b_{2}\right)
c_{2},\ldots,\left(  a_{n}b_{n}\right)  c_{n}\right) \\
&  =\left(  a_{1}\left(  b_{1}c_{1}\right)  ,a_{2}\left(  b_{2}c_{2}\right)
,\ldots,a_{n}\left(  b_{n}c_{n}\right)  \right)
\end{align*}
with%
\begin{align*}
&  \left(  a_{1},a_{2},\ldots,a_{n}\right)  \cdot\underbrace{\left(
b_{1},b_{2},\ldots,b_{n}\right)  \cdot\left(  c_{1},c_{2},\ldots,c_{n}\right)
}_{=\left(  b_{1}c_{1},b_{2}c_{2},\ldots,b_{n}c_{n}\right)  }\\
&  =\left(  a_{1},a_{2},\ldots,a_{n}\right)  \cdot\left(  b_{1}c_{1}%
,b_{2}c_{2},\ldots,b_{n}c_{n}\right) \\
&  =\left(  a_{1}\left(  b_{1}c_{1}\right)  ,a_{2}\left(  b_{2}c_{2}\right)
,\ldots,a_{n}\left(  b_{n}c_{n}\right)  \right)  .
\end{align*}


The additive inverse of $\left(  a_{1},a_{2},\ldots,a_{n}\right)  $ is
$\left(  -a_{1},-a_{2},\ldots,-a_{n}\right)  $.
\end{proof}

\begin{definition}
\label{def.ring.dirprod2}The ring $\mathbb{K}_{1}\times\mathbb{K}_{2}%
\times\cdots\times\mathbb{K}_{n}$ constructed in Proposition
\ref{prop.ring.dirprod.ring} is called the \textit{Cartesian product} (or
\textit{direct product}) of the rings $\mathbb{K}_{1},\mathbb{K}_{2}%
,\ldots,\mathbb{K}_{n}$.
\end{definition}

We have already seen a Cartesian product. Indeed, recall the binary operations
$\operatorname*{XOR}$ defined back in Subsection \ref{subsect.intro.XOR}. We
first defined an operation $\operatorname*{XOR}$ on bits (Definition
\ref{def.intro.XOR.XOR01}), and then defined an operation $\operatorname*{XOR}%
$ on bitstrings (Definition \ref{def.intro.XOR.XOR01m}). It is easy to see
that
\[
\left(  \left\{  0,1\right\}  ,\operatorname*{XOR},\cdot,0,1\right)
\]
is a commutative ring. Let me call this ring $\mathbb{X}$ for now. Note that
this ring $\mathbb{X}$ can be seen as $\mathbb{Z}/2$ with its elements
relabeled (more precisely, the elements $\left[  0\right]  _{2}$ and $\left[
1\right]  _{2}$ of $\mathbb{Z}/2$ need to be relabelled as $0$ and $1$ in
order to get $\mathbb{X}$); for example, the correspondence between the
$\operatorname*{XOR}$ operation on $\mathbb{X}$ and the addition on
$\mathbb{Z}/2$ can be seen by comparing their results face to face:%
\begin{align*}
0\operatorname*{XOR}0  &  =0\ \ \ \ \ \ \ \ \ \ \text{and}%
\ \ \ \ \ \ \ \ \ \ \left[  0\right]  _{2}+\left[  0\right]  _{2}=\left[
0\right]  _{2},\\
0\operatorname*{XOR}1  &  =1\ \ \ \ \ \ \ \ \ \ \text{and}%
\ \ \ \ \ \ \ \ \ \ \left[  0\right]  _{2}+\left[  1\right]  _{2}=\left[
1\right]  _{2},\\
1\operatorname*{XOR}0  &  =1\ \ \ \ \ \ \ \ \ \ \text{and}%
\ \ \ \ \ \ \ \ \ \ \left[  1\right]  _{2}+\left[  0\right]  _{2}=\left[
1\right]  _{2},\\
1\operatorname*{XOR}1  &  =0\ \ \ \ \ \ \ \ \ \ \text{and}%
\ \ \ \ \ \ \ \ \ \ \left[  1\right]  _{2}+\left[  1\right]  _{2}=\left[
0\right]  _{2}.
\end{align*}


In Definition \ref{def.intro.XOR.XOR01m}, we defined a binary operation
$\operatorname*{XOR}$ on $\left\{  0,1\right\}  ^{m}$, i.e., on bitstrings.
This gives a ring%
\[
\left(  \left\{  0,1\right\}  ^{m},\operatorname*{XOR},\text{entrywise
multiplication},00\cdots0,11\cdots1\right)
\]
of bitstrings. This ring is precisely the Cartesian product%
\[
\underbrace{\mathbb{X}\times\mathbb{X}\times\cdots\times\mathbb{X}}_{m\text{
times}}.
\]


\subsection{\label{sect.ring.matrix}Matrices and matrix rings}

\begin{convention}
In this section, we fix a ring $\mathbb{K}$.
\end{convention}

We take the familiar concept of matrices, and generalize it in a
straightforward way, allowing matrices with entries in $\mathbb{K}$:

\begin{definition}
\label{def.matrix.matrix}Given $n,m\in\mathbb{N}$, we define an $n\times
m$\textit{-matrix over }$\mathbb{K}$ to be a rectangular table with $n$ rows
and $m$ columns whose entries are elements of $\mathbb{K}$. When $\mathbb{K}$
is clear from the context (or irrelevant), we just say \textquotedblleft%
$n\times m$-matrix\textquotedblright\ instead of \textquotedblleft$n\times
m$-matrix over $\mathbb{K}$\textquotedblright.
\end{definition}

For example, if $\mathbb{K}=\mathbb{Q}$, then%
\[
\left(
\begin{array}
[c]{ccc}%
0 & 1/3 & -6\\
-1 & -2/5 & 1
\end{array}
\right)
\]
is a $2\times3$-matrix over $\mathbb{K}$.

(Formally, an $n\times m$-matrix is defined as a map from $\left\{
1,2,\ldots,n\right\}  \times\left\{  1,2,\ldots,m\right\}  $ to $\mathbb{K}$.
Its entry in row $i$ and column $j$ is then defined to be the image of the
pair $\left(  i,j\right)  $ under this map.)

Note that the \textquotedblleft$\times$\textquotedblright\ symbol in the
notion of an \textquotedblleft$n\times m$-matrix\textquotedblright\ is just a
symbol, not an invitation to actually multiply the numbers $n$ and $m$
together! For example, $2\cdot3=3\cdot2$, yet a $2\times3$-matrix is not the
same as a $3\times2$-matrix.

Let us define two pieces of notation:

\begin{definition}
\label{def.matrix.ij-entry}Let $A$ be an $n\times m$-matrix over $\mathbb{K}$.
Let $i\in\left\{  1,2,\ldots,n\right\}  $ and $j\in\left\{  1,2,\ldots
,m\right\}  $. The $\left(  i,j\right)  $\textit{-th entry of}\textbf{ }$A$ is
defined to be the entry of $A$ in row $i$ and column $j$.
\end{definition}

\begin{definition}
\label{def.matrix.(aij)}Let $n,m\in\mathbb{N}$. Assume that we are given some
element $a_{i,j}\in\mathbb{K}$ for every $\left(  i,j\right)  \in\left\{
1,2,\ldots,n\right\}  \times\left\{  1,2,\ldots,m\right\}  $. Then, we shall
use the notation
\begin{equation}
\left(  a_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq m}
\label{eq.def.matrix.(aij).(aij)}%
\end{equation}
for the $n\times m$-matrix%
\[
\left(
\begin{array}
[c]{cccc}%
a_{1,1} & a_{1,2} & \cdots & a_{1,m}\\
a_{2,1} & a_{2,2} & \cdots & a_{2,m}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n,1} & a_{n,2} & \cdots & a_{n,m}%
\end{array}
\right)
\]
(this is the $n\times m$-matrix whose $\left(  i,j\right)  $-th entry is
$a_{i,j}$ for all $i$ and $j$).
\end{definition}

For example,%
\begin{align*}
\left(  i+j\right)  _{1\leq i\leq3,\ 1\leq j\leq4}  &  =\left(
\begin{array}
[c]{cccc}%
2 & 3 & 4 & 5\\
3 & 4 & 5 & 6\\
4 & 5 & 6 & 7
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \text{and}\\
\left(  i-j\right)  _{1\leq i\leq3,\ 1\leq j\leq4}  &  =\left(
\begin{array}
[c]{cccc}%
0 & -1 & -2 & -3\\
1 & 0 & -1 & -2\\
2 & 1 & 0 & -1
\end{array}
\right)  .
\end{align*}


The letters $i$ and $j$ in the notation (\ref{eq.def.matrix.(aij).(aij)}) are
not set in stone; we can use any other letters instead. For example,%
\[
\left(  i-j\right)  _{1\leq i\leq3,\ 1\leq j\leq4}=\left(  x-y\right)  _{1\leq
x\leq3,\ 1\leq y\leq4}=\left(  j-i\right)  _{1\leq j\leq3,\ 1\leq i\leq4}.
\]


\begin{definition}
\label{def.matrix.Knm}Let $n,m\in\mathbb{N}$. Then, $\mathbb{K}^{n\times m}$
will denote the set of all $n\times m$-matrices. (Some call it
$\operatorname*{M}\nolimits_{n,m}\left(  \mathbb{K}\right)  $ instead.)
\end{definition}

Again, the \textquotedblleft$\times$\textquotedblright\ symbol in this
notation is just a symbol; it does not stand for a product of numbers.

\begin{definition}
\label{def.matrix.square}\textbf{(a)} A \textit{matrix} means an $n\times
m$-matrix for some $n,m\in\mathbb{N}$.

\textbf{(b)} A \textit{square matrix} means an $n\times n$-matrix for some
$n\in\mathbb{N}$.
\end{definition}

For example, $\left(
\begin{array}
[c]{ccc}%
1 & 2 & 6\\
3 & 4 & 5
\end{array}
\right)  $ is a matrix, and $\left(
\begin{array}
[c]{cc}%
2 & 6\\
4 & 5
\end{array}
\right)  $ is a square matrix.

We now define various operations with matrices:

\begin{definition}
\label{def.matrix.+-}Fix $n,m\in\mathbb{N}$.

\textbf{(a)} The \textit{sum} $A+B$ of two $n\times m$-matrices $A$ and $B$ is
defined entrywise: i.e., if $A=\left(  a_{i,j}\right)  _{1\leq i\leq n,\ 1\leq
j\leq m}$ and $B=\left(  b_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq m}$,
then%
\[
A+B=\left(  a_{i,j}+b_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq m}.
\]


\textbf{(b)} The \textit{difference} $A-B$ of two $n\times m$-matrices $A$ and
$B$ is defined entrywise: i.e., if $A=\left(  a_{i,j}\right)  _{1\leq i\leq
n,\ 1\leq j\leq m}$ and $B=\left(  b_{i,j}\right)  _{1\leq i\leq n,\ 1\leq
j\leq m}$, then%
\[
A-B=\left(  a_{i,j}-b_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq m}.
\]


\textbf{(c)} We define \textit{scaling} of $n\times m$-matrices as follows: If
$\lambda\in\mathbb{K}$ and $A\in\mathbb{K}^{n\times m}$, then the matrix
$\lambda A\in\mathbb{K}^{n\times m}$ is defined by multiplying each entry of
$A$ by $\lambda$. Formally speaking: if $A=\left(  a_{i,j}\right)  _{1\leq
i\leq n,\ 1\leq j\leq m}$, then%
\[
\lambda A=\left(  \lambda a_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq m}.
\]

\end{definition}

To be more honest, the operation we defined in Definition \ref{def.matrix.+-}
\textbf{(c)} should have been called \textquotedblleft left
scaling\textquotedblright\ rather than \textquotedblleft
scaling\textquotedblright. And we should have defined an analogous operation
called \textquotedblleft right scaling\textquotedblright, which takes an
element $\lambda\in\mathbb{K}$ and a matrix $A=\left(  a_{i,j}\right)  _{1\leq
i\leq n,\ 1\leq j\leq m}\in\mathbb{K}^{n\times m}$, and returns a new matrix
\[
A\lambda=\left(  a_{i,j}\lambda\right)  _{1\leq i\leq n,\ 1\leq j\leq m}.
\]
But we will mostly be dealing with the case when the ring $\mathbb{K}$ is
commutative; and in this case, we always have $A\lambda=\lambda A$ (meaning
that \textquotedblleft right scaling\textquotedblright\ and \textquotedblleft
left scaling\textquotedblright\ are the same operation). Thus, we take the
liberty to neglect the \textquotedblleft right scaling\textquotedblright%
\ operation. (Its properties are analogous to the corresponding properties of
\textquotedblleft left scaling\textquotedblright\ anyway.)

\begin{definition}
\label{def.matrix.AB}Let $n,m,p\in\mathbb{N}$. Let $A=\left(  a_{i,j}\right)
_{1\leq i\leq n,\ 1\leq j\leq m}$ be an $n\times m$-matrix. Let $B=\left(
b_{i,j}\right)  _{1\leq i\leq m,\ 1\leq j\leq p}$ be an $m\times p$-matrix.
Then, we define the \textit{product} $AB$ of the two matrices $A$ and $B$ by%
\[
AB=\left(  \sum_{k=1}^{m}a_{i,k}b_{k,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq
p}.
\]
This is an $n\times p$-matrix.
\end{definition}

So you can add together two $n\times m$-matrices, but only multiply an
$n\times m$-matrix with an $m\times p$-matrix. (You cannot multiply two
$n\times m$-matrices, unless $n=m$.)

\begin{definition}
\label{def.matrix.01}\textbf{(a)} If $n,m\in\mathbb{N}$, then the $n\times m$
\textit{zero matrix} is defined to be the $n\times m$-matrix%
\[
\left(  0\right)  _{1\leq i\leq n,\ 1\leq j\leq m}=\left(
\begin{array}
[c]{cccc}%
0 & 0 & \cdots & 0\\
0 & 0 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 0
\end{array}
\right)  .
\]
It is called $0_{n\times m}$.

\textbf{(b)} If $n\in\mathbb{N}$, then the $n\times n$\textbf{ }%
\textit{identity matrix} is defined to be the $n\times n$-matrix%
\[
\left(  \delta_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq n}=\left(
\begin{array}
[c]{cccc}%
1 & 0 & \cdots & 0\\
0 & 1 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1
\end{array}
\right)  ,
\]
where%
\[
\delta_{i,j}=%
\begin{cases}
1, & \text{if }i=j;\\
0, & \text{if }i\neq j
\end{cases}
.
\]
(Note that using the Iverson bracket notation we introduced in Exercise
\ref{exe.binom.legendre}, we have $\delta_{i,j}=\left[  i=j\right]  $.)

The $n\times n$ identity matrix is called $I_{n}$.
\end{definition}

Note that the $0$ and the $1$ here are the zero and the unity of $\mathbb{K}$.

Thus, a zero matrix can be of any size, but an identity matrix has to be a
square matrix.

The following rules hold for addition, subtraction, multiplication and scaling
of matrices:

\begin{theorem}
\label{thm.matrix.rules}Let $n,m,p,q\in\mathbb{N}$.

\textbf{(a)} We have $A+B=B+A$ for any $A,B\in\mathbb{K}^{n\times m}$.

\textbf{(b)} We have $A+\left(  B+C\right)  =\left(  A+B\right)  +C$ for any
$A,B,C\in\mathbb{K}^{n\times m}$.

\textbf{(c)} We have $A+0_{n\times m}=0_{n\times m}+A=A$ for any
$A\in\mathbb{K}^{n\times m}$.

\textbf{(d)} We have $A\cdot I_{m}=I_{n}\cdot A=A$ for any $A\in
\mathbb{K}^{n\times m}$.

\textbf{(e)} In general, we \textbf{do not} have $AB=BA$. In fact, it can
happen that one of $AB$ and $BA$ is defined and the other is not; but even if
both are defined, they can be distinct (even if $\mathbb{K}$ is commutative).

\textbf{(f)} We have $A\left(  BC\right)  =\left(  AB\right)  C$ for any
$A\in\mathbb{K}^{n\times m}$, $B\in\mathbb{K}^{m\times p}$ and $C\in
\mathbb{K}^{p\times q}$.

\textbf{(g)} We have $A\left(  B+C\right)  =AB+AC$ for any $A\in
\mathbb{K}^{n\times m}$ and $B,C\in\mathbb{K}^{m\times p}$.

We have $\left(  A+B\right)  C=AC+BC$ for any $A,B\in\mathbb{K}^{n\times m}$
and $C\in\mathbb{K}^{m\times p}$.

\textbf{(h)} We have $A\cdot0_{m\times p}=0_{n\times p}$ and $0_{p\times
n}\cdot A=0_{p\times m}$ for any $A\in\mathbb{K}^{n\times m}$.

\textbf{(i)} If $A,B,C\in\mathbb{K}^{n\times m}$, then we have the equivalence
$\left(  A-B=C\right)  \Longleftrightarrow\left(  A=B+C\right)  $.

\textbf{(j)} We have $r\left(  A+B\right)  =rA+rB$ for any $r\in\mathbb{K}$
and $A,B\in\mathbb{K}^{n\times m}$.

\textbf{(k)} We have $\left(  r+s\right)  A=rA+sA$ for any $r,s\in\mathbb{K}$
and $A\in\mathbb{K}^{n\times m}$.

\textbf{(l)} We have $r\left(  sA\right)  =\left(  rs\right)  A$ for any
$r,s\in\mathbb{K}$ and $A\in\mathbb{K}^{n\times m}$.

\textbf{(m)} We have $r\left(  AB\right)  =\left(  rA\right)  B=A\left(
rB\right)  $ for any $r\in\mathbb{K}$ and $A\in\mathbb{K}^{n\times m}$ and
$B\in\mathbb{K}^{m\times p}$ if $\mathbb{K}$ is commutative. The first
equality also holds in general.

\textbf{(n)} We have $-\left(  rA\right)  =\left(  -r\right)  A=r\left(
-A\right)  $ for any $r\in\mathbb{K}$ and $A\in\mathbb{K}^{n\times m}$.

\textbf{(o)} We have $1A=A$ for any $A\in\mathbb{K}^{n\times m}$.

\textbf{(p)} We have $\left(  -1\right)  A=-A$ for any $A\in\mathbb{K}%
^{n\times m}$.

\textbf{(q)} We have $-\left(  A+B\right)  =\left(  -A\right)  +\left(
-B\right)  $ for any $A,B\in\mathbb{K}^{n\times m}$.

\textbf{(r)} We have $-0_{n\times m}=0_{n\times m}$.

\textbf{(s)} We have $-\left(  -A\right)  =A$ for any $A\in\mathbb{K}^{n\times
m}$.

\textbf{(t)} We have $-\left(  AB\right)  =\left(  -A\right)  B=A\left(
-B\right)  $ for any $A\in\mathbb{K}^{n\times m}$ and $B\in\mathbb{K}^{m\times
p}$.

\textbf{(u)} We have $A-B-C=A-\left(  B+C\right)  $ for any $A,B,C\in
\mathbb{K}^{n\times m}$. (Here and in the following, \textquotedblleft%
$A-B-C$\textquotedblright\ should be read as \textquotedblleft$\left(
A-B\right)  -C$\textquotedblright.)
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.matrix.rules}.]Most of these are trivial. The
hardest one is part \textbf{(f)}. See \cite[\S 2.9]{lina} for its proof.
\end{proof}

\begin{corollary}
\label{cor.matrix.ring}Let $n\in\mathbb{N}$. The set $\mathbb{K}^{n\times n}$
of all $n\times n$-matrices (endowed with addition $+$, multiplication $\cdot
$, zero $0_{n\times n}$ and unity $I_{n}$) is a ring.
\end{corollary}

\begin{proof}
Follows from Theorem \ref{thm.matrix.rules}.
\end{proof}

\begin{definition}
\label{def.matrix.ring}Let $n\in\mathbb{N}$. The ring $\mathbb{K}^{n\times n}$
defined in Corollary \ref{cor.matrix.ring} is called the $n$\textit{-th matrix
ring} over $\mathbb{K}$.
\end{definition}

\begin{center}
\textbf{2019-04-05 lecture}
\end{center}

So we know that $\mathbb{K}^{n\times n}$ is a ring whenever $n\in\mathbb{N}$.
Hence, Proposition \ref{thm.rings.sum.wd} shows that can define finite sums
and finite products in $\mathbb{K}^{n\times n}$ (but finite products need to
have the order of their factors specified: i.e., we can make sense of
\textquotedblleft$A_{1}A_{2}\cdots A_{k}$\textquotedblright\ but not of
\textquotedblleft$\prod_{s\in S}A_{s}$\textquotedblright). These also make
sense for non-square matrices whenever \textquotedblleft their sizes
match\textquotedblright:\ e.g., you can define a sum of finitely many $n\times
m$-matrices, and a product $A_{1}A_{2}\cdots A_{k}$ where each $A_{i}$ is an
$n_{i}\times n_{i+1}$-matrix (for any $n_{1},n_{2},\ldots,n_{k+1}\in
\mathbb{N}$). Standard rules for sums and products hold, at least to the
extent they don't rely on commutativity of multiplication.

But $\mathbb{K}^{n\times n}$ is not the only ring we can make out of matrices.
In fact, $\mathbb{K}^{n\times n}$ is full of interesting subrings, which are
obtained by restricting ourselves to special kinds of matrices. Here are some
of these:

\begin{definition}
\label{def.matrix.triang}Let $n\in\mathbb{N}$. Let $A=\left(  a_{i,j}\right)
_{1\leq i\leq n,\ 1\leq j\leq n}$ be an $n\times n$-matrix.

\textbf{(a)} We say that $A$ is \textit{lower-triangular} if and only if
\[
a_{i,j}=0\ \ \ \ \ \ \ \ \ \ \text{whenever }i<j.
\]


\textbf{(b)} We say that $A$ is \textit{upper-triangular} if and only if
\[
a_{i,j}=0\ \ \ \ \ \ \ \ \ \ \text{whenever }i>j.
\]


\textbf{(c)} We say that $A$ is \textit{diagonal} if and only if
\[
a_{i,j}=0\ \ \ \ \ \ \ \ \ \ \text{whenever }i\neq j.
\]

\end{definition}

For example, the $2\times2$-matrix $\left(
\begin{array}
[c]{cc}%
1 & 2\\
0 & 3
\end{array}
\right)  $ is upper-triangular (but not lower-triangular), while the
$2\times2$-matrix $\left(
\begin{array}
[c]{cc}%
1 & 0\\
2 & 3
\end{array}
\right)  $ is lower-triangular (but not upper-triangular).

\begin{proposition}
\label{prop.matrix.triang-ring}Let $n\in\mathbb{N}$.

\textbf{(a)} The set of all lower-triangular $n\times n$-matrices is a subring
of $\mathbb{K}^{n\times n}$.

\textbf{(b)} The set of all upper-triangular $n\times n$-matrices is a subring
of $\mathbb{K}^{n\times n}$.

\textbf{(c)} The set of all diagonal $n\times n$-matrices is a subring of
$\mathbb{K}^{n\times n}$.
\end{proposition}

\begin{example}
For $n=2$, the multiplication of lower-triangular $n\times n$-matrices looks
as follows:%
\[
\left(
\begin{array}
[c]{cc}%
a & b\\
0 & c
\end{array}
\right)  \left(
\begin{array}
[c]{cc}%
x & y\\
0 & z
\end{array}
\right)  =\left(
\begin{array}
[c]{cc}%
ax & ay+bz\\
0 & cz
\end{array}
\right)  ,
\]
and the multiplication of diagonal $n\times n$-matrices looks as follows:%
\[
\left(
\begin{array}
[c]{cc}%
a & 0\\
0 & c
\end{array}
\right)  \left(
\begin{array}
[c]{cc}%
x & 0\\
0 & z
\end{array}
\right)  =\left(
\begin{array}
[c]{cc}%
ax & 0\\
0 & cz
\end{array}
\right)  .
\]

\end{example}

\begin{proof}
[Proof of Proposition \ref{prop.matrix.triang-ring}.]The main
\textquotedblleft difficulty\textquotedblright\ is showing that the product of
two upper-triangular matrices is upper-triangular (and similarly for
lower-triangular matrices). This is \cite[Theorem 3.23 \textbf{(a)}]{lina}.
\end{proof}

Note that diagonal $n\times n$-matrices are \textquotedblleft
essentially\textquotedblright\ the same as $n$-tuples of elements of
$\mathbb{K}$; the ring they form is $\underbrace{\mathbb{K}\times
\mathbb{K}\times\cdots\times\mathbb{K}}_{n\text{ times}}$ in disguise. We will
make this precise in Example \ref{exa.riiso.dn} (using the notion of a ring isomorphism).

One of the most important operations on matrices is taking the transpose:

\begin{definition}
\label{def.matrix.transpose}Let $n\in\mathbb{N}$ and $m\in\mathbb{N}$. Let
$A=\left(  a_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq m}$ be an $n\times
m$-matrix. Then, we define an $m\times n$-matrix $A^{T}$ by%
\[
A^{T}=\left(  a_{j,i}\right)  _{1\leq i\leq m,\ 1\leq j\leq n}.
\]
Thus, for each $i\in\left\{  1,2,\ldots,m\right\}  $ and $j\in\left\{
1,2,\ldots,n\right\}  $, the $\left(  i,j\right)  $-th entry of $A^{T}$ is the
$\left(  j,i\right)  $-th entry of $A$. This matrix $A^{T}$ is called the
\textit{transpose} of $A$.
\end{definition}

For example,%
\[
\left(
\begin{array}
[c]{ccc}%
1 & 2 & 3\\
4 & 5 & 6
\end{array}
\right)  ^{T}=\left(
\begin{array}
[c]{cc}%
1 & 4\\
2 & 5\\
3 & 6
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \text{and}\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{cc}%
1 & 2\\
1 & 0
\end{array}
\right)  ^{T}=\left(
\begin{array}
[c]{cc}%
1 & 1\\
2 & 0
\end{array}
\right)  .
\]


Let us use this occasion to define column vectors and row vectors:

\begin{definition}
\label{def.matrix.row-col-vecs}Let $n\in\mathbb{N}$.

\textbf{(a)} A \textit{column vector of size }$n$ will mean an $n\times1$-matrix.

\textbf{(b)} A row vector of size $n$ will mean a $1\times n$-matrix.
\end{definition}

For example, $\left(
\begin{array}
[c]{c}%
1\\
2
\end{array}
\right)  $ is a column vector of size $2$, while $\left(
\begin{array}
[c]{ccc}%
1 & 2 & 3
\end{array}
\right)  $ is a row vector of size $3$. We will often identify a row vector
$\left(
\begin{array}
[c]{cccc}%
a_{1} & a_{2} & \cdots & a_{n}%
\end{array}
\right)  \in\mathbb{K}^{1\times n}$ with the corresponding $n$-tuple $\left(
a_{1},a_{2},\ldots,a_{n}\right)  $.

If $v$ is a column vector of size $n$, then $v^{T}$ is a row vector of size
$n$.

\subsection{\label{sect.ring.riho}Ring homomorphisms}

\begin{definition}
\label{def.riho.riho}Let $\mathbb{K}$ and $\mathbb{L}$ be two rings. A
\textit{ring homomorphism} from $\mathbb{K}$ to $\mathbb{L}$ means a map
$f:\mathbb{K}\rightarrow\mathbb{L}$ that satisfies the following four axioms:

\textbf{(a)} We have $f\left(  a+b\right)  =f\left(  a\right)  +f\left(
b\right)  $ for all $a,b\in\mathbb{K}$. (This is called \textquotedblleft$f$
respects addition\textquotedblright\ or \textquotedblleft$f$ preserves
addition\textquotedblright.)

\textbf{(b)} We have $f\left(  0\right)  =0$. (This, of course, means
$f\left(  0_{\mathbb{K}}\right)  =0_{\mathbb{L}}$.)

\textbf{(c)} We have $f\left(  ab\right)  =f\left(  a\right)  f\left(
b\right)  $ for all $a,b\in\mathbb{K}$. (This is called \textquotedblleft$f$
respects multiplication\textquotedblright\ or \textquotedblleft$f$ preserves
multiplication\textquotedblright.)

\textbf{(d)} We have $f\left(  1\right)  =1$. (This, of course, means
$f\left(  1_{\mathbb{K}}\right)  =1_{\mathbb{L}}$.)
\end{definition}

\begin{remark}
\label{rmk.riho.0-free}The axiom \textbf{(b)} in Definition
\ref{def.riho.riho} is redundant -- it follows from axiom \textbf{(a)}.
\end{remark}

\begin{proof}
[Proof of Remark \ref{rmk.riho.0-free}.]Assume that axiom \textbf{(a)} holds.
Apply axiom \textbf{(a)} to $a=0$ and $b=0$. Thus, you get%
\[
f\left(  0+0\right)  =f\left(  0\right)  +f\left(  0\right)  .
\]
Since $0+0=0$, this rewrites as%
\[
f\left(  0\right)  =f\left(  0\right)  +f\left(  0\right)  .
\]
Subtracting $f\left(  0\right)  $ on both sides (we can do this, since
$\mathbb{L}$ is a ring), we obtain $0=f\left(  0\right)  $, thus $f\left(
0\right)  =0$. Thus, axiom \textbf{(b)} holds.
\end{proof}

If the axiom \textbf{(b)} in Definition \ref{def.riho.riho} is redundant, then
why did we require it? One reason to do so is purely aesthetical: It ensures
that each of the two \textquotedblleft multiplicative\textquotedblright%
\ axioms (viz., axioms \textbf{(c)} and \textbf{(d)}) is matched by a
corresponding \textquotedblleft additive\textquotedblright\ axiom (viz.,
axioms \textbf{(a)} and \textbf{(b)}). We cannot omit axiom \textbf{(d)}%
\footnote{More precisely: if we did, then we would obtain a weaker, less
useful notion of ring homomorphism.}; thus, to avoid breaking the symmetry, I
prefer not to omit axiom \textbf{(b)} either. But there is also another reason
to keep axiom \textbf{(b)}. Indeed, if we want to define \textit{semiring
homomorphisms} (i.e., the analogue of ring homomorphisms in which rings are
replaced by semirings), then axiom \textbf{(b)} is no longer redundant (since
we cannot subtract elements in a semiring); thus, if we omitted axiom
\textbf{(b)}, our definition of ring homomorphisms would become less robust
with respect to replacing \textquotedblleft ring\textquotedblright\ by
\textquotedblleft semiring\textquotedblright.

\begin{example}
\label{exa.riho.id}Let $\mathbb{K}$ be any ring. The map $\operatorname*{id}%
:\mathbb{K}\rightarrow\mathbb{K}$ is a ring homomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.riho.id}.]Let us check that $\operatorname*{id}$
satisfies the axiom \textbf{(c)} in Definition \ref{def.riho.riho}: Indeed,
this simply means checking that $\operatorname*{id}\left(  ab\right)
=\operatorname*{id}\left(  a\right)  \operatorname*{id}\left(  b\right)  $ for
all $a,b\in\mathbb{K}$. But this rewrites as $ab=ab$, which is obvious.
Similarly, the other three axioms hold.
\end{proof}

We can slightly generalize Example \ref{exa.riho.id} as follows:

\begin{example}
\label{exa.riho.incl}Let $\mathbb{K}$ be a subring of a ring $\mathbb{L}$. Let
$\iota:\mathbb{K}\rightarrow\mathbb{L}$ be the map that sends each
$a\in\mathbb{K}$ to $a$ itself. (This map is called the \textit{inclusion map}
from $\mathbb{K}$ to $\mathbb{L}$.) Then, $\iota$ is a ring homomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.riho.incl}.]The four axioms in Definition
\ref{def.riho.riho} follow straight from the five requirements in Definition
\ref{def.ring.subring}.
\end{proof}

\begin{example}
\label{exa.riho.triv}Let $\mathbb{K}$ be any ring, and let $\mathbb{M}$ be the
zero ring $\left\{  0\right\}  $. Then, the map%
\[
\mathbb{K}\rightarrow\mathbb{M},\ \ \ \ \ \ \ \ \ \ a\mapsto0
\]
is a ring homomorphism.{}
\end{example}

\begin{proof}
[Proof of Example \ref{exa.riho.triv}.]Each of the four axioms in Definition
\ref{def.riho.riho} holds trivially for this map (since $\mathbb{M}$ has only
one element, and thus any two elements of $\mathbb{M}$ are equal).
\end{proof}

\begin{example}
\label{exa.riho.pin}Let $n$ be an integer. Consider the projection%
\begin{align*}
\pi_{\underset{n}{\equiv}}:\mathbb{Z}  &  \rightarrow\mathbb{Z}/n,\\
s  &  \mapsto\left[  s\right]  _{n}.
\end{align*}
This is a ring homomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.riho.pin}.]Again, let us check axiom \textbf{(c)}
only. So let $a,b\in\mathbb{Z}$. We must prove that $\pi_{\underset{n}{\equiv
}}\left(  ab\right)  =\pi_{\underset{n}{\equiv}}\left(  a\right)  \cdot
\pi_{\underset{n}{\equiv}}\left(  b\right)  $.

The left hand side is $\left[  ab\right]  _{n}$, while the right hand side is
$\left[  a\right]  _{n}\cdot\left[  b\right]  _{n}$. So they are equal,
because this is how $\left[  a\right]  _{n}\cdot\left[  b\right]  _{n}$ was
defined. Thus, axiom \textbf{(c)} holds.
\end{proof}

\begin{example}
\label{exa.riho.Rn-not}Let $n$ be a positive integer. Consider the map%
\begin{align*}
R_{n}:\mathbb{Z}/n  &  \rightarrow\mathbb{Z},\\
\left[  s\right]  _{n}  &  \mapsto s\%n.
\end{align*}
(This is the map sending $\left[  0\right]  _{n},\left[  1\right]  _{n}%
,\ldots,\left[  n-1\right]  _{n}$ to the numbers $0,1,\ldots,n-1$.) This map
$R_{n}$ is \textbf{not} a ring homomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.riho.Rn-not}.]Assume the contrary. Thus, $R_{n}$ is
a ring homomorphism. We want a contradiction.

We are in one of the following two cases:

\textit{Case 1:} We have $n>1$.

\textit{Case 2:} We have $n=1$.

Let us first consider Case 1. In this case, we have $n>1$.

We have assumed that $R_{n}$ is a ring homomorphism. Thus, axiom \textbf{(a)}
can be applied to $a=\left[  1\right]  _{n}$ and $b=\left[  n-1\right]  _{n}$,
and thus we get $R_{n}\left(  \left[  1\right]  _{n}+\left[  n-1\right]
_{n}\right)  =R_{n}\left(  \left[  1\right]  _{n}\right)  +R_{n}\left(
\left[  n-1\right]  _{n}\right)  $. But comparing%
\[
R_{n}\left(  \left[  1\right]  _{n}+\left[  n-1\right]  _{n}\right)
=R_{n}\left(  \left[  n\right]  _{n}\right)  =R_{n}\left(  \left[  0\right]
_{n}\right)  =0
\]
with%
\[
\underbrace{R_{n}\left(  \left[  1\right]  _{n}\right)  }_{=1}%
+\underbrace{R_{n}\left(  \left[  n-1\right]  _{n}\right)  }_{=n-1}=1+\left(
n-1\right)  =n,
\]
we see that this is not true. So we have found a contradiction in Case 1.

Let us now consider Case 2. In this case, we have $n=1$. Thus, $\left[
1\right]  _{1}=\left[  0\right]  _{1}$. But the map $R_{n}$ maps $\left[
0\right]  _{1}$ to $0$ (by its definition). However, axiom \textbf{(d)} forces
$R_{n}\left(  \left[  1\right]  _{1}\right)  =1$, which contradicts
$R_{n}\left(  \left[  1\right]  _{1}\right)  =R_{n}\left(  \left[  0\right]
_{1}\right)  =0$. So we have found a contradiction in Case 2.

Thus, we always get a contradiction.
\end{proof}

\textbf{Warning:} The same people who don't require rings to have a unity, of
course, do not require ring homomorphisms to satisfy axiom \textbf{(d)}. So
for them, $R_{n}$ would be a ring homomorphism for $n=1$.

\begin{example}
\label{exa.riho.pind}Let $n$ and $d$ be integers such that $d\mid n$. Then,
the map%
\begin{align*}
\pi_{n,d}:\mathbb{Z}/n  &  \rightarrow\mathbb{Z}/d,\\
\left[  s\right]  _{n}  &  \mapsto\left[  s\right]  _{d}%
\end{align*}
is a ring homomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.riho.pind}.]Let us check axiom \textbf{(c)}. So we
must prove that $\pi_{n,d}\left(  \alpha\beta\right)  =\pi_{n,d}\left(
\alpha\right)  \cdot\pi_{n,d}\left(  \beta\right)  $ for all $\alpha,\beta
\in\mathbb{Z}/n$.

Fix $\alpha,\beta\in\mathbb{Z}/n$. Write $\alpha$ as $\alpha=\left[  a\right]
_{n}$ with $a\in\mathbb{Z}$. Write $\beta$ as $\beta=\left[  b\right]  _{n}$
with $b\in\mathbb{Z}$.

Thus, $\pi_{n,d}\left(  \alpha\right)  =\pi_{n,d}\left(  \left[  a\right]
_{n}\right)  =\left[  a\right]  _{d}$ and $\pi_{n,d}\left(  \beta\right)
=\pi_{n,d}\left(  \left[  b\right]  _{n}\right)  =\left[  b\right]  _{d}$.
Multiplying these two equalities, we obtain
\begin{equation}
\underbrace{\pi_{n,d}\left(  \alpha\right)  }_{=\left[  a\right]  _{d}}%
\cdot\underbrace{\pi_{n,d}\left(  \beta\right)  }_{=\left[  b\right]  _{d}%
}=\left[  a\right]  _{d}\cdot\left[  b\right]  _{d}=\left[  ab\right]  _{d}.
\label{pf.exa.riho.pind.2}%
\end{equation}


But $\underbrace{\alpha}_{=\left[  a\right]  _{n}}\underbrace{\beta}_{=\left[
b\right]  _{n}}=\left[  a\right]  _{n}\cdot\left[  b\right]  _{n}=\left[
ab\right]  _{n}$ and thus $\pi_{n,d}\left(  \alpha\beta\right)  =\pi
_{n,d}\left(  \left[  ab\right]  _{n}\right)  =\left[  ab\right]  _{d}$.
Comparing this equality to (\ref{pf.exa.riho.pind.2}), we conclude $\pi
_{n,d}\left(  \alpha\beta\right)  =\pi_{n,d}\left(  \alpha\right)  \cdot
\pi_{n,d}\left(  \beta\right)  $. Thus, axiom \textbf{(c)} is proven. The
other three axioms are proven similarly (we leave the details to the reader).
\end{proof}

\begin{remark}
\label{rmk.riho.pind.only}Let $n$ and $d$ be integers. Then:

\textbf{(a)} If $d\mid n$, then the only ring homomorphism from $\mathbb{Z}/n$
to $\mathbb{Z}/d$ is $\pi_{n,d}$.

\textbf{(b)} If $d\nmid n$, then there is no ring homomorphism from
$\mathbb{Z}/n$ to $\mathbb{Z}/d$.
\end{remark}

Remark \ref{rmk.riho.pind.only} is not hard to prove, but we won't do this here.

\begin{example}
\label{exa.riho.C-mu}Consider the map $\mu:\mathbb{C}\rightarrow
\mathbb{R}^{2\times2}$ defined in Proposition \ref{prop.CC.as-matrices.mu}.
This map $\mu$ is a ring homomorphism.
\end{example}

\begin{proof}
Proposition \ref{prop.CC.as-matrices.mu} yields that the map $\mu$ satisfies
axioms \textbf{(a)} and \textbf{(c)}. It is easy to see that it satisfies the
other two.
\end{proof}

\begin{example}
\label{exa.riho.C-iota}Let $\iota_{\mathbb{C}}$ be the map%
\begin{align*}
\mathbb{R}  &  \rightarrow\mathbb{C},\\
r  &  \mapsto r_{\mathbb{C}}=\left(  r,0\right)  .
\end{align*}
This is a ring homomorphism.
\end{example}

\begin{proof}
Theorem \ref{thm.CC.RRtoCC.hom} shows that $\iota_{\mathbb{C}}$ satisfies
axioms \textbf{(a)} and \textbf{(c)}. As for \textbf{(b)} and \textbf{(d)},
these follow from the fact that the zero of $\mathbb{C}$ is $0_{\mathbb{C}%
}=\left(  0,0\right)  $ and the unity of $\mathbb{C}$ is $1_{\mathbb{C}%
}=\left(  1,0\right)  $.
\end{proof}

\begin{example}
\label{exa.riho.transp2}Let $\mathbb{K}$ be a commutative ring.

Let $\mathbb{K}^{2\leq2}$ be the ring of upper-triangular $2\times2$-matrices.
(This is a ring, by Proposition \ref{prop.matrix.triang-ring}.)

Let $\mathbb{K}^{2\geq2}$ be the ring of lower-triangular $2\times2$-matrices.
(This is a ring, by Proposition \ref{prop.matrix.triang-ring}.)

\textbf{(a)} Consider the map%
\begin{align*}
\mathbb{K}^{2\leq2}  &  \rightarrow\mathbb{K}^{2\geq2},\\
\left(
\begin{array}
[c]{cc}%
a & b\\
0 & c
\end{array}
\right)   &  \mapsto\left(
\begin{array}
[c]{cc}%
a & 0\\
b & c
\end{array}
\right)  .
\end{align*}
In other words, this is the map sending each $A$ to $A^{T}$ (the transpose of
$A$). Is this a ring homomorphism? No, because $\left(  AB\right)  ^{T}$ is
$B^{T}A^{T}$, not $A^{T}B^{T}$ (in general). This is called a \textit{ring
antihomomorphism}. Note that if $\mathbb{K}$ was an arbitrary (not
commutative) ring, then $\left(  AB\right)  ^{T}$ would (in general!) equal
neither $B^{T}A^{T}$ nor $A^{T}B^{T}$.

\textbf{(b)} Consider the map%
\begin{align*}
\mathbb{K}^{2\leq2}  &  \rightarrow\mathbb{K}^{2\geq2},\\
\left(
\begin{array}
[c]{cc}%
a & b\\
0 & c
\end{array}
\right)   &  \mapsto\left(
\begin{array}
[c]{cc}%
c & 0\\
b & a
\end{array}
\right)  .
\end{align*}
In other words, this is the map that reverses the order of the rows and
reverses the order of the columns. You can check that this is a ring
homomorphism. This holds even if $\mathbb{K}$ is an arbitrary (not
commutative) ring.
\end{example}

\begin{proposition}
\label{prop.riho.subtract}Let $\mathbb{K}$ and $\mathbb{L}$ be two rings. Let
$f:\mathbb{K}\rightarrow\mathbb{L}$ be a ring homomorphism.

\textbf{(a)} We have $f\left(  -a\right)  =-f\left(  a\right)  $ for all
$a\in\mathbb{K}$. (In other words, $f$ \textquotedblleft preserves additive
inverses\textquotedblright.)

\textbf{(b)} If $a\in\mathbb{K}$ is invertible, then $f\left(  a\right)
\in\mathbb{L}$ is also invertible, and we have $f\left(  a^{-1}\right)
=\left(  f\left(  a\right)  \right)  ^{-1}$. (In other words, $f$
\textquotedblleft preserves multiplicative inverses\textquotedblright.)

\textbf{(c)} We have $f\left(  a-b\right)  =f\left(  a\right)  -f\left(
b\right)  $ for all $a,b\in\mathbb{K}$.

\textbf{(d)} If the rings $\mathbb{K}$ and $\mathbb{L}$ are commutative, then
we have $f\left(  \dfrac{a}{b}\right)  =\dfrac{f\left(  a\right)  }{f\left(
b\right)  }$ for all $a,b\in\mathbb{K}$ for which $b$ is invertible.

\textbf{(e)} We have $f\left(  \sum_{s\in S}a_{s}\right)  =\sum_{s\in
S}f\left(  a_{s}\right)  $ whenever $S$ is a finite set and $a_{s}%
\in\mathbb{K}$ for all $s\in S$.

\textbf{(f)} We have $f\left(  a_{1}a_{2}\cdots a_{k}\right)  =f\left(
a_{1}\right)  f\left(  a_{2}\right)  \cdots f\left(  a_{k}\right)  $ whenever
$a_{1},a_{2},\ldots,a_{k}\in\mathbb{K}$.

\textbf{(g)} If the rings $\mathbb{K}$ and $\mathbb{L}$ are commutative, then
$f\left(  \prod_{s\in S}a_{s}\right)  =\prod_{s\in S}f\left(  a_{s}\right)  $
whenever $S$ is a finite set and $a_{s}\in\mathbb{K}$ for all $s\in S$.

\textbf{(h)} We have $f\left(  a^{n}\right)  =\left(  f\left(  a\right)
\right)  ^{n}$ for each $a\in\mathbb{K}$ and each $n\in\mathbb{N}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.riho.subtract}.]The map $f$ is a ring
homomorphism, and thus satisfies the four axioms \textbf{(a)}, \textbf{(b)},
\textbf{(c)} and \textbf{(d)} of Definition \ref{def.riho.riho}.

\textbf{(b)} Let $a\in\mathbb{K}$ be invertible. We have%
\[
f\left(  a^{-1}a\right)  =f\left(  a^{-1}\right)  f\left(  a\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by axiom \textbf{(c)}}\right)  .
\]
Thus,%
\[
f\left(  a^{-1}\right)  f\left(  a\right)  =f\left(  \underbrace{a^{-1}a}%
_{=1}\right)  =f\left(  1\right)  =1\ \ \ \ \ \ \ \ \ \ \left(  \text{by axiom
\textbf{(d)}}\right)  .
\]
Similarly, $f\left(  a\right)  f\left(  a^{-1}\right)  =1$. These two
equations are saying that $f\left(  a^{-1}\right)  $ is a multiplicative
inverse of $f\left(  a\right)  $. Thus, $f\left(  a\right)  $ is invertible,
and $f\left(  a^{-1}\right)  =\left(  f\left(  a\right)  \right)  ^{-1}$. This
proves part \textbf{(b)}.

\textbf{(a)} Repeat the proof we gave for part \textbf{(b)}, but replace
multiplication and $1$ by addition and $0$ (and forget about invertibility,
because every element of $\mathbb{K}$ or $\mathbb{L}$ has an additive inverse).

\textbf{(c)} Let $a,b\in\mathbb{K}$. Then,%
\begin{align*}
f\left(  a-b\right)   &  =f\left(  a+\left(  -b\right)  \right)  =f\left(
a\right)  +\underbrace{f\left(  -b\right)  }_{\substack{=-f\left(  b\right)
\\\text{(by Proposition \ref{prop.riho.subtract} \textbf{(a)})}}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{by axiom \textbf{(a)}}\right) \\
&  =f\left(  a\right)  +\left(  -f\left(  b\right)  \right)  =f\left(
a\right)  -f\left(  b\right)  .
\end{align*}


\textbf{(d)} Similar to part \textbf{(c)}, but addition is replaced by multiplication.

\textbf{(e)} Induction on $\left\vert S\right\vert $. The induction base uses
axiom \textbf{(b)}; the induction step uses axiom \textbf{(a)}.

\textbf{(f)} Induction on $k$. The induction base uses axiom \textbf{(d)}; the
induction step uses axiom \textbf{(c)}.

\textbf{(g)} Induction on $\left\vert S\right\vert $. The induction base uses
axiom \textbf{(d)}; the induction step uses axiom \textbf{(c)}.

\textbf{(h)} Follows from \textbf{(f)}, applied to $k=n$ and $a_{i}=a$.
\end{proof}

The composition of two ring homomorphisms is again a ring homomorphism, as the
following proposition shows:

\begin{proposition}
\label{prop.riho.compose}Let $\mathbb{K}$, $\mathbb{L}$ and $\mathbb{M}$ be
three rings. Let $f:\mathbb{K}\rightarrow\mathbb{L}$ and $g:\mathbb{L}%
\rightarrow\mathbb{M}$ be two ring homomorphisms. Then, the composition
$g\circ f:\mathbb{K}\rightarrow\mathbb{M}$ is also a ring homomorphism.
\end{proposition}

\begin{proof}
HW6 exercise 4 \textbf{(a)}.
\end{proof}

\subsection{\label{sect.ring.riiso}Ring isomorphisms}

\begin{definition}
\label{def.riiso.riiso}Let $\mathbb{K}$ and $\mathbb{L}$ be two rings. Let
$f:\mathbb{K}\rightarrow\mathbb{L}$ be a map. Then, $f$ is called a
\textit{ring isomorphism} if and only if $f$ is invertible (i.e., bijective)
and both $f$ and $f^{-1}$ are ring homomorphisms.
\end{definition}

\begin{example}
\label{exa.riiso.id}Let $\mathbb{K}$ be a ring. The identity map
$\operatorname*{id}:\mathbb{K}\rightarrow\mathbb{K}$ is a ring isomorphism.
\end{example}

\begin{example}
\label{exa.riiso.dn}Let $\mathbb{K}$ be a ring. Let $n\in\mathbb{N}$. Consider
the map%
\begin{align*}
\mathbf{d}_{n}:\underbrace{\mathbb{K}\times\mathbb{K}\times\cdots
\times\mathbb{K}}_{n\text{ times}}  &  \rightarrow\left\{  \text{diagonal
}n\times n\text{-matrices over }\mathbb{K}\right\}  ,\\
\left(  d_{1},d_{2},\ldots,d_{n}\right)   &  \mapsto\left(
\begin{array}
[c]{ccccc}%
d_{1} & 0 & 0 & \cdots & 0\\
0 & d_{2} & 0 & \cdots & 0\\
0 & 0 & d_{3} & \cdots & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & 0 & \cdots & d_{n}%
\end{array}
\right)  .
\end{align*}
Note that both $\underbrace{\mathbb{K}\times\mathbb{K}\times\cdots
\times\mathbb{K}}_{n\text{ times}}$ and $\left\{  \text{diagonal }n\times
n\text{-matrices over }\mathbb{K}\right\}  $ are rings (the former by
Definition \ref{def.ring.dirprod2}; the latter by Proposition
\ref{prop.matrix.triang-ring} \textbf{(c)}).

The map $\mathbf{d}_{n}$ is invertible. I claim that furthermore,
$\mathbf{d}_{n}$ is a ring isomorphism. This is easiest to check using
Proposition \ref{prop.riiso.invertible} further below. Note that this claim is
a rigorous version of our earlier informal statement that the ring formed by
the diagonal $n\times n$-matrices is just $\underbrace{\mathbb{K}%
\times\mathbb{K}\times\cdots\times\mathbb{K}}_{n\text{ times}}$ in disguise.
The isomorphism $\mathbf{d}_{n}$ is responsible for the disguise!
\end{example}

\begin{example}
The map from $\mathbb{K}^{2\leq2}$ to $\mathbb{K}^{2\geq2}$ introduced in
Example \ref{exa.riho.transp2} \textbf{(b)} is a ring isomorphism. Its inverse
is the map%
\begin{align*}
\mathbb{K}^{2\geq2}  &  \rightarrow\mathbb{K}^{2\leq2},\\
\left(
\begin{array}
[c]{cc}%
c & 0\\
b & a
\end{array}
\right)   &  \mapsto\left(
\begin{array}
[c]{cc}%
a & b\\
0 & c
\end{array}
\right)  .
\end{align*}

\end{example}

\begin{proposition}
\label{prop.riiso.invertible}Let $\mathbb{K}$ and $\mathbb{L}$ be two rings.
Let $f:\mathbb{K}\rightarrow\mathbb{L}$ be an invertible ring homomorphism.
Then, $f$ is a ring isomorphism.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.riiso.invertible}.]We just need to show that
$f^{-1}$ is a ring homomorphism.

Let us verify axiom \textbf{(c)} for $f^{-1}$. This means that we must prove
that%
\[
f^{-1}\left(  ab\right)  =f^{-1}\left(  a\right)  f^{-1}\left(  b\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in\mathbb{L}.
\]


So let $a,b\in\mathbb{L}$. We know that $f$ is a ring homomorphism; thus it
satisfies axiom \textbf{(c)}. Applying this axiom to $f^{-1}\left(  a\right)
$ and $f^{-1}\left(  b\right)  $ instead of $a$ and $b$, we find%
\[
f\left(  f^{-1}\left(  a\right)  f^{-1}\left(  b\right)  \right)
=\underbrace{f\left(  f^{-1}\left(  a\right)  \right)  }_{=a}\cdot
\underbrace{f\left(  f^{-1}\left(  b\right)  \right)  }_{=b}=ab=f\left(
f^{-1}\left(  ab\right)  \right)  .
\]
Since $f$ is injective (because $f$ is invertible), we thus conclude%
\[
f^{-1}\left(  a\right)  f^{-1}\left(  b\right)  =f^{-1}\left(  ab\right)  ,
\]
which is precisely what we wanted to prove.

So axiom \textbf{(c)} for $f^{-1}$ is verified. Axiom \textbf{(a)} follows by
the same argument with $+$ instead of $\cdot$.

Since $f$ satisfies axiom \textbf{(d)} (being a ring homomorphism), we have
$f\left(  1\right)  =1$. But this yields $f^{-1}\left(  1\right)  =1$; thus,
$f^{-1}$ satisfies axiom \textbf{(d)}. Similarly, $f^{-1}$ satisfies axiom
\textbf{(b)}.

Thus, the map $f^{-1}:\mathbb{L}\rightarrow\mathbb{K}$ satisfies all four
axioms for a ring homomorphism. Hence, $f^{-1}$ is a ring homomorphism. Thus,
$f$ is a ring isomorphism (by the definition of a ring isomorphism).
\end{proof}

\begin{center}
\textbf{2019-04-08 lecture}
\end{center}

\begin{example}
\label{exa.riiso.CRT}Let $m$ and $n$ be two coprime positive integers. Then,
$\left(  \mathbb{Z}/m\right)  \times\left(  \mathbb{Z}/n\right)  $ is a ring
(according to Definition \ref{def.ring.dirprod2}). Theorem
\ref{thm.eqrel.CRT2} says that the map%
\begin{align*}
S_{m,n}:\mathbb{Z}/\left(  mn\right)   &  \rightarrow\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  ,\\
\alpha &  \mapsto\left(  \pi_{mn,m}\left(  \alpha\right)  ,\pi_{mn,n}\left(
\alpha\right)  \right)
\end{align*}
is well-defined and is a bijection. This map $S_{m,n}$ is furthermore a ring isomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.riiso.CRT}.]The map $S_{m,n}$ is a bijection, thus invertible.

Let us next prove that the map $S_{m,n}$ is a ring homomorphism.

For each $s\in\mathbb{Z}$, we have%
\begin{equation}
S_{m,n}\left(  \left[  s\right]  _{mn}\right)  =\left(  \underbrace{\pi
_{mn,m}\left(  \left[  s\right]  _{mn}\right)  }_{=\left[  s\right]  _{m}%
},\underbrace{\pi_{mn,n}\left(  \left[  s\right]  _{mn}\right)  }_{=\left[
s\right]  _{n}}\right)  =\left(  \left[  s\right]  _{m},\left[  s\right]
_{n}\right)  . \label{pf.exa.riiso.CRT.1}%
\end{equation}


Let us check axiom \textbf{(c)} from Definition \ref{def.riho.riho} for
$f=S_{m,n}$. Let $\alpha,\beta\in\mathbb{Z}/\left(  mn\right)  $. We must
prove that $S_{m,n}\left(  \alpha\beta\right)  =S_{m,n}\left(  \alpha\right)
\cdot S_{m,n}\left(  \beta\right)  $.

Write $\alpha$ and $\beta$ in the form $\alpha=\left[  a\right]  _{mn}$ and
$\beta=\left[  b\right]  _{mn}$ for some $a,b\in\mathbb{Z}$. Then,
$\alpha\beta=\left[  a\right]  _{mn}\left[  b\right]  _{mn}=\left[  ab\right]
_{mn}$, so
\[
S_{m,n}\left(  \alpha\beta\right)  =S_{m,n}\left(  \left[  ab\right]
_{mn}\right)  =\left(  \left[  ab\right]  _{m},\left[  ab\right]  _{n}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{pf.exa.riiso.CRT.1})}\right)  .
\]
Comparing this with%
\begin{align*}
&  S_{m,n}\left(  \underbrace{\alpha}_{=\left[  a\right]  _{mn}}\right)  \cdot
S_{m,n}\left(  \underbrace{\beta}_{=\left[  b\right]  _{mn}}\right) \\
&  =\underbrace{S_{m,n}\left(  \left[  a\right]  _{mn}\right)  }%
_{\substack{=\left(  \left[  a\right]  _{m},\left[  a\right]  _{n}\right)
\\\text{(by (\ref{pf.exa.riiso.CRT.1}))}}}\cdot\underbrace{S_{m,n}\left(
\left[  b\right]  _{mn}\right)  }_{\substack{=\left(  \left[  b\right]
_{m},\left[  b\right]  _{n}\right)  \\\text{(by (\ref{pf.exa.riiso.CRT.1}))}%
}}\\
&  =\left(  \left[  a\right]  _{m},\left[  a\right]  _{n}\right)  \cdot\left(
\left[  b\right]  _{m},\left[  b\right]  _{n}\right)  =\left(
\underbrace{\left[  a\right]  _{m}\left[  b\right]  _{m}}_{=\left[  ab\right]
_{m}},\underbrace{\left[  a\right]  _{n}\left[  b\right]  _{n}}_{=\left[
ab\right]  _{n}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the multiplication }\cdot\text{ on the Cartesian product }\left(
\mathbb{Z}/m\right)  \times\left(  \mathbb{Z}/n\right) \\
\text{is defined entrywise}%
\end{array}
\right) \\
&  =\left(  \left[  ab\right]  _{m},\left[  ab\right]  _{n}\right)  ,
\end{align*}
we obtain $S_{m,n}\left(  \alpha\beta\right)  =S_{m,n}\left(  \alpha\right)
\cdot S_{m,n}\left(  \beta\right)  $. This proves axiom \textbf{(c)} for our
map $S_{m,n}$. Similarly, the other axioms can be shown. Thus, $S_{m,n}$ is a
ring homomorphism. Therefore, Proposition \ref{prop.riiso.invertible} shows
that $S_{m,n}$ is a ring isomorphism (since $S_{m,n}$ is invertible).
\end{proof}

Note one more simple general fact:

\begin{proposition}
\label{prop.riiso.inverse}Let $\mathbb{K}$ and $\mathbb{L}$ be two rings. Let
$f:\mathbb{K}\rightarrow\mathbb{L}$ be a ring isomorphism. Then,
$f^{-1}:\mathbb{L}\rightarrow\mathbb{K}$ is also a ring isomorphism.
\end{proposition}

\begin{proof}
Clearly, $f^{-1}$ is a ring homomorphism (since $f$ is a ring isomorphism).
Furthermore, $f^{-1}$ is invertible (with inverse $\left(  f^{-1}\right)
^{-1}=f$) and its inverse $\left(  f^{-1}\right)  ^{-1}=f$ is a ring
homomorphism as well. Thus, $f^{-1}$ is a ring isomorphism.
\end{proof}

Let me attempt to discuss the use of ring isomorphisms; unfortunately, I will
have to be vague at this point. Ring homomorphisms allow us to transfer some
things from one ring into another. For example, if $f:\mathbb{K\rightarrow L}$
is a ring homomorphism from a ring $\mathbb{K}$ to a ring $\mathbb{L}$, then
$f$ sends any invertible element of $\mathbb{K}$ to an invertible element of
$\mathbb{L}$ (by Proposition \ref{prop.riho.subtract} \textbf{(b)}). However,
they are generally only \textquotedblleft one-way roads\textquotedblright. For
instance, if $f:\mathbb{K\rightarrow L}$ is a ring homomorphism from a ring
$\mathbb{K}$ to a ring $\mathbb{L}$, and if $a\in\mathbb{K}$ is such that
$f\left(  a\right)  \in\mathbb{L}$ is invertible, then $a$ may and may not be
invertible. A ring homomorphism from a ring $\mathbb{K}$ to a ring
$\mathbb{L}$ does not determine either ring in terms of the other. You can
have homomorphisms between completely different rings, such as from
$\mathbb{Z}$ to the zero ring, or from $\mathbb{Z}$ to $\mathbb{C}$.

On the other hand, ring isomorphisms let us go \textquotedblleft back and
forth\textquotedblright\ between the rings they connect; if we have a ring
isomorphism $f:\mathbb{K}\rightarrow\mathbb{L}$, we can regard $\mathbb{L}$ as
being \textquotedblleft the same ring as $\mathbb{K}$, with its elements
renamed\textquotedblright. (The isomorphism $f$ does the renaming: you should
think of each $a\in\mathbb{K}$ being renamed as $f\left(  a\right)  $.)

Thus, when you have a ring isomorphism $f:\mathbb{K}\rightarrow\mathbb{L}$,
you can take any ``intrinsic'' property\footnote{What do we mean by
``intrinsic''? Roughly speaking, an \textit{intrinsic} property of a ring is a
property that can be stated entirely in terms of its structure (i.e., its
ground set and its operations $+$ and $\cdot$ and its elements $0$ and $1$),
without referring to outside objects. For instance, ``every element $a$ of the
ring satisfies $a^{3} = a^{2}$'' is an intrinsic property (since $a^{3}=aaa$
and $a^{2}=aa$ are defined purely in terms of the operation $\cdot$), and
``the ring has two nonzero elements $a$ and $b$ such that $ab = 0$'' is an
intrinsic property as well (provided that ``nonzero'' and ``$0$'' refer to the
zero of the ring, rather than the number $0$), but ``the ring contains the
number $\sqrt[3]{2}$'' is not an intrinsic property (since it refers to an
outside object -- namely, the number $\sqrt[3]{2}$).} of $\mathbb{K}$ and
obtain the corresponding property of $\mathbb{L}$, and vice versa. Here is an example:

\begin{proposition}
\label{prop.riiso.fieldfield}Let $\mathbb{K}$ and $\mathbb{L}$ be two rings.
Let $f:\mathbb{K}\rightarrow\mathbb{L}$ be a ring isomorphism.

\textbf{(a)} If $\mathbb{K}$ is commutative, then $\mathbb{L}$ is commutative.

\textbf{(b)} If $0\neq1$ in $\mathbb{K}$, then $0\neq1$ in $\mathbb{L}$.

\textbf{(c)} If $\mathbb{K}$ is a skew field, then $\mathbb{L}$ is a skew field.

\textbf{(d)} If $\mathbb{K}$ is a field, then $\mathbb{L}$ is a field.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.riiso.fieldfield}.]The proofs given below are
exemplary; you should be able to similarly transfer any other property of
$\mathbb{K}$ to $\mathbb{L}$ and vice versa.

Recall that $f$ is a ring isomorphism. Thus, the map $f$ is invertible, and
both $f$ and $f^{-1}$ are ring homomorphisms (by the definition of a ring isomorphism).

\textbf{(a)} Assume that $\mathbb{K}$ is commutative. We must prove that
$\mathbb{L}$ is commutative. In other words, we must prove that $ab=ba$ for
any $a,b\in\mathbb{L}$.

Fix $a,b\in\mathbb{L}$. We know that $f$ is invertible. Hence, $f^{-1}\left(
a\right)  ,f^{-1}\left(  b\right)  \in\mathbb{K}$ are well-defined. Since
$\mathbb{K}$ is commutative, these satisfy%
\[
f^{-1}\left(  a\right)  f^{-1}\left(  b\right)  =f^{-1}\left(  b\right)
f^{-1}\left(  a\right)  .
\]
Applying $f$ to this equality, we get%
\begin{equation}
f\left(  f^{-1}\left(  a\right)  f^{-1}\left(  b\right)  \right)  =f\left(
f^{-1}\left(  b\right)  f^{-1}\left(  a\right)  \right)  .
\label{pf.prop.riiso.fieldfield.a.1}%
\end{equation}
But since $f$ is a ring homomorphism, we can apply axiom \textbf{(c)} of
Definition \ref{def.riho.riho} to $f^{-1}\left(  a \right)  $ and
$f^{-1}\left(  b \right)  $ instead of $a$ and $b$. We thus obtain
\[
f\left(  f^{-1}\left(  a\right)  f^{-1}\left(  b\right)  \right)
=\underbrace{f\left(  f^{-1}\left(  a\right)  \right)  }_{=a}%
\underbrace{f\left(  f^{-1}\left(  b\right)  \right)  }_{=b}=ab
\]
and similarly $f\left(  f^{-1}\left(  b\right)  f^{-1}\left(  a\right)
\right)  =ba$; thus, the equality (\ref{pf.prop.riiso.fieldfield.a.1}) becomes
$ab=ba$. This shows that $\mathbb{L}$ is commutative. This proves Proposition
\ref{prop.riiso.fieldfield} \textbf{(a)}.

Before I move on to the next part of Proposition \ref{prop.riiso.fieldfield},
let me explain how the above proof could be found straightforwardly, without
any creative input. The point of this is to show how to prove not just
Proposition \ref{prop.riiso.fieldfield} \textbf{(a)}, but any similar claim as well.

The (only) idea involved in the above proof was the following: The two
mutually inverse bijections $f : \mathbb{K} \to\mathbb{L}$ and $f^{-1} :
\mathbb{L} \to\mathbb{K}$ provide a ``railway system'' that can be used to
transport anything (elements, equalities, subsets, etc.) between $\mathbb{K}$
and $\mathbb{L}$. Since these bijections are ring homomorphisms, the structure
of the objects that we are transporting does not get ``damaged in transit'':
Products remain products (i.e., if we have three elements $a$, $b$ and $c$ of
$\mathbb{K}$ satisfying $ab = c$, and if we transport these three elements to
$\mathbb{L}$ via $f$, then the resulting three elements of $\mathbb{L}$ will
still satisfy $f\left(  a \right)  f\left(  b \right)  = f\left(  c \right)
$), sums remain sums, etc.. Thus, we can move back and forth between
$\mathbb{K}$ and $\mathbb{L}$ without keeping track of where precisely we take
our sums and products.

With this in mind, our above proof of Proposition \ref{prop.riiso.fieldfield}
\textbf{(a)} can be discovered as follows:

Assume that $\mathbb{K}$ is commutative. We must prove that $\mathbb{L}$ is
commutative. In other words, we must prove that $ab = ba$ for any $a, b
\in\mathbb{L}$. So let us fix $a, b \in\mathbb{L}$. We want to prove $ab =
ba$, but all we have is an analogous identity for elements of $\mathbb{K}$
(since we know that $\mathbb{K}$ is commutative). In other words, we have
\begin{equation}
a^{\prime}b^{\prime}= b^{\prime}a^{\prime}\ \ \ \ \ \ \ \ \ \ \text{for all }
a^{\prime}, b^{\prime}\in\mathbb{K} .
\label{pf.prop.riiso.fieldfield.a.idea.1}%
\end{equation}


So we transport our two elements $a,b$ of $\mathbb{L}$ to $\mathbb{K}$ (by our
\textquotedblleft railway system\textquotedblright\ -- specifically, using the
map $f^{-1}$), in order to be able to apply
\eqref{pf.prop.riiso.fieldfield.a.idea.1} to them. The result are the two
elements $f^{-1}\left(  a\right)  ,f^{-1}\left(  b\right)  $ of $\mathbb{K}$.
Applying the identity \eqref{pf.prop.riiso.fieldfield.a.idea.1} to $a^{\prime
}=f^{-1}\left(  a\right)  $ and $b^{\prime}=f^{-1}\left(  b\right)  $, we
obtain $f^{-1}\left(  a\right)  f^{-1}\left(  b\right)  =f^{-1}\left(
b\right)  f^{-1}\left(  a\right)  $. This is an equality inside $\mathbb{K}$,
whereas our goal is to prove an equality inside $\mathbb{L}$ (namely, the
equality $ab=ba$). So we transport this equality back into $\mathbb{L}$ by
applying $f$ to its two sides. We thus obtain
\begin{equation}
f\left(  f^{-1}\left(  a\right)  f^{-1}\left(  b\right)  \right)  =f\left(
f^{-1}\left(  b\right)  f^{-1}\left(  a\right)  \right)  .
\label{pf.prop.riiso.fieldfield.a.idea.2}%
\end{equation}
But recalling that $f$ is a ring homomorphism and thus no structure gets
\textquotedblleft damaged in transit\textquotedblright, we see that
\[
f\left(  f^{-1}\left(  a\right)  f^{-1}\left(  b\right)  \right)
=\underbrace{f\left(  f^{-1}\left(  a\right)  \right)  }_{=a}%
\underbrace{f\left(  f^{-1}\left(  b\right)  \right)  }_{=b}=ab
\]
and similarly $f\left(  f^{-1}\left(  b\right)  f^{-1}\left(  a\right)
\right)  =ba$. Hence, the equality (\ref{pf.prop.riiso.fieldfield.a.idea.2})
that we have just proven rewrites as $ab=ba$, which is precisely what we
wanted to prove. Thus, we have proven Proposition \ref{prop.riiso.fieldfield}
\textbf{(a)} by merely going back and forth between $\mathbb{K}$ and
$\mathbb{L}$.

Let us now prove the rest of Proposition \ref{prop.riiso.fieldfield}:

\textbf{(b)} Assume $0\neq1$ in $\mathbb{K}$. We must prove $0\neq1$ in
$\mathbb{L}$.

The map $f$ is an isomorphism, thus invertible, thus bijective, thus
injective. Hence, from $0\neq1$ in $\mathbb{K}$, we conclude $f\left(
0\right)  \neq f\left(  1\right)  $ in $\mathbb{L}$. But since $f$ is a ring
homomorphism, we have $f\left(  0\right)  =0$ and $f\left(  1\right)  =1$; so
this rewrites as $0\neq1$ in $\mathbb{L}$. This proves Proposition
\ref{prop.riiso.fieldfield} \textbf{(b)}.

\textbf{(c)} Assume that $\mathbb{K}$ is a skew field. We must prove that
$\mathbb{L}$ is a skew field.

Since $\mathbb{K}$ is a skew field, we have $0\neq1$ in $\mathbb{K}$, thus
$0\neq1$ in $\mathbb{L}$ (by Proposition \ref{prop.riiso.fieldfield}
\textbf{(b)}). Hence, it remains to prove that every nonzero element
$a\in\mathbb{L}$ has a multiplicative inverse.

Let $a\in\mathbb{L}$ be nonzero. Then, $f^{-1}\left(  a\right)  \in\mathbb{K}$
is nonzero (because if it was zero, then we would have $f^{-1}\left(
a\right)  =0$ and thus $f\left(  f^{-1}\left(  a\right)  \right)  =f\left(
0\right)  =0$ (since $f$ is a ring homomorphism); but this would contradict
the fact that $f\left(  f^{-1}\left(  a\right)  \right)  =a$ is nonzero).
Hence, $f^{-1}\left(  a\right)  \in\mathbb{K}$ has a multiplicative inverse
$b$ (since $\mathbb{K}$ is a skew field). Consider this $b$. Thus,
$f^{-1}\left(  a\right)  b=bf^{-1}\left(  a\right)  =1$ (since $b$ is a
multiplicative inverse of $f^{-1}\left(  a\right)  $). Applying $f$ to this
chain of equalities, we obtain%
\[
f\left(  f^{-1}\left(  a\right)  b\right)  =f\left(  bf^{-1}\left(  a\right)
\right)  =f\left(  1\right)  .
\]
This quickly rewrites as
\[
af\left(  b\right)  =f\left(  b\right)  a=1
\]
(since $f$ is a ring homomorphism). Thus, $f\left(  b\right)  $ is a
multiplicative inverse of $a$. Hence, $a$ has a multiplicative inverse. Thus,
we have shown that every nonzero element $a\in\mathbb{L}$ has a multiplicative
inverse. Since $0\neq1$ in $\mathbb{L}$, this shows that $\mathbb{L}$ is a
skew field. This proves Proposition \ref{prop.riiso.fieldfield} \textbf{(c)}.

\textbf{(d)} Assume that $\mathbb{K}$ is a field. We must prove that
$\mathbb{L}$ is a field.

Since $\mathbb{K}$ is a field, $\mathbb{K}$ is commutative, and thus
$\mathbb{L}$ is commutative (by Proposition \ref{prop.riiso.fieldfield}
\textbf{(a)}).

But $\mathbb{K}$ is a field, and thus a skew field. Hence, Proposition
\ref{prop.riiso.fieldfield} \textbf{(c)} shows that $\mathbb{L}$ is a skew
field. Since $\mathbb{L}$ is commutative, this yields that $\mathbb{L}$ is a
field. This proves Proposition \ref{prop.riiso.fieldfield} \textbf{(d)}.
\end{proof}

The idea of the above proof (and of many similar proofs, which we will omit)
is that if you have a ring isomorphism $f:\mathbb{K}\rightarrow\mathbb{L}$,
you can transport any equality or element from $\mathbb{K}$ to $\mathbb{L}$
(via $f$) or vice versa (via $f^{-1}$); and each time, the ring operations
($+$, $-$, $\cdot$, $\sum$, $0$, $1$) do not get damaged on the way (since $f$
and $f^{-1}$ are ring homomorphisms).

Here is another example of this sort of reasoning:

\begin{proposition}
\label{prop.riiso.equal-invertibles}Let $\mathbb{K}$ and $\mathbb{L}$ be two
rings. Let $f:\mathbb{K}\rightarrow\mathbb{L}$ be a ring isomorphism. Then:

\textbf{(a)} We have%
\[
\left\vert \left\{  \text{invertible elements of }\mathbb{K}\right\}
\right\vert =\left\vert \left\{  \text{invertible elements of }\mathbb{L}%
\right\}  \right\vert .
\]


\textbf{(b)} We have%
\[
\left\vert \left\{  \text{idempotent elements of }\mathbb{K}\right\}
\right\vert =\left\vert \left\{  \text{idempotent elements of }\mathbb{L}%
\right\}  \right\vert .
\]

\end{proposition}

Here, an element $a$ of a ring $\mathbb{K}$ is said to be \textit{idempotent}
if $a^{2}=a$.

\begin{proof}
[Proof of Proposition \ref{prop.riiso.equal-invertibles}.]Proposition
\ref{prop.riiso.equal-invertibles} is another instance of the
\textquotedblleft anything can be transported along a ring
isomorphism\textquotedblright\ principle (which we have used in Proposition
\ref{prop.riiso.fieldfield}). Here is a proof in more detail:

\textbf{(a)} If $a$ is an invertible element of $\mathbb{K}$, then $f\left(
a\right)  $ is an invertible element of $\mathbb{L}$ (since we can pick a
multiplicative inverse $b$ of $a$ in $\mathbb{K}$, and then $f\left(
b\right)  $ will be a multiplicative inverse of $f\left(  a\right)  $ in
$\mathbb{L}$). Hence, the map%
\begin{align*}
\left\{  \text{invertible elements of }\mathbb{K}\right\}   &  \rightarrow
\left\{  \text{invertible elements of }\mathbb{L}\right\}  ,\\
a  &  \mapsto f\left(  a\right)
\end{align*}
is well-defined. Similarly, the map%
\begin{align*}
\left\{  \text{invertible elements of }\mathbb{L}\right\}   &  \rightarrow
\left\{  \text{invertible elements of }\mathbb{K}\right\}  ,\\
a  &  \mapsto f^{-1}\left(  a\right)
\end{align*}
is also well-defined (since Proposition \ref{prop.riiso.inverse} shows that
the map $f^{-1}:\mathbb{L}\rightarrow\mathbb{K}$ is also a ring isomorphism).
These two maps are clearly mutually inverse, and therefore are bijections.
Hence, we have found a bijection from $\left\{  \text{invertible elements of
}\mathbb{K}\right\}  $ to $\left\{  \text{invertible elements of }%
\mathbb{L}\right\}  $. Thus,%
\[
\left\vert \left\{  \text{invertible elements of }\mathbb{K}\right\}
\right\vert =\left\vert \left\{  \text{invertible elements of }\mathbb{L}%
\right\}  \right\vert .
\]
This proves Proposition \ref{prop.riiso.equal-invertibles} \textbf{(a)}.

\textbf{(b)} If $a$ is an idempotent element of $\mathbb{K}$, then $f\left(
a\right)  $ is an idempotent element of $\mathbb{L}$ (since $f$ is a ring
homomorphism and thus $\left(  f\left(  a\right)  \right)  ^{2}=f\left(
\underbrace{a^{2}}_{=a}\right)  =f\left(  a\right)  $). Hence, the map%
\begin{align*}
\left\{  \text{idempotent elements of }\mathbb{K}\right\}   &  \rightarrow
\left\{  \text{idempotent elements of }\mathbb{L}\right\}  ,\\
a  &  \mapsto f\left(  a\right)
\end{align*}
is well-defined. Similarly, the map%
\begin{align*}
\left\{  \text{idempotent elements of }\mathbb{L}\right\}   &  \rightarrow
\left\{  \text{idempotent elements of }\mathbb{K}\right\}  ,\\
a  &  \mapsto f^{-1}\left(  a\right)
\end{align*}
is also well-defined (since Proposition \ref{prop.riiso.inverse} shows that
the map $f^{-1}:\mathbb{L}\rightarrow\mathbb{K}$ is also a ring isomorphism).
These two maps are clearly mutually inverse, and therefore are bijections.
Hence, we have found a bijection from $\left\{  \text{idempotent elements of
}\mathbb{K}\right\}  $ to $\left\{  \text{idempotent elements of }%
\mathbb{L}\right\}  $. Thus,%
\[
\left\vert \left\{  \text{idempotent elements of }\mathbb{K}\right\}
\right\vert =\left\vert \left\{  \text{idempotent elements of }\mathbb{L}%
\right\}  \right\vert .
\]
This proves Proposition \ref{prop.riiso.equal-invertibles} \textbf{(b)}.
\end{proof}

Now let us see some applications of ring isomorphisms.

Recall that we proved Theorem \ref{thm.ent.phi.mult} using the Chinese
Remainder Theorem in Section \ref{sect.equiv.CRT-bij}. Let us redo this proof
in a shorter way:

\begin{proof}
[New version of our Second proof of Theorem \ref{thm.ent.phi.mult}.]Example
\ref{exa.riiso.CRT} says that the map%
\begin{align*}
S_{m,n}:\mathbb{Z}/\left(  mn\right)   &  \rightarrow\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  ,\\
\alpha &  \mapsto\left(  \pi_{mn,m}\left(  \alpha\right)  ,\pi_{mn,n}\left(
\alpha\right)  \right)
\end{align*}
is a ring isomorphism. Thus,%
\begin{align}
&  \left\vert \left\{  \text{invertible elements of }\mathbb{Z}/\left(
mn\right)  \right\}  \right\vert \nonumber\\
&  =\left\vert \left\{  \text{invertible elements of }\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  \right\}  \right\vert
\label{pf.thm.ent.phi.mult.3rd.1}%
\end{align}
(by Proposition \ref{prop.riiso.equal-invertibles} \textbf{(a)}).

But if $\mathbb{K}$ and $\mathbb{L}$ are any two rings, then%
\begin{align*}
&  \left\{  \text{invertible elements of }\mathbb{K}\times\mathbb{L}\right\}
\\
&  =\left\{  \text{invertible elements of }\mathbb{K}\right\}  \times\left\{
\text{invertible elements of }\mathbb{L}\right\}
\end{align*}
(since multiplication on $\mathbb{K}\times\mathbb{L}$ is defined entrywise, so
an element $\left(  a,b\right)  \in\mathbb{K}\times\mathbb{L}$ is invertible
if and only if both $a\in\mathbb{K}$ and $b\in\mathbb{L}$ are invertible).
Hence,%
\begin{align*}
&  \left\{  \text{invertible elements of }\left(  \mathbb{Z}/m\right)
\times\left(  \mathbb{Z}/n\right)  \right\} \\
&  =\left\{  \text{invertible elements of }\mathbb{Z}/m\right\}
\times\left\{  \text{invertible elements of }\mathbb{Z}/n\right\}  ,
\end{align*}
so that%
\begin{align*}
&  \left\vert \left\{  \text{invertible elements of }\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  \right\}  \right\vert \\
&  =\left\vert \left\{  \text{invertible elements of }\mathbb{Z}/m\right\}
\times\left\{  \text{invertible elements of }\mathbb{Z}/n\right\}  \right\vert
\\
&  =\left\vert \left\{  \text{invertible elements of }\mathbb{Z}/m\right\}
\right\vert \cdot\left\vert \left\{  \text{invertible elements of }%
\mathbb{Z}/n\right\}  \right\vert .
\end{align*}
Hence, (\ref{pf.thm.ent.phi.mult.3rd.1}) becomes%
\begin{align}
&  \left\vert \left\{  \text{invertible elements of }\mathbb{Z}/\left(
mn\right)  \right\}  \right\vert \nonumber\\
&  =\left\vert \left\{  \text{invertible elements of }\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  \right\}  \right\vert
\nonumber\\
&  =\left\vert \left\{  \text{invertible elements of }\mathbb{Z}/m\right\}
\right\vert \cdot\left\vert \left\{  \text{invertible elements of }%
\mathbb{Z}/n\right\}  \right\vert . \label{pf.thm.ent.phi.mult.3rd.5}%
\end{align}


On the other hand, we know that%
\[
\phi\left(  n\right)  =\left\vert \left\{  \text{invertible elements of
}\mathbb{Z}/n\right\}  \right\vert
\]
(in fact, this is Corollary \ref{cor.equiv.modinv.Unphi} \textbf{(b)}, since
what we called $U_{n}$ in this corollary is exactly $\left\{  \text{invertible
elements of }\mathbb{Z}/n\right\}  $). Similarly,%
\begin{align*}
\phi\left(  m\right)   &  =\left\vert \left\{  \text{invertible elements of
}\mathbb{Z}/m\right\}  \right\vert \ \ \ \ \ \ \ \ \ \ \text{and}\\
\phi\left(  mn\right)   &  =\left\vert \left\{  \text{invertible elements of
}\mathbb{Z}/\left(  mn\right)  \right\}  \right\vert .
\end{align*}
So the equality (\ref{pf.thm.ent.phi.mult.3rd.5}) rewrites as $\phi\left(
mn\right)  =\phi\left(  m\right)  \cdot\phi\left(  n\right)  $. So Theorem
\ref{thm.ent.phi.mult} is proven again.
\end{proof}

The next exercise offers another example of the same strategy:

\begin{exercise}
Let $p$ and $q$ be two distinct primes. How many idempotent elements does the
ring $\mathbb{Z}/\left(  pq\right)  $ have?
\end{exercise}

\begin{proof}
[Solution.]The primes $p$ and $q$ are distinct, so they are coprime. Hence,
Example \ref{exa.riiso.CRT} (applied to $m=p$ and $n=q$) says that the map%
\begin{align*}
S_{p,q}:\mathbb{Z}/\left(  pq\right)   &  \rightarrow\left(  \mathbb{Z}%
/p\right)  \times\left(  \mathbb{Z}/q\right)  ,\\
\alpha &  \mapsto\left(  \pi_{pq,p}\left(  \alpha\right)  ,\pi_{pq,q}\left(
\alpha\right)  \right)
\end{align*}
is a ring isomorphism. Hence, Proposition \ref{prop.riiso.equal-invertibles}
\textbf{(b)} yields%
\begin{align*}
&  \left\vert \left\{  \text{idempotent elements of }\mathbb{Z}/\left(
pq\right)  \right\}  \right\vert \\
&  =\left\vert \left\{  \text{idempotent elements of }\left(  \mathbb{Z}%
/p\right)  \times\left(  \mathbb{Z}/q\right)  \right\}  \right\vert \\
&  =\left\vert \left\{  \text{idempotent elements of }\mathbb{Z}/p\right\}
\times\left\{  \text{idempotent elements of }\mathbb{Z}/q\right\}
\right\vert
\end{align*}
(since for any two rings $\mathbb{K}$ and $\mathbb{L}$, we have%
\begin{align*}
&  \left\{  \text{idempotent elements of }\mathbb{K}\times\mathbb{L}\right\}
\\
&  =\left\{  \text{idempotent elements of }\mathbb{K}\right\}  \times\left\{
\text{idempotent elements of }\mathbb{L}\right\}  ,
\end{align*}
because of the entrywise multiplication on $\mathbb{K}\times\mathbb{L}$).
Thus, it remains to find the number of idempotent elements of $\mathbb{Z}/p$
and the number of idempotent elements of $\mathbb{Z}/q$.

How many idempotent elements does $\mathbb{Z}/p$ have? For any $a\in
\mathbb{Z}$, we have the following chain of equivalences:%
\begin{align*}
&  \ \left(  \left[  a\right]  _{p}\text{ is idempotent}\right) \\
&  \Longleftrightarrow\ \left(  \left(  \left[  a\right]  _{p}\right)
^{2}=\left[  a\right]  _{p}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the
definition of \textquotedblleft idempotent\textquotedblright}\right) \\
&  \Longleftrightarrow\ \left(  \left[  a^{2}\right]  _{p}=\left[  a\right]
_{p}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left(  \left[
a\right]  _{p}\right)  ^{2}=\left[  a^{2}\right]  _{p}\right) \\
&  \Longleftrightarrow\ \left(  a^{2}\equiv a\operatorname{mod}p\right) \\
&  \Longleftrightarrow\ \left(  p\mid\underbrace{a^{2}-a}_{=a\left(
a-1\right)  }\right)  \ \Longleftrightarrow\ \left(  p\mid a\left(
a-1\right)  \right) \\
&  \Longleftrightarrow\ \left(  p\mid a\text{ or }p\mid a-1\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }p\text{ is prime}\right) \\
&  \Longleftrightarrow\ \left(  a\equiv0\operatorname{mod}p\text{ or }%
a\equiv1\operatorname{mod}p\right) \\
&  \Longleftrightarrow\ \left(  \left[  a\right]  _{p}=\left[  0\right]
_{p}\text{ or }\left[  a\right]  _{p}=\left[  1\right]  _{p}\right)  .
\end{align*}
In other words, for a given $a\in\mathbb{Z}$, the residue class $\left[
a\right]  _{p}$ is idempotent if and only if $\left[  a\right]  _{p}$ equals
$\left[  0\right]  _{p}$ or $\left[  1\right]  _{p}$. Since every residue
class $\alpha\in\mathbb{Z}/p$ has the form $\left[  a\right]  _{p}$ for some
$a\in\mathbb{Z}$, we can restate this as follows: A residue class $\alpha
\in\mathbb{Z}/p$ is idempotent if and only if it equals $\left[  0\right]
_{p}$ or $\left[  1\right]  _{p}$. Thus, the ring $\mathbb{Z}/p$ has exactly
two idempotent elements (namely, $\left[  0\right]  _{p}$ and $\left[
1\right]  _{p}$). In other words,%
\[
\left\vert \left\{  \text{idempotent elements of }\mathbb{Z}/p\right\}
\right\vert =2.
\]
Similarly,%
\[
\left\vert \left\{  \text{idempotent elements of }\mathbb{Z}/q\right\}
\right\vert =2.
\]
Now, the above computation becomes%
\begin{align*}
&  \left\vert \left\{  \text{idempotent elements of }\mathbb{Z}/\left(
pq\right)  \right\}  \right\vert \\
&  =\left\vert \left\{  \text{idempotent elements of }\mathbb{Z}/p\right\}
\times\left\{  \text{idempotent elements of }\mathbb{Z}/q\right\}  \right\vert
\\
&  =\underbrace{\left\vert \left\{  \text{idempotent elements of }%
\mathbb{Z}/p\right\}  \right\vert }_{=2}\cdot\underbrace{\left\vert \left\{
\text{idempotent elements of }\mathbb{Z}/q\right\}  \right\vert }_{=2}\\
&  =2\cdot2=4.
\end{align*}
In other words, the ring $\mathbb{Z}/\left(  pq\right)  $ has $4$ idempotent elements.

Side-note: What are these $4$ idempotent elements?

Two of them are easy to find: $\left[  0\right]  _{pq}$ and $\left[  1\right]
_{pq}$ (in fact, $0$ and $1$ are idempotent elements in any ring). But how to
get the other two?

Here is a systematic approach: Recall that $S_{p,q}:\mathbb{Z}/\left(
pq\right)  \rightarrow\left(  \mathbb{Z}/p\right)  \times\left(
\mathbb{Z}/q\right)  $ is a ring isomorphism. Thus, looking back at the proof
of Proposition \ref{prop.riiso.equal-invertibles} \textbf{(b)}, we see that
the idempotent elements of $\mathbb{Z}/\left(  pq\right)  $ are the preimages
of the idempotent elements of $\left(  \mathbb{Z}/p\right)  \times\left(
\mathbb{Z}/q\right)  $ under this isomorphism $S_{p,q}$.

The $4$ idempotent elements of $\left(  \mathbb{Z}/p\right)  \times\left(
\mathbb{Z}/q\right)  $ are%
\[
\left(  \left[  0\right]  _{p},\left[  0\right]  _{q}\right)
,\ \ \ \ \ \ \ \ \ \ \left(  \left[  1\right]  _{p},\left[  1\right]
_{q}\right)  ,\ \ \ \ \ \ \ \ \ \ \left(  \left[  0\right]  _{p},\left[
1\right]  _{q}\right)  ,\ \ \ \ \ \ \ \ \ \ \left(  \left[  1\right]
_{p},\left[  0\right]  _{q}\right)  .
\]
To find the $4$ idempotent elements in $\mathbb{Z}/\left(  pq\right)  $, we
thus have to apply the inverse $\left(  S_{p,q}\right)  ^{-1}$ of the
isomorphism $S_{p,q}$ to them.

\begin{itemize}
\item The first gets sent to $\left[  0\right]  _{pq}$.

\item The second gets sent to $\left[  1\right]  _{pq}$.

\item The last two get sent to $\left[  px\right]  _{pq}$ and $\left[
qy\right]  _{pq}$, where $x$ is a modular inverse of $p$ modulo $q$, and where
$y$ is a modular inverse of $q$ modulo $p$. (It does not matter which inverses
we choose; we get the same elements.)

Here is a slightly different way to get the last two idempotent elements:
Bezout's theorem yields that there exist integers $x$ and $y$ such that
$xp+yq=1$. Then, $\left[  xp\right]  _{pq}$ and $\left[  yq\right]  _{pq}$ are
the two missing idempotents.
\end{itemize}
\end{proof}

\begin{center}
\textbf{2019-04-10 lecture}
\end{center}

\begin{example}
Let $A$ be the $2\times2$-matrix $\left(
\begin{array}
[c]{cc}%
0 & 1\\
1 & 1
\end{array}
\right)  \in\mathbb{Z}^{2\times2}$.

On \href{http://www-users.math.umn.edu/~dgrinber/19s/mt2s.pdf}{midterm \#2}
exercise 5, you have encountered the ring%
\[
\mathcal{F}=\left\{  aA+bI_{2}\ \mid\ a,b\in\mathbb{Z}\right\}  =\left\{
\left(
\begin{array}
[c]{cc}%
b & a\\
a & a+b
\end{array}
\right)  \ \mid\ a,b\in\mathbb{Z}\right\}  .
\]
This is a subring of the matrix ring $\mathbb{Z}^{2\times2}$.

On \href{http://www-users.math.umn.edu/~dgrinber/19s/hw5s.pdf}{homework set
\#5} exercise 5, you have encountered the ring%
\[
\mathbb{Z}\left[  \phi\right]  =\left\{  a+b\phi\ \mid\ a,b\in\mathbb{Z}%
\right\}  ,
\]
where $\phi=\dfrac{1+\sqrt{5}}{2}=\allowbreak1.\,\allowbreak618\ldots$ is the
golden ratio. This is a subring of $\mathbb{R}$.

I claim that there is an isomorphism from $\mathbb{Z}\left[  \phi\right]  $ to
$\mathcal{F}$. Namely, the map%
\begin{align*}
f:\mathbb{Z}\left[  \phi\right]   &  \rightarrow\mathcal{F},\\
a+b\phi &  \mapsto bA+aI_{2}=\left(
\begin{array}
[c]{cc}%
a & b\\
b & a+b
\end{array}
\right)
\end{align*}
is a ring isomorphism (but not the only one!).
\end{example}

(Check this by hand.)

\begin{definition}
\label{def.riiso.isomorphic}Let $\mathbb{K}$ and $\mathbb{L}$ be two rings. We
say that the rings $\mathbb{K}$ and $\mathbb{L}$ are \textit{isomorphic} if
there exists a ring isomorphism $f:\mathbb{K}\rightarrow\mathbb{L}$.

We write \textquotedblleft$\mathbb{K}\cong\mathbb{L}$ (as
rings)\textquotedblright\ to say that the rings $\mathbb{K}$ and $\mathbb{L}$
are isomorphic.
\end{definition}

\section{\label{chp.la}Linear algebra over commutative rings}

We shall now continue studying rings, but slowly shift our focus. Namely,
while we so far have been studying rings themselves, we are now going to move
towards structures \textquotedblleft over\textquotedblright\ rings -- such as
matrices and $\mathbb{K}$-modules (a generalization of vector spaces). The
rings will no longer be the place where everything happens, but rather they
will \textquotedblleft act\textquotedblright\ on our structures in the way
scalars act on vectors in linear algebra.

\subsection{\label{sect.la.matrix-review}An overview of matrix algebra over
fields}

I assume you have all seen some basic matrix algebra: Gaussian elimination,
ranks of matrices, inverses of matrices, determinants, etc. (If not, see
\cite{Hefferon}.)

Usually, these things are done for matrices over $\mathbb{R}$ or $\mathbb{C}$.
But we can try doing the same with matrices over an arbitrary commutative ring
$\mathbb{K}$.

\subsubsection{Matrices over fields}

Let us first study the situation when $\mathbb{K}$ is a field.

\textbf{Example:} Let $\mathbb{K}=\mathbb{Z}/3$, and let $A=\left(
\begin{array}
[c]{ccc}%
0 & 1 & 1\\
1 & 0 & 1\\
1 & 1 & 0
\end{array}
\right)  \in\mathbb{K}^{3\times3}$. (Here, of course, $0$ and $1$ mean
$\left[  0\right]  _{3}$ and $\left[  1\right]  _{3}$.) Let $b=\left(
\begin{array}
[c]{c}%
1\\
1\\
1
\end{array}
\right)  \in\mathbb{K}^{3\times1}$. We want to find a column vector
$x\in\mathbb{K}^{3\times1}$ such that $Ax=b$. This means, explicitly, to find
$x_{1},x_{2},x_{3}\in\mathbb{K}$ such that%
\[
\left\{
\begin{array}
[c]{c}%
0x_{1}+1x_{2}+1x_{3}=1;\\
1x_{1}+0x_{2}+1x_{3}=1;\\
1x_{1}+1x_{2}+0x_{3}=1.
\end{array}
\right.
\]


Can we do this? Well, we can try: Augment the matrix $A$ with the column $b$,
obtaining the augmented matrix%
\[
\left(  A\mid b\right)  =\left(
\begin{array}
[c]{cccc}%
0 & 1 & 1 & 1\\
1 & 0 & 1 & 1\\
1 & 1 & 0 & 1
\end{array}
\right)  .
\]
Now, we shall transform this matrix into reduced row echelon form (see
\cite[\S 5]{Strickland} or \cite[Chapter One, \S III]{Hefferon}\footnote{The
reduced row echelon form is called \textquotedblleft reduced echelon
form\textquotedblright\ in \cite{Hefferon}.}) by a series of row operations
(this is called \textit{Gauss-Jordan reduction} in \cite[Chapter One,
\S III]{Hefferon}, and also appears as Method 6.3 in \cite{Strickland}):%
\begin{align*}
\left(  A\mid b\right)   &  =\left(
\begin{array}
[c]{cccc}%
0 & 1 & 1 & 1\\
1 & 0 & 1 & 1\\
1 & 1 & 0 & 1
\end{array}
\right)  \overset{\text{swap row }2\text{ with row }1}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 1\\
0 & 1 & 1 & 1\\
1 & 1 & 0 & 1
\end{array}
\right) \\
&  \overset{\text{subtract row }1\text{ from row }3}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 1\\
0 & 1 & 1 & 1\\
0 & 1 & 2 & 0
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }-1=2\text{ in }%
\mathbb{Z}/3\right) \\
&  \overset{\text{subtract row }2\text{ from row }3}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 1\\
0 & 1 & 1 & 1\\
0 & 0 & 1 & 2
\end{array}
\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{this is a row echelon form, but not a
reduced one}\right) \\
&  \overset{\text{subtract row }3\text{ from row }1}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 0 & 2\\
0 & 1 & 1 & 1\\
0 & 0 & 1 & 2
\end{array}
\right) \\
&  \overset{\text{subtract row }3\text{ from row }2}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 0 & 2\\
0 & 1 & 0 & 2\\
0 & 0 & 1 & 2
\end{array}
\right)  .
\end{align*}
So for any vector $x=\left(
\begin{array}
[c]{c}%
x_{1}\\
x_{2}\\
x_{3}%
\end{array}
\right)  \in\mathbb{K}^{3\times1}$, we have the following chain of
equivalences:%
\begin{align*}
&  \ \left(  Ax=b\right) \\
&  \Longleftrightarrow\ \left(  Ax-b=0_{3\times1}\right) \\
&  \Longleftrightarrow\ \left(  \left(  A\mid b\right)  \left(
\begin{array}
[c]{c}%
x_{1}\\
x_{2}\\
x_{3}\\
-1
\end{array}
\right)  =0_{3\times1}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}Ax-b=\left(  A\mid b\right)  \left(
\begin{array}
[c]{c}%
x_{1}\\
x_{2}\\
x_{3}\\
-1
\end{array}
\right)  \right) \\
&  \Longleftrightarrow\ \left(  \left(
\begin{array}
[c]{cccc}%
1 & 0 & 0 & 2\\
0 & 1 & 0 & 2\\
0 & 0 & 1 & 2
\end{array}
\right)  \left(
\begin{array}
[c]{c}%
x_{1}\\
x_{2}\\
x_{3}\\
-1
\end{array}
\right)  =0\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\left(  A\mid b\right)  \mapsto\left(
\begin{array}
[c]{cccc}%
1 & 0 & 0 & 2\\
0 & 1 & 0 & 2\\
0 & 0 & 1 & 2
\end{array}
\right)  \text{ by a series}\\
\text{of row operations}%
\end{array}
\right) \\
&  \Longleftrightarrow\ \left(  \left(
\begin{array}
[c]{c}%
x_{1}-2\\
x_{2}-2\\
x_{3}-2
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
0\\
0\\
0
\end{array}
\right)  \right)  \ \Longleftrightarrow\ \left(  \left(
\begin{array}
[c]{c}%
x_{1}\\
x_{2}\\
x_{3}%
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
2\\
2\\
2
\end{array}
\right)  \right)  .
\end{align*}
So our linear system has the unique solution%
\[
x=\left(
\begin{array}
[c]{c}%
2\\
2\\
2
\end{array}
\right)  .
\]


Next, try doing the same for $\mathbb{K}=\mathbb{Z}/2$, with the
\textquotedblleft same\textquotedblright\ matrix. (It will not be literally
the same matrix, of course, since $0$ and $1$ will now mean $\left[  0\right]
_{2}$ and $\left[  1\right]  _{2}$.)

Thus, let $\mathbb{K}=\mathbb{Z}/2$, and let $A=\left(
\begin{array}
[c]{ccc}%
0 & 1 & 1\\
1 & 0 & 1\\
1 & 1 & 0
\end{array}
\right)  \in\mathbb{K}^{3\times3}$. (Here, of course, $0$ and $1$ mean
$\left[  0\right]  _{2}$ and $\left[  1\right]  _{2}$.) Let $b=\left(
\begin{array}
[c]{c}%
1\\
1\\
1
\end{array}
\right)  \in\mathbb{K}^{3\times1}$. We want to find a column vector
$x\in\mathbb{K}^{3\times1}$ such that $Ax=b$. This means, explicitly, to find
$x_{1},x_{2},x_{3}\in\mathbb{K}$ such that%
\[
\left\{
\begin{array}
[c]{c}%
0x_{1}+1x_{2}+1x_{3}=1;\\
1x_{1}+0x_{2}+1x_{3}=1;\\
1x_{1}+1x_{2}+0x_{3}=1.
\end{array}
\right.
\]


Can we do this? Again, we can try: Augment the matrix $A$ with the column $b$,
obtaining%
\[
\left(  A\mid b\right)  =\left(
\begin{array}
[c]{cccc}%
0 & 1 & 1 & 1\\
1 & 0 & 1 & 1\\
1 & 1 & 0 & 1
\end{array}
\right)  .
\]
Now, we shall transform this matrix into reduced row echelon form by a series
of row operations:%
\begin{align*}
\left(  A\mid b\right)   &  =\left(
\begin{array}
[c]{cccc}%
0 & 1 & 1 & 1\\
1 & 0 & 1 & 1\\
1 & 1 & 0 & 1
\end{array}
\right)  \overset{\text{swap row }2\text{ with row }1}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 1\\
0 & 1 & 1 & 1\\
1 & 1 & 0 & 1
\end{array}
\right) \\
&  \overset{\text{subtract row }1\text{ from row }3}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 1\\
0 & 1 & 1 & 1\\
0 & 1 & 1 & 0
\end{array}
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }-1=1\text{ in }%
\mathbb{Z}/2\right) \\
&  \overset{\text{subtract row }2\text{ from row }3}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 1\\
0 & 1 & 1 & 1\\
0 & 0 & 0 & 1
\end{array}
\right) \\
&  \overset{\text{subtract row }3\text{ from row }1}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 0\\
0 & 1 & 1 & 1\\
0 & 0 & 0 & 1
\end{array}
\right) \\
&  \overset{\text{subtract row }3\text{ from row }2}{\mapsto}\left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 0\\
0 & 1 & 1 & 0\\
0 & 0 & 0 & 1
\end{array}
\right)  .
\end{align*}
So for any vector $x=\left(
\begin{array}
[c]{c}%
x_{1}\\
x_{2}\\
x_{3}%
\end{array}
\right)  \in\mathbb{K}^{3\times1}$, we have the following chain of
equivalences:
\begin{align*}
&  \ \left(  Ax=b\right) \\
&  \Longleftrightarrow\ \left(  Ax-b=0_{3\times1}\right) \\
&  \Longleftrightarrow\ \left(  \left(  A\mid b\right)  \left(
\begin{array}
[c]{c}%
x_{1}\\
x_{2}\\
x_{3}\\
-1
\end{array}
\right)  =0_{3\times1}\right) \\
&  \Longleftrightarrow\ \left(  \left(
\begin{array}
[c]{cccc}%
1 & 0 & 1 & 0\\
0 & 1 & 1 & 0\\
0 & 0 & 0 & 1
\end{array}
\right)  \left(
\begin{array}
[c]{c}%
x_{1}\\
x_{2}\\
x_{3}\\
-1
\end{array}
\right)  =0\right) \\
&  \Longleftrightarrow\ \left(  \left(
\begin{array}
[c]{c}%
x_{1}+x_{3}=0\\
x_{2}+x_{3}=0\\
-1=0
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
0\\
0\\
0
\end{array}
\right)  \right)  \ \Longleftrightarrow\ \left(  \text{false}\right)  .
\end{align*}
So our linear system has no solution.

By the way, you could have easily seen this from the system itself:%
\[
\left\{
\begin{array}
[c]{c}%
0x_{1}+1x_{2}+1x_{3}=1;\\
1x_{1}+0x_{2}+1x_{3}=1;\\
1x_{1}+1x_{2}+0x_{3}=1.
\end{array}
\right.
\]
Adding together the three equations, we get $0=1$ (since $1+1=0$ and $1+1+1=1$
in $\mathbb{Z}/2$), which is absurd. So the system has no solution.

\textbf{Upshot:} We can do linear algebra over any field more or less in the
same as we did over real/complex numbers. But the result may depend on the field.

Let me recall a couple theorems from linear algebra that hold (with the same
proofs) over any field:

\begin{theorem}
\label{thm.field.LA-main}Let $\mathbb{K}$ be a field.

\textbf{(a)} Any matrix over $\mathbb{K}$ has a reduced row echelon form (RREF).

\textbf{(b)} If $A\in\mathbb{K}^{n\times m}$ is any matrix and $R$ is its
RREF, then the row space, kernel (= nullspace) and rank of $A$ are equal to
those of $R$. (Here, the \textit{row space}, \textit{kernel} and \textit{rank}
of a matrix is defined as for real/complex matrices.)

\textbf{(c)} If $A\in\mathbb{K}^{n\times m}$ is any matrix, and if
$b\in\mathbb{K}^{n\times1}$ is any column vector, then the equation $Ax=b$
(for an unknown column vector $x\in\mathbb{K}^{m\times1}$) can be solved using
the Gaussian elimination algorithm (e.g., by forming the augmented matrix
$\left(  A\mid b\right)  $, then transforming it into RREF, and reading off
the solutions from this RREF by the same method as you learned in Linear Algebra).

\textbf{(d)} If $A\in\mathbb{K}^{n\times m}$ is a matrix with $n<m$, then
there exists a nonzero $x\in\mathbb{K}^{m\times1}$ such that $Ax=0_{n\times1}%
$. (\textquotedblleft Nonzero\textquotedblright\ means \textquotedblleft
distinct from $0_{m\times1}$\textquotedblright\ here.)

\textbf{(e)} Let $A\in\mathbb{K}^{n\times n}$. Then, the following are equivalent:

\begin{itemize}
\item The matrix $A$ is invertible.

\item The matrix $A$ is row-equivalent to $I_{n}$. (Two matrices are said to
be \textit{row-equivalent} if one can be transformed into the other via row
operations: swapping rows, scaling rows and adding a multiple of one row to another.)

\item The matrix $A$ is column-equivalent to $I_{n}$. (The definition of
\textquotedblleft\textit{column-equivalent}\textquotedblright\ is the same as
of \textquotedblleft row-equivalent\textquotedblright, but with columns
instead of rows.)

\item The RREF of $A$ is $I_{n}$.

\item The RREF of $A$ has $n$ pivots.

\item The rank of $A$ is $n$.

\item The equation $Ax=0_{n\times1}$ (for an unknown $x\in\mathbb{K}%
^{n\times1}$) has only the trivial solution (that is, $x=0_{n\times1}$).

\item For each vector $b\in\mathbb{K}^{n\times1}$, the equation $Ax=b$ has a solution.

\item For each vector $b\in\mathbb{K}^{n\times1}$, the equation $Ax=b$ has a
unique solution.

\item The columns of $A$ are linearly independent.

\item The rows of $A$ are linearly independent.

\item There is a matrix $B\in\mathbb{K}^{n\times n}$ such that $AB=I_{n}$.

\item There is a matrix $B\in\mathbb{K}^{n\times n}$ such that $BA=I_{n}$.

\item We have $\det A\neq0$. (We will later define determinants.)
\end{itemize}

(Matrices satisfying these equivalent conditions are called
\textit{nonsingular}.)
\end{theorem}

\subsubsection{What if $\mathbb{K}$ is not a field?}

Things get weird when $\mathbb{K}$ is not a field. For an example, set
$\mathbb{K}=\mathbb{Z}/26$. This is not a field, since $26$ is not prime
(after all, $26=2\cdot13$). The ring $\mathbb{Z}/26$ has been used in
classical cryptography, since its elements are in bijection with the letters
of the (modern) Roman alphabet:%
\[
0\mapsto A,\ \ \ \ \ \ \ \ \ \ 1\mapsto B,\ \ \ \ \ \ \ \ \ \ 2\mapsto
C,\ \ \ \ \ \ \ \ \ \ \ldots.
\]
For example, \href{https://en.wikipedia.org/wiki/Hill_cipher}{the \textit{Hill
cipher}} lets you encrypt a word using a $3\times3$-matrix over $\mathbb{Z}%
/26$ as a key. The idea is simple: You split the word into $3$-letter chunks;
you turn each chunk into a column vector in $\left(  \mathbb{Z}/26\right)
^{3\times1}$; and you multiply each of these columns vectors by your key
matrix. To decrypt, you would have to invert the key matrix.

So we want to know how to invert a matrix over $\mathbb{Z}/26$.

If $\mathbb{Z}/26$ was a field, you would know how to do this via Gaussian elimination.

Most of Theorem \ref{thm.field.LA-main} collapses when $\mathbb{K}$ is not a
field. For example, let $\mathbb{K}=\mathbb{Z}/26$ and%
\[
A=\left(
\begin{array}
[c]{cc}%
2 & 13\\
13 & 20
\end{array}
\right)  \in\mathbb{K}^{2\times2}.
\]
(We are abusing notation here: In truth, the entries of $A$ are not the
integers $2,13,13,20$ but rather their residue classes $\left[  2\right]
_{26},\left[  13\right]  _{26},\left[  13\right]  _{26},\left[  20\right]
_{26}$. But we shall simply write the integers instead and hope that the
reader knows what we mean.)

Is this matrix $A$ invertible?

Let us first try to find the RREF of $A$. If we would blindly follow the
Gaussian elimination algorithm, we would fail very quickly: None of the $4$
entries of $A$ has a multiplicative inverse; thus we could not transform any
entry of $A$ into $1$ by scaling a row of $A$. But we can try to loosen
Gaussian elimination by allowing more strategic row operations: Instead of
trying to get a $1$ in a pivot position immediately by scaling a row, we can
attempt to obtain a $1$ by row addition operations. For example, we can
transform our matrix $A$ above as follows:%
\begin{align*}
&  \left(
\begin{array}
[c]{cc}%
2 & 13\\
13 & 20
\end{array}
\right) \\
&  \overset{\text{subtract }6\text{ times row }1\text{ from row }2}{\mapsto
}\left(
\begin{array}
[c]{cc}%
2 & 13\\
1 & 20
\end{array}
\right) \\
&  \overset{\text{swap row }1\text{ with row }2}{\mapsto}\left(
\begin{array}
[c]{cc}%
1 & 20\\
2 & 13
\end{array}
\right) \\
&  \overset{\text{subtract }2\text{ times row }1\text{ from row }2}{\mapsto
}\left(
\begin{array}
[c]{cc}%
1 & 20\\
0 & 25
\end{array}
\right) \\
&  \overset{\text{scale row }2\text{ by }-1}{\mapsto}\left(
\begin{array}
[c]{cc}%
1 & 20\\
0 & 1
\end{array}
\right) \\
&  \overset{\text{subtract }20\text{ times row }2\text{ from row }1}{\mapsto
}\left(
\begin{array}
[c]{cc}%
1 & 0\\
0 & 1
\end{array}
\right)  =I_{2}.
\end{align*}
So our matrix $A$ does have a RREF (namely, $I_{2}$), and even is invertible!
(We can find an inverse of $A$ by computing an RREF of the block matrix
$\left(  A\mid I_{2}\right)  $; see, e.g., \cite[Method 11.11]{Strickland} for
this procedure.)

What exactly was the method behind our above row-reduction procedure? Let us
see how the first column has been transformed:%
\begin{align*}
&  \left(
\begin{array}
[c]{c}%
2\\
13
\end{array}
\right)  \overset{\text{subtract }6\text{ times row }1\text{ from row
}2}{\mapsto}\left(
\begin{array}
[c]{c}%
2\\
1
\end{array}
\right)  \overset{\text{swap row }1\text{ with row }2}{\mapsto}\left(
\begin{array}
[c]{c}%
1\\
2
\end{array}
\right) \\
&  \overset{\text{subtract }2\text{ times row }1\text{ from row }2}{\mapsto
}\left(
\begin{array}
[c]{c}%
1\\
0
\end{array}
\right)  .
\end{align*}
So what we did was progressively making the entries of the first column
smaller by subtracting a multiple of the first entry from the second entry
(and swapping the two entries, in order to move the smaller entry into the
first position). This is exactly the Euclidean algorithm! (Or, rather, it
would be the Euclidean algorithm if we had used honest integers instead of
residue classes in $\mathbb{Z}/26$.)

What happens in general? In general, when $\mathbb{K}=\mathbb{Z}/n$, the
Gaussian elimination algorithm as defined in linear algebra does not always
work. Nevertheless, a variant of it works, in which you do not directly scale
rows to turn entries into $1$, but instead \textquotedblleft
minimize\textquotedblright\ the whole column using the Euclidean algorithm as
we did with our matrix $A$ above. You will not always be able to get $1$'s in
pivot positions, because the gcd (which the Euclidean algorithm computes) may
not be $1$; thus, the result will not always be an RREF in the classical
sense, but rather something loosely resembling it.

For details, look up
\href{https://en.wikipedia.org/wiki/Smith_normal_form}{the \textit{Smith
normal form}} (e.g., in \cite[\S 113]{Elman18}). Note that for $n=0$, we have
$\mathbb{Z}/n\cong\mathbb{Z}$ (as rings), so this applies to matrices with
integer entries.

\begin{center}
\textbf{2019-04-12 lecture}
\end{center}

\subsubsection{Review of basic notions from linear algebra}

\begin{convention}
For the rest of this section, we fix a field $\mathbb{K}$. The elements of
$\mathbb{K}$ will be referred to as \textit{scalars}.
\end{convention}

In the linear algebra you have seen before, the scalars are usually real
numbers (i.e., we have $\mathbb{K}=\mathbb{R}$), but much of the theory works
in the same way for every field.

\begin{definition}
\label{def.laf.subspace-of-row}Let $n\in\mathbb{N}$. Recall that
$\mathbb{K}^{1\times n}$ is the set of all row vectors of size $n$.

A \textit{subspace} of $\mathbb{K}^{1\times n}$ means a subset $S\subseteq
\mathbb{K}^{1\times n}$ satisfying the following axioms:

\textbf{(a)} We have $0_{1\times n}\in S$.

\textbf{(b)} If $a,b\in S$, then $a+b\in S$.

\textbf{(c)} If $a\in S$ and $\lambda\in\mathbb{K}$, then $\lambda a\in S$.
\end{definition}

In other words, a subspace of $\mathbb{K}^{1\times n}$ is a subset of
$\mathbb{K}^{1\times n}$ that contains the zero vector and is closed under
addition and scaling.

Subspaces are often called \textit{vector subspaces}.

A similar definition defines subspaces of $\mathbb{K}^{n\times1}$ (column vectors).

There is a more general version of this definition, which extends it to
subspaces of arbitrary vector spaces (see below).

\begin{definition}
\label{def.laf.lincomb}Let $n\in\mathbb{N}$. Let $v_{1},v_{2},\ldots,v_{k}$ be
some row vectors in $\mathbb{K}^{1\times n}$.

\textbf{(a)} A \textit{linear combination} of $v_{1},v_{2},\ldots,v_{k}$ means
a row vector of the form%
\[
\lambda_{1}v_{1}+\lambda_{2}v_{2}+\cdots+\lambda_{k}v_{k}%
,\ \ \ \ \ \ \ \ \ \ \text{with }\lambda_{1},\lambda_{2},\ldots,\lambda_{k}%
\in\mathbb{K}.
\]


\textbf{(b)} The \textit{span} of $v_{1},v_{2},\ldots,v_{k}$ is defined to be
the subset%
\begin{align*}
&  \left\{  \lambda_{1}v_{1}+\lambda_{2}v_{2}+\cdots+\lambda_{k}v_{k}%
\ \mid\ \lambda_{1},\lambda_{2},\ldots,\lambda_{k}\in\mathbb{K}\right\} \\
&  =\left\{  \text{linear combinations of }v_{1},v_{2},\ldots,v_{k}\right\}
\end{align*}
of $\mathbb{K}^{1\times n}$. This span is a subspace of $\mathbb{K}^{1\times
n}$. (This is easy to check.)

\textbf{(c)} The vectors $v_{1},v_{2},\ldots,v_{k}$ are said to be
\textit{linearly independent} if the only $k$-tuple $\left(  \lambda
_{1},\lambda_{2},\ldots,\lambda_{k}\right)  \in\mathbb{K}^{k}$ satisfying
$\lambda_{1}v_{1}+\lambda_{2}v_{2}+\cdots+\lambda_{k}v_{k}=0_{1\times n}$ is
$\left(  \underbrace{0,0,\ldots,0}_{k\text{ times}}\right)  $.

\textbf{(d)} Let $U$ be a subspace of $\mathbb{K}^{1\times n}$. We say that
$v_{1},v_{2},\ldots,v_{k}$ form a \textit{basis} of $U$ (or, more formally,
$\left(  v_{1},v_{2},\ldots,v_{k}\right)  $ is a basis of $U$) if and only if
the vectors $v_{1},v_{2},\ldots,v_{k}$ are linearly independent and their span
is $U$.
\end{definition}

All the terminology we have just introduced depends on $\mathbb{K}$. Whenever
the field $\mathbb{K}$ is not clear from the context, you can insert it into
this terminology to make it unambiguous: e.g., say \textquotedblleft%
$\mathbb{K}$-linear combination\textquotedblright\ instead of
\textquotedblleft linear combination\textquotedblright, and \textquotedblleft%
$\mathbb{K}$-span\textquotedblright\ instead of \textquotedblleft
span\textquotedblright.

\begin{theorem}
\label{thm.laf.basis-of-subspace}Let $n\in\mathbb{N}$. Let $U$ be a subspace
of $\mathbb{K}^{1\times n}$.

\textbf{(a)} There exists at least one basis of $U$.

\textbf{(b)} Any two bases of $U$ have the same size (= number of vectors).

\textbf{(c)} Given $k$ linearly independent vectors in $U$, and given $\ell$
vectors that span $U$, we always have $k\leq\ell$.

\textbf{(d)} Any list of $k$ linearly independent vectors in $U$ can be
extended to a basis of $U$.

\textbf{(e)} Any list of $\ell$ vectors that span $U$ can be shrunk\ to a
basis of $U$ (i.e., we can remove some vectors from this list to get a basis
of $U$).
\end{theorem}

\begin{proof}
[Proof sketch.]This all is proven just as in standard linear algebra. (For a
specific reference: See \cite[Chapter Two, Theorem III.2.5]{Hefferon} for part
\textbf{(b)}; \cite[Chapter Two, Corollary III.2.13]{Hefferon} for part
\textbf{(d)}; \cite[Chapter Two, Corollary III.2.14]{Hefferon} for part
\textbf{(e)}. Part \textbf{(a)} follows by applying part \textbf{(d)} to the
empty list (with $k=0$). Part \textbf{(c)} follows from parts \textbf{(b)},
\textbf{(d)} and \textbf{(e)} once you extend your list of $k$ linearly
independent vectors in $U$ to a basis of $U$ and shrink your list of $\ell$
vectors spanning $U$ to a basis of $U$.)
\end{proof}

Again, the same holds for column vectors.

\begin{definition}
\label{def.laf.dim-of-subspace}Let $U$ be a subspace of $\mathbb{K}^{1\times
n}$.

The \textit{dimension} of $U$ is defined to be the size of a basis of $U$.
(Parts \textbf{(a)} and \textbf{(b)} of Theorem
\ref{thm.laf.basis-of-subspace} show that this is indeed well-defined.) The
dimension of $U$ is denoted by $\dim U$.
\end{definition}

\begin{proposition}
\label{prop.laf.dim-increases}Let $U$ and $V$ be two subspaces of
$\mathbb{K}^{1\times n}$ such that $U\subseteq V$.

\textbf{(a)} We have $\dim U\leq\dim V$.

\textbf{(b)} If $\dim U=\dim V$, then $U=V$.
\end{proposition}

\begin{proof}
[Proof sketch.]Pick a basis of $U$. This basis is a list of $\dim U$ many
linearly independent vectors in $V$ (since $U\subseteq V$). Thus, Theorem
\ref{thm.laf.basis-of-subspace} \textbf{(d)} (applied to $\dim U$ and $V$
instead of $k$ and $U$) shows that this list can be extended to a basis of
$V$. The latter basis, of course, has size $\dim V$. Thus, $\dim U\leq\dim V$
(since we have extended a list of size $\dim U$ and obtained a list of size
$\dim V$). This proves Proposition \ref{prop.laf.dim-increases} \textbf{(a)}.

\textbf{(b)} Assume that $\dim U=\dim V$. We have just found a basis of $V$ by
extending a basis of $U$. In light of $\dim U=\dim V$, this extension must
have been trivial -- i.e., we must have extended our basis of $U$ by no
further vectors. This means that our basis of $U$ was already a basis of $V$
to begin with. From this, it is easy to see that $U=V$ (because the span of a
basis of $U$ is always $U$, whereas the span of a basis of $V$ is always $V$).
This proves Proposition \ref{prop.laf.dim-increases} \textbf{(b)}.
\end{proof}

Now, let us connect this with matrices:

\begin{definition}
\label{def.laf.rowspace}Let $A\in\mathbb{K}^{n\times m}$ be a matrix.

\textbf{(a)} The \textit{row space} of $A$ is defined to be the span of the
rows of $A$. This is a subspace of $\mathbb{K}^{1\times m}$, and is called
$\operatorname*{Row}A$.

\textbf{(b)} The \textit{column space} of $A$ is defined to be the span of the
columns of $A$. This is a subspace of $\mathbb{K}^{n\times1}$, and is called
$\operatorname*{Col}A$.
\end{definition}

\begin{theorem}
\label{thm.laf.ranks-equal}Let $A\in\mathbb{K}^{n\times m}$ be a matrix. Then,
$\dim\operatorname*{Row}A=\dim\operatorname*{Col}A$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.laf.ranks-equal} (sketched).]One way to prove this
is to transform $A$ into RREF, and argue that both $\dim\operatorname*{Row}A$
and $\dim\operatorname*{Col}A$ equal the number of pivots in the RREF. There
are other, more abstract ways. See linear algebra textbooks for this proof:
for example, \cite[Chapter Two, Theorem III.3.11]{Hefferon} (where
$\dim\operatorname*{Row}A$ is called the \textquotedblleft row
rank\textquotedblright\ of $A$, and $\dim\operatorname*{Col}A$ is called the
\textquotedblleft column rank\textquotedblright\ of $A$).
\end{proof}

\begin{definition}
\label{def.laf.rank}Let $A\in\mathbb{K}^{n\times m}$ be a matrix. Theorem
\ref{thm.laf.ranks-equal} shows that $\dim\operatorname*{Row}A=\dim
\operatorname*{Col}A$. This number $\dim\operatorname*{Row}A=\dim
\operatorname*{Col}A$ is called the \textit{rank} of $A$ and is denoted by
$\operatorname*{rank}A$.
\end{definition}

The following is easy to see:

\begin{proposition}
Let $A\in\mathbb{K}^{n\times m}$ be a matrix. Then, $\operatorname*{rank}A$ is
an integer between $0$ and $\min\left\{  n,m\right\}  $.
\end{proposition}

So we have seen that a matrix gives rise to two subspaces: its row space and
its column space. But there is more:

\begin{definition}
\label{def.laf.ker}Let $A\in\mathbb{K}^{n\times m}$ be a matrix.

\textbf{(a)} The \textit{kernel} (or \textit{nullspace}) of $A$ is defined to
be the set of all column vectors $v\in\mathbb{K}^{m\times1}$ such that
$Av=0_{n\times1}$. This is a subspace of $\mathbb{K}^{m\times1}$, and is
called $\operatorname*{Ker}A$.

\textbf{(b)} The \textit{left kernel} (or \textit{left nullspace}) of $A$ is
defined to be the set of all row vectors $w\in\mathbb{K}^{1\times n}$ such
that $wA=0_{1\times m}$. This is a subspace of $\mathbb{K}^{1\times n}$.
\end{definition}

Altogether, we have thus found four subspaces coming out of a matrix $A$.
These are
\href{https://en.wikipedia.org/wiki/Fundamental_theorem_of_linear_algebra}{the
famous \textquotedblleft four fundamental subspaces\textquotedblright} (in
Gilbert Strang's terminology). One result that connects two of them is the
following fact, known as
\href{https://en.wikipedia.org/wiki/Rank-nullity_theorem#Matrices}{the
\textit{rank-nullity theorem}}:

\begin{theorem}
\label{thm.laf.rank-null}Let $A\in\mathbb{K}^{n\times m}$ be a matrix. Then,%
\[
\operatorname*{rank}A+\dim\operatorname*{Ker}A=m.
\]

\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.laf.rank-null} (sketched).]Most textbooks state
Theorem \ref{thm.laf.rank-null} not in terms of matrices, but rather in the
(equivalent) language of linear maps. For example, this is how it is stated in
\cite[Chapter Three, Theorem II.2.14]{Hefferon}.
\end{proof}

Note that the number $\dim\operatorname*{Ker}A$ is known as the
\textit{nullity} of a matrix $A$.

\subsubsection{Linear algebra over $\mathbb{Z}/2$: \textquotedblleft button
madness\textquotedblright\ / \textquotedblleft lights out\textquotedblright}

We now discuss an old puzzle, which is known as \textquotedblleft button
madness\textquotedblright\ or \textquotedblleft lights out\textquotedblright%
\ (more precisely, these are two slightly different variants of the same
puzzle). You can try it out on
\[
\text{\url{http://bz.var.ru/comp/web/js/floor.html}}%
\]
(see also \url{https://www.win.tue.nl/~aeb/ca/madness/madrect.html} for a list
of mathematical sources on this puzzle).

One version of this puzzle gives you $16$ lamps arranged into a $4\times
4$-grid. Each lamp comes with a lightswitch; but flipping this lightswitch
toggles not just this lamp, but also its four adjacent lamps (or three or two
adjacent lamps, if the switch you have flipped is at the border of the grid).
For example, if your grid looks like this:%
\[%
\begin{tabular}
[c]{|c|c|c|c|}\hline
$1$ & $0$ & $0$ & $1$\\\hline
$0$ & $1$ & $1$ & $0$\\\hline
$0$ & $0$ & $1$ & $0$\\\hline
$1$ & $1$ & $0$ & $1$\\\hline
\end{tabular}
\ \
\]
(where an entry $1$ means a lamp turned on, and an entry $0$ means a lamp
turned off), and you flip the lightswitch in cell $\left(  2,3\right)  $ (that
is, the third cell from the left in the second row from the top), then you
obtain the grid%
\[%
\begin{tabular}
[c]{|c|c|c|c|}\hline
$1$ & $0$ & $1$ & $1$\\\hline
$0$ & $0$ & $0$ & $1$\\\hline
$0$ & $0$ & $0$ & $0$\\\hline
$1$ & $1$ & $0$ & $1$\\\hline
\end{tabular}
\ \ .
\]
(A total of $5$ lamps have changed their state: three have been turned off,
and two have been turned on.) If you then flip the lightswitch in cell
$\left(  1,3\right)  $ of this new grid, then you obtain the grid
\[%
\begin{tabular}
[c]{|c|c|c|c|}\hline
$1$ & $1$ & $0$ & $0$\\\hline
$0$ & $0$ & $1$ & $1$\\\hline
$0$ & $0$ & $0$ & $0$\\\hline
$1$ & $1$ & $0$ & $1$\\\hline
\end{tabular}
\ \ .
\]


At the beginning, all lamps are turned off. Your goal is to achieve the
opposite state (i.e., all lamps being on at the same time) by flipping a
sequence of lightswitches. Is this possible, and how? (In some versions of
this puzzle -- such as
\href{https://en.wikipedia.org/wiki/Lights_Out_(game)}{the \textquotedblleft
lights out\textquotedblright\ version} -- it's exactly the other way round:
The lights are all on initially, and you must turn them all off. Of course,
this makes no difference to the solution.)

In some versions of this puzzle, the grid is \textquotedblleft
toroidal\textquotedblright, in the sense that it is understood to wrap around
-- for example, the cells $\left(  1,4\right)  $ and $\left(  1,1\right)  $
are considered to be adjacent, and so are the cells $\left(  4,1\right)  $ and
$\left(  1,1\right)  $. We shall not consider this case here, but it can be
solved by the same method.

Of course, you can play the same game on larger grids, triangular grids, etc..
But in order to get a grip on how to solve such a puzzle, we shall first
analyze a much simpler version: the \textquotedblleft1-dimensional
version\textquotedblright\ of the puzzle.

Here is this \textquotedblleft1-dimensional version\textquotedblright: We have
$4$ lamps in a row (numbered $1,2,3,4$), each equipped with a lightswitch. The
lightswitch at lamp $i$ toggles lamp $i$, lamp $i-1$ (if it exists) and lamp
$i+1$ (if it exists). Initially, all $4$ lamps are off. Can we turn them all
on by flipping a sequence of lightswitches?

Yes, of course: we just have to flip the lightswitches at lamps $1$ and $4$.
But let us pretend that we aren't that smart, and instead try to solve the
puzzle systematically.

We model the states of our lamps by a row vector in $\left(  \mathbb{Z}%
/2\right)  ^{1\times4}$. We write a row vector $\left(
\begin{array}
[c]{cccc}%
a_{1} & a_{2} & \cdots & a_{n}%
\end{array}
\right)  $ as $\left(  a_{1},a_{2},\ldots,a_{n}\right)  $.

More precisely, we model each state by the row vector $\left(  a_{1}%
,a_{2},a_{3},a_{4}\right)  \in\left(  \mathbb{Z}/2\right)  ^{1\times4}$, where%
\[
a_{i}=%
\begin{cases}
\left[  0\right]  _{2}, & \text{if lamp }i\text{ is off};\\
\left[  1\right]  _{2}, & \text{if lamp }i\text{ is on}%
\end{cases}
=\underbrace{\left[  \underbrace{\left[  \text{lamp }i\text{ is on}\right]
}_{\text{Iverson bracket}}\right]  _{2}}_{\text{residue class}}.
\]


We shall write $0$ and $1$ for $\left[  0\right]  _{2}$ and $\left[  1\right]
_{2}$ throughout this section (except in Proposition \ref{prop.laf.Ac0bc0}),
so we can rewrite this as%

\[
a_{i}=%
\begin{cases}
0, & \text{if lamp }i\text{ is off};\\
1, & \text{if lamp }i\text{ is on}%
\end{cases}
=\underbrace{\left[  \text{lamp }i\text{ is on}\right]  }_{\text{Iverson
bracket}},
\]
but keep in mind that these values are understood to be in $\mathbb{Z}/2$.

The initial state is $\left(  0,0,0,0\right)  $. The final state that we want
to achieve is $\left(  1,1,1,1\right)  $. Flipping a lightswitch corresponds
to adding a certain row vector to our state. Namely:

\begin{itemize}
\item Flipping lightswitch $1$ means adding $\left(  1,1,0,0\right)  $.

\item Flipping lightswitch $2$ means adding $\left(  1,1,1,0\right)  $.

\item Flipping lightswitch $3$ means adding $\left(  0,1,1,1\right)  $.

\item Flipping lightswitch $4$ means adding $\left(  0,0,1,1\right)  $.
\end{itemize}

\noindent Thus, flipping a lightswitch means adding the corresponding row of
the matrix%
\[
A:=\left(
\begin{array}
[c]{cccc}%
1 & 1 & 0 & 0\\
1 & 1 & 1 & 0\\
0 & 1 & 1 & 1\\
0 & 0 & 1 & 1
\end{array}
\right)  \in\left(  \mathbb{Z}/2\right)  ^{4\times4}%
\]
to our state. The reachable states are thus exactly the elements of
$\operatorname*{Row}A$, the row space of $A$.

Hence, our goal is to show that $\left(  1,1,1,1\right)  \in
\operatorname*{Row}A$.

This is quite easy for the concrete matrix $A$ above (just notice that
$\left(  1,1,1,1\right)  $ is the sum of the $1$-st and $4$-th rows of $A$);
but let us try a theoretical argument. It will rely on the following general fact:

\begin{proposition}
\label{prop.laf.Ac0bc0}Let $\mathbb{K}$ be a field. Let $A\in\mathbb{K}%
^{n\times m}$ and $b\in\mathbb{K}^{1\times m}$. Assume the following:

\begin{statement}
\textit{Assumption 1:} If $c\in\mathbb{K}^{m\times1}$ satisfies $Ac=0$, then
$bc=0$.
\end{statement}

\noindent Then, $b\in\operatorname*{Row}A$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.laf.Ac0bc0}.]Let $\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $ denote the $\left(  n+1\right)  \times m$-matrix formed from $A$ by
attaching the row vector $b$ to its bottom. For example, if $A=\left(
\begin{array}
[c]{cc}%
a_{1,1} & a_{1,2}\\
a_{2,1} & a_{2,2}%
\end{array}
\right)  $ and $b=\left(
\begin{array}
[c]{cc}%
b_{1} & b_{2}%
\end{array}
\right)  $, then $\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  =\left(
\begin{array}
[c]{cc}%
a_{1,1} & a_{1,2}\\
a_{2,1} & a_{2,2}\\
b_{1} & b_{2}%
\end{array}
\right)  $.

Theorem \ref{thm.laf.rank-null} yields $\operatorname*{rank}A+\dim
\operatorname*{Ker}A=m$. Thus,
\begin{equation}
\operatorname*{rank}A=m-\dim\operatorname*{Ker}A. \label{pf.prop.laf.Ac0bc0.1}%
\end{equation}


The same argument can be applied to the matrix $\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $ instead of $A$. We thus obtain%
\begin{equation}
\operatorname*{rank}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  =m-\dim\operatorname*{Ker}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  . \label{pf.prop.laf.Ac0bc0.2}%
\end{equation}


But each $c\in\operatorname*{Ker}A$ satisfies $Ac=0$ and thus $bc=0$ (by
Assumption 1), and therefore $c\in\operatorname*{Ker}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $ (because the \textquotedblleft row-by-column\textquotedblright%
\ nature of matrix multiplication shows that $\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  c=\left(
\begin{array}
[c]{c}%
Ac\\
bc
\end{array}
\right)  =\left(
\begin{array}
[c]{c}%
0\\
0
\end{array}
\right)  =0$). So we have $\operatorname*{Ker}A\subseteq\operatorname*{Ker}%
\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $. Also, clearly, $\operatorname*{Ker}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  \subseteq\operatorname*{Ker}A$ (because if $c\in\operatorname*{Ker}%
\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $, then $\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  c=0$, so that $0=\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  c=\left(
\begin{array}
[c]{c}%
Ac\\
bc
\end{array}
\right)  $ and thus $Ac=0$, so that $c\in\operatorname*{Ker}A$). Combining
these two relations, we obtain $\operatorname*{Ker}A=\operatorname*{Ker}%
\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $. Hence, the right hand sides of (\ref{pf.prop.laf.Ac0bc0.1}) and
(\ref{pf.prop.laf.Ac0bc0.2}) are equal. Thus, the left hand sides are equal as
well. In other words, $\operatorname*{rank}A=\operatorname*{rank}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $. In other words,%
\[
\dim\operatorname*{Row}A=\dim\operatorname*{Row}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)
\]
(since $\operatorname{rank}B=\dim\operatorname{Row}B$ for any matrix $B$). But
$\operatorname*{Row}A\subseteq\operatorname*{Row}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $ (by the definition of a row space). Combining these facts, we
obtain%
\[
\operatorname*{Row}A=\operatorname*{Row}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)
\]
(by Proposition \ref{prop.laf.dim-increases} \textbf{(b)}, applied to
$U=\operatorname*{Row}A$ and $V=\operatorname*{Row}\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  $). But the definition of a row space yields $b\in\operatorname*{Row}%
\left(
\begin{array}
[c]{c}%
A\\
b
\end{array}
\right)  =\operatorname*{Row}A$. This proves Proposition \ref{prop.laf.Ac0bc0}.
\end{proof}

Over the field $\mathbb{Z}/2$, this fact has the following consequence:

\begin{corollary}
\label{cor.laf.lights-out-diag}Let $A\in\left(  \mathbb{Z}/2\right)  ^{n\times
n}$ be a symmetric matrix. (\textquotedblleft\textit{Symmetric}%
\textquotedblright\ means that the $\left(  i,j\right)  $-th entry of $A$
equals the $\left(  j,i\right)  $-th entry of $A$ for all $i$ and $j$. In
other words, it means that $A^{T}=A$.)

Let $d$ be the diagonal of $A$, written as a row vector. (In other words, let
$D=\left(  a_{1,1},a_{2,2},\ldots,a_{n,n}\right)  $, where $a_{i,j}$ is the
$\left(  i,j\right)  $-th entry of $A$.)

Then, $d\in\operatorname*{Row}A$.
\end{corollary}

Note that Corollary \ref{cor.laf.lights-out-diag} brutally fails over fields
different from $\mathbb{Z}/2$. For example, if we allow $A$ to be a matrix in
$\mathbb{Z}^{n\times n}$ instead, then $A=\left(
\begin{array}
[c]{cc}%
1 & -1\\
-1 & 1
\end{array}
\right)  $ is symmetric but its diagonal $d=\left(  1,1\right)  $ does not
belong to $\operatorname*{Row}A$.

\begin{proof}
[Proof of Corollary \ref{cor.laf.lights-out-diag}.]Set $\mathbb{K}%
=\mathbb{Z}/2$. By Proposition \ref{prop.laf.Ac0bc0} (applied to $m=n$ and
$b=d$), it suffices to show the following:

\begin{statement}
\textit{Assumption 1:} If $c\in\mathbb{K}^{n\times1}$ satisfies $Ac=0$, then
$dc=0$.
\end{statement}

[\textit{Proof of Assumption 1:} Let $c\in\mathbb{K}^{n\times1}$ satisfy
$Ac=0$. We must prove that $dc=0$.

I claim that $dc=c^{T}Ac$.

To see this, write $c$ as $c=\left(  c_{1},c_{2},\ldots,c_{n}\right)  ^{T}$
and $A$ as $A=\left(  a_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq n}$. Then,
expanding $c^{T}Ac$ yields%
\begin{align*}
c^{T}Ac  &  =\sum_{i,j}c_{i}a_{i,j}c_{j}=\sum_{i,j}a_{i,j}c_{i}c_{j}\\
&  =\underbrace{\sum_{i<j}a_{i,j}c_{i}c_{j}}_{\substack{=\sum_{j<i}%
a_{j,i}c_{j}c_{i}\\\text{(here, we have renamed}\\\text{the indices }i\text{
and }j\text{ as }j\text{ and }i\text{)}}}+\underbrace{\sum_{i=j}a_{i,j}%
c_{i}c_{j}}_{=\sum_{i}a_{i,i}c_{i}c_{i}}+\underbrace{\sum_{i>j}}_{=\sum_{j<i}%
}\underbrace{a_{i,j}}_{\substack{=a_{j,i}\\\text{(since }A\\\text{is
symmetric)}}}\underbrace{c_{i}c_{j}}_{=c_{j}c_{i}}\\
&  =\sum_{j<i}a_{j,i}c_{j}c_{i}+\sum_{i}a_{i,i}c_{i}c_{i}+\sum_{j<i}%
a_{j,i}c_{j}c_{i}=\underbrace{2}_{\substack{=0\\\text{(since we are}\\\text{in
}\mathbb{Z}/2\text{)}}}\sum_{j<i}a_{j,i}c_{j}c_{i}+\sum_{i}a_{i,i}c_{i}c_{i}\\
&  =\sum_{i}a_{i,i}\underbrace{c_{i}c_{i}}_{\substack{=c_{i}^{2}%
=c_{i}\\\text{(since }x^{2}=x\\\text{for all }x\in\mathbb{Z}/2\text{)}}%
}=\sum_{i}a_{i,i}c_{i}=dc
\end{align*}
(since $c=\left(  c_{1},c_{2},\ldots,c_{n}\right)  ^{T}$ and $d=\left(
a_{1,1},a_{2,2},\ldots,a_{n,n}\right)  $). So $dc=c^{T}\underbrace{Ac}%
_{=0}=c^{T}0=0$. Thus, Assumption 1 is proven.]

Corollary \ref{cor.laf.lights-out-diag} now follows.
\end{proof}

Now, why can the lights-out puzzle be solved?

We want to prove that $\left(  1,1,1,1\right)  \in\operatorname*{Row}A$ for
our matrix $A\in\left(  \mathbb{Z}/2\right)  ^{4\times4}$.

This follows from Corollary \ref{cor.laf.lights-out-diag}, since the matrix
$A$ is symmetric, and since its diagonal is $\left(  1,1,1,1\right)  $.

The same argument works for the \textquotedblleft proper\textquotedblright%
\ (2-dimensional) lights-out puzzle; we just have to use row vectors of size
$16$ (not $4$) and $16\times16$-matrices (not $4\times4$-matrices). More
generally, the same argument works for any such puzzle on any
\textquotedblleft grid\textquotedblright\ as long as:

\begin{itemize}
\item each lamp $i$ has a lightswitch which toggles at least lamp $i$;

\item if the lightswitch at lamp $i$ toggles lamp $j$, then the lightswitch at
lamp $j$ toggles lamp $i$.
\end{itemize}

These conditions guarantee that the corresponding matrix $A$ will be symmetric
and its diagonal will be $\left(  1,1,\ldots,1\right)  $ (and thus we can
apply Corollary \ref{cor.laf.lights-out-diag}).

How to find the exact sequence of flips that results in all lights being on?
This is tantamount to finding the coefficient of a linear combination of the
rows of $A$ that equals $\left(  1,1,\ldots,1\right)  $. This boils down to
solving a system of linear equations over $\mathbb{Z}/2$, which can be
achieved using Gaussian elimination.

What other states can be achieved by flipping lightswitches? Again, for each
specific grid and each specific state, this can be solved by Gaussian
elimination; but characterizing the reachable states more explicitly is a hard
problem with no unified answer. (See the link above.)

\begin{center}
\textbf{2019-04-15 lecture}
\end{center}

\subsubsection{A warning about orthogonality and positivity}

I have said above that \textquotedblleft more or less\textquotedblright\ all
linear algebra over $\mathbb{R}$ works identically over any field $\mathbb{K}%
$. There is an exception: Anything that uses positivity will break down over
some fields $\mathbb{K}$. Let me briefly telegraph what can go wrong. (Don't
worry if the things I am mentioning are not familiar to you.)

One thing that uses positivity is QR-decomposition. And indeed, not every
matrix over an arbitrary field has a QR-decomposition.

You can still define dot products and orthogonal complements of subspaces. But
it is no longer true that $\mathbb{K}^{n\times1}=U\oplus U^{\perp}$ for any
subspace $U$ of $\mathbb{K}^{n\times1}$. It can happen that $U\cap U^{\perp
}\neq\left\{  0\right\}  $. For example, there are column vectors
$v\neq0_{n\times1}$ that are orthogonal to themselves with respect to the dot
product (that is, $v^{T}v=0$).

\textbf{Example:} In $\mathbb{Z}/3$, we have%
\[
\left(
\begin{array}
[c]{c}%
1\\
1\\
1
\end{array}
\right)  ^{T}\left(
\begin{array}
[c]{c}%
1\\
1\\
1
\end{array}
\right)  =\left(  1,1,1\right)  \left(
\begin{array}
[c]{c}%
1\\
1\\
1
\end{array}
\right)  =1\cdot1+1\cdot1+1\cdot1=3=0.
\]
So the vector $\left(
\begin{array}
[c]{c}%
1\\
1\\
1
\end{array}
\right)  \in\left(  \mathbb{Z}/3\right)  ^{3\times1}$ is orthogonal to itself.

\subsection{Matrix algebra vs. coordinate-free linear algebra}

There are two common approaches to linear algebra: The first is the study of
matrices and column vectors (or row vectors); this is down-to-earth but often
clumsy and unenlightening. The second is the study of vector spaces and linear
transformations; this is more abstract but more general and often better for
conceptual understanding. The first approach is known as \textit{matrix
algebra}; the second is called \textit{coordinate-free linear algebra}.

These two approaches are closely connected: The first can be viewed as a
particular case of the second (as the column vectors of a given size $n$ form
a vector space, and any matrix defines a linear map between two such vector
spaces); the second appears more general but in reality can often be reduced
to the first (viz., theorems about vector spaces can often be proven by
\textquotedblleft picking bases\textquotedblright\ and representing linear
maps by matrices with respect to these bases). Thus, a sufficiently deep
course on linear algebra will necessarily survey both of these approaches, and
practitioners of the subject will often apply whichever approach fits a
problem better.

In the previous section, we have seen how the first approach can be
generalized from real or complex matrices to matrices over any field (and, as
far as the basics are concerned, over any commutative ring). We shall now try
this with the second approach. Over a field, the second approach turns out to
work out in pretty much the same way as over the real or complex numbers;
however, over a commutative ring, things become a lot more interesting.

\subsection{\label{sect.la.mod-def}$\mathbb{K}$-modules: the definition}

Let us begin by defining the analogue of a vector space: a \textit{module}.
Roughly speaking, a module is the same as a vector space, except that it is
over a commutative ring instead of a field:

\begin{definition}
\label{def.module.module}Let $\mathbb{K}$ be a commutative ring.

A $\mathbb{K}$\textit{-module} means a set $M$ equipped with

\begin{itemize}
\item a binary operation $+$ on $M$ (called \textquotedblleft\textit{addition}%
\textquotedblright, and not to be confused with the addition $+_{\mathbb{K}}$
of $\mathbb{K}$),

\item a map $\cdot\ :\ \mathbb{K}\times M\rightarrow M$ (called
\textquotedblleft\textit{scaling\textquotedblright}, and not to be confused
with the multiplication $\cdot_{\mathbb{K}}$ of $\mathbb{K}$), and

\item an element $0_{M}\in M$ (called \textquotedblleft\textit{zero
vector}\textquotedblright\ or \textquotedblleft zero\textquotedblright, and
not to be confused with the zero of $\mathbb{K}$)
\end{itemize}

\noindent satisfying the following axioms:

\begin{itemize}
\item \textbf{(a)} We have $a+b=b+a$ for all $a,b\in M$.

\item \textbf{(b)} We have $a+\left(  b+c\right)  =\left(  a+b\right)  +c$ for
all $a,b,c\in M$.

\item \textbf{(c)} We have $a+0_{M}=0_{M}+a=a$ for all $a\in M$.

\item \textbf{(d)} Each $a\in M$ has an additive inverse (i.e., there is an
$a^{\prime}\in M$ such that $a+a^{\prime}=a^{\prime}+a=0_{M}$).

\item \textbf{(e)} We have $\lambda\left(  a+b\right)  =\lambda a+\lambda b$
for all $\lambda\in\mathbb{K}$ and $a,b\in M$. Here and in the following, we
use the notation \textquotedblleft$\lambda c$\textquotedblright\ (or,
equivalently, \textquotedblleft$\lambda\cdot c$\textquotedblright) for the
image of a pair $\left(  \lambda,c\right)  \in\mathbb{K}\times M$ under the
\textquotedblleft scaling\textquotedblright\ map $\cdot$ (similarly to how we
write $ab$ for the image of a pair $\left(  a,b\right)  \in\mathbb{K}%
\times\mathbb{K}$ under the \textquotedblleft multiplication\textquotedblright%
\ map $\cdot$).

\item \textbf{(f)} We have $\left(  \lambda+\mu\right)  a=\lambda a+\mu a$ for
all $\lambda,\mu\in\mathbb{K}$ and $a\in M$.

\item \textbf{(g)} We have $0a=0_{M}$ for all $a\in M$.

\item \textbf{(h)} We have $\left(  \lambda\mu\right)  a=\lambda\left(  \mu
a\right)  $ for all $\lambda,\mu\in\mathbb{K}$ and $a\in M$.

\item \textbf{(i)} We have $1a=a$ for all $a\in M$.

\item \textbf{(j)} We have $\lambda\cdot0_{M}=0_{M}$ for all $\lambda
\in\mathbb{K}$.
\end{itemize}

\noindent These ten axioms are called the \textit{module axioms}.
\end{definition}

A $\mathbb{K}$-module is often called a \textquotedblleft module over
$\mathbb{K}$\textquotedblright.

\begin{definition}
\label{def.module.vectors}If $\mathbb{K}$ is a commutative ring and $M$ is a
$\mathbb{K}$-module, then the elements of $M$ are called \textit{vectors},
while the elements of $\mathbb{K}$ are called \textit{scalars}.
\end{definition}

\begin{definition}
\label{def.module.vec-sp}If $\mathbb{K}$ is a field, then $\mathbb{K}$-modules
are called $\mathbb{K}$\textit{-vector spaces}. (When $\mathbb{K}=\mathbb{R}$,
these are the usual real vector spaces known from undergraduate linear algebra classes.)
\end{definition}

\subsection{\label{sect.la.mod-exa}Examples of $\mathbb{K}$-modules}

Thus, any vector space you have seen in linear algebra is an example of a
module. Let us see some other examples:

\begin{example}
\label{exa.module.K}Let $\mathbb{K}$ be a commutative ring. Then, $\mathbb{K}$
itself is a $\mathbb{K}$-module (with the addition given by the addition
$+_{\mathbb{K}}$ of $\mathbb{K}$, and with the scaling given by the
multiplication $\cdot_{\mathbb{K}}$ of $\mathbb{K}$, and with zero vector
given by the zero $0_{\mathbb{K}}$ of $\mathbb{K}$).
\end{example}

\begin{example}
\label{exa.module.Kn}Let $\mathbb{K}$ be a commutative ring. Let
$n\in\mathbb{N}$. Equip the set $\mathbb{K}^{n}$ (that is, the set of all
$n$-tuples of elements of $\mathbb{K}$) with entrywise addition (that is, a
binary operation $+$ on $\mathbb{K}^{n}$ defined by%
\[
\left(  a_{1},a_{2},\ldots,a_{n}\right)  +\left(  b_{1},b_{2},\ldots
,b_{n}\right)  =\left(  a_{1}+b_{1},a_{2}+b_{2},\ldots,a_{n}+b_{n}\right)
\]
for all $\left(  a_{1},a_{2},\ldots,a_{n}\right)  ,\left(  b_{1},b_{2}%
,\ldots,b_{n}\right)  \in\mathbb{K}^{n}$) and entrywise scaling (that is, a
map $\cdot:\mathbb{K}\times\mathbb{K}^{n}\rightarrow\mathbb{K}^{n}$ defined by%
\[
\lambda\left(  a_{1},a_{2},\ldots,a_{n}\right)  =\left(  \lambda a_{1},\lambda
a_{2},\ldots,\lambda a_{n}\right)
\]
for all $\lambda\in\mathbb{K}$ and $\left(  a_{1},a_{2},\ldots,a_{n}\right)
\in\mathbb{K}^{n}$) and the zero vector $\left(  0,0,\ldots,0\right)  $. Then,
$\mathbb{K}^{n}$ becomes a $\mathbb{K}$-module.
\end{example}

\begin{example}
\label{exa.module.Knm}Let $\mathbb{K}$ be a commutative ring. Let
$n,m\in\mathbb{N}$. Equip the set $\mathbb{K}^{n\times m}$ (that is, the set
of all $n\times m$-matrices over $\mathbb{K}$) with the addition defined in
Definition \ref{def.matrix.+-} \textbf{(a)} and the scaling defined in
Definition \ref{def.matrix.+-} \textbf{(c)} and the zero vector $0_{n\times
m}$. Then, $\mathbb{K}^{n\times m}$ becomes a $\mathbb{K}$-module.
\end{example}

\begin{example}
Let $\mathbb{K}$ be a commutative ring. The one-element set $\left\{
0\right\}  $ is a $\mathbb{K}$-module (with $+$ and $\cdot$ and zero vector
defined in the only possible way). This is called the \textit{zero module}. It
is often called $0$.
\end{example}

\begin{example}
\label{exa.module.Z/n}Let $n$ be an integer. Then:

\textbf{(a)} The set $\mathbb{Z}/n$ is a $\mathbb{Z}$-module, if you equip it
with the addition and the scaling that we defined above (in Definition
\ref{def.eqrel.Z/n.op} and Definition \ref{def.eqrel.Z/n.scaling}) and with
the zero vector $\left[  0\right]  _{n}$.

\textbf{(b)} The set $n\mathbb{Z}:=\left\{  nz\ \mid\ z\in\mathbb{Z}\right\}
=\left\{  \text{all multiples of }n\right\}  $ is a $\mathbb{Z}$-module (again
equipped with the usual addition as addition, and the usual multiplication as
scaling, and the integer $0$ as zero vector).
\end{example}

\begin{example}
\label{exa.module.Q}\textbf{(a)} The set $\mathbb{Q}$ (equipped with the usual
addition, and with a scaling defined by the usual multiplication, and the zero
vector $0$) is a $\mathbb{Z}$-module.

\textbf{(b)} For every $q\in\mathbb{Q}$, the subset $q\mathbb{Z}:=\left\{
qz\ \mid\ z\in\mathbb{Z}\right\}  $ of $\mathbb{Q}$ (again equipped with the
usual $+$ and $\cdot$ and $0$) is a $\mathbb{Z}$-module. For example,
$\dfrac{1}{2}\mathbb{Z}=\left\{  \ldots,-2,-1.5,-1,-0.5,0,0.5,1,1.5,2,\ldots
\right\}  $ is a $\mathbb{Z}$-module. Note that $\dfrac{1}{2}\mathbb{Z}$ is
\textbf{not} a ring (at least not with the usual $\cdot$ as multiplication),
since $\dfrac{1}{2}\cdot\dfrac{1}{2}=\dfrac{1}{4}\notin\dfrac{1}{2}\mathbb{Z}$.

\textbf{(c)} What other $\mathbb{Z}$-modules can we find inside $\mathbb{Q}$ ?
Quite a few, it turns out. Here is a not-completely-obvious one: Let us call
an integer $n$ \textit{squarefree} if it is not divisible by any perfect
square other than $1$. It is easy to see that an integer $n$ is squarefree if
and only if $n$ is a product of \textbf{distinct} primes (or, equivalently,
$v_{p}\left(  n\right)  \leq1$ for each prime $p$). Thus, the squarefree
integers are $1,2,3,5,6,7,10,11,13,\ldots$ and their negatives. Now, let
$\mathbb{Q}_{\operatorname*{sqf}}$ be the subset%
\[
\left\{  \dfrac{a}{b}\ \mid\ a,b\in\mathbb{Z}\text{ with }b\text{
squarefree}\right\}
\]
of $\mathbb{Q}$. Then, $\mathbb{Q}_{\operatorname*{sqf}}$ (equipped with the
usual addition as addition, the usual multiplication as scaling, and the usual
$0$ as zero vector) is a $\mathbb{Z}$-module. (Check this!)
\end{example}

\subsection{\label{sect.la.submod}Submodules}

\begin{convention}
\label{conv.module.K}For the rest of Chapter \ref{chp.la}, we fix a
\textbf{commutative} ring $\mathbb{K}$, and we denote its addition,
multiplication, zero and unity by $+$, $\cdot$, $0$ and $1$.
\end{convention}

In Section \ref{sect.ring.subring}, we have defined the notion of a subring of
a ring. Similarly, we shall now define a submodule of a $\mathbb{K}$-module.
For example, the $\mathbb{Z}$-modules $q\mathbb{Z}$ and $\mathbb{Q}%
_{\operatorname*{sqf}}$ from Example \ref{exa.module.Q} will fall under this
concept. The idea is the same as for subrings: A submodule of a $\mathbb{K}%
$-module $M$ is a $\mathbb{K}$-module $N$ that is a subset of $N$ and has
\textquotedblleft the same\textquotedblright\ addition, scaling and zero
vector. Here is the formal definition (analogous to Definition
\ref{def.ring.subring}):

\begin{definition}
\label{def.la.submod}Let $M$ and $N$ be two $\mathbb{K}$-modules. We say that
$M$ is a $\mathbb{K}$\textit{-submodule} (or, for short, \textit{submodule})
of $N$ if and only if it satisfies the following four requirements:

\begin{itemize}
\item the set $M$ is a subset of $N$;

\item the addition of $M$ is a restriction of the addition of $N$ (that is, we
have $a_{1}+_{M}a_{2}=a_{1}+_{N}a_{2}$ for all $a_{1},a_{2}\in M$);

\item the scaling of $M$ is a restriction of the scaling of $N$ (that is, we
have $\lambda\cdot_{M}a=\lambda\cdot_{N}a$ for all $\lambda\in\mathbb{K}$ and
$a\in M$);

\item the zero vector of $M$ is the zero vector of $N$ (that is, we have
$0_{M}=0_{N}$).
\end{itemize}
\end{definition}

Thus, according to this definition:

\begin{itemize}
\item the $\mathbb{Z}$-modules $n\mathbb{Z}$ from Example \ref{exa.module.Z/n}
\textbf{(b)} are $\mathbb{Z}$-submodules of $\mathbb{Z}$;

\item the $\mathbb{Z}$-modules $q\mathbb{Z}$ and $\mathbb{Q}%
_{\operatorname*{sqf}}$ from Example \ref{exa.module.Q} are $\mathbb{Z}%
$-submodules of $\mathbb{Q}$;

\item every $\mathbb{K}$-module $M$ is a $\mathbb{K}$-submodule of itself.
\end{itemize}

Again, you can find examples of two $\mathbb{K}$-modules $M$ and $N$ for which
the set $M$ is a \textbf{subset} of $N$ yet the $\mathbb{K}$-module $M$ is
\textbf{not a }$\mathbb{K}$\textbf{-submodule} of $N$. For example,
$\mathbb{C}$ becomes a $\mathbb{C}$-module in the usual way (with addition
playing the role of addition, and multiplication playing the role of scaling);
but you can also define a second \textquotedblleft scaling\textquotedblright%
\ operation $\overline{\cdot}:\mathbb{C}\times\mathbb{C}\rightarrow\mathbb{C}$
by setting%
\[
\alpha\left.  \overline{\cdot}\right.  \beta=\overline{\alpha}\beta
\ \ \ \ \ \ \ \ \ \ \text{for all }\alpha,\beta\in\mathbb{C}\text{.}%
\]
Then, we can turn the set $\mathbb{C}$ into a $\mathbb{C}$-module by endowing
it with the usual addition, the unusual scaling operation $\left.
\overline{\cdot}\right.  $ and the zero vector $0$. This new $\mathbb{C}%
$-module may be called $\overline{\mathbb{C}}$, and is useful in studying
\href{https://en.wikipedia.org/wiki/Sesquilinear_form}{Hermitian forms}. The
$\mathbb{C}$-modules $\mathbb{C}$ and $\overline{\mathbb{C}}$ are equal as
sets, but neither is a $\mathbb{C}$-submodule of the other.

\begin{definition}
If $\mathbb{K}$ is a field, then $\mathbb{K}$-submodules are also known as
$\mathbb{K}$\textit{-vector subspaces} (or, short, $\mathbb{K}$%
\textit{-subspaces}).
\end{definition}

When we have two $\mathbb{K}$-modules $M$ and $N$ such that $M\subseteq N$ as
sets (or, more generally, such that $M$ and $N$ have elements in common), we
generally need to be careful using the symbol \textquotedblleft$+$%
\textquotedblright: This symbol may mean both the addition of $M$ and the
addition of $N$, and these additions might not be the same. Thus it is prudent
to disambiguate its meaning by attaching a subscript \textquotedblleft$_{M}%
$\textquotedblright\ or \textquotedblleft$_{N}$\textquotedblright\ to it. The
same applies to the symbols \textquotedblleft$\cdot$\textquotedblright\ and
\textquotedblleft$0$\textquotedblright\ and expressions like \textquotedblleft%
$\lambda a$\textquotedblright\ (which have an implicit scaling sign). However,
when $M$ is a $\mathbb{K}$-submodule of $N$, we do not need to take this
precaution; in this case, the meaning of expressions like \textquotedblleft%
$a+b$\textquotedblright\ does not depend on whether you read \textquotedblleft%
$+$\textquotedblright\ as the addition of $M$ or as the addition of
$\mathbb{L}$.

The following is analogous to Proposition \ref{prop.ring.subring.as-subset}:

\begin{proposition}
\label{prop.module.submod.as-subset}Let $N$ be a $\mathbb{K}$-module. Let $S$
be a subset of $N$ that satisfies the following three conditions:\footnotemark

\begin{itemize}
\item We have $0\in S$.

\item The subset $S$ is \textit{closed under addition}. (This means that all
$a,b\in S$ satisfy $a+b\in S$.)

\item The subset $S$ is \textit{closed under scaling}. (This means that all
$\lambda\in\mathbb{K}$ and $a\in S$ satisfy $\lambda a\in S$.)
\end{itemize}

Then, the set $S$ itself becomes a $\mathbb{K}$-module if we endow it with:

\begin{itemize}
\item an addition operation $+$ which is defined as the restriction of the
addition operation of the $\mathbb{K}$-module $N$;

\item a scaling map $\cdot:\mathbb{K}\times S\rightarrow S$ which is defined
as the restriction of the scaling map of the $\mathbb{K}$-module $N$,
\end{itemize}

\noindent and the zero vector $0$. Furthermore, this $\mathbb{K}$-module $S$
is a $\mathbb{K}$-submodule of $N$.
\end{proposition}

\footnotetext{In this proposition, the symbols \textquotedblleft%
$+$\textquotedblright, \textquotedblleft$\cdot$\textquotedblright\ and
\textquotedblleft$0$\textquotedblright\ mean the addition, the scaling and the
zero vector of $N$.}

\begin{proof}
[Proof of Proposition \ref{prop.module.submod.as-subset}.]Similar to the proof
of Proposition \ref{prop.ring.subring.as-subset}, except that we now need to
argue that each $a\in S$ satisfies $-a\in S$. (But this is easy: Since $S$ is
closed under scaling, we have $\left(  -1\right)  a\in S$, and thus
$-a=\left(  -1\right)  a\in S$.)
\end{proof}

\begin{definition}
\label{def.module.submod.as-subset} Let $N$ be a $\mathbb{K}$-module. Let $S$
be a subset of $N$ that satisfies the three conditions of Proposition
\ref{prop.module.submod.as-subset}. Then, we shall say that \textquotedblleft%
$S$ is a $\mathbb{K}$-submodule of $N$\textquotedblright. Technically
speaking, this is premature, since $S$ is so far just a subset of $N$ without
the structure of a $\mathbb{K}$-module; however, Proposition
\ref{prop.module.submod.as-subset} shows that there is an obvious way of
turning $S$ into a $\mathbb{K}$-module (viz.: define an operation $+$ by
restricting the corresponding operation of $N$, define a map $\cdot$
similarly, and steal the zero vector from $N$), and we shall automatically
regard $S$ as becoming a $\mathbb{K}$-module in this way (unless we say
otherwise). We say that the operation $+$ on $S$ (obtained by restricting the
corresponding operation on $N$) and the map $\cdot$ on $S$ and the zero vector
of $S$ are \textit{inherited from }$N$.
\end{definition}

Thus, finding $\mathbb{K}$-submodules of a $\mathbb{K}$-module $N$ boils down
to finding subsets that contain its $0$ and are closed under addition and
under scaling; the module axioms don't need to be re-checked.

Thus, in particular, when $\mathbb{K}$ is a field, the vector subspaces of
$\mathbb{K}^{n\times1}$ (as in Definition \ref{def.laf.subspace-of-row}) are
precisely the $\mathbb{K}$-submodules of $\mathbb{K}^{n\times1}$. Many
examples of $\mathbb{K}$-submodules can thus be found in textbooks on linear algebra.

\subsection{\label{sect.la.cart-prod}Cartesian products of $\mathbb{K}%
$-modules}

Instead of giving further examples, let us show a way of constructing new
$\mathbb{K}$-modules from old (analogous to Definition \ref{def.ring.dirprod2}):

\begin{definition}
\label{def.module.dirprod1}Let $M_{1},M_{2},\ldots,M_{n}$ be $n$ many
$\mathbb{K}$-modules. Consider the set $M_{1}\times M_{2}\times\cdots\times
M_{n}$, whose elements are $n$-tuples $\left(  m_{1},m_{2},\ldots
,m_{n}\right)  $ with $m_{i}\in M_{i}$.

We define a binary operation $+$ on $M_{1}\times M_{2}\times\cdots\times
M_{n}$ by%
\[
\left(  a_{1},a_{2},\ldots,a_{n}\right)  +\left(  b_{1},b_{2},\ldots
,b_{n}\right)  =\left(  a_{1}+b_{1},a_{2}+b_{2},\ldots,a_{n}+b_{n}\right)  ,
\]
and we define a \textquotedblleft scaling\textquotedblright\ map
$\cdot\ :\ \mathbb{K}\times\left(  M_{1}\times M_{2}\times\cdots\times
M_{n}\right)  \rightarrow M_{1}\times M_{2}\times\cdots\times M_{n}$ by%
\[
\lambda\cdot\left(  a_{1},a_{2},\ldots,a_{n}\right)  =\left(  \lambda
a_{1},\lambda a_{2},\ldots,\lambda a_{n}\right)  .
\]

\end{definition}

\begin{proposition}
\label{prop.module.dirprod.module}Let $M_{1},M_{2},\ldots,M_{n}$ be $n$ many
$\mathbb{K}$-modules. The set $M_{1}\times M_{2}\times\cdots\times M_{n}$,
endowed with the operation $+$ and the map $\cdot$ we just defined and with
the zero vector $\left(  0,0,\ldots,0\right)  $, is a $\mathbb{K}$-module.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.module.dirprod.module}.]Similar to the proof
of Proposition \ref{prop.ring.dirprod.ring}.
\end{proof}

\begin{definition}
\label{def.module.dirprod2}The $\mathbb{K}$-module $M_{1}\times M_{2}%
\times\cdots\times M_{n}$ constructed in Proposition
\ref{prop.module.dirprod.module} is called the \textit{Cartesian product} (or
\textit{direct product}) of the $\mathbb{K}$-modules $M_{1},M_{2},\ldots
,M_{n}$.
\end{definition}

\subsection{\label{sect.la.rules}Features and rules}

Again, we shall follow the PEMDAS convention for addition and scaling. For
example, the expression \textquotedblleft$a+\lambda b$\textquotedblright%
\ shall mean $a+\left(  \lambda b\right)  $.

\begin{proposition}
\label{prop.module.redundant-1}Axioms \textbf{(g)} and \textbf{(j)} in
Definition \ref{def.module.module} follow from the others.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.module.redundant-1}.]\textit{Proof of axiom
\textbf{(g)}:} Let $a\in M$. Then, axiom \textbf{(f)} (applied to $\lambda=0$
and $\mu=0$) yields%
\[
\left(  0+0\right)  a=0a+0a.
\]
This rewrites as $0a=0a+0a$. We can cancel $0a$ from this equation by adding
an additive inverse of $0a$ to both sides (such an inverse exists because of
axiom \textbf{(d)}); we thus get $0_{M}=0a$. This proves axiom \textbf{(g)}.

The proof of axiom \textbf{(j)} is analogous, with use of \textbf{(e)} instead
of \textbf{(f)}.
\end{proof}

\begin{proposition}
\label{prop.module.redundant-2}Axiom \textbf{(d)} in Definition
\ref{def.module.module} follows from the others.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.module.redundant-2}.]Let $a\in M$. We must
prove that $a$ has an additive inverse.

Axiom \textbf{(f)} in Definition \ref{def.module.module} (applied to
$\lambda=1$ and $\mu=-1$) yields $\left(  1+\left(  -1\right)  \right)
a=\underbrace{1a}_{\substack{=a\\\text{(by axiom \textbf{(i)})}}}+\left(
-1\right)  a=a+\left(  -1\right)  a$. Hence,
\[
a+\left(  -1\right)  a=\underbrace{\left(  1+\left(  -1\right)  \right)
}_{=0}a=0a=0_{M}\ \ \ \ \ \ \ \ \ \ \left(  \text{by axiom \textbf{(g)}%
}\right)  .
\]
Also, axiom \textbf{(a)} yields $a+\left(  -1\right)  a=\left(  -1\right)
a+a$, so that $a+\left(  -1\right)  a=\left(  -1\right)  a+a=0_{M}$. Thus,
$\left(  -1\right)  a$ is an additive inverse of $a$. Hence, $a$ has an
additive inverse. Thus, axiom \textbf{(d)} is proven.
\end{proof}

Note that Proposition \ref{prop.module.redundant-1} and Proposition
\ref{prop.module.redundant-2} cannot be merged: If we omit all three axioms
\textbf{(d)}, \textbf{(g)} and \textbf{(j)}, then we cannot recover these
axioms any more. (Indeed, our proof of axiom \textbf{(d)} relied on axiom
\textbf{(g)} and vice versa.)

What can you do when you have a $\mathbb{K}$-module?

\begin{convention}
For the rest of this subsection, we fix a $\mathbb{K}$-module $M$. We shall
denote its zero vector $0_{M}$ by $0$. (More generally, it is common to denote
the zero vector of any $\mathbb{K}$-module by $0$ as long as you are not
afraid of confusion.)
\end{convention}

Just as in a ring, elements of a module have unique additive inverses:

\begin{theorem}
\label{thm.module.inv-add.uni}Let $a\in M$. Then:

\textbf{(a)} The element $a$ has exactly one additive inverse.

\textbf{(b)} This additive inverse is $\left(  -1\right)  a$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.module.inv-add.uni}.]\textbf{(a)} Same as the proof
of Theorem \ref{thm.rings.inv-add.uni}.

\textbf{(b)} This was shown in the proof of Proposition
\ref{prop.module.redundant-2}.
\end{proof}

\begin{definition}
\label{def.module.inv-add-a}\textbf{(a)} If $a\in M$, then the additive
inverse of $a$ will be called $-a$. (This is well-defined, since Theorem
\ref{thm.module.inv-add.uni} \textbf{(a)} shows that this additive inverse is unique.)

\textbf{(b)} If $a\in M$ and $b\in M$, then we define the \textit{difference}
$a-b$ to be the element $a+\left(  -b\right)  $ of $M$. This new binary
operation $-$ on $M$ is called \textquotedblleft\textit{subtraction}%
\textquotedblright.
\end{definition}

\begin{remark}
The subtraction we just defined for an arbitrary $\mathbb{K}$-module
generalizes both

\begin{itemize}
\item the subtraction of matrices (when the $\mathbb{K}$-module is
$\mathbb{K}^{n\times m}$), and

\item the subtraction in $\mathbb{Z}/n$ (when $\mathbb{K}=\mathbb{Z}$ and the
$\mathbb{K}$-module is $\mathbb{Z}/n$).
\end{itemize}
\end{remark}

\begin{proof}
This is easy to see from the definitions of these subtractions.
\end{proof}

Additive inverses and subtraction satisfy certain rules that should not
surprise you:

\begin{proposition}
\label{prop.module.inv-add.rules}Let $a,b,c\in M$.

\textbf{(a)} We have $a-b=c$ if and only if $a=b+c$. (Roughly speaking, this
means that subtraction undoes addition.)

\textbf{(b)} We have $-\left(  a+b\right)  =\left(  -a\right)  +\left(
-b\right)  $.

\textbf{(c)} We have $-0=0$.

\textbf{(d)} We have $0-a=-a$.

\textbf{(e)} We have $-\left(  -a\right)  =a$.

\textbf{(f)} We have $-\left(  \lambda a\right)  =\left(  -\lambda\right)
a=\lambda\left(  -a\right)  $ for all $\lambda\in\mathbb{K}$.

\textbf{(g)} We have $a-b-c=a-\left(  b+c\right)  $. (Here and in the
following, \textquotedblleft$a-b-c$\textquotedblright\ should be read as
\textquotedblleft$\left(  a-b\right)  -c$\textquotedblright.)
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.module.inv-add.rules}.]Same as for Proposition
\ref{prop.rings.inv-add.rules}.
\end{proof}

Again, Proposition \ref{prop.module.inv-add.rules} shows that certain
expressions are unambiguous.

Theorem \ref{thm.rings.sum.wd} holds for the $\mathbb{K}$-module $M$ just as
it holds for the ring $\mathbb{K}$. Thus, we have a notion of finite sums of
elements of $M$; it behaves exactly like finite sums of elements of
$\mathbb{K}$ do. However, Theorem \ref{thm.rings.prod.wd} has no analogue for
$\mathbb{K}$-modules. (However, you can get something similar to Theorem
\ref{thm.rings.prod.wd} \textbf{(b)} by defining finite products of the form
$\lambda_{1}\lambda_{2}\cdots\lambda_{k}a$ with $\lambda_{1},\lambda
_{2},\ldots,\lambda_{k}\in\mathbb{K}$ and $a\in M$.)

Definition \ref{def.rings.na} can be extended to modules by simply replacing
$\mathbb{K}$ with $M$:

\begin{definition}
\label{def.module.na}Let $a\in M$ and $n\in\mathbb{Z}$. Then, we define an
element $na$ of $M$ by%
\[
na=%
\begin{cases}
\underbrace{a+a+\cdots+a}_{n\text{ times}}, & \text{if }n\geq0;\\
-\left(  \underbrace{a+a+\cdots+a}_{-n\text{ times}}\right)  , & \text{if }n<0
\end{cases}
.
\]

\end{definition}

We cannot define $a^{n}$ for $a\in M$ and $n\in\mathbb{N}$.

Some parts of Proposition \ref{prop.rings.pow.rules} \textbf{(a)} have
analogues for a $\mathbb{K}$-module; namely, we have the following:

\begin{proposition}
\label{prop.module.na.rules}We have%
\begin{align}
\left(  n+m\right)  a  &  =na+ma\ \ \ \ \ \ \ \ \ \ \text{for all }a\in
M\text{ and }n,m\in\mathbb{Z};\\
n\left(  a+b\right)   &  =na+nb\ \ \ \ \ \ \ \ \ \ \text{for all }a,b\in
M\text{ and }n\in\mathbb{Z};\\
-\left(  na\right)   &  =\left(  -n\right)  a=n\left(  -a\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }a\in M\text{ and }n\in\mathbb{Z};\\
\left(  nm\right)  a  &  =n\left(  ma\right)  \ \ \ \ \ \ \ \ \ \ \text{for
all }a\in M\text{ and }n,m\in\mathbb{Z};\\
n\left(  \lambda a\right)   &  =\left(  n\lambda\right)  a=\lambda\left(
na\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }a\in M\text{ and }\lambda
\in\mathbb{K}\text{ and }n\in\mathbb{Z};\\
1a  &  =a\ \ \ \ \ \ \ \ \ \ \text{for all }a\in M;\\
\left(  -1\right)  a  &  =-a\ \ \ \ \ \ \ \ \ \ \text{for all }a\in M.
\end{align}
(Here, \textquotedblleft$1$\textquotedblright\ stands for the number
$1\in\mathbb{Z}$, not for the scalar $1\in\mathbb{K}$.) In particular, these
equalities show that certain expressions (like \textquotedblleft%
$nma$\textquotedblright\ and \textquotedblleft$n\lambda a$\textquotedblright)
are unambiguous.
\end{proposition}

\textbf{Upshot:} All the rules relating to addition that we know from rings
are still true for $\mathbb{K}$-modules. Some basic rules relating to
multiplication can be salvaged\ (i.e., made to work for $\mathbb{K}$-modules)
by replacing multiplication by scaling.

\subsection{\label{sect.la.liho}Linear maps}

Recall Definition \ref{def.riho.riho}. In a similar way, we define
$\mathbb{K}$\textit{-module homomorphisms}, also known as $\mathbb{K}%
$\textit{-linear maps}:

\begin{definition}
\label{def.module.moho}Let $M$ and $N$ be two $\mathbb{K}$-modules. A
$\mathbb{K}$\textit{-module homomorphism} from $M$ to $N$ means a map
$f:M\rightarrow N$ that satisfies the following three axioms:

\textbf{(a)} We have $f\left(  a+b\right)  =f\left(  a\right)  +f\left(
b\right)  $ for all $a,b\in M$. (This is called \textquotedblleft$f$ respects
addition\textquotedblright\ or \textquotedblleft$f$ preserves
addition\textquotedblright.)

\textbf{(b)} We have $f\left(  0\right)  =0$. (This, of course, means
$f\left(  0_{M}\right)  =0_{N}$.)

\textbf{(c)} We have $f\left(  \lambda a\right)  =\lambda f\left(  a\right)  $
for all $\lambda\in\mathbb{K}$ and $a\in M$. (This is called \textquotedblleft%
$f$ respects scaling\textquotedblright\ or \textquotedblleft$f$ preserves
scaling\textquotedblright.)

Instead of \textquotedblleft$\mathbb{K}$-module homomorphism\textquotedblright%
, we can also say \textquotedblleft$\mathbb{K}$\textit{-linear map}%
\textquotedblright\ or just \textquotedblleft\textit{linear map}%
\textquotedblright\ (when $\mathbb{K}$ is clear).
\end{definition}

\begin{remark}
\label{rmk.module.moho.0-free}The axiom \textbf{(b)} in Definition
\ref{def.module.moho} is redundant -- it follows from axiom \textbf{(a)}.
\end{remark}

\begin{proof}
Same argument as for Remark \ref{rmk.riho.0-free}.
\end{proof}

Some authors (for example, Hefferon in \cite[Chapter Three, Definition
II.1.1]{Hefferon}, and the authors of \cite[Definition 6.1.1]{LaNaSc16}) omit
the axiom \textbf{(b)} when they define $\mathbb{K}$-linear maps. This does
not change the concept, as Remark \ref{rmk.module.moho.0-free} shows.

What are some examples of module homomorphisms?

\begin{example}
\label{exa.module.moho.id}Let $M$ be a $\mathbb{K}$-module.

\textbf{(a)} The identity map $\operatorname*{id}:M\rightarrow M$ is
$\mathbb{K}$-linear.

\textbf{(b)} For any $\lambda\in\mathbb{K}$, the map $L_{\lambda}:M\rightarrow
M,\ a\mapsto\lambda a$ is $\mathbb{K}$-linear.

\textbf{(c)} If $M=\mathbb{K}$ (specifically, the $\mathbb{K}$-module
$\mathbb{K}$ defined in Example \ref{exa.module.K}), then the maps
$L_{\lambda}$ (for $\lambda\in\mathbb{K}$) that we just defined are the only
$\mathbb{K}$-linear maps from $M$ to $M$.
\end{example}

Next comes a less basic example:

\begin{theorem}
\label{thm.module.LA}Let $n,m\in\mathbb{N}$. Let $A\in\mathbb{K}^{n\times m}$
be an $n\times m$-matrix. Define a map%
\begin{align*}
L_{A}:\mathbb{K}^{m\times1}  &  \rightarrow\mathbb{K}^{n\times1},\\
v  &  \mapsto Av.
\end{align*}
This map $L_{A}$ is a $\mathbb{K}$-module homomorphism from $\mathbb{K}%
^{m\times1}$ to $\mathbb{K}^{n\times1}$.
\end{theorem}

\begin{proof}
[Proof of Theorem \ref{thm.module.LA}.]We just need to check that the three
axioms \textbf{(a)}, \textbf{(b)} and \textbf{(c)} in Definition
\ref{def.module.moho} are satisfied for $M=\mathbb{K}^{m\times1}$,
$N=\mathbb{K}^{n\times1}$ and $f=L_{A}$.

\textit{Proof of axiom \textbf{(a)}:} We must prove that $L_{A}\left(
a+b\right)  =L_{A}\left(  a\right)  +L_{A}\left(  b\right)  $ for all
$a,b\in\mathbb{K}^{m\times1}$. Indeed: Comparing%
\begin{align*}
L_{A}\left(  a+b\right)   &  =A\left(  a+b\right)
=Aa+Ab\ \ \ \ \ \ \ \ \ \ \text{with}\\
L_{A}\left(  a\right)  +L_{A}\left(  b\right)   &  =Aa+Ab,
\end{align*}
we obtain $L_{A}\left(  a+b\right)  =L_{A}\left(  a\right)  +L_{A}\left(
b\right)  $. Thus, axiom \textbf{(a)} has been verified.

The axioms \textbf{(b)} and \textbf{(c)} are proven similarly (details are
left to the reader).
\end{proof}

\begin{proposition}
\label{prop.module.f=LA}Let $n,m\in\mathbb{N}$. Each $\mathbb{K}$-module
homomorphism from $\mathbb{K}^{m\times1}$ to $\mathbb{K}^{n\times1}$ has the
form $L_{A}$ for a unique $A\in\mathbb{K}^{n\times m}$ (where $L_{A}$ is
defined as in Theorem \ref{thm.module.LA}).
\end{proposition}

We shall delay the proof of this proposition until we have shown some
auxiliary results. First, we define a specific kind of column vectors:

\begin{definition}
\label{def.module.ej}Let $m\in\mathbb{N}$. For each $j\in\left\{
1,2,\ldots,m\right\}  $, we let $e_{j}\in\mathbb{K}^{m\times1}$ be the column
vector
\[
\left(
\begin{array}
[c]{c}%
0\\
0\\
\vdots\\
0\\
1\\
0\\
0\\
\vdots\\
0
\end{array}
\right)  =\left(  0,0,\ldots,0,1,0,0,\ldots,0\right)  ^{T}%
\]
where the $1$ is at the $j$-th position. (Strictly speaking, we should denote
it by $e_{j,m}$ rather than $e_{j}$, since it depends on $m$ and not just on
$j$; but the $m$ will always be clear from the context.)

These column vectors $e_{1},e_{2},\ldots,e_{m}$ are called the
\textit{standard basis vectors} of $\mathbb{K}^{m\times1}$.
\end{definition}

For example, if $m=3$, then $e_{1}=\left(
\begin{array}
[c]{c}%
1\\
0\\
0
\end{array}
\right)  $ and $e_{2}=\left(
\begin{array}
[c]{c}%
0\\
1\\
0
\end{array}
\right)  $ and $e_{3}=\left(
\begin{array}
[c]{c}%
0\\
0\\
1
\end{array}
\right)  $.

\begin{lemma}
\label{lem.module.Aej}Let $n,m\in\mathbb{N}$. Let $A\in\mathbb{K}^{n\times m}$
be an $n\times m$-matrix.

\textbf{(a)} We have $Ae_{j}=\left(  \text{the }j\text{-th column of
}A\right)  $ for all $j\in\left\{  1,2,\ldots,m\right\}  $.

\textbf{(b)} Consider the map $L_{A}$ defined in Theorem \ref{thm.module.LA}.
Then,%
\[
L_{A}\left(  e_{j}\right)  =\left(  \text{the }j\text{-th column of }A\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }j\in\left\{  1,2,\ldots,m\right\}  .
\]

\end{lemma}

\begin{proof}
[Proof of Lemma \ref{lem.module.Aej}.]\textbf{(a)} Let $j\in\left\{
1,2,\ldots,m\right\}  $. Then, $Ae_{j}$ is a column vector in $\mathbb{K}%
^{n\times1}$. For each $i\in\left\{  1,2,\ldots,n\right\}  $, we have%
\begin{align*}
&  \left(  \text{the }i\text{-th entry of the column vector }Ae_{j}\right) \\
&  =\left(  \text{the }\left(  i,1\right)  \text{-th entry of the matrix
}Ae_{j}\right) \\
&  =\sum_{k=1}^{m}\left(  \text{the }\left(  i,k\right)  \text{-th entry of
}A\right)  \cdot\underbrace{\left(  \text{the }\left(  k,1\right)  \text{-th
entry of }e_{j}\right)  }_{\substack{=%
\begin{cases}
1, & \text{if }k=j;\\
0, & \text{if }k\neq j
\end{cases}
\\\text{(by the definition of }e_{j}\text{)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of multiplication of
matrices}\right) \\
&  =\sum_{k=1}^{m}\left(  \text{the }\left(  i,k\right)  \text{-th entry of
}A\right)  \cdot%
\begin{cases}
1, & \text{if }k=j;\\
0, & \text{if }k\neq j
\end{cases}
\\
&  =\left(  \text{the }\left(  i,j\right)  \text{-th entry of }A\right)
=\left(  \text{the }i\text{-th entry of the }j\text{-th column of }A\right)  .
\end{align*}
Hence, $Ae_{j}=\left(  \text{the }j\text{-th column of }A\right)  $. This
proves Lemma \ref{lem.module.Aej} \textbf{(a)}.

\textbf{(b)} Let $j\in\left\{  1,2,\ldots,m\right\}  $. The definition of
$L_{A}$ yields%
\[
L_{A}\left(  e_{j}\right)  =Ae_{j}=\left(  \text{the }j\text{-th column of
}A\right)
\]
(by Lemma \ref{lem.module.Aej} \textbf{(a)}). This proves Lemma
\ref{lem.module.Aej} \textbf{(b)}.
\end{proof}

\begin{proposition}
\label{prop.module.f-pres-lc}Let $M$ and $N$ be two $\mathbb{K}$-modules. Let
$f:M\rightarrow N$ be a $\mathbb{K}$-linear map.

\textbf{(a)} We have $f\left(  \lambda a+\mu b\right)  =\lambda f\left(
a\right)  +\mu f\left(  b\right)  $ for all $\lambda,\mu\in\mathbb{K}$ and
$a,b\in M$.

\textbf{(b)} Let $\lambda_{1},\lambda_{2},\ldots,\lambda_{k}\in\mathbb{K}$ and
$a_{1},a_{2},\ldots,a_{k}\in M$. Then,%
\[
f\left(  \sum_{i=1}^{k}\lambda_{i}a_{i}\right)  =\sum_{i=1}^{k}\lambda
_{i}f\left(  a_{i}\right)  .
\]
(In words: $f$ \textquotedblleft preserves linear
combinations\textquotedblright.)
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.module.f-pres-lc}.]\textbf{(a)} Let
$\lambda,\mu\in\mathbb{K}$ and $a,b\in M$. Then,%
\begin{align*}
f\left(  \lambda a+\mu b\right)   &  =\underbrace{f\left(  \lambda a\right)
}_{\substack{=\lambda f\left(  a\right)  \\\text{(by axiom \textbf{(c)})}%
}}+\underbrace{f\left(  \mu b\right)  }_{\substack{=\mu f\left(  b\right)
\\\text{(by axiom \textbf{(c)})}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{by axiom
\textbf{(a)}}\right) \\
&  =\lambda f\left(  a\right)  +\mu f\left(  b\right)  .
\end{align*}
This proves part \textbf{(a)}.

\textbf{(b)} This is proven by induction on $k$. The induction base follows
from axiom \textbf{(b)}; the induction step uses Proposition
\ref{prop.module.f-pres-lc} \textbf{(a)} (or axioms \textbf{(a)} and
\textbf{(c)}, if you wish). Details are left to the reader.
\end{proof}

Proposition \ref{prop.module.f-pres-lc} \textbf{(a)} has a converse:

\begin{proposition}
\label{prop.module.moho-alt}Let $M$ and $N$ be two $\mathbb{K}$-modules. Let
$f:M\rightarrow N$ be a map. Assume that
\begin{equation}
f\left(  \lambda a+\mu b\right)  =\lambda f\left(  a\right)  +\mu f\left(
b\right)  \ \ \ \ \ \ \ \ \ \ \text{for all }\lambda,\mu\in\mathbb{K}\text{
and }a,b\in M. \label{eq.prop.module.moho-alt.ass}%
\end{equation}
Then, $f$ is $\mathbb{K}$-linear.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.module.moho-alt}.]We must prove that the three
axioms \textbf{(a)}, \textbf{(b)} and \textbf{(c)} of Definition
\ref{def.module.moho} are satisfied.

\textit{Proof of axiom \textbf{(a)}:} Let $a,b\in M$. Then,
(\ref{eq.prop.module.moho-alt.ass}) (applied to $\lambda=1$ and $\mu=1$)
yields $f\left(  1a+1b\right)  =1f\left(  a\right)  +1f\left(  b\right)  $.
This quickly simplifies to $f\left(  a+b\right)  =f\left(  a\right)  +f\left(
b\right)  $. Thus, axiom \textbf{(a)} has been verified.

\textit{Proof of axiom \textbf{(b)}:} Applying
(\ref{eq.prop.module.moho-alt.ass}) to $\lambda=0$, $\mu=0$, $a=0_{M}$ and
$b=0_{M}$, we obtain $f\left(  0\cdot0_{M}+0\cdot0_{M}\right)  =0f\left(
0_{M}\right)  +0f\left(  0_{M}\right)  =0_{N}$. In view of $0\cdot0_{M}%
+0\cdot0_{M}=0_{M}$, we can rewrite this as $f\left(  0_{M}\right)  =0_{N}$.
Thus, axiom \textbf{(b)} has been verified.

\textit{Proof of axiom \textbf{(c)}:} Let $\lambda\in\mathbb{K}$ and $a\in M$.
Applying (\ref{eq.prop.module.moho-alt.ass}) to $\mu=0$ and $b=0_{M}$, we
obtain $f\left(  \lambda a+0\cdot0_{M}\right)  =\lambda f\left(  a\right)
+0f\left(  0_{M}\right)  =\lambda f\left(  a\right)  $. In view of $\lambda
a+\underbrace{0\cdot0_{M}}_{=0_{M}}=\lambda a+0_{M}=\lambda a$, this rewrites
as $f\left(  \lambda a\right)  =\lambda f\left(  a\right)  $. Thus, axiom
\textbf{(c)} has been verified.
\end{proof}

Some authors use the axiom (\ref{eq.prop.module.moho-alt.ass}) as their
definition of what it means for a map $f:M\rightarrow N$ between two
$\mathbb{K}$-modules $M$ and $N$ to be $\mathbb{K}$-linear. This definition is
equivalent to ours (due to Proposition \ref{prop.module.moho-alt} and
Proposition \ref{prop.module.f-pres-lc} \textbf{(a)}).

\begin{lemma}
\label{lem.module.f=g.ej-suff}Let $m\in\mathbb{N}$, and let $N$ be a
$\mathbb{K}$-module. For each $j\in\left\{  1,2,\ldots,m\right\}  $, we let
define a column vector $e_{j}$ as in Definition \ref{def.module.ej}.

Let $f,g:\mathbb{K}^{m\times1}\rightarrow N$ be two $\mathbb{K}$-linear maps.
Assume that $f\left(  e_{j}\right)  =g\left(  e_{j}\right)  $ for all
$j\in\left\{  1,2,\ldots,m\right\}  $. Then, $f=g$.
\end{lemma}

\begin{proof}
Let $v\in\mathbb{K}^{m\times1}$. Write $v$ as $\left(  v_{1},v_{2}%
,\ldots,v_{m}\right)  ^{T}$, where $v_{1},v_{2},\ldots,v_{m}\in\mathbb{K}$.
Then,%
\begin{align*}
v  &  =\left(  v_{1},v_{2},\ldots,v_{m}\right)  ^{T}\\
&  =\left(
\begin{array}
[c]{c}%
v_{1}\\
v_{2}\\
v_{3}\\
\vdots\\
v_{m}%
\end{array}
\right)  =\underbrace{\left(
\begin{array}
[c]{c}%
v_{1}\\
0\\
0\\
\vdots\\
0
\end{array}
\right)  }_{=v_{1}e_{1}}+\underbrace{\left(
\begin{array}
[c]{c}%
0\\
v_{2}\\
0\\
\vdots\\
0
\end{array}
\right)  }_{=v_{2}e_{2}}+\underbrace{\left(
\begin{array}
[c]{c}%
0\\
0\\
v_{3}\\
\vdots\\
0
\end{array}
\right)  }_{=v_{3}e_{3}}\cdots+\underbrace{\left(
\begin{array}
[c]{c}%
0\\
0\\
0\\
\vdots\\
v_{m}%
\end{array}
\right)  }_{=v_{m}e_{m}}\\
&  =v_{1}e_{1}+v_{2}e_{2}+v_{3}e_{3}+\cdots+v_{m}e_{m}=\sum_{i=1}^{m}%
v_{i}e_{i}.
\end{align*}
Hence,%
\begin{align*}
f\left(  v\right)   &  =f\left(  \sum_{i=1}^{m}v_{i}e_{i}\right)  =\sum
_{i=1}^{m}v_{i}f\left(  e_{i}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
Proposition \ref{prop.module.f-pres-lc} \textbf{(b)}}\right) \\
&  =\sum_{j=1}^{m}v_{j}f\left(  e_{j}\right)
\end{align*}
and similarly $g\left(  v\right)  =\sum_{j=1}^{m}v_{j}g\left(  e_{j}\right)
$. Now, the right hand sides of these two equalities are equal, since we
assumed that $f\left(  e_{j}\right)  =g\left(  e_{j}\right)  $ for all
$j\in\left\{  1,2,\ldots,m\right\}  $. Hence, the left hand sides are equal,
too. So $f\left(  v\right)  =g\left(  v\right)  $. Since we have proven this
for every $v\in\mathbb{K}^{m\times1}$, we thus conclude that $f=g$. This
proves the lemma.
\end{proof}

We are now ready to prove Proposition \ref{prop.module.f=LA}:

\begin{proof}
[Proof of Proposition \ref{prop.module.f=LA}.]Let $f$ be a $\mathbb{K}$-module
homomorphism from $\mathbb{K}^{m\times1}$ to $\mathbb{K}^{n\times1}$. We must
prove that $f=L_{A}$ for a unique $A\in\mathbb{K}^{n\times m}$.

For each $j\in\left\{  1,2,\ldots,m\right\}  $, we let define a column vector
$e_{j}$ as in Definition \ref{def.module.ej}.

Now, let $F$ be the $n\times m$-matrix whose columns are the $m$ column
vectors \newline$f\left(  e_{1}\right)  ,f\left(  e_{2}\right)  ,\ldots
,f\left(  e_{m}\right)  $. We claim that $f=L_{F}$.

Indeed, for each $j\in\left\{  1,2,\ldots,m\right\}  $, we have%
\begin{align*}
f\left(  e_{j}\right)   &  =\left(  \text{the }j\text{-th column of }F\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }F\right) \\
&  =L_{F}\left(  e_{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since Lemma \ref{lem.module.Aej} \textbf{(b)} (applied to }A=F\text{)}\\
\text{yields }L_{F}\left(  e_{j}\right)  =\left(  \text{the }j\text{-th column
of }F\right)
\end{array}
\right)  .
\end{align*}
So the maps $f$ and $L_{F}$ are equal at least on the vectors $e_{1}%
,e_{2},\ldots,e_{m}$. But furthermore, they are $\mathbb{K}$-linear. Hence,
Lemma \ref{lem.module.f=g.ej-suff} (applied to $N=\mathbb{K}^{n\times1}$ and
$g=L_{F}$) shows that they are identical. Hence, $f=L_{F}$. This shows that
$f=L_{A}$ for \textbf{some} $A\in\mathbb{K}^{n\times m}$.

How to prove that this $A$ is unique? The idea is that $A$ can be
reconstructed from $L_{A}$, because $\left(  \text{the }j\text{-th column of
}A\right)  =L_{A}\left(  e_{j}\right)  $ for each $j\in\left\{  1,2,\ldots
,m\right\}  $ (by Lemma \ref{lem.module.Aej} \textbf{(b)}).
\end{proof}

\begin{center}
\textbf{2019-04-17 lecture}
\end{center}

\begin{definition}
\label{def.module.Hom}Let $M$ and $N$ be two $\mathbb{K}$-modules.

\textbf{(a)} Let $\operatorname*{Hom}\left(  M,N\right)  $ be the set of all
$\mathbb{K}$-module homomorphisms (= linear maps) from $M$ to $N$. We shall
now turn this set into a $\mathbb{K}$-module.

\textbf{(b)} We define an addition $+$ on $\operatorname*{Hom}\left(
M,N\right)  $ as follows: If $f,g\in\operatorname*{Hom}\left(  M,N\right)  $,
then $f+g\in\operatorname*{Hom}\left(  M,N\right)  $ is defined by%
\[
\left(  f+g\right)  \left(  v\right)  =f\left(  v\right)  +g\left(  v\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }v\in M.
\]
(That is, the addition is pointwise. This is well-defined by Proposition
\ref{prop.module.Hom.wd} \textbf{(a)} below.)

\textbf{(c)} We define a scaling $\cdot$ on $\operatorname*{Hom}\left(
M,N\right)  $ as follows: If $\lambda\in\mathbb{K}$ and $f\in
\operatorname*{Hom}\left(  M,N\right)  $, then $\lambda f\in
\operatorname*{Hom}\left(  M,N\right)  $ is defined by%
\[
\left(  \lambda f\right)  \left(  v\right)  =\lambda\cdot f\left(  v\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }v\in M.
\]
(That is, the scaling is pointwise. This is well-defined by Proposition
\ref{prop.module.Hom.wd} \textbf{(b)} below.)

\textbf{(d)} We define a map $0_{M\rightarrow N}:M\rightarrow N$ by setting
\[
0_{M\rightarrow N}\left(  v\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for all }v\in
M.
\]


\textbf{(e)} We equip $\operatorname*{Hom}\left(  M,N\right)  $ with the
addition $+$, the scaling $\cdot$ and the zero vector $0_{M\rightarrow N}$ we
have just defined. This yields a $\mathbb{K}$-module (by Proposition
\ref{prop.module.Hom.wd} \textbf{(d)} below).
\end{definition}

\begin{proposition}
\label{prop.module.Hom.wd}\textbf{(a)} The addition $+$ defined in Definition
\ref{def.module.Hom} \textbf{(b)} is well-defined (i.e., we have
$f+g\in\operatorname*{Hom}\left(  M,N\right)  $ for all $f,g\in
\operatorname*{Hom}\left(  M,N\right)  $).

\textbf{(b)} The scaling $\cdot$ defined in Definition \ref{def.module.Hom}
\textbf{(c)} is well-defined (i.e., we have $\lambda f\in\operatorname*{Hom}%
\left(  M,N\right)  $ for all $\lambda\in\mathbb{K}$ and $f\in
\operatorname*{Hom}\left(  M,N\right)  $).

\textbf{(c)} The map $0_{M\rightarrow N}$ defined in Definition
\ref{def.module.Hom} \textbf{(d)} belongs to $\operatorname*{Hom}\left(
M,N\right)  $.

\textbf{(d)} The set $\operatorname*{Hom}\left(  M,N\right)  $, equipped with
the addition $+$, the scaling $\cdot$ and the zero vector $0_{M\rightarrow N}%
$, is a $\mathbb{K}$-module.
\end{proposition}

\begin{proof}
Straightforward and LTTR.
\end{proof}

\begin{proposition}
\label{prop.module.Hom.compose}Let $M$, $N$ and $P$ be three $\mathbb{K}%
$-modules. Let $f:M\rightarrow N$ and $g:N\rightarrow P$ be two $\mathbb{K}%
$-module homomorphisms. Then, the composition $g\circ f:M\rightarrow P$ is
also a $\mathbb{K}$-module homomorphism.
\end{proposition}

\begin{proof}
Straightforward and LTTR.
\end{proof}

Note the analogy between Proposition \ref{prop.module.Hom.compose} and
Proposition \ref{prop.riho.compose}.

We shall follow PEMDAS-style conventions when writing expressions involving
addition and composition of $\mathbb{K}$-linear maps (where we treat
composition as a multiplication-like operation). For example, the expression
\textquotedblleft$f\circ h+g\circ h$\textquotedblright\ (where $f,g,h$ are
three $\mathbb{K}$-linear maps) is to be understood as $\left(  f\circ
h\right)  +\left(  g\circ h\right)  $.

The following rules hold for addition, multiplication and scaling of module
homomorphisms (similarly to Theorem \ref{thm.matrix.rules}):

\begin{theorem}
\label{thm.module.Hom.rules}Let $N,M,P,Q$ be $\mathbb{K}$-modules.

\textbf{(a)} We have $f+g=g+f$ for any $f,g\in\operatorname*{Hom}\left(
M,N\right)  $.

\textbf{(b)} We have $f+\left(  g+h\right)  =\left(  f+g\right)  +h$ for any
$f,g,h\in\operatorname*{Hom}\left(  M,N\right)  $.

\textbf{(c)} We have $f+0_{M\rightarrow N}=0_{M\rightarrow N}+f=f$ for any
$f\in\operatorname*{Hom}\left(  M,N\right)  $.

\textbf{(d)} We have $f\circ\operatorname*{id}\nolimits_{M}=\operatorname*{id}%
\nolimits_{N}\circ f=f$ for any $f\in\operatorname*{Hom}\left(  M,N\right)  $.

\textbf{(e)} In general, we \textbf{do not} have $f\circ g=g\circ f$. In fact,
it can happen that one of $f\circ g$ and $g\circ f$ is defined and the other
is not; but even if both are defined, they can be distinct.

\textbf{(f)} We have $f\circ\left(  g\circ h\right)  =\left(  f\circ g\right)
\circ h$ for any $f\in\operatorname*{Hom}\left(  P,Q\right)  $, $g\in
\operatorname*{Hom}\left(  N,P\right)  $ and $h\in\operatorname*{Hom}\left(
M,N\right)  $.

\textbf{(g)} We have $f\circ\left(  g+h\right)  =f\circ g+f\circ h$ for any
$f\in\operatorname*{Hom}\left(  N,P\right)  $ and $g,h\in\operatorname*{Hom}%
\left(  M,N\right)  $.

We have $\left(  f+g\right)  \circ h=f\circ h+g\circ h$ for any $f,g\in
\operatorname*{Hom}\left(  N,P\right)  $ and $h\in\operatorname*{Hom}\left(
M,N\right)  $.

\textbf{(h)} We have $f\circ0_{P\rightarrow M}=0_{P\rightarrow N}$ and
$0_{N\rightarrow P}\circ f=0_{M\rightarrow P}$ for any $f\in
\operatorname*{Hom}\left(  M,N\right)  $.

\textbf{(j)} We have $r\left(  f+g\right)  =rf+rg$ for any $r\in\mathbb{K}$
and $f,g\in\operatorname*{Hom}\left(  M,N\right)  $.

\textbf{(k)} We have $\left(  r+s\right)  f=rf+sf$ for any $r,s\in\mathbb{K}$
and $f\in\operatorname*{Hom}\left(  M,N\right)  $.

\textbf{(l)} We have $r\left(  sf\right)  =\left(  rs\right)  f$ for any
$r,s\in\mathbb{K}$ and $f\in\operatorname*{Hom}\left(  M,N\right)  $.

\textbf{(m)} We have $r\left(  f\circ g\right)  =\left(  rf\right)  \circ
g=f\circ\left(  rg\right)  $ for any $r\in\mathbb{K}$ and $f\in
\operatorname*{Hom}\left(  N,P\right)  $ and $g\in\operatorname*{Hom}\left(
M,N\right)  $.

\textbf{(o)} We have $1f=f$ for any $f\in\operatorname*{Hom}\left(
M,N\right)  $.
\end{theorem}

(The above list is skipping a few letters since we have not defined
subtraction yet; nevertheless, subtraction exists and satisfies the
appropriate rules. See below for the details.)

\begin{proof}
[Proof of Theorem \ref{thm.module.Hom.rules}.]Most of these claims are trivial
and hold not just for $\mathbb{K}$-linear maps, but for arbitrary maps. Only
the first part of \textbf{(g)}, the first part of \textbf{(h)}, and the second
equality sign in \textbf{(m)} do not hold for arbitrary maps. So let us prove
the first part of \textbf{(g)} (and leave the rest to the reader):

Let $f\in\operatorname*{Hom}\left(  N,P\right)  $ and $g,h\in
\operatorname*{Hom}\left(  M,N\right)  $. We must prove that%
\[
f\circ\left(  g+h\right)  =f\circ g+f\circ h.
\]


So let $v\in M$. The map $f:N\rightarrow P$ is $\mathbb{K}$-linear (because
$f\in\operatorname*{Hom}\left(  N,P\right)  $). The definition of $g+h$ yields
$\left(  g+h\right)  \left(  v\right)  =g\left(  v\right)  +h\left(  v\right)
$. Now, comparing%
\begin{align*}
\left(  f\circ\left(  g+h\right)  \right)  \left(  v\right)   &  =f\left(
\underbrace{\left(  g+h\right)  \left(  v\right)  }_{=g\left(  v\right)
+h\left(  v\right)  }\right)  =f\left(  g\left(  v\right)  +h\left(  v\right)
\right) \\
&  =f\left(  g\left(  v\right)  \right)  +f\left(  h\left(  v\right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }f\text{ is }\mathbb{K}\text{-linear}%
\right)
\end{align*}
with%
\[
\left(  f\circ g+f\circ h\right)  \left(  v\right)  =\underbrace{\left(
f\circ g\right)  \left(  v\right)  }_{=f\left(  g\left(  v\right)  \right)
}+\underbrace{\left(  f\circ h\right)  \left(  v\right)  }_{=f\left(  h\left(
v\right)  \right)  }=f\left(  g\left(  v\right)  \right)  +f\left(  h\left(
v\right)  \right)  ,
\]
we obtain $\left(  f\circ\left(  g+h\right)  \right)  \left(  v\right)
=\left(  f\circ g+f\circ h\right)  \left(  v\right)  $. Since we have proven
this for \textbf{all} $v\in M$, we thus conclude that $f\circ\left(
g+h\right)  =f\circ g+f\circ h$. This finishes the proof of the first half of
\textbf{(g)}.

The rest is equally straightforward.
\end{proof}

So far, we have not defined a subtraction operation $-$ on
$\operatorname*{Hom}\left(  M,N\right)  $ (where $M$ and $N$ are two
$\mathbb{K}$-modules). But this does not mean that such an operation does not
exist; we simply don't want to waste our time defining it \textquotedblleft
manually\textquotedblright\ when we can trivially obtain it from general
principles. Namely: We know that $\operatorname*{Hom}\left(  M,N\right)  $ is
a $\mathbb{K}$-module, but Definition \ref{def.module.inv-add-a} shows that
every $\mathbb{K}$-module automatically has a subtraction operation. Thus, we
get a subtraction operation on $\operatorname*{Hom}\left(  M,N\right)  $ for
free. This subtraction is precisely the pointwise subtraction: i.e., it is
given by%
\begin{align}
\left(  f-g\right)  \left(  v\right)   &  =f\left(  v\right)  -g\left(
v\right) \label{eq.module.Hom.-.ptwise}\\
&  \ \ \ \ \ \ \ \ \ \ \text{for all }f,g\in\operatorname*{Hom}\left(
M,N\right)  \text{ and }v\in M\nonumber
\end{align}
\footnote{\textit{Proof of (\ref{eq.module.Hom.-.ptwise}):} Let $f,g\in
\operatorname*{Hom}\left(  M,N\right)  $ and $v\in M$. Then, $f-g$ has the
property that $f=\left(  f-g\right)  +g$ (by Proposition
\ref{prop.module.inv-add.rules} \textbf{(a)}). Applying both sides of this
equality to $v$, we obtain%
\[
f\left(  v\right)  =\left(  \left(  f-g\right)  +g\right)  \left(  v\right)
=\left(  f-g\right)  \left(  v\right)  +g\left(  v\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\left(  f-g\right)
+g\right)  ;
\]
but this yields $\left(  f-g\right)  \left(  v\right)  =f\left(  v\right)
-g\left(  v\right)  $. This proves (\ref{eq.module.Hom.-.ptwise}).}.

Proposition \ref{prop.module.inv-add.rules} shows that the subtraction
operation on $\operatorname*{Hom}\left(  M,N\right)  $ (for arbitrary
$\mathbb{K}$-modules $M$ and $N$) has almost all the properties that one would
expect. The only rule that we do not automatically obtain from these general
principles is%
\[
-\left(  f\circ g\right)  =\left(  -f\right)  \circ g=f\circ\left(  -g\right)
\ \ \ \ \ \ \ \ \ \ \text{for all }f\in\operatorname*{Hom}\left(  N,P\right)
\text{ and }g\in\operatorname*{Hom}\left(  M,P\right)
\]
(where $M$, $N$ and $P$ are three $\mathbb{K}$-modules). But this rule is
easily verified by direct comparison (using (\ref{eq.module.Hom.-.ptwise})).

\begin{corollary}
\label{cor.module.End-ring}Let $M$ be a $\mathbb{K}$-module. The set
$\operatorname*{Hom}\left(  M,M\right)  $ of all $\mathbb{K}$-linear maps from
$M$ to $M$ (endowed with the addition $+$, the multiplication $\circ$, the
zero $0_{M\rightarrow M}$ and the unity $\operatorname*{id}\nolimits_{M}$) is
a ring. This ring is called the \textit{endomorphism ring} of $M$, and is
denoted by $\operatorname*{End}M$; its elements (i.e., the $\mathbb{K}$-linear
maps $M\rightarrow M$) are called the \textit{endomorphisms} of $M$.
\end{corollary}

So the multiplication of the ring $\operatorname*{End}M$ is composition of
maps. This ring $\operatorname*{End}M$ is, in general, not commutative.

Note that $\operatorname*{End}M=\operatorname*{Hom}\left(  M,M\right)  $ as
sets, and the additions of $\operatorname*{End}M$ and of $\operatorname*{Hom}%
\left(  M,M\right)  $ are the same. But $\operatorname*{End}M$ is a ring (thus
has no scaling), whereas $\operatorname*{Hom}\left(  M,M\right)  $ is a
$\mathbb{K}$-module (thus has no multiplication).

There is a notion which combines both the structure of a ring and the
structure of a $\mathbb{K}$-module (so it has both multiplication and
scaling); this is the notion of a $\mathbb{K}$\textit{-algebra}. Roughly
speaking, it is defined as follows:

\begin{definition}
\label{def.K-alg.K-alg.short-def}A $\mathbb{K}$\textit{-algebra} is a set $M$
endowed with two binary operations $+$ and $\cdot$ as well as a scaling map
$\cdot:\mathbb{K}\times M\rightarrow M$ (not to be confused with the
multiplication map, which is also denoted by $\cdot$) and two elements $0,1\in
M$ that satisfy all the ring axioms (with $\mathbb{K}$ replaced by $M$) as
well as all the module axioms and also the following axiom:

\begin{itemize}
\item \textbf{Scale-invariance of multiplication:} We have $\lambda\left(
ab\right)  =\left(  \lambda a\right)  \cdot b=a\cdot\left(  \lambda b\right)
$ for all $\lambda\in\mathbb{K}$ and $a,b\in M$.
\end{itemize}
\end{definition}

It seems somewhat confusing that both the multiplication map $M\times
M\rightarrow M$ and the scaling map $\mathbb{K}\times M\rightarrow M$ are
denoted by the same symbol $\cdot$; but in practice, this does not cause any
trouble, since it is (almost) always clear from the context which one is being
applied (just check if the first argument belongs to $M$ or to $\mathbb{K}$).

So, roughly speaking, a $\mathbb{K}$\textit{-algebra} is a $\mathbb{K}$-module
that is also a ring, with the same addition and $0$ and satisfying the
\textquotedblleft Scale-invariance of multiplication\textquotedblright\ axiom.
In other words, you get the definition of a $\mathbb{K}$-algebra by throwing
the definitions of a ring and of a $\mathbb{K}$-module together, requiring the
two additions $+$ to be the same map, requiring the zero of the ring to
coincide with the zero vector of the $\mathbb{K}$-module, and requiring the
multiplication to be \textquotedblleft nice to the scaling\textquotedblright%
\ (in the sense that the \textquotedblleft Scale-invariance of
multiplication\textquotedblright\ axiom holds).

Examples of $\mathbb{K}$-algebras include the following:

\begin{itemize}
\item The commutative ring $\mathbb{K}$ itself is a $\mathbb{K}$-algebra (with
both multiplication and scaling being the usual multiplication $\cdot$ of
$\mathbb{K}$).

\item If $M$ is any $\mathbb{K}$-module, then the endomorphism ring
$\operatorname*{End}M$ becomes a $\mathbb{K}$-algebra. (Its multiplication is
composition of maps, whereas its scaling is the scaling on
$\operatorname*{Hom}\left(  M,M\right)  $.)

\item The matrix ring $\mathbb{K}^{n\times n}$ is a $\mathbb{K}$-algebra for
any $n\in\mathbb{N}$.

\item The ring $\mathbb{C}$ is an $\mathbb{R}$-algebra.

\item The ring $\mathbb{R}$ is a $\mathbb{Q}$-algebra.

\item The polynomial ring $\mathbb{K}\left[  x\right]  $ (see below for
details) is a $\mathbb{K}$-algebra.
\end{itemize}

\subsection{\label{sect.la.modiso}Module isomorphisms}

In analogy to Definition \ref{def.riiso.riiso}, we define:

\begin{definition}
\label{def.modiso.modiso}Let $M$ and $N$ be two $\mathbb{K}$-modules. Let
$f:M\rightarrow N$ be a map. Then, $f$ is called a $\mathbb{K}$\textit{-module
isomorphism} if and only if $f$ is invertible (i.e., bijective) and both $f$
and $f^{-1}$ are $\mathbb{K}$-module homomorphisms.
\end{definition}

\begin{example}
Let $M$ be a $\mathbb{K}$-module. The identity map $\operatorname*{id}%
:M\rightarrow M$ is a $\mathbb{K}$-module isomorphism.
\end{example}

More generally:

\begin{example}
\label{exa.modho.incl}Let $M$ be a $\mathbb{K}$-submodule of a $\mathbb{K}%
$-module $N$. Let $\iota:M\rightarrow N$ be the map that sends each $a\in M$
to $a$ itself. (This map is called the \textit{inclusion map} from $M$ to $N$.)

\textbf{(a)} Then, the map $\iota$ is a $\mathbb{K}$-module homomorphism.

\textbf{(b)} It is an isomorphism if and only if $M=N$.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.modho.incl}.]LTTR.
\end{proof}

Proposition \ref{prop.riiso.invertible} has an analogue for $\mathbb{K}%
$-module isomorphisms:

\begin{proposition}
\label{prop.modiso.invertible}Let $M$ and $N$ be two $\mathbb{K}$-modules. Let
$f:M\rightarrow N$ be an invertible $\mathbb{K}$-module homomorphism. Then,
$f$ is a $\mathbb{K}$-module isomorphism.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.modiso.invertible}.]Similar to the proof of
Proposition \ref{prop.riiso.invertible}.
\end{proof}

The Chinese Remainder Theorem already brought us an example of a ring
isomorphism (Example \ref{exa.riiso.CRT}); we can also turn it into an example
of a module isomorphism:

\begin{example}
\label{exa.modiso.CRT}Let $m$ and $n$ be two coprime positive integers. Then,
$\left(  \mathbb{Z}/m\right)  \times\left(  \mathbb{Z}/n\right)  $ is a
$\mathbb{Z}$-module (according to Definition \ref{def.module.dirprod2}).
Theorem \ref{thm.eqrel.CRT2} says that the map%
\begin{align*}
S_{m,n}:\mathbb{Z}/\left(  mn\right)   &  \rightarrow\left(  \mathbb{Z}%
/m\right)  \times\left(  \mathbb{Z}/n\right)  ,\\
\alpha &  \mapsto\left(  \pi_{mn,m}\left(  \alpha\right)  ,\pi_{mn,n}\left(
\alpha\right)  \right)
\end{align*}
is well-defined and is a bijection. This map $S_{m,n}$ is furthermore a
$\mathbb{Z}$-module isomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.modiso.CRT}.]Similar to the proof of Example
\ref{exa.riiso.CRT}.
\end{proof}

\begin{definition}
\label{def.modiso.isomorphic}Let $M$ and $N$ be two $\mathbb{K}$-modules. We
say that the $\mathbb{K}$-modules $M$ and $N$ are \textit{isomorphic} if there
exists a $\mathbb{K}$-module isomorphism $f:M\rightarrow N$.

We write \textquotedblleft$M\cong N$ (as $\mathbb{K}$%
-modules)\textquotedblright\ to say that the $\mathbb{K}$-modules $M$ and $N$
are isomorphic.
\end{definition}

Keep in mind that one and the same symbol can stand both for a ring and for a
$\mathbb{K}$-module. Thus, when saying something like \textquotedblleft$M\cong
N$\textquotedblright, you should clarify whether you mean \textquotedblleft%
$M\cong N$ (as rings)\textquotedblright\ or \textquotedblleft$M\cong N$ (as
$\mathbb{K}$-modules)\textquotedblright. For example, $\mathbb{C}$ and
$\mathbb{R}\times\mathbb{R}$ are both rings and $\mathbb{R}$%
-modules\footnote{Indeed:
\par
\begin{itemize}
\item The set $\mathbb{C}$ becomes an $\mathbb{R}$-module by defining scaling
as multiplication (and addition as addition, and the zero vector as $0$),
whereas
\par
\item the set $\mathbb{R}\times\mathbb{R}$ becomes an $\mathbb{R}$-module
according to Definition \ref{def.module.dirprod2} (so its scaling is defined
entrywise: that is, $\lambda\left(  u,v\right)  =\left(  \lambda u,\lambda
v\right)  $ for all $\lambda\in\mathbb{R}$ and $\left(  u,v\right)
\in\mathbb{R}\times\mathbb{R}$).
\end{itemize}
}. We do have $\mathbb{C}\cong\mathbb{R}\times\mathbb{R}$ as $\mathbb{R}%
$-modules, but we don't have $\mathbb{C}\cong\mathbb{R}\times\mathbb{R}$ as
rings (since $\mathbb{C}$ is a field, but $\mathbb{R}\times\mathbb{R}$ is not
a field). So an unqualified statement like \textquotedblleft$\mathbb{C}%
\cong\mathbb{R}\times\mathbb{R}$\textquotedblright\ would be dangerous.

\begin{example}
\label{exa.modiso.mat.transp}Let $n,m\in\mathbb{N}$. Then, the map%
\begin{align*}
\mathbb{K}^{n\times m}  &  \rightarrow\mathbb{K}^{m\times n},\\
A  &  \mapsto A^{T}%
\end{align*}
is a $\mathbb{K}$-module isomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.modiso.mat.transp}.]By Proposition
\ref{prop.modiso.invertible}, it suffices to prove that this map is
$\mathbb{K}$-linear and invertible. The $\mathbb{K}$-linearity follows from
the formulas%
\begin{align*}
\left(  A+B\right)  ^{T}  &  =A^{T}+B^{T};\\
\left(  \lambda A\right)  ^{T}  &  =\lambda A^{T};\\
\left(  0_{n\times m}\right)  ^{T}  &  =0_{m\times n}%
\end{align*}
which hold for arbitrary $A,B\in\mathbb{K}^{n\times m}$ and $\lambda
\in\mathbb{K}$. The invertibility follows by constructing its inverse, which
is the map%
\begin{align*}
\mathbb{K}^{m\times n}  &  \rightarrow\mathbb{K}^{n\times m},\\
A  &  \mapsto A^{T}.
\end{align*}

\end{proof}

\begin{example}
\label{exa.modiso.vec.col=tup}Let $n\in\mathbb{N}$. Then, the map%
\begin{align*}
\mathbb{K}^{n\times1}  &  \rightarrow\mathbb{K}^{n},\\
\left(
\begin{array}
[c]{c}%
a_{1}\\
a_{2}\\
\vdots\\
a_{n}%
\end{array}
\right)   &  \mapsto\left(  a_{1},a_{2},\ldots,a_{n}\right)
\end{align*}
is a $\mathbb{K}$-module isomorphism.
\end{example}

\begin{proof}
Easy.
\end{proof}

The previous two examples show that%
\[
\mathbb{K}^{1\times n}\cong\mathbb{K}^{n\times1}\cong\mathbb{K}^{n}%
\ \ \ \ \ \ \ \ \ \ \text{as }\mathbb{K}\text{-modules.}%
\]


\begin{example}
\label{exa.modiso.mat.vec}Let $n,m\in\mathbb{N}$. Then, we define a map%
\begin{align*}
\operatorname*{vec}:\mathbb{K}^{n\times m}  &  \rightarrow\mathbb{K}^{nm},\\
\left(  a_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq m}  &  \mapsto\left(
a_{1,1},a_{1,2},\ldots,a_{1,m},a_{2,1},a_{2,2},\ldots,a_{2,m},\ldots
,a_{n,1},a_{n,2},\ldots,a_{n,m}\right)  .
\end{align*}
For example, if $n=2$ and $m=3$, then%
\[
\operatorname*{vec}\left(
\begin{array}
[c]{ccc}%
a & b & c\\
d & e & f
\end{array}
\right)  =\left(  a,b,c,d,e,f\right)  .
\]
This map $\operatorname*{vec}$ is called \textit{row reading} or \textit{row
vectorization}.

This map $\operatorname*{vec}$ is a $\mathbb{K}$-module isomorphism.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.modiso.mat.vec}.]The map $\operatorname*{vec}$ is
$\mathbb{K}$-linear (since addition and scaling are defined entrywise on both
$\mathbb{K}^{n\times m}$ and $\mathbb{K}^{nm}$) and invertible. Thus,
Proposition \ref{prop.modiso.invertible} shows that it is a $\mathbb{K}%
$-module isomorphism.
\end{proof}

\begin{example}
\label{exa.modiso.scal-lam}Let $M$ be any $\mathbb{K}$-module. Let $\lambda
\in\mathbb{K}$. Define the map
\begin{align*}
L_{\lambda}:M  &  \rightarrow M,\\
a  &  \mapsto\lambda a.
\end{align*}
(This is called \textquotedblleft scaling by $\lambda$\textquotedblright.) As
we know from Example \ref{exa.module.moho.id} \textbf{(b)}, this map
$L_{\lambda}$ is $\mathbb{K}$-linear, i.e., a $\mathbb{K}$-module
homomorphism. When is it an isomorphism?

\textbf{(a)} If $\lambda\in\mathbb{K}$ is invertible, then $L_{\lambda}$ is a
$\mathbb{K}$-module isomorphism.

\textbf{(b)} If $M=\mathbb{K}$ and $L_{\lambda}$ is a $\mathbb{K}$-module
isomorphism, then $\lambda$ is invertible.

\textbf{(c)} If $\mathbb{K}=\mathbb{Z}$ and $M=\mathbb{Z}/n$ for some integer
$n$, then $L_{\lambda}$ is a $\mathbb{K}$-module isomorphism whenever
$\lambda\perp n$.
\end{example}

\begin{proof}
[Proof of Example \ref{exa.modiso.scal-lam}.]\textbf{(a)} If $\lambda
\in\mathbb{K}$ is invertible, then the map $L_{\lambda^{-1}}$ is inverse to
$L_{\lambda}$. (Actually, we have rules like $L_{\lambda\mu}=L_{\lambda}\circ
L_{\mu}$ and $L_{\lambda+\mu}=L_{\lambda}+L_{\mu}$; see Remark
\ref{rmk.modhom.KtoEnd} below.)

\textbf{(b)} LTTR.

\textbf{(c)} Let $\mathbb{K}=\mathbb{Z}$ and $M=\mathbb{Z}/n$ for some integer
$n$. Assume that $\lambda\perp n$. Then, $\lambda$ has a modular inverse $\mu$
modulo $n$. It is now easy to check that the map $L_{\mu}$ is inverse to
$L_{\lambda}$; thus, $L_{\lambda}$ is invertible and therefore a $\mathbb{K}%
$-module isomorphism (since we already know that $L_{\lambda}$ is a
$\mathbb{K}$-module homomorphism).
\end{proof}

\begin{remark}
\label{rmk.modhom.KtoEnd}Fix any $\mathbb{K}$-module $M$. Then, the map%
\begin{align*}
\mathbb{K}  &  \rightarrow\operatorname*{End}M,\\
\lambda &  \mapsto L_{\lambda}%
\end{align*}
is a ring homomorphism.
\end{remark}

\begin{proof}
Straightforward.
\end{proof}

We talked for a while about the meaning and use of ring isomorphisms. The same
can be said about $\mathbb{K}$-module isomorphisms. So, in particular, two
isomorphic $\mathbb{K}$-modules can be viewed as being \textquotedblleft the
same $\mathbb{K}$-module up to renaming its elements\textquotedblright, and
any property of one can be transferred to the other. For example, two
isomorphic $\mathbb{K}$-modules must have the same size; their endomorphism
rings must be isomorphic; etc.

\begin{proposition}
\label{prop.modiso.mat-Hom}Let $n,m\in\mathbb{N}$. The map%
\begin{align*}
\mathbb{K}^{n\times m}  &  \rightarrow\operatorname*{Hom}\left(
\mathbb{K}^{m\times1},\mathbb{K}^{n\times1}\right)  ,\\
A  &  \mapsto L_{A}%
\end{align*}
(where $L_{A}$ is defined as in Theorem \ref{thm.module.LA}) is a $\mathbb{K}%
$-module isomorphism.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.modiso.mat-Hom}.]This map is $\mathbb{K}%
$-linear (due to easily proven statements like $L_{A+B}=L_{A}+L_{B}$ and
$L_{\lambda A}=\lambda L_{A}$) and invertible (since Proposition
\ref{prop.module.f=LA} shows that it is bijective).
\end{proof}

So $\mathbb{K}^{n\times m}\cong\operatorname*{Hom}\left(  \mathbb{K}%
^{m\times1},\mathbb{K}^{n\times1}\right)  $ as $\mathbb{K}$-modules whenever
$n,m\in\mathbb{N}$. This means that $\mathbb{K}$\textbf{-linear maps between
}$\mathbb{K}^{m\times1}$\textbf{ and }$\mathbb{K}^{n\times1}$ \textbf{are
\textquotedblleft the same as\textquotedblright\ }$n\times m$%
\textbf{-matrices}. This says that the \textquotedblleft
matrix\textquotedblright\ way of doing linear algebra can be embedded into the
\textquotedblleft$\mathbb{K}$-module\textquotedblright\ way of doing linear algebra.

Furthermore:

\begin{proposition}
\label{prop.module.LAB}Let $n,m,p\in\mathbb{N}$. Let $A\in\mathbb{K}^{n\times
m}$ and $B\in\mathbb{K}^{m\times p}$. Then, $L_{AB}=L_{A}\circ L_{B}$.
\end{proposition}

\begin{proof}
[Proof of Proposition \ref{prop.module.LAB}.]For any $C\in\mathbb{K}%
^{p\times1}$, we have $L_{AB}\left(  C\right)  =\left(  L_{A}\circ
L_{B}\right)  \left(  C\right)  $ (this follows by comparing the equalities
$L_{AB}\left(  C\right)  =\left(  AB\right)  C=ABC$ and $\left(  L_{A}\circ
L_{B}\right)  \left(  C\right)  =L_{A}\left(  L_{B}\left(  C\right)  \right)
=A\left(  BC\right)  =ABC$).
\end{proof}

\begin{corollary}
\label{cor.modiso.mat-End}Let $n\in\mathbb{N}$. The map%
\begin{align*}
\mathbb{K}^{n\times n}  &  \rightarrow\operatorname*{End}\left(
\mathbb{K}^{n\times1}\right)  ,\\
A  &  \mapsto L_{A}%
\end{align*}
(where $L_{A}$ is defined as in Theorem \ref{thm.module.LA} for $m=n$) is a
ring isomorphism.
\end{corollary}

\begin{center}
\textbf{2019-04-19 lecture}
\end{center}

\subsection{Linear independence, spans, bases}

Now, let us generalize Definition \ref{def.laf.lincomb} to arbitrary
$\mathbb{K}$-modules (where $\mathbb{K}$ is still an arbitrary commutative ring):

\begin{definition}
\label{def.module.lincomb}Let $M$ be a $\mathbb{K}$-module. Let $v_{1}%
,v_{2},\ldots,v_{k}$ be some vectors in $M$.

\textbf{(a)} A \textbf{linear combination} of $v_{1},v_{2},\ldots,v_{k}$ means
a vector of the form%
\[
\lambda_{1}v_{1}+\lambda_{2}v_{2}+\cdots+\lambda_{k}v_{k}%
,\ \ \ \ \ \ \ \ \ \ \text{where }\lambda_{1},\lambda_{2},\ldots,\lambda
_{k}\in\mathbb{K}.
\]


\textbf{(b)} The \textbf{span} of $v_{1},v_{2},\ldots,v_{k}$ is defined to be
the subset%
\begin{align*}
& \left\{  \lambda_{1}v_{1}+\lambda_{2}v_{2}+\cdots+\lambda_{k}v_{k}%
\mid\lambda_{1},\lambda_{2},\ldots,\lambda_{k}\in\mathbb{K}\right\}  \\
& =\left\{  \text{linear combinations of }v_{1},v_{2},\ldots,v_{k}\right\}
\end{align*}
of $M$. This span is a $\mathbb{K}$-submodule of $M$.

\textbf{(c)} The vectors $v_{1},v_{2},\ldots,v_{k}$ are said to be
\textbf{linearly independent} if the only $\left(  \lambda_{1},\lambda
_{2},\ldots,\lambda_{k}\right)  \in\mathbb{K}^{k}$ satisfying $\lambda
_{1}v_{1}+\lambda_{2}v_{2}+\cdots+\lambda_{k}v_{k}=0$ is $\left(
0,0,\ldots,0\right)  $.

\textbf{(d)} Let $U$ be a $\mathbb{K}$-submodule of $M$. We say that
$v_{1},v_{2},\ldots,v_{k}$ form a \textbf{basis} of $U$ (or, more formally,
$\left(  v_{1},v_{2},\ldots,v_{k}\right)  $ is a basis of $U$) if and only if
$v_{1},v_{2},\ldots,v_{k}$ are linearly independent and their span is $U$.
\end{definition}

\begin{definition}
Let $M$ be a $\mathbb{K}$-module. Then, we say that $M$ is \textbf{finitely
generated} if there exists some $k\in\mathbb{N}$ and $k$ vectors $v_{1}%
,v_{2},\ldots,v_{k}$ that span $M$.
\end{definition}

Finitely generated $\mathbb{K}$-modules generalize finite-dimensional
$\mathbb{K}$-vector space.

\begin{theorem}
If $\mathbb{K}$ is a field, then every finitely generated $\mathbb{K}$-module
(= $\mathbb{K}$-vector space) has a basis.
\end{theorem}

\begin{proof}
Classical (see Conrad on dimension).
\end{proof}

This theorem fails horribly when $\mathbb{K}$ is not a field. For example, the
$\mathbb{Z}$-module $\mathbb{Z}/2$ has no basis. Indeed, the only $\mathbb{Z}%
$-linearly independent list of vectors in $\mathbb{Z}/2$ is the empty list
$\left(  {}\right)  $, since any vector in $\mathbb{Z}/2$ becomes $0$ when
scaled by the nonzero integer $2$. More generally, if $\mathbb{K}$ is not a
field, then there is a $\mathbb{K}$-module spanned by a single vector that has
no basis.

Submodules of $\mathbb{K}^{1\times n}$ fare only somewhat better than
arbitrary $\mathbb{K}$-modules in terms of having bases. It can be shown that
every $\mathbb{Z}$-submodule of $\mathbb{Z}^{1\times n}$ has a basis. Thus,
Theorem 6.1.5 \textbf{(a)} holds for $\mathbb{K}=\mathbb{Z}$. But it fails for
$\mathbb{K}=\mathbb{Z}\left[  \sqrt{-3}\right]  $ and for $\mathbb{K}%
=\mathbb{Z}/4$.

Parts \textbf{(d)} and \textbf{(e)} of Theorem 6.1.5 fail even for
$\mathbb{K}=\mathbb{Z}$ and $n=1$ (so $\mathbb{K}^{1\times1}\cong\mathbb{K}$):

\begin{itemize}
\item For part \textbf{(d)}: There is a list of $1$ linearly independent
vector in $\mathbb{Z}$ that cannot be extended to a basis. Namely, $\left(
2\right)  $.

\item For part \textbf{(e)}: There is a list of $2$ vectors in $\mathbb{Z}$
whose span is $\mathbb{Z}$ yet which cannot be shrunk to a basis. Namely, take
the list $\left(  2,3\right)  $.
\end{itemize}

What about parts \textbf{(b)} and \textbf{(c)}?

Literally speaking, they fail. If $\mathbb{K}$ is the zero ring, then there is
only one $\mathbb{K}$-module (namely, $\left\{  0\right\}  $), but it has
bases of all sizes (indeed, for each $n\in\mathbb{N}$, the $n$-element list
$\left(  0,0,\ldots,0\right)  $ is a basis).

However, magically, this turns out to be the only counterexample for parts
\textbf{(b)} and \textbf{(c)}! More precisely, if the ring $\mathbb{K}$ has
more than $1$ element, then any two bases of a $\mathbb{K}$-module have the
same size, and given $k$ linearly independent vectors in $U$ and $\ell$
vectors that span $U$, then $k\leq\ell$.

This is much harder to prove than Theorem 6.1.5. The simplest argument I know
uses determinants.

\subsection{$\mathbb{K}$-submodules from linear maps}

\begin{proposition}
Let $M$ and $N$ be two $\mathbb{K}$-modules. Let $f:M\rightarrow N$ be a
$\mathbb{K}$-module homomorphism (i.e., a $\mathbb{K}$-linear map).

\textbf{(a)} The set%
\[
\left\{  v\in M\ \mid\ f\left(  v\right)  =0\right\}
\]
is a $\mathbb{K}$-submodule of $M$. This is called the \textbf{kernel} of $f$,
and is written $\operatorname*{Ker}f$ or $\ker f$.

\textbf{(b)} The set $f\left(  M\right)  =\left\{  f\left(  v\right)  \mid
v\in M\right\}  $ is a $\mathbb{K}$-submodule of $N$. This is called the
\textbf{image} of $f$.

\textbf{(c)} Let $V$ be a $\mathbb{K}$-submodule of $N$. Then, the set%
\[
\left\{  v\in M\ \mid\ f\left(  v\right)  \in V\right\}
\]
is a $\mathbb{K}$-submodule of $M$. This is called the \textbf{preimage of
}$V$ \textbf{under }$f$, and is written $f^{-1}\left(  V\right)  $.

\textbf{(d)} Let $U$ be a $\mathbb{K}$-submodule of $M$. Then, the set
$f\left(  U\right)  =\left\{  f\left(  v\right)  \mid v\in U\right\}  $ is a
$\mathbb{K}$-submodule of $N$. This is called the \textbf{image of }$U$
\textbf{under }$f$.
\end{proposition}

\begin{proof}
See notes (in a few hours).
\end{proof}

\section{Polynomials}

\subsection{Motivation}

Back in our proof of Theorem 2.17.14, we have used a vague notion of
polynomials. Let us now try to formalize it, and while at that, extend it from
\textquotedblleft coefficients in $\mathbb{Q}$\textquotedblright\ to
\textquotedblleft coefficients in any commutative ring $\mathbb{K}%
$\textquotedblright.

The most \textquotedblleft naive\textquotedblright\ notion of polynomial is
that of a polynomial function:

\begin{definition}
Let $\mathbb{K}$ be a commutative ring. A function $f:\mathbb{K}%
\rightarrow\mathbb{K}$ is said to be a \textbf{polynomial function} if there
exist some elements $a_{0},a_{1},\ldots,a_{n}\in\mathbb{K}$ such that every
$u\in\mathbb{K}$ satisfies%
\[
f\left(  u\right)  =a_{0}u^{0}+a_{1}u^{1}+\cdots+a_{n}u^{n}.
\]

\end{definition}

For example, the function%
\[
\mathbb{R}\rightarrow\mathbb{R},\ \ \ \ \ \ \ \ \ \ u\mapsto6u^{3}-\dfrac
{1}{2}u+\sqrt{3}%
\]
is a polynomial function.

This definition has its uses, and is sufficient as long as you stick to
$\mathbb{R}$ or $\mathbb{C}$. But when we want polynomials over other rings,
it shows weaknesses. In what sense?

Here is an example. In Section 5.6, we constructed a field with $4$ elements
by adjoining a $j$ satisfying $j^{2}=j+1$ to $\mathbb{Z}/2$. In other words,
we adjoined a root of \textquotedblleft the polynomial\textquotedblright%
\ $x^{2}-x-1$ to $\mathbb{Z}/2$. How can we adjoin a root of a polynomial to a
ring? If we can do this with polynomials of higher degree than $2$, we might
be able to construct larger finite fields. For example, we may hope to get a
field of size $8$ by adjoining a root of a degree-$3$ polynomial.

So we need a notion of polynomials over $\mathbb{Z}/2$, and we need there to
be infinitely many of them, ideally at least one of each degree. With
polynomial functions, this is doomed. In fact, there are only $4$ functions
from $\mathbb{Z}/2$ to $\mathbb{Z}/2$.

Worse yet, if we treat $x^{2}-x-1$ as a polynomial function $\mathbb{Z}%
/2\rightarrow\mathbb{Z}/2$, then we realize that it is the same function as
\textquotedblleft constant $1$\textquotedblright. So when we adjoined a root
of this polynomial, did we just adjoin a root of $1$ ?

The moral of the story is that when we adjoin a root of a polynomial to a
field, we are certainly not adjoining a root of a polynomial function. So we
need a concept of polynomials that is finer than polynomial functions.

Another reason why we want this is: Polynomial functions $\mathbb{K}%
\rightarrow\mathbb{K}$ can only be applied to elements of $\mathbb{K}$, but we
want our polynomials to be applied to other things as well (such as square
matrices or other polynomials).

For example, the polynomial functions%
\[
\mathbb{Z}/2\rightarrow\mathbb{Z}/2,\ \ \ \ \ \ \ \ \ \ x\mapsto x^{2}%
\]
and%
\[
\mathbb{Z}/2\rightarrow\mathbb{Z}/2,\ \ \ \ \ \ \ \ \ \ x\mapsto x
\]
are identical, but if we applied them to the matrix $A=\left(
\begin{array}
[c]{cc}%
0 & 1\\
0 & 0
\end{array}
\right)  \in\left(  \mathbb{Z}/2\right)  ^{2\times2}$, then we would get
$A^{2}$ and $A$, which are \textbf{not} identical. Thus we cannot apply a
polynomial function to a square matrix.

We gave a hint of a better definition of a polynomial in Section 2.17.3,
defining it as an \textquotedblleft expression\textquotedblright\ involving an
\textquotedblleft indeterminate\textquotedblright\ $x$. Let us try to make
this rigorous.

Idea: A polynomial of degree $\leq1$ over $\mathbb{R}$ always has the form
$a_{0}+a_{1}x$ (with $a_{0},a_{1}\in\mathbb{R}$), so why not just define it as
the \textbf{pair} $\left(  a_{0},a_{1}\right)  $ ? Then, we can define an
addition on polynomials of degree $\leq1$ by%
\[
\left(  a_{0},a_{1}\right)  +\left(  b_{0},b_{1}\right)  =\left(  a_{0}%
+b_{0},a_{1}+b_{1}\right)  ,
\]
imitating the rule%
\[
\left(  a_{0}+a_{1}x\right)  +\left(  b_{0}+b_{1}x\right)  =\left(
a_{0}+b_{0}\right)  +\left(  a_{1}+b_{1}\right)  x.
\]
Furthermore, we can define a multiplication on these polynomials by%
\[
\left(  a_{0},a_{1}\right)  \cdot\left(  b_{0},b_{1}\right)  =\left(
a_{0}b_{0},a_{0}b_{1}+a_{1}b_{0},a_{1}b_{1}\right)  ,
\]
imitating the \textquotedblleft FOIL\textquotedblright\ rule%
\[
\left(  a_{0}+a_{1}x\right)  \cdot\left(  b_{0}+b_{1}x\right)  =a_{0}%
b_{0}+\left(  a_{0}b_{1}+a_{1}b_{0}\right)  x+a_{1}b_{1}x^{2}.
\]
But this multiplication yields triples, not pairs, so it is not a binary operation.

So, if you want to define polynomials in a way that they would form a ring,
you should define them not as pairs or triples, but as infinite sequences
(\textquotedblleft$\infty$-tuples\textquotedblright).

\subsection{The definition of formal power series and polynomials}

An upside of this strategy is that you get a second object for free: the
\textit{formal power series}.

\begin{convention}
For the rest of this chapter, we fix a commutative ring $\mathbb{K}$.
\end{convention}

\begin{definition}
\textbf{(a)} A \textbf{formal power series} (short: \textbf{FPS}) (in $1$
indeterminate over $\mathbb{K}$) is defined to be a sequence $\left(
a_{0},a_{1},a_{2},\ldots\right)  =\left(  a_{i}\right)  _{i\in\mathbb{N}}%
\in\mathbb{K}^{\mathbb{N}}$ of elements of $\mathbb{K}$.

We let $\mathbb{K}\left[  \left[  x\right]  \right]  $ be the set of all FPSs.

\textbf{(b)} A \textbf{polynomial} (in $1$ indeterminate over $\mathbb{K}$) is
defined to be a FPS $\left(  a_{0},a_{1},a_{2},\ldots\right)  $ such that%
\[
\text{all but finitely many }i\in\mathbb{N}\text{ satisfy }a_{i}=0
\]
(that is, only finitely many $i\in\mathbb{N}$ satisfy $a_{i}\neq0$).

We let $\mathbb{K}\left[  x\right]  $ be the set of all polynomials.

\textbf{(c)} If $\mathbf{a}=\left(  a_{0},a_{1},a_{2},\ldots\right)  $ is a
polynomial, then the \textbf{degree} of $\mathbf{a}$ is defined to be the
largest $i\in\mathbb{N}$ such that $a_{i}\neq0$. (If no such $i$ exists, then
we define it to be $-\infty$, which is a symbolic quantity that is understood
to be smaller than every integer and to satisfy $\left(  -\infty\right)
+m=-\infty$ for all $m$.)
\end{definition}

So, for now, our FPSs are just sequences, with no other meaning; we will later
see why we can actually view them as \textquotedblleft
series\textquotedblright\ and what the \textquotedblleft$x$\textquotedblright%
\ means in $\mathbb{K}\left[  \left[  x\right]  \right]  $.

\begin{example}
For this example, let $\mathbb{K}=\mathbb{Z}$.

\textbf{(a)} The sequence $\left(  1,2,3,4,5,\ldots\right)  $ is a FPS, but
not a polynomial. We will later write it as $1+2x+3x^{2}+4x^{3}+5x^{4}+\cdots$.

\textbf{(b)} The sequence $\left(  3,0,2,5,\underbrace{0,0,0,0,\ldots
}_{\text{zeroes}}\right)  $ is a polynomial of degree $3$. We will later write
it as $3+2x^{2}+5x^{3}$.
\end{example}

\begin{definition}
The goal of this definition is to make $\mathbb{K}\left[  \left[  x\right]
\right]  $ into a $\mathbb{K}$-algebra.

\textbf{(a)} We define a binary operation $+$ (called \textbf{addition}) on
$\mathbb{K}\left[  \left[  x\right]  \right]  $ by%
\[
\left(  a_{0},a_{1},a_{2},\ldots\right)  +\left(  b_{0},b_{1},b_{2}%
,\ldots\right)  =\left(  a_{0}+b_{0},a_{1}+b_{1},a_{2}+b_{2},\ldots\right)  .
\]
(This is just entrywise addition.)
\end{definition}


\end{document}